{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T12:50:25.876212Z",
     "start_time": "2022-01-18T12:50:25.870149Z"
    }
   },
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:36.076844Z",
     "start_time": "2022-01-22T07:32:36.067533Z"
    }
   },
   "outputs": [],
   "source": [
    "description = 'train_mobilenet_from_pretrain_v2_tune_valance_arousal_batch_32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:37.550077Z",
     "start_time": "2022-01-22T07:32:36.079358Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#from scipy.misc import imread, imresize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:37.558232Z",
     "start_time": "2022-01-22T07:32:37.551550Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:41.427399Z",
     "start_time": "2022-01-22T07:32:37.560290Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/Manually_Annotated_file_lists/training_face_mesh_crop.csv')\n",
    "train_df.subDirectory_filePath = '../../data/Manually_Annotated_Images_FaceMesh_Cropped/' + train_df.subDirectory_filePath\n",
    "\n",
    "#train_df_2 = pd.read_csv('../../data/Automatically_annotated_file_list/automatically_annotated_face_mesh_crop.csv')\n",
    "#train_df_2.subDirectory_filePath = '../../data/Automatically_Annotated_Images_FaceMesh_Cropped/' + train_df_2.subDirectory_filePath\n",
    "#train_df = train_df.append(train_df_2)\n",
    "#del train_df_2\n",
    "\n",
    "train_df = train_df[train_df['have_facemesh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:41.433430Z",
     "start_time": "2022-01-22T07:32:41.428924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_file_name='01_22_15:32:41.log'\n"
     ]
    }
   ],
   "source": [
    "from eason_utils import DataFrameBatchIterator\n",
    "from eason_utils import lprint, now_time_string, log_file_name, change_log_file_name\n",
    "\n",
    "change_log_file_name(f'''{log_file_name.replace('.log', '')}_{description}.log''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T13:57:18.682279Z",
     "start_time": "2022-01-19T13:57:18.670590Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:43.419731Z",
     "start_time": "2022-01-22T07:32:41.434985Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(allow_growth = True))\n",
    "sess = tf.compat.v1.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:44.007974Z",
     "start_time": "2022-01-22T07:32:43.421276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./models_h5/01_20_22:12:38_mobilenet_from_pretrain_v2_epoch6_batch_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:44.015122Z",
     "start_time": "2022-01-22T07:32:44.009468Z"
    }
   },
   "outputs": [],
   "source": [
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:44.022689Z",
     "start_time": "2022-01-22T07:32:44.016556Z"
    }
   },
   "outputs": [],
   "source": [
    "want_train = ['feat_arousal', 'feat_valence', 'outputs_valence', 'outputs_arousal']\n",
    "for n in model.layers:\n",
    "    if n.name not in want_train:\n",
    "        n.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:44.064134Z",
     "start_time": "2022-01-22T07:32:44.024907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_train\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 225, 225, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 112, 112, 32  864         ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 32  128         ['conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (ReLU)              (None, 112, 112, 32  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1 (DepthwiseConv2D)    (None, 112, 112, 32  288         ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1_bn (BatchNormalizati  (None, 112, 112, 32  128        ['conv_dw_1[0][0]']              \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1_relu (ReLU)          (None, 112, 112, 32  0           ['conv_dw_1_bn[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1 (Conv2D)             (None, 112, 112, 64  2048        ['conv_dw_1_relu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1_bn (BatchNormalizati  (None, 112, 112, 64  256        ['conv_pw_1[0][0]']              \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1_relu (ReLU)          (None, 112, 112, 64  0           ['conv_pw_1_bn[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pad_2 (ZeroPadding2D)     (None, 113, 113, 64  0           ['conv_pw_1_relu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_2 (DepthwiseConv2D)    (None, 56, 56, 64)   576         ['conv_pad_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_2_bn (BatchNormalizati  (None, 56, 56, 64)  256         ['conv_dw_2[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_2_relu (ReLU)          (None, 56, 56, 64)   0           ['conv_dw_2_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_2 (Conv2D)             (None, 56, 56, 128)  8192        ['conv_dw_2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_2_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_pw_2[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_2_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_pw_2_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_3 (DepthwiseConv2D)    (None, 56, 56, 128)  1152        ['conv_pw_2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_3_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_dw_3[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_3_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_dw_3_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_3 (Conv2D)             (None, 56, 56, 128)  16384       ['conv_dw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_3_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_pw_3[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_3_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_pw_3_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pad_4 (ZeroPadding2D)     (None, 57, 57, 128)  0           ['conv_pw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_4 (DepthwiseConv2D)    (None, 28, 28, 128)  1152        ['conv_pad_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_4_bn (BatchNormalizati  (None, 28, 28, 128)  512        ['conv_dw_4[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_4_relu (ReLU)          (None, 28, 28, 128)  0           ['conv_dw_4_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_4 (Conv2D)             (None, 28, 28, 256)  32768       ['conv_dw_4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_4_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_pw_4[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_4_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_pw_4_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_5 (DepthwiseConv2D)    (None, 28, 28, 256)  2304        ['conv_pw_4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_5_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_dw_5[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_5_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_dw_5_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_5 (Conv2D)             (None, 28, 28, 256)  65536       ['conv_dw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_5_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_pw_5[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_5_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_pw_5_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pad_6 (ZeroPadding2D)     (None, 29, 29, 256)  0           ['conv_pw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_6 (DepthwiseConv2D)    (None, 14, 14, 256)  2304        ['conv_pad_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_6_bn (BatchNormalizati  (None, 14, 14, 256)  1024       ['conv_dw_6[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_6_relu (ReLU)          (None, 14, 14, 256)  0           ['conv_dw_6_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_6 (Conv2D)             (None, 14, 14, 512)  131072      ['conv_dw_6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_6_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_6[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_6_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_6_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_7 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_7_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_7[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_7_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_7_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_7 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_7_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_7_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_7[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_7_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_7_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_8 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_7_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_8_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_8[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_8_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_8_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_8 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_8_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_8_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_8[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_8_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_8_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_9 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_8_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_9_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_9[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_9_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_9_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_9 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_9_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_9_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_9[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_9_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_9_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_10 (DepthwiseConv2D)   (None, 14, 14, 512)  4608        ['conv_pw_9_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_10_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_dw_10[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_10_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_dw_10_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_10 (Conv2D)            (None, 14, 14, 512)  262144      ['conv_dw_10_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_10_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_pw_10[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_10_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_pw_10_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_dw_11 (DepthwiseConv2D)   (None, 14, 14, 512)  4608        ['conv_pw_10_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_11_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_dw_11[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_11_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_dw_11_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_11 (Conv2D)            (None, 14, 14, 512)  262144      ['conv_dw_11_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_11_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_pw_11[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_11_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_pw_11_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pad_12 (ZeroPadding2D)    (None, 15, 15, 512)  0           ['conv_pw_11_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_12 (DepthwiseConv2D)   (None, 7, 7, 512)    4608        ['conv_pad_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv_dw_12_bn (BatchNormalizat  (None, 7, 7, 512)   2048        ['conv_dw_12[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_12_relu (ReLU)         (None, 7, 7, 512)    0           ['conv_dw_12_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_12 (Conv2D)            (None, 7, 7, 1024)   524288      ['conv_dw_12_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_12_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_pw_12[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_12_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_pw_12_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_dw_13 (DepthwiseConv2D)   (None, 7, 7, 1024)   9216        ['conv_pw_12_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_13_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_dw_13[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_13_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_dw_13_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_13 (Conv2D)            (None, 7, 7, 1024)   1048576     ['conv_dw_13_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_13_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_pw_13[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_13_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_pw_13_bn[0][0]']          \n",
      "                                                                                                  \n",
      " global_pooling (GlobalAverageP  (None, 1024)        0           ['conv_pw_13_relu[0][0]']        \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " feat_valence (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " feat_arousal (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " feat_emotion (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " outputs_valence (Dense)        (None, 1)            257         ['feat_valence[0][0]']           \n",
      "                                                                                                  \n",
      " outputs_arousal (Dense)        (None, 1)            257         ['feat_arousal[0][0]']           \n",
      "                                                                                                  \n",
      " outputs_emotion (Dense)        (None, 11)           2827        ['feat_emotion[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,019,405\n",
      "Trainable params: 525,314\n",
      "Non-trainable params: 3,494,091\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:44.068668Z",
     "start_time": "2022-01-22T07:32:44.065472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# Instantiate a loss function.\n",
    "MSE_loss = tf.keras.losses.MeanSquaredError()\n",
    "SCC_loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T07:32:44.072719Z",
     "start_time": "2022-01-22T07:32:44.070020Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 4\n",
    "\n",
    "logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-22T07:32:32.946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 22, \"valence_loss\": 1.7539684772491455, \"arousal_loss\": 1.6943268775939941, \"emotion_loss\": 0.8116551637649536, \"time_take\": 2.5103800296783447}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9873614311218262, \"arousal_loss\": 0.8364459276199341, \"emotion_loss\": 0.8624258041381836, \"time_take\": 2.7180533409118652}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.499220609664917, \"arousal_loss\": 1.3123559951782227, \"emotion_loss\": 1.0606036186218262, \"time_take\": 2.8703835010528564}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.1160099506378174, \"arousal_loss\": 0.950114369392395, \"emotion_loss\": 0.7665302157402039, \"time_take\": 3.0850627422332764}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.8861911296844482, \"arousal_loss\": 0.6699682474136353, \"emotion_loss\": 0.656857967376709, \"time_take\": 3.2869625091552734}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.8876493573188782, \"arousal_loss\": 0.7608251571655273, \"emotion_loss\": 0.7322604060173035, \"time_take\": 3.4488983154296875}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.205430507659912, \"arousal_loss\": 1.0754525661468506, \"emotion_loss\": 0.6608901023864746, \"time_take\": 3.688068389892578}\n",
      "{\"emotion_correct\": 27, \"valence_loss\": 1.420865774154663, \"arousal_loss\": 1.202010154724121, \"emotion_loss\": 0.4933505654335022, \"time_take\": 3.9602091312408447}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.003946304321289, \"arousal_loss\": 0.7139968276023865, \"emotion_loss\": 0.7428867816925049, \"time_take\": 4.165435552597046}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.2735214233398438, \"arousal_loss\": 1.2294420003890991, \"emotion_loss\": 1.019029974937439, \"time_take\": 4.295047760009766}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.7429714202880859, \"arousal_loss\": 0.5690258741378784, \"emotion_loss\": 0.5623681545257568, \"time_take\": 4.575561761856079}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.779297947883606, \"arousal_loss\": 0.6221156120300293, \"emotion_loss\": 1.0595941543579102, \"time_take\": 4.807583808898926}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.7028837203979492, \"arousal_loss\": 0.5372198820114136, \"emotion_loss\": 0.7856397032737732, \"time_take\": 4.975086450576782}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.3466665744781494, \"arousal_loss\": 1.2193372249603271, \"emotion_loss\": 0.6983371376991272, \"time_take\": 5.192774534225464}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.2045681476593018, \"arousal_loss\": 1.1161351203918457, \"emotion_loss\": 0.9451639652252197, \"time_take\": 5.338197231292725}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.1354076862335205, \"arousal_loss\": 0.977558970451355, \"emotion_loss\": 0.8811569809913635, \"time_take\": 5.485915899276733}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.449150562286377, \"arousal_loss\": 1.3316341638565063, \"emotion_loss\": 0.6184274554252625, \"time_take\": 5.655937433242798}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.936471164226532, \"arousal_loss\": 0.8615442514419556, \"emotion_loss\": 0.937360942363739, \"time_take\": 5.83693790435791}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.1829440593719482, \"arousal_loss\": 1.1103310585021973, \"emotion_loss\": 1.0780991315841675, \"time_take\": 5.995166063308716}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.531611680984497, \"arousal_loss\": 1.3058373928070068, \"emotion_loss\": 0.5923922657966614, \"time_take\": 6.165670156478882}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.1344971656799316, \"arousal_loss\": 0.979147732257843, \"emotion_loss\": 0.753046452999115, \"time_take\": 6.574049949645996}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.4548583030700684, \"arousal_loss\": 1.3466569185256958, \"emotion_loss\": 1.0592087507247925, \"time_take\": 6.753173351287842}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.1037986278533936, \"arousal_loss\": 0.9633653163909912, \"emotion_loss\": 0.830708384513855, \"time_take\": 6.955798625946045}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.9509936571121216, \"arousal_loss\": 0.8469883799552917, \"emotion_loss\": 0.6983482837677002, \"time_take\": 7.171762943267822}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 0.6365174055099487, \"arousal_loss\": 0.4696158766746521, \"emotion_loss\": 0.5878589153289795, \"time_take\": 7.323323488235474}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.2370879650115967, \"arousal_loss\": 1.0822356939315796, \"emotion_loss\": 0.9058897495269775, \"time_take\": 7.509772777557373}\n",
      "{\"emotion_correct\": 29, \"valence_loss\": 1.2098679542541504, \"arousal_loss\": 1.073725938796997, \"emotion_loss\": 0.3616620600223541, \"time_take\": 7.65978741645813}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.484600305557251, \"arousal_loss\": 1.3587796688079834, \"emotion_loss\": 1.086067795753479, \"time_take\": 7.837982177734375}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.2100746631622314, \"arousal_loss\": 1.0942344665527344, \"emotion_loss\": 1.177672266960144, \"time_take\": 8.009131908416748}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.0162450075149536, \"arousal_loss\": 0.8320380449295044, \"emotion_loss\": 0.9778178930282593, \"time_take\": 8.169125318527222}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.1073822975158691, \"arousal_loss\": 0.9587273001670837, \"emotion_loss\": 0.9761428236961365, \"time_take\": 8.369269371032715}\n",
      "{\"emotion_correct\": 28, \"valence_loss\": 0.7555005550384521, \"arousal_loss\": 0.619807243347168, \"emotion_loss\": 0.6487721800804138, \"time_take\": 8.488490104675293}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.1547439098358154, \"arousal_loss\": 1.1123509407043457, \"emotion_loss\": 0.8700646162033081, \"time_take\": 8.67457914352417}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.1521234512329102, \"arousal_loss\": 1.064469814300537, \"emotion_loss\": 0.9693773984909058, \"time_take\": 8.860587358474731}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.012388825416565, \"arousal_loss\": 1.00028657913208, \"emotion_loss\": 1.0368980169296265, \"time_take\": 9.003775596618652}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.359756350517273, \"arousal_loss\": 1.1689261198043823, \"emotion_loss\": 1.0475990772247314, \"time_take\": 9.312021732330322}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.9950883984565735, \"arousal_loss\": 0.8334803581237793, \"emotion_loss\": 0.8549982309341431, \"time_take\": 9.533234119415283}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.604950189590454, \"arousal_loss\": 1.4647290706634521, \"emotion_loss\": 0.9185203313827515, \"time_take\": 9.673271179199219}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.959478497505188, \"arousal_loss\": 0.8472995162010193, \"emotion_loss\": 0.9899842739105225, \"time_take\": 9.922139644622803}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.1191952228546143, \"arousal_loss\": 0.9466893076896667, \"emotion_loss\": 0.5613110065460205, \"time_take\": 10.124260902404785}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 0.9624417424201965, \"arousal_loss\": 0.8512842655181885, \"emotion_loss\": 0.6319534778594971, \"time_take\": 10.281119346618652}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.9377589225769043, \"arousal_loss\": 0.8430877923965454, \"emotion_loss\": 0.6493005752563477, \"time_take\": 10.487782716751099}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.8486376404762268, \"arousal_loss\": 0.7128297090530396, \"emotion_loss\": 0.7575584053993225, \"time_take\": 10.608802080154419}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.1687453985214233, \"arousal_loss\": 0.9312141537666321, \"emotion_loss\": 0.6603084206581116, \"time_take\": 10.800803899765015}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.7205567359924316, \"arousal_loss\": 0.5732631087303162, \"emotion_loss\": 0.8254375457763672, \"time_take\": 10.957711219787598}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.247757911682129, \"arousal_loss\": 1.0379579067230225, \"emotion_loss\": 0.7931188344955444, \"time_take\": 11.164108753204346}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.5987428426742554, \"arousal_loss\": 0.5072495937347412, \"emotion_loss\": 0.9786056280136108, \"time_take\": 11.319942951202393}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.985040009021759, \"arousal_loss\": 0.7937014102935791, \"emotion_loss\": 0.7206618785858154, \"time_take\": 11.557255744934082}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.137641429901123, \"arousal_loss\": 0.9756366014480591, \"emotion_loss\": 0.9174644947052002, \"time_take\": 11.715025424957275}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.1021544933319092, \"arousal_loss\": 0.967195987701416, \"emotion_loss\": 0.7811774015426636, \"time_take\": 11.877208232879639}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.338747501373291, \"arousal_loss\": 1.217984914779663, \"emotion_loss\": 0.9252021312713623, \"time_take\": 12.053922891616821}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 22, \"valence_loss\": 1.1764295101165771, \"arousal_loss\": 1.120519757270813, \"emotion_loss\": 0.9927271604537964, \"time_take\": 12.237197399139404}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.8973127603530884, \"arousal_loss\": 0.7201377153396606, \"emotion_loss\": 0.6989763975143433, \"time_take\": 12.428892850875854}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0062406063079834, \"arousal_loss\": 0.8073654770851135, \"emotion_loss\": 0.9005831480026245, \"time_take\": 12.587623834609985}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0528342723846436, \"arousal_loss\": 0.9170677661895752, \"emotion_loss\": 0.8994420170783997, \"time_take\": 12.787463426589966}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.861380934715271, \"arousal_loss\": 0.7408355474472046, \"emotion_loss\": 0.6859170198440552, \"time_take\": 13.000807523727417}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2998660802841187, \"arousal_loss\": 1.082478642463684, \"emotion_loss\": 1.1253674030303955, \"time_take\": 13.182730913162231}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 1.1640146970748901, \"arousal_loss\": 1.115101933479309, \"emotion_loss\": 0.5596346259117126, \"time_take\": 13.374265909194946}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.4227955341339111, \"arousal_loss\": 1.3784981966018677, \"emotion_loss\": 1.0855298042297363, \"time_take\": 13.55035924911499}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.9421892166137695, \"arousal_loss\": 0.8816901445388794, \"emotion_loss\": 0.7647867798805237, \"time_take\": 13.715564489364624}\n",
      "{\"emotion_correct\": 27, \"valence_loss\": 0.9459389448165894, \"arousal_loss\": 0.8681762218475342, \"emotion_loss\": 0.5852044820785522, \"time_take\": 13.927766799926758}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.9676741361618042, \"arousal_loss\": 0.8365975618362427, \"emotion_loss\": 0.8302251100540161, \"time_take\": 14.164836645126343}\n",
      "{\"emotion_correct\": 27, \"valence_loss\": 0.9456827640533447, \"arousal_loss\": 0.7081944942474365, \"emotion_loss\": 0.5043727159500122, \"time_take\": 14.390231847763062}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.9899765849113464, \"arousal_loss\": 0.8823657631874084, \"emotion_loss\": 0.8417803049087524, \"time_take\": 14.550050258636475}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.894477128982544, \"arousal_loss\": 0.7790119647979736, \"emotion_loss\": 0.957074761390686, \"time_take\": 14.71037483215332}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.004318118095398, \"arousal_loss\": 0.8843002319335938, \"emotion_loss\": 0.9499428868293762, \"time_take\": 14.854109764099121}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.7821706533432007, \"arousal_loss\": 0.5703151226043701, \"emotion_loss\": 0.548492431640625, \"time_take\": 15.058228254318237}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.8636844158172607, \"arousal_loss\": 0.7213444113731384, \"emotion_loss\": 0.5661028623580933, \"time_take\": 15.239364624023438}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.2152924537658691, \"arousal_loss\": 1.0912206172943115, \"emotion_loss\": 0.8881908655166626, \"time_take\": 15.403165817260742}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.3839867115020752, \"arousal_loss\": 1.325484037399292, \"emotion_loss\": 0.5656517148017883, \"time_take\": 15.573462009429932}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 0.5911442041397095, \"arousal_loss\": 0.3467450439929962, \"emotion_loss\": 0.6064828634262085, \"time_take\": 15.743706941604614}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.5514119863510132, \"arousal_loss\": 1.4528710842132568, \"emotion_loss\": 1.097590446472168, \"time_take\": 15.91182804107666}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.3506183624267578, \"arousal_loss\": 1.1893963813781738, \"emotion_loss\": 0.7992352247238159, \"time_take\": 16.07327699661255}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.0053367614746094, \"arousal_loss\": 0.8332139849662781, \"emotion_loss\": 0.7290421724319458, \"time_take\": 16.234696865081787}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.5042389035224915, \"arousal_loss\": 0.31805986166000366, \"emotion_loss\": 0.8122081756591797, \"time_take\": 16.54070258140564}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.9642348289489746, \"arousal_loss\": 0.8096240758895874, \"emotion_loss\": 0.7155835032463074, \"time_take\": 16.713056564331055}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.4711579084396362, \"arousal_loss\": 1.3437867164611816, \"emotion_loss\": 0.8876038789749146, \"time_take\": 16.90880799293518}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.6798576712608337, \"arousal_loss\": 0.5056073069572449, \"emotion_loss\": 1.1178903579711914, \"time_take\": 17.02902364730835}\n",
      "{\"emotion_correct\": 27, \"valence_loss\": 0.7496311068534851, \"arousal_loss\": 0.6305103898048401, \"emotion_loss\": 0.4388298988342285, \"time_take\": 17.227315664291382}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.669342279434204, \"arousal_loss\": 1.601877212524414, \"emotion_loss\": 0.7615160346031189, \"time_take\": 17.37741756439209}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 1.80056631565094, \"arousal_loss\": 1.7186017036437988, \"emotion_loss\": 0.6436615586280823, \"time_take\": 17.528670072555542}\n",
      "{\"emotion_correct\": 27, \"valence_loss\": 0.8797085285186768, \"arousal_loss\": 0.7559751272201538, \"emotion_loss\": 0.5127261877059937, \"time_take\": 17.677440881729126}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.6967403888702393, \"arousal_loss\": 0.5914919376373291, \"emotion_loss\": 0.7627875804901123, \"time_take\": 17.851730823516846}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.8761508464813232, \"arousal_loss\": 0.734670877456665, \"emotion_loss\": 0.9710384607315063, \"time_take\": 18.049465894699097}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.6334266662597656, \"arousal_loss\": 1.441741704940796, \"emotion_loss\": 1.0294702053070068, \"time_take\": 18.251168727874756}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 0.8577615022659302, \"arousal_loss\": 0.7092616558074951, \"emotion_loss\": 0.6935365200042725, \"time_take\": 18.42660641670227}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.8632425665855408, \"arousal_loss\": 0.7592829465866089, \"emotion_loss\": 0.8722673058509827, \"time_take\": 18.594887495040894}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.0227984189987183, \"arousal_loss\": 0.9954450130462646, \"emotion_loss\": 0.7582638263702393, \"time_take\": 18.73072123527527}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.090516209602356, \"arousal_loss\": 0.9420009851455688, \"emotion_loss\": 0.9306221008300781, \"time_take\": 18.907037496566772}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.7600905895233154, \"arousal_loss\": 0.5883684754371643, \"emotion_loss\": 1.125351905822754, \"time_take\": 19.037888526916504}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 1.3198822736740112, \"arousal_loss\": 1.1760468482971191, \"emotion_loss\": 0.6418864130973816, \"time_take\": 19.182939291000366}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.0833079814910889, \"arousal_loss\": 1.0210275650024414, \"emotion_loss\": 0.7720234394073486, \"time_take\": 19.337037086486816}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.7001468539237976, \"arousal_loss\": 0.6514089703559875, \"emotion_loss\": 1.11323082447052, \"time_take\": 19.543238162994385}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9659883975982666, \"arousal_loss\": 0.8780518770217896, \"emotion_loss\": 0.8468809723854065, \"time_take\": 19.66958999633789}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.3187451362609863, \"arousal_loss\": 1.2143107652664185, \"emotion_loss\": 0.9538280367851257, \"time_take\": 19.864267349243164}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.5380610227584839, \"arousal_loss\": 1.3214854001998901, \"emotion_loss\": 0.870684027671814, \"time_take\": 20.02037024497986}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.9480001926422119, \"arousal_loss\": 0.8752579689025879, \"emotion_loss\": 0.8624181151390076, \"time_take\": 20.191637992858887}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.8439351320266724, \"arousal_loss\": 0.7667815685272217, \"emotion_loss\": 0.5380560755729675, \"time_take\": 20.4032244682312}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.1321306228637695, \"arousal_loss\": 0.933102011680603, \"emotion_loss\": 1.267357587814331, \"time_take\": 20.59071159362793}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.236859917640686, \"arousal_loss\": 1.0688152313232422, \"emotion_loss\": 0.851166307926178, \"time_take\": 20.76986837387085}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.5946910381317139, \"arousal_loss\": 0.48823094367980957, \"emotion_loss\": 0.772980809211731, \"time_take\": 20.90384316444397}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 23, \"valence_loss\": 1.1195471286773682, \"arousal_loss\": 0.9685310125350952, \"emotion_loss\": 0.9138703346252441, \"time_take\": 21.075616598129272}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.1861746311187744, \"arousal_loss\": 1.078669548034668, \"emotion_loss\": 0.8430830240249634, \"time_take\": 21.26012659072876}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.1027873754501343, \"arousal_loss\": 0.951934814453125, \"emotion_loss\": 1.03126859664917, \"time_take\": 21.399864673614502}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8519412279129028, \"arousal_loss\": 0.7445626854896545, \"emotion_loss\": 1.3117996454238892, \"time_take\": 21.609960556030273}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.010627031326294, \"arousal_loss\": 0.9462558627128601, \"emotion_loss\": 0.9275684356689453, \"time_take\": 21.790491819381714}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.8810668587684631, \"arousal_loss\": 0.707556962966919, \"emotion_loss\": 0.6405255794525146, \"time_take\": 21.999329090118408}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.2527763843536377, \"arousal_loss\": 1.2623684406280518, \"emotion_loss\": 0.9108527898788452, \"time_take\": 22.22955822944641}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.1334370374679565, \"arousal_loss\": 0.9849226474761963, \"emotion_loss\": 1.1201419830322266, \"time_take\": 22.34701180458069}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.1291601657867432, \"arousal_loss\": 0.9460314512252808, \"emotion_loss\": 0.8635505437850952, \"time_take\": 22.533122062683105}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.2453818321228027, \"arousal_loss\": 1.0914642810821533, \"emotion_loss\": 1.0926201343536377, \"time_take\": 22.776874780654907}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.1117268800735474, \"arousal_loss\": 0.983186662197113, \"emotion_loss\": 0.8814574480056763, \"time_take\": 22.92371940612793}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9535536766052246, \"arousal_loss\": 0.8718898892402649, \"emotion_loss\": 0.8686321973800659, \"time_take\": 23.073235273361206}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.035522222518921, \"arousal_loss\": 0.8224931955337524, \"emotion_loss\": 0.5904817581176758, \"time_take\": 23.231308937072754}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.4099831581115723, \"arousal_loss\": 1.3363322019577026, \"emotion_loss\": 0.6584522128105164, \"time_take\": 23.3717782497406}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.5755400657653809, \"arousal_loss\": 0.5111503601074219, \"emotion_loss\": 1.388751745223999, \"time_take\": 23.5399386882782}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.098085641860962, \"arousal_loss\": 0.954393744468689, \"emotion_loss\": 0.9250047206878662, \"time_take\": 23.79297637939453}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.124748945236206, \"arousal_loss\": 1.1165406703948975, \"emotion_loss\": 0.8681111931800842, \"time_take\": 24.014048099517822}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 1.223339319229126, \"arousal_loss\": 1.063444972038269, \"emotion_loss\": 0.6360417604446411, \"time_take\": 24.184697151184082}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9932757019996643, \"arousal_loss\": 0.873139500617981, \"emotion_loss\": 0.9590599536895752, \"time_take\": 24.397261381149292}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.0683540105819702, \"arousal_loss\": 0.9767191410064697, \"emotion_loss\": 1.2717849016189575, \"time_take\": 24.536043405532837}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.994329571723938, \"arousal_loss\": 0.8257525563240051, \"emotion_loss\": 0.7193915843963623, \"time_take\": 24.683692455291748}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.0978230237960815, \"arousal_loss\": 0.9157454967498779, \"emotion_loss\": 0.7832352519035339, \"time_take\": 24.85033631324768}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.1335196495056152, \"arousal_loss\": 0.9879666566848755, \"emotion_loss\": 0.8408272862434387, \"time_take\": 25.040136098861694}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 0.8969773054122925, \"arousal_loss\": 0.8742239475250244, \"emotion_loss\": 0.5824384689331055, \"time_take\": 25.248142957687378}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.1626999378204346, \"arousal_loss\": 0.9827935695648193, \"emotion_loss\": 0.615927517414093, \"time_take\": 25.35442042350769}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.1329575777053833, \"arousal_loss\": 0.9632001519203186, \"emotion_loss\": 0.9249760508537292, \"time_take\": 25.4786856174469}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.9588992595672607, \"arousal_loss\": 0.8083268404006958, \"emotion_loss\": 0.8436642289161682, \"time_take\": 25.68559193611145}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.0929014682769775, \"arousal_loss\": 0.9694005846977234, \"emotion_loss\": 0.9542675018310547, \"time_take\": 25.794583797454834}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.2805249691009521, \"arousal_loss\": 1.116835594177246, \"emotion_loss\": 0.6164817810058594, \"time_take\": 25.977689266204834}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.5926175713539124, \"arousal_loss\": 0.34391093254089355, \"emotion_loss\": 0.69342041015625, \"time_take\": 26.141907691955566}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 1.3740816116333008, \"arousal_loss\": 1.2461521625518799, \"emotion_loss\": 0.8294215202331543, \"time_take\": 26.28863501548767}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.8322775363922119, \"arousal_loss\": 0.7088901996612549, \"emotion_loss\": 0.6911280155181885, \"time_take\": 26.57063937187195}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.3292922973632812, \"arousal_loss\": 1.1454648971557617, \"emotion_loss\": 0.838687539100647, \"time_take\": 26.771259307861328}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.0931586027145386, \"arousal_loss\": 0.9897502660751343, \"emotion_loss\": 0.9353823065757751, \"time_take\": 26.954267740249634}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.1006832122802734, \"arousal_loss\": 0.9832594394683838, \"emotion_loss\": 1.3861558437347412, \"time_take\": 27.16594362258911}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.1771080493927002, \"arousal_loss\": 1.0017454624176025, \"emotion_loss\": 0.7555763125419617, \"time_take\": 27.31824278831482}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.2279391288757324, \"arousal_loss\": 1.1175599098205566, \"emotion_loss\": 0.7201125025749207, \"time_take\": 27.554155826568604}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.2247605323791504, \"arousal_loss\": 1.1142574548721313, \"emotion_loss\": 0.5702261328697205, \"time_take\": 27.70111107826233}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.6659014225006104, \"arousal_loss\": 0.5783481597900391, \"emotion_loss\": 0.9646508097648621, \"time_take\": 27.886677742004395}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.3393096923828125, \"arousal_loss\": 1.229905366897583, \"emotion_loss\": 0.5902263522148132, \"time_take\": 28.08725595474243}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.2507102489471436, \"arousal_loss\": 1.226930856704712, \"emotion_loss\": 1.2073264122009277, \"time_take\": 28.280733346939087}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.1675063371658325, \"arousal_loss\": 0.9234644174575806, \"emotion_loss\": 0.9062536954879761, \"time_take\": 28.42399525642395}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 0.9208856225013733, \"arousal_loss\": 0.8557536602020264, \"emotion_loss\": 0.5879970788955688, \"time_take\": 28.61701464653015}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.028664231300354, \"arousal_loss\": 0.8172094821929932, \"emotion_loss\": 0.7462759017944336, \"time_take\": 28.77926254272461}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 0.7125838994979858, \"arousal_loss\": 0.6018130779266357, \"emotion_loss\": 0.840417742729187, \"time_take\": 28.97924256324768}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.2023248672485352, \"arousal_loss\": 1.0988014936447144, \"emotion_loss\": 0.9825101494789124, \"time_take\": 29.150871515274048}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.7637959122657776, \"arousal_loss\": 0.6426580548286438, \"emotion_loss\": 0.8880405426025391, \"time_take\": 29.328890323638916}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.9598429203033447, \"arousal_loss\": 0.8089944124221802, \"emotion_loss\": 0.705200731754303, \"time_take\": 29.48000717163086}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.3239094018936157, \"arousal_loss\": 1.2029387950897217, \"emotion_loss\": 1.0621497631072998, \"time_take\": 29.6164870262146}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.836531400680542, \"arousal_loss\": 0.7143419981002808, \"emotion_loss\": 0.6776130199432373, \"time_take\": 29.80913209915161}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.0708023309707642, \"arousal_loss\": 0.9806761741638184, \"emotion_loss\": 0.909659743309021, \"time_take\": 29.991326808929443}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 25, \"valence_loss\": 1.3493882417678833, \"arousal_loss\": 1.220069169998169, \"emotion_loss\": 0.8775332570075989, \"time_take\": 30.16627311706543}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.7703328132629395, \"arousal_loss\": 0.5751264095306396, \"emotion_loss\": 0.6830350756645203, \"time_take\": 30.358267307281494}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.294429898262024, \"arousal_loss\": 1.041663646697998, \"emotion_loss\": 0.544386625289917, \"time_take\": 30.536280155181885}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.9688500761985779, \"arousal_loss\": 0.8234019875526428, \"emotion_loss\": 0.8029906749725342, \"time_take\": 30.707453966140747}\n",
      "{\"emotion_correct\": 27, \"valence_loss\": 0.847244143486023, \"arousal_loss\": 0.6366018056869507, \"emotion_loss\": 0.5573456287384033, \"time_take\": 30.913920402526855}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.1789608001708984, \"arousal_loss\": 1.101930856704712, \"emotion_loss\": 0.7932533621788025, \"time_take\": 31.04757308959961}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.195935606956482, \"arousal_loss\": 0.934175968170166, \"emotion_loss\": 0.7929959297180176, \"time_take\": 31.249004125595093}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.0872650146484375, \"arousal_loss\": 0.9833015203475952, \"emotion_loss\": 0.48731398582458496, \"time_take\": 31.45940351486206}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.0153260231018066, \"arousal_loss\": 0.9035463929176331, \"emotion_loss\": 0.8816187381744385, \"time_take\": 31.685547590255737}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.2426543235778809, \"arousal_loss\": 1.076497197151184, \"emotion_loss\": 0.7478477358818054, \"time_take\": 31.892475605010986}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2517220973968506, \"arousal_loss\": 1.0736613273620605, \"emotion_loss\": 0.7984795570373535, \"time_take\": 32.04936957359314}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.029250979423523, \"arousal_loss\": 0.8384766578674316, \"emotion_loss\": 1.0201743841171265, \"time_take\": 32.27786421775818}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.8653953075408936, \"arousal_loss\": 0.6734539270401001, \"emotion_loss\": 0.6835269927978516, \"time_take\": 32.42362022399902}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.47566503286361694, \"arousal_loss\": 0.4029390811920166, \"emotion_loss\": 1.0342696905136108, \"time_take\": 32.566115617752075}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.7403404712677002, \"arousal_loss\": 0.5885178446769714, \"emotion_loss\": 0.8941735625267029, \"time_take\": 32.747554063797}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.5394917726516724, \"arousal_loss\": 1.4317723512649536, \"emotion_loss\": 0.8695625066757202, \"time_take\": 32.91033148765564}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.5788782835006714, \"arousal_loss\": 1.4186606407165527, \"emotion_loss\": 1.0868332386016846, \"time_take\": 33.08003306388855}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9769469499588013, \"arousal_loss\": 0.8474752306938171, \"emotion_loss\": 1.1751537322998047, \"time_take\": 33.2725555896759}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 1.3626376390457153, \"arousal_loss\": 1.2096035480499268, \"emotion_loss\": 0.7423831820487976, \"time_take\": 33.43998146057129}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.8259705305099487, \"arousal_loss\": 0.7281994819641113, \"emotion_loss\": 0.7595456838607788, \"time_take\": 33.6030433177948}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.31251060962677, \"arousal_loss\": 1.232461929321289, \"emotion_loss\": 0.8433222770690918, \"time_take\": 33.76837921142578}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.0389020442962646, \"arousal_loss\": 0.8073033690452576, \"emotion_loss\": 1.0119965076446533, \"time_take\": 33.9226610660553}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.277542233467102, \"arousal_loss\": 1.2545583248138428, \"emotion_loss\": 1.1358892917633057, \"time_take\": 34.04010725021362}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.0068559646606445, \"arousal_loss\": 0.8551353216171265, \"emotion_loss\": 0.6865129470825195, \"time_take\": 34.215826749801636}\n"
     ]
    }
   ],
   "source": [
    "from telegram_notifier import send_message\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_step = 0\n",
    "    total_emotion_correct = 0\n",
    "    total_valence_loss = 0\n",
    "    total_arousal_loss = 0\n",
    "    total_emotion_loss = 0\n",
    "    total_process = 0\n",
    "    for step, row in enumerate(DataFrameBatchIterator(train_df, batch_size=batch_size)):\n",
    "\n",
    "        imgs = row.subDirectory_filePath.apply(lambda x: cv2.resize(\n",
    "            cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2RGB), (224, 224)))\n",
    "        img_array = np.array(list(imgs))\n",
    "\n",
    "        y_valence = np.array(row.valence)\n",
    "        y_arousal = np.array(row.arousal)\n",
    "        y_emotion = np.array(row.expression)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(img_array, training=True)\n",
    "\n",
    "            pred_valence = logits[0]\n",
    "            pred_arousal = logits[1]\n",
    "            pred_emotion = logits[2]\n",
    "\n",
    "            valence_loss = MSE_loss(y_valence, pred_valence)\n",
    "            arousal_loss = MSE_loss(y_arousal, pred_arousal)\n",
    "            emotion_loss = SCC_loss(y_emotion, pred_emotion)\n",
    "\n",
    "            loss = valence_loss + arousal_loss # + emotion_loss\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_weights)\n",
    "\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        total_loss += float(loss)\n",
    "        total_step += 1\n",
    "        \n",
    "        total_process += len(row)\n",
    "\n",
    "        valence_loss = float(valence_loss)\n",
    "        arousal_loss = float(arousal_loss)\n",
    "        emotion_loss = float(emotion_loss)\n",
    "        \n",
    "        total_valence_loss += valence_loss\n",
    "        total_arousal_loss += arousal_loss\n",
    "        total_emotion_loss += emotion_loss\n",
    "        \n",
    "        emotion_correct = int(sum(pred_emotion.numpy().argmax(axis = 1) == y_emotion))\n",
    "        total_emotion_correct += emotion_correct\n",
    "        \n",
    "        log = {\n",
    "            'emotion_correct': emotion_correct,\n",
    "            'valence_loss': valence_loss,\n",
    "            'arousal_loss': arousal_loss,\n",
    "            'emotion_loss': emotion_loss,\n",
    "            'time_take': time.time() - start_time\n",
    "        }\n",
    "        log = json.dumps(log)\n",
    "        lprint(log)\n",
    "    save_model_path = f\"models/{now_time_string}_{description}_epoch{epoch}_batch_{batch_size}\"\n",
    "    model.save(save_model_path)\n",
    "    lprint(f\"Save {save_model_path}\")\n",
    "    send_message(f\"Save {save_model_path}\\nepoch {epoch} is finish\")\n",
    "    log = {\n",
    "        'model_path': save_model_path,\n",
    "        'total_emotion_correct': total_emotion_correct,\n",
    "        'total_loss': total_loss,\n",
    "        'total_valence_loss': total_valence_loss,\n",
    "        'total_arousal_loss': total_arousal_loss,\n",
    "        'total_emotion_loss': total_emotion_loss,\n",
    "        'total_process': total_process,\n",
    "        'time_take': time.time() - start_time\n",
    "    }\n",
    "    log = json.dumps(log)\n",
    "    lprint(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "tf27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
