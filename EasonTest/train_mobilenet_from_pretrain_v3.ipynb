{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T12:50:25.876212Z",
     "start_time": "2022-01-18T12:50:25.870149Z"
    }
   },
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:11.345831Z",
     "start_time": "2022-01-22T15:43:11.334431Z"
    }
   },
   "outputs": [],
   "source": [
    "description = 'mobilenet_from_pretrain_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:12.999056Z",
     "start_time": "2022-01-22T15:43:11.348093Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#from scipy.misc import imread, imresize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:13.008426Z",
     "start_time": "2022-01-22T15:43:13.000531Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:17.413673Z",
     "start_time": "2022-01-22T15:43:13.010933Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/Manually_Annotated_file_lists/training_face_mesh_crop.csv')\n",
    "train_df.subDirectory_filePath = '../../data/Manually_Annotated_Images_FaceMesh_Cropped/' + train_df.subDirectory_filePath\n",
    "\n",
    "#train_df_2 = pd.read_csv('../../data/Automatically_annotated_file_list/automatically_annotated_face_mesh_crop.csv')\n",
    "#train_df_2.subDirectory_filePath = '../../data/Automatically_Annotated_Images_FaceMesh_Cropped/' + train_df_2.subDirectory_filePath\n",
    "#train_df = train_df.append(train_df_2)\n",
    "#del train_df_2\n",
    "\n",
    "train_df = train_df[train_df['have_facemesh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:17.421562Z",
     "start_time": "2022-01-22T15:43:17.416706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_file_name='01_22_23:43:17.log'\n"
     ]
    }
   ],
   "source": [
    "from eason_utils import DataFrameBatchIterator\n",
    "from eason_utils import lprint, now_time_string, log_file_name, change_log_file_name\n",
    "\n",
    "change_log_file_name(f'''{log_file_name.replace('.log', '')}_{description}.log''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T13:57:18.682279Z",
     "start_time": "2022-01-19T13:57:18.670590Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:19.775857Z",
     "start_time": "2022-01-22T15:43:17.423220Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(allow_growth = True))\n",
    "sess = tf.compat.v1.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:20.491809Z",
     "start_time": "2022-01-22T15:43:19.778694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "mobilenet_pretrained = tf.keras.models.load_model('../models/affectnet_emotions/mobilenet_7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:20.498000Z",
     "start_time": "2022-01-22T15:43:20.493568Z"
    }
   },
   "outputs": [],
   "source": [
    "mobilenet_output = mobilenet_pretrained.get_layer(\"global_pooling\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:20.501865Z",
     "start_time": "2022-01-22T15:43:20.499547Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_layers = [256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:20.575764Z",
     "start_time": "2022-01-22T15:43:20.508495Z"
    }
   },
   "outputs": [],
   "source": [
    "valaence_feat = mobilenet_output\n",
    "for size in hidden_layers:\n",
    "    valence_feat = tf.keras.layers.Dense(size, activation = 'relu', name = f'feat_valence')(valaence_feat)\n",
    "outputs_valence = (tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'outputs_valence')(valence_feat) * 4) - 2\n",
    "\n",
    "arousal_feat = mobilenet_output\n",
    "for size in hidden_layers:\n",
    "    arousal_feat = tf.keras.layers.Dense(size, activation = 'relu', name = f'feat_arousal')(arousal_feat)\n",
    "outputs_arousal = (tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'outputs_arousal')(arousal_feat) * 4) - 2\n",
    "\n",
    "emotion_feat = mobilenet_output\n",
    "for size in hidden_layers:\n",
    "    emotion_feat = tf.keras.layers.Dense(size, activation = 'relu', name = f'feat_emotion')(emotion_feat)\n",
    "emotions_count = len(np.unique(train_df.expression))\n",
    "outputs_emotion = tf.keras.layers.Dense(emotions_count, activation = 'softmax', name = 'outputs_emotion')(emotion_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:20.591875Z",
     "start_time": "2022-01-22T15:43:20.577190Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=mobilenet_pretrained.input,\n",
    "                       outputs=(outputs_valence, outputs_arousal, outputs_emotion) , name=\"mobilenet_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:20.642961Z",
     "start_time": "2022-01-22T15:43:20.593909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_train\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 225, 225, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 112, 112, 32  864         ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 32  128         ['conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (ReLU)              (None, 112, 112, 32  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1 (DepthwiseConv2D)    (None, 112, 112, 32  288         ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1_bn (BatchNormalizati  (None, 112, 112, 32  128        ['conv_dw_1[0][0]']              \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1_relu (ReLU)          (None, 112, 112, 32  0           ['conv_dw_1_bn[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1 (Conv2D)             (None, 112, 112, 64  2048        ['conv_dw_1_relu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1_bn (BatchNormalizati  (None, 112, 112, 64  256        ['conv_pw_1[0][0]']              \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1_relu (ReLU)          (None, 112, 112, 64  0           ['conv_pw_1_bn[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pad_2 (ZeroPadding2D)     (None, 113, 113, 64  0           ['conv_pw_1_relu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_2 (DepthwiseConv2D)    (None, 56, 56, 64)   576         ['conv_pad_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_2_bn (BatchNormalizati  (None, 56, 56, 64)  256         ['conv_dw_2[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_2_relu (ReLU)          (None, 56, 56, 64)   0           ['conv_dw_2_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_2 (Conv2D)             (None, 56, 56, 128)  8192        ['conv_dw_2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_2_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_pw_2[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_2_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_pw_2_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_3 (DepthwiseConv2D)    (None, 56, 56, 128)  1152        ['conv_pw_2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_3_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_dw_3[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_3_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_dw_3_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_3 (Conv2D)             (None, 56, 56, 128)  16384       ['conv_dw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_3_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_pw_3[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_3_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_pw_3_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pad_4 (ZeroPadding2D)     (None, 57, 57, 128)  0           ['conv_pw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_4 (DepthwiseConv2D)    (None, 28, 28, 128)  1152        ['conv_pad_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_4_bn (BatchNormalizati  (None, 28, 28, 128)  512        ['conv_dw_4[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_4_relu (ReLU)          (None, 28, 28, 128)  0           ['conv_dw_4_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_4 (Conv2D)             (None, 28, 28, 256)  32768       ['conv_dw_4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_4_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_pw_4[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_4_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_pw_4_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_5 (DepthwiseConv2D)    (None, 28, 28, 256)  2304        ['conv_pw_4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_5_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_dw_5[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_5_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_dw_5_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_5 (Conv2D)             (None, 28, 28, 256)  65536       ['conv_dw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_5_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_pw_5[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_5_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_pw_5_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pad_6 (ZeroPadding2D)     (None, 29, 29, 256)  0           ['conv_pw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_6 (DepthwiseConv2D)    (None, 14, 14, 256)  2304        ['conv_pad_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_6_bn (BatchNormalizati  (None, 14, 14, 256)  1024       ['conv_dw_6[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_6_relu (ReLU)          (None, 14, 14, 256)  0           ['conv_dw_6_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_6 (Conv2D)             (None, 14, 14, 512)  131072      ['conv_dw_6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_6_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_6[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_6_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_6_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_7 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_7_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_7[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_7_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_7_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_7 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_7_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_7_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_7[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_7_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_7_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_8 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_7_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_8_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_8[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_8_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_8_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_8 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_8_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_8_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_8[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_8_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_8_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_9 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_8_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_9_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_9[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_9_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_9_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_9 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_9_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_9_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_9[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_9_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_9_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_10 (DepthwiseConv2D)   (None, 14, 14, 512)  4608        ['conv_pw_9_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_10_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_dw_10[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_10_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_dw_10_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_10 (Conv2D)            (None, 14, 14, 512)  262144      ['conv_dw_10_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_10_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_pw_10[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_10_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_pw_10_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_dw_11 (DepthwiseConv2D)   (None, 14, 14, 512)  4608        ['conv_pw_10_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_11_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_dw_11[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_11_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_dw_11_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_11 (Conv2D)            (None, 14, 14, 512)  262144      ['conv_dw_11_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_11_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_pw_11[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_11_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_pw_11_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pad_12 (ZeroPadding2D)    (None, 15, 15, 512)  0           ['conv_pw_11_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_12 (DepthwiseConv2D)   (None, 7, 7, 512)    4608        ['conv_pad_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv_dw_12_bn (BatchNormalizat  (None, 7, 7, 512)   2048        ['conv_dw_12[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_12_relu (ReLU)         (None, 7, 7, 512)    0           ['conv_dw_12_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_12 (Conv2D)            (None, 7, 7, 1024)   524288      ['conv_dw_12_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_12_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_pw_12[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_12_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_pw_12_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_dw_13 (DepthwiseConv2D)   (None, 7, 7, 1024)   9216        ['conv_pw_12_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_13_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_dw_13[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_13_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_dw_13_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_13 (Conv2D)            (None, 7, 7, 1024)   1048576     ['conv_dw_13_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_13_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_pw_13[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_13_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_pw_13_bn[0][0]']          \n",
      "                                                                                                  \n",
      " global_pooling (GlobalAverageP  (None, 1024)        0           ['conv_pw_13_relu[0][0]']        \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " feat_valence (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " feat_arousal (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " outputs_valence (Dense)        (None, 1)            257         ['feat_valence[0][0]']           \n",
      "                                                                                                  \n",
      " outputs_arousal (Dense)        (None, 1)            257         ['feat_arousal[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1)            0           ['outputs_valence[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 1)           0           ['outputs_arousal[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " feat_emotion (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 1)            0           ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 1)           0           ['tf.math.multiply_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " outputs_emotion (Dense)        (None, 11)           2827        ['feat_emotion[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,019,405\n",
      "Trainable params: 3,997,517\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:20.648306Z",
     "start_time": "2022-01-22T15:43:20.644491Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# Instantiate a loss function.\n",
    "MSE_loss = tf.keras.losses.MeanSquaredError()\n",
    "SCC_loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T15:43:20.653136Z",
     "start_time": "2022-01-22T15:43:20.650111Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 16\n",
    "\n",
    "logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-22T15:43:07.893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 1, \"valence_loss\": 1.8172329664230347, \"arousal_loss\": 1.3659603595733643, \"emotion_loss\": 2.5122873783111572, \"time_take\": 3.1972382068634033}\n",
      "{\"emotion_correct\": 10, \"valence_loss\": 2.534557819366455, \"arousal_loss\": 2.4423470497131348, \"emotion_loss\": 2.122739791870117, \"time_take\": 3.500185966491699}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 2.379204511642456, \"arousal_loss\": 1.736830711364746, \"emotion_loss\": 1.7736867666244507, \"time_take\": 3.7280919551849365}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.9437247514724731, \"arousal_loss\": 1.1171879768371582, \"emotion_loss\": 1.7552037239074707, \"time_take\": 4.014060735702515}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.3788342475891113, \"arousal_loss\": 0.6247645616531372, \"emotion_loss\": 1.5749136209487915, \"time_take\": 4.3767781257629395}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0181050300598145, \"arousal_loss\": 0.8321330547332764, \"emotion_loss\": 1.649595856666565, \"time_take\": 4.616724014282227}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.1351094245910645, \"arousal_loss\": 1.2562267780303955, \"emotion_loss\": 1.6789456605911255, \"time_take\": 4.93600869178772}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.4634521007537842, \"arousal_loss\": 1.2866034507751465, \"emotion_loss\": 1.572982907295227, \"time_take\": 5.27029824256897}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0438604354858398, \"arousal_loss\": 0.7008193731307983, \"emotion_loss\": 1.5488728284835815, \"time_take\": 5.535295009613037}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.4238393306732178, \"arousal_loss\": 1.1146447658538818, \"emotion_loss\": 1.74897038936615, \"time_take\": 5.7079973220825195}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.7500991225242615, \"arousal_loss\": 0.5727308988571167, \"emotion_loss\": 1.221492052078247, \"time_take\": 6.068868637084961}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 0.7880998253822327, \"arousal_loss\": 0.6360776424407959, \"emotion_loss\": 1.939824104309082, \"time_take\": 6.2616376876831055}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 0.682123064994812, \"arousal_loss\": 0.4706656336784363, \"emotion_loss\": 1.9432669878005981, \"time_take\": 6.4847869873046875}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.2865442037582397, \"arousal_loss\": 1.0078542232513428, \"emotion_loss\": 1.3763256072998047, \"time_take\": 6.77166748046875}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.0737555027008057, \"arousal_loss\": 0.9996793270111084, \"emotion_loss\": 1.617724895477295, \"time_take\": 6.968348741531372}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.9759848713874817, \"arousal_loss\": 0.8453164100646973, \"emotion_loss\": 1.8396522998809814, \"time_take\": 7.165747880935669}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.2439393997192383, \"arousal_loss\": 1.043980360031128, \"emotion_loss\": 1.3188788890838623, \"time_take\": 7.382563352584839}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.8864009380340576, \"arousal_loss\": 0.75971519947052, \"emotion_loss\": 1.9011962413787842, \"time_take\": 7.592450380325317}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.1256277561187744, \"arousal_loss\": 0.9556481838226318, \"emotion_loss\": 1.433171272277832, \"time_take\": 7.822957992553711}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.402017593383789, \"arousal_loss\": 1.0006752014160156, \"emotion_loss\": 1.135951042175293, \"time_take\": 8.04263687133789}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.1368675231933594, \"arousal_loss\": 0.7991034984588623, \"emotion_loss\": 1.6062965393066406, \"time_take\": 8.563369989395142}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.2488765716552734, \"arousal_loss\": 1.095210313796997, \"emotion_loss\": 1.4239566326141357, \"time_take\": 8.802640199661255}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0668251514434814, \"arousal_loss\": 0.8710510730743408, \"emotion_loss\": 1.385105848312378, \"time_take\": 9.079657316207886}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.0085575580596924, \"arousal_loss\": 0.8006808757781982, \"emotion_loss\": 1.3063075542449951, \"time_take\": 9.368157863616943}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8887123465538025, \"arousal_loss\": 0.593951404094696, \"emotion_loss\": 1.479423999786377, \"time_take\": 9.566232442855835}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1380535364151, \"arousal_loss\": 0.9201927185058594, \"emotion_loss\": 1.801952600479126, \"time_take\": 9.799440145492554}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1082594394683838, \"arousal_loss\": 0.9545074105262756, \"emotion_loss\": 1.218246579170227, \"time_take\": 10.002695322036743}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.3492233753204346, \"arousal_loss\": 1.1395496129989624, \"emotion_loss\": 1.7368203401565552, \"time_take\": 10.234935998916626}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.1280860900878906, \"arousal_loss\": 0.9535341858863831, \"emotion_loss\": 1.730199933052063, \"time_take\": 10.460547685623169}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9821719527244568, \"arousal_loss\": 0.7210249900817871, \"emotion_loss\": 1.3549697399139404, \"time_take\": 10.664875268936157}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.036975383758545, \"arousal_loss\": 0.8064907789230347, \"emotion_loss\": 1.4245884418487549, \"time_take\": 10.949857473373413}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.7561039924621582, \"arousal_loss\": 0.6062359809875488, \"emotion_loss\": 1.548386812210083, \"time_take\": 11.126163721084595}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.063995361328125, \"arousal_loss\": 0.950783371925354, \"emotion_loss\": 1.5835697650909424, \"time_take\": 11.36150050163269}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.063568353652954, \"arousal_loss\": 0.8758039474487305, \"emotion_loss\": 1.6380232572555542, \"time_take\": 11.593197584152222}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 0.924107015132904, \"arousal_loss\": 0.8808387517929077, \"emotion_loss\": 1.6334463357925415, \"time_take\": 11.78912615776062}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.2185050249099731, \"arousal_loss\": 0.832307755947113, \"emotion_loss\": 1.5096774101257324, \"time_take\": 12.19834041595459}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9766060709953308, \"arousal_loss\": 0.7546236515045166, \"emotion_loss\": 1.396640419960022, \"time_take\": 12.538849115371704}\n",
      "{\"emotion_correct\": 11, \"valence_loss\": 1.334043025970459, \"arousal_loss\": 1.089634656906128, \"emotion_loss\": 1.6106219291687012, \"time_take\": 12.74365782737732}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.9402527809143066, \"arousal_loss\": 0.826531708240509, \"emotion_loss\": 1.8992853164672852, \"time_take\": 13.058817386627197}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.9555304050445557, \"arousal_loss\": 0.820149838924408, \"emotion_loss\": 1.0835633277893066, \"time_take\": 13.314615964889526}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.916366696357727, \"arousal_loss\": 0.8554761409759521, \"emotion_loss\": 1.4607152938842773, \"time_take\": 13.514972925186157}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.8777364492416382, \"arousal_loss\": 0.8311558961868286, \"emotion_loss\": 1.5951476097106934, \"time_take\": 13.785372018814087}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.779465913772583, \"arousal_loss\": 0.7212307453155518, \"emotion_loss\": 1.4857202768325806, \"time_take\": 13.938466310501099}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.1697731018066406, \"arousal_loss\": 0.7842068672180176, \"emotion_loss\": 1.075065016746521, \"time_take\": 14.204275608062744}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8246766328811646, \"arousal_loss\": 0.538663387298584, \"emotion_loss\": 1.176271677017212, \"time_take\": 14.417105197906494}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1690795421600342, \"arousal_loss\": 0.8982207775115967, \"emotion_loss\": 1.341289758682251, \"time_take\": 14.70079255104065}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.6340705156326294, \"arousal_loss\": 0.5611566305160522, \"emotion_loss\": 1.6578550338745117, \"time_take\": 14.929907321929932}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9347711205482483, \"arousal_loss\": 0.7031217217445374, \"emotion_loss\": 1.1938012838363647, \"time_take\": 15.22802448272705}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.0662431716918945, \"arousal_loss\": 0.8712993860244751, \"emotion_loss\": 1.7187280654907227, \"time_take\": 15.437788248062134}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9916025400161743, \"arousal_loss\": 0.895521879196167, \"emotion_loss\": 1.3627245426177979, \"time_take\": 15.67025375366211}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1350010633468628, \"arousal_loss\": 1.106296420097351, \"emotion_loss\": 1.4829273223876953, \"time_take\": 15.898763179779053}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 13, \"valence_loss\": 1.095099687576294, \"arousal_loss\": 1.0274053812026978, \"emotion_loss\": 1.4648865461349487, \"time_take\": 16.127872943878174}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8357353806495667, \"arousal_loss\": 0.6631572246551514, \"emotion_loss\": 1.1698901653289795, \"time_take\": 16.38991117477417}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.8980485796928406, \"arousal_loss\": 0.706078052520752, \"emotion_loss\": 1.5663654804229736, \"time_take\": 16.600515842437744}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.9819141626358032, \"arousal_loss\": 0.8125412464141846, \"emotion_loss\": 1.195940613746643, \"time_take\": 16.8737370967865}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.8631972670555115, \"arousal_loss\": 0.6595410704612732, \"emotion_loss\": 1.7667741775512695, \"time_take\": 17.168280124664307}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.177485466003418, \"arousal_loss\": 0.876213550567627, \"emotion_loss\": 1.3248322010040283, \"time_take\": 17.40528106689453}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.0800206661224365, \"arousal_loss\": 0.9812117218971252, \"emotion_loss\": 1.2640223503112793, \"time_take\": 17.6478853225708}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.2003262042999268, \"arousal_loss\": 1.1334714889526367, \"emotion_loss\": 1.4429795742034912, \"time_take\": 17.878734350204468}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.9496450424194336, \"arousal_loss\": 0.8437440395355225, \"emotion_loss\": 1.3651511669158936, \"time_take\": 18.106184244155884}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8528990745544434, \"arousal_loss\": 0.8583519458770752, \"emotion_loss\": 1.1782519817352295, \"time_take\": 18.383865118026733}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.946560263633728, \"arousal_loss\": 0.8051314353942871, \"emotion_loss\": 1.2998309135437012, \"time_take\": 18.646851778030396}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.9839909076690674, \"arousal_loss\": 0.7431116104125977, \"emotion_loss\": 1.0141847133636475, \"time_take\": 18.9241783618927}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9335837364196777, \"arousal_loss\": 0.8624504208564758, \"emotion_loss\": 1.1668089628219604, \"time_take\": 19.11901545524597}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.8805807828903198, \"arousal_loss\": 0.7429808378219604, \"emotion_loss\": 1.5577948093414307, \"time_take\": 19.314440727233887}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.0436716079711914, \"arousal_loss\": 0.8801510334014893, \"emotion_loss\": 1.3365988731384277, \"time_take\": 19.508452653884888}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8593571186065674, \"arousal_loss\": 0.5634588003158569, \"emotion_loss\": 1.1751371622085571, \"time_take\": 19.766346216201782}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.8967475891113281, \"arousal_loss\": 0.6527888774871826, \"emotion_loss\": 1.0922175645828247, \"time_take\": 19.98567247390747}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.1245825290679932, \"arousal_loss\": 0.9139392971992493, \"emotion_loss\": 1.270228624343872, \"time_take\": 20.202996492385864}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.231177806854248, \"arousal_loss\": 1.1676701307296753, \"emotion_loss\": 1.5259978771209717, \"time_take\": 20.44197988510132}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.6793529391288757, \"arousal_loss\": 0.3458603322505951, \"emotion_loss\": 0.8951197862625122, \"time_take\": 20.650498867034912}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.4270009994506836, \"arousal_loss\": 1.2173898220062256, \"emotion_loss\": 1.5543580055236816, \"time_take\": 20.90521812438965}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.2793190479278564, \"arousal_loss\": 1.0384156703948975, \"emotion_loss\": 1.2109849452972412, \"time_take\": 21.131821393966675}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9306780695915222, \"arousal_loss\": 0.7445024847984314, \"emotion_loss\": 1.366119623184204, \"time_take\": 21.370684146881104}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.5595476627349854, \"arousal_loss\": 0.3794358968734741, \"emotion_loss\": 0.952140212059021, \"time_take\": 21.742947340011597}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9439603090286255, \"arousal_loss\": 0.680328369140625, \"emotion_loss\": 1.1329050064086914, \"time_take\": 21.97585701942444}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.3307573795318604, \"arousal_loss\": 1.1292394399642944, \"emotion_loss\": 1.6199612617492676, \"time_take\": 22.25378656387329}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.7082208395004272, \"arousal_loss\": 0.5866480469703674, \"emotion_loss\": 1.5268969535827637, \"time_take\": 22.427026510238647}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.7200421094894409, \"arousal_loss\": 0.6687971353530884, \"emotion_loss\": 1.2667078971862793, \"time_take\": 22.675588607788086}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.5005662441253662, \"arousal_loss\": 1.3083093166351318, \"emotion_loss\": 1.3024914264678955, \"time_take\": 22.860166788101196}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.5862147808074951, \"arousal_loss\": 1.4031288623809814, \"emotion_loss\": 1.1898598670959473, \"time_take\": 23.065604209899902}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8401179313659668, \"arousal_loss\": 0.764697253704071, \"emotion_loss\": 1.2450672388076782, \"time_take\": 23.25847625732422}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.72334223985672, \"arousal_loss\": 0.5764963626861572, \"emotion_loss\": 1.2196425199508667, \"time_take\": 23.479610681533813}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.8761792182922363, \"arousal_loss\": 0.7500861883163452, \"emotion_loss\": 1.1453756093978882, \"time_take\": 23.710942029953003}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.4787588119506836, \"arousal_loss\": 1.0203702449798584, \"emotion_loss\": 1.3142480850219727, \"time_take\": 23.975776433944702}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.8502820134162903, \"arousal_loss\": 0.6641587018966675, \"emotion_loss\": 1.0776405334472656, \"time_take\": 24.19479203224182}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8441318273544312, \"arousal_loss\": 0.7829657196998596, \"emotion_loss\": 1.1707640886306763, \"time_take\": 24.42387080192566}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.8824670314788818, \"arousal_loss\": 0.8622415065765381, \"emotion_loss\": 1.8556621074676514, \"time_take\": 24.602501392364502}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 0.9439167976379395, \"arousal_loss\": 0.7607556581497192, \"emotion_loss\": 1.4596819877624512, \"time_take\": 24.848494052886963}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.7219570279121399, \"arousal_loss\": 0.6517376899719238, \"emotion_loss\": 1.5429259538650513, \"time_take\": 25.030200004577637}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.1597844362258911, \"arousal_loss\": 0.9040651917457581, \"emotion_loss\": 1.053015947341919, \"time_take\": 25.22290825843811}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0394859313964844, \"arousal_loss\": 0.9226471185684204, \"emotion_loss\": 1.2879786491394043, \"time_take\": 25.445463180541992}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.746284008026123, \"arousal_loss\": 0.698884129524231, \"emotion_loss\": 1.6436327695846558, \"time_take\": 25.71204137802124}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8733632564544678, \"arousal_loss\": 0.836666464805603, \"emotion_loss\": 1.4747190475463867, \"time_take\": 25.90353226661682}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.1365551948547363, \"arousal_loss\": 1.0535495281219482, \"emotion_loss\": 1.5198519229888916, \"time_take\": 26.189903497695923}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.3592119216918945, \"arousal_loss\": 1.0756571292877197, \"emotion_loss\": 1.263366460800171, \"time_take\": 26.39662480354309}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8931463360786438, \"arousal_loss\": 0.8227385878562927, \"emotion_loss\": 1.3876063823699951, \"time_take\": 26.61609387397766}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8448912501335144, \"arousal_loss\": 0.7222983241081238, \"emotion_loss\": 1.182206153869629, \"time_take\": 26.87567949295044}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.0247175693511963, \"arousal_loss\": 0.8173239231109619, \"emotion_loss\": 1.5509583950042725, \"time_take\": 27.167874813079834}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0665779113769531, \"arousal_loss\": 0.9182835817337036, \"emotion_loss\": 1.2341021299362183, \"time_take\": 27.40858292579651}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.6050167083740234, \"arousal_loss\": 0.4622941017150879, \"emotion_loss\": 1.3156788349151611, \"time_take\": 27.590619802474976}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 16, \"valence_loss\": 1.0501819849014282, \"arousal_loss\": 0.8314739465713501, \"emotion_loss\": 1.5765527486801147, \"time_take\": 27.81778907775879}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.9621105194091797, \"arousal_loss\": 0.8744242191314697, \"emotion_loss\": 1.6403563022613525, \"time_take\": 28.086568355560303}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.0288560390472412, \"arousal_loss\": 0.8244643211364746, \"emotion_loss\": 1.092559576034546, \"time_take\": 28.284438371658325}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.8552061915397644, \"arousal_loss\": 0.6578271389007568, \"emotion_loss\": 1.6717792749404907, \"time_take\": 28.564780950546265}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.8997143507003784, \"arousal_loss\": 0.8133645057678223, \"emotion_loss\": 1.6959797143936157, \"time_take\": 28.785289525985718}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8706861138343811, \"arousal_loss\": 0.5929892063140869, \"emotion_loss\": 1.2487353086471558, \"time_take\": 29.037788152694702}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 1.0222725868225098, \"arousal_loss\": 1.0337412357330322, \"emotion_loss\": 1.6428442001342773, \"time_take\": 29.325220108032227}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0062460899353027, \"arousal_loss\": 0.8647741675376892, \"emotion_loss\": 1.3836551904678345, \"time_take\": 29.49704647064209}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.1025826930999756, \"arousal_loss\": 0.8629254102706909, \"emotion_loss\": 1.3235960006713867, \"time_take\": 29.75048542022705}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.1502636671066284, \"arousal_loss\": 0.9780069589614868, \"emotion_loss\": 1.3499500751495361, \"time_take\": 30.067508220672607}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0129048824310303, \"arousal_loss\": 0.840603232383728, \"emotion_loss\": 1.556762456893921, \"time_take\": 30.237209796905518}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.9380518198013306, \"arousal_loss\": 0.743587851524353, \"emotion_loss\": 1.2295968532562256, \"time_take\": 30.42068362236023}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0512351989746094, \"arousal_loss\": 0.682600736618042, \"emotion_loss\": 1.1952650547027588, \"time_take\": 30.64062213897705}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.178990364074707, \"arousal_loss\": 1.016263723373413, \"emotion_loss\": 1.4208253622055054, \"time_take\": 30.822036743164062}\n",
      "{\"emotion_correct\": 11, \"valence_loss\": 0.5875518321990967, \"arousal_loss\": 0.5959271788597107, \"emotion_loss\": 1.8519532680511475, \"time_take\": 31.043683767318726}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0616629123687744, \"arousal_loss\": 0.8359096646308899, \"emotion_loss\": 1.3472732305526733, \"time_take\": 31.38620686531067}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9346559047698975, \"arousal_loss\": 0.9537188410758972, \"emotion_loss\": 1.288149118423462, \"time_take\": 31.722670793533325}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.109443187713623, \"arousal_loss\": 0.8901488780975342, \"emotion_loss\": 1.3646395206451416, \"time_take\": 32.00535798072815}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9481046795845032, \"arousal_loss\": 0.781467080116272, \"emotion_loss\": 1.2651219367980957, \"time_take\": 32.29879641532898}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9299971461296082, \"arousal_loss\": 0.85149085521698, \"emotion_loss\": 1.6106390953063965, \"time_take\": 32.48333430290222}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9305440783500671, \"arousal_loss\": 0.7162125110626221, \"emotion_loss\": 1.2497106790542603, \"time_take\": 32.66887307167053}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.9848010540008545, \"arousal_loss\": 0.7763115763664246, \"emotion_loss\": 1.334946632385254, \"time_take\": 32.895315647125244}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0705596208572388, \"arousal_loss\": 0.8708276152610779, \"emotion_loss\": 1.1815353631973267, \"time_take\": 33.162320613861084}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.847588300704956, \"arousal_loss\": 0.80063796043396, \"emotion_loss\": 1.3471095561981201, \"time_take\": 33.469913721084595}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.1704216003417969, \"arousal_loss\": 0.882459282875061, \"emotion_loss\": 1.0916519165039062, \"time_take\": 33.643839597702026}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9315557479858398, \"arousal_loss\": 0.8194743394851685, \"emotion_loss\": 1.4501469135284424, \"time_take\": 33.80735397338867}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8976702690124512, \"arousal_loss\": 0.738324761390686, \"emotion_loss\": 1.276324987411499, \"time_take\": 34.06614422798157}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9370168447494507, \"arousal_loss\": 0.8517935872077942, \"emotion_loss\": 1.7654743194580078, \"time_take\": 34.24060535430908}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.2176434993743896, \"arousal_loss\": 0.9642350673675537, \"emotion_loss\": 1.0318622589111328, \"time_take\": 34.522767543792725}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.744994044303894, \"arousal_loss\": 0.42674654722213745, \"emotion_loss\": 1.2173521518707275, \"time_take\": 34.783379554748535}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.1699466705322266, \"arousal_loss\": 1.0658743381500244, \"emotion_loss\": 1.4266573190689087, \"time_take\": 34.98978233337402}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.8460114002227783, \"arousal_loss\": 0.6484497785568237, \"emotion_loss\": 0.9212117195129395, \"time_take\": 35.42491316795349}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.230797529220581, \"arousal_loss\": 0.9200643301010132, \"emotion_loss\": 1.2353720664978027, \"time_take\": 35.69984555244446}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0086537599563599, \"arousal_loss\": 0.8897738456726074, \"emotion_loss\": 1.4515303373336792, \"time_take\": 35.96624779701233}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.9857264757156372, \"arousal_loss\": 0.8688322305679321, \"emotion_loss\": 1.4873785972595215, \"time_take\": 36.25455665588379}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0198107957839966, \"arousal_loss\": 0.9289256930351257, \"emotion_loss\": 1.4054161310195923, \"time_take\": 36.489466190338135}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.1597485542297363, \"arousal_loss\": 0.9889570474624634, \"emotion_loss\": 1.1744797229766846, \"time_take\": 36.80591607093811}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.0965824127197266, \"arousal_loss\": 0.9681861400604248, \"emotion_loss\": 1.0189049243927002, \"time_take\": 37.01492929458618}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.6693180203437805, \"arousal_loss\": 0.5735825300216675, \"emotion_loss\": 1.2283796072006226, \"time_take\": 37.289273262023926}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.159571886062622, \"arousal_loss\": 1.047715663909912, \"emotion_loss\": 1.2186552286148071, \"time_take\": 37.57894253730774}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.002105474472046, \"arousal_loss\": 1.0251988172531128, \"emotion_loss\": 1.7692806720733643, \"time_take\": 37.865254640579224}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.094419240951538, \"arousal_loss\": 0.744651198387146, \"emotion_loss\": 1.257392168045044, \"time_take\": 38.09324598312378}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.8826528787612915, \"arousal_loss\": 0.7135885953903198, \"emotion_loss\": 1.1208503246307373, \"time_take\": 38.33882665634155}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0315091609954834, \"arousal_loss\": 0.765883207321167, \"emotion_loss\": 1.5102059841156006, \"time_take\": 38.574156284332275}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.7372934222221375, \"arousal_loss\": 0.6222438216209412, \"emotion_loss\": 1.3539440631866455, \"time_take\": 38.83251357078552}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1804966926574707, \"arousal_loss\": 0.892842710018158, \"emotion_loss\": 1.3146426677703857, \"time_take\": 39.07025361061096}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8471964001655579, \"arousal_loss\": 0.6584377288818359, \"emotion_loss\": 1.1344846487045288, \"time_take\": 39.319677114486694}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.8680821657180786, \"arousal_loss\": 0.7424339056015015, \"emotion_loss\": 1.2854664325714111, \"time_take\": 39.552977323532104}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.1975799798965454, \"arousal_loss\": 1.0112353563308716, \"emotion_loss\": 1.4966744184494019, \"time_take\": 39.74103331565857}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.8062273859977722, \"arousal_loss\": 0.6672737002372742, \"emotion_loss\": 1.166128158569336, \"time_take\": 40.022481203079224}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9615222215652466, \"arousal_loss\": 0.8672041893005371, \"emotion_loss\": 1.6435189247131348, \"time_take\": 40.301098346710205}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2191381454467773, \"arousal_loss\": 1.0335361957550049, \"emotion_loss\": 1.138778567314148, \"time_take\": 40.54243493080139}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.827662467956543, \"arousal_loss\": 0.5733834505081177, \"emotion_loss\": 1.0488879680633545, \"time_take\": 40.83232522010803}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.2355034351348877, \"arousal_loss\": 0.8424631357192993, \"emotion_loss\": 0.9995455741882324, \"time_take\": 41.09494638442993}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9094462394714355, \"arousal_loss\": 0.7269243597984314, \"emotion_loss\": 1.2399563789367676, \"time_take\": 41.347001791000366}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.8508040308952332, \"arousal_loss\": 0.6736345291137695, \"emotion_loss\": 1.1414024829864502, \"time_take\": 41.67621612548828}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0773494243621826, \"arousal_loss\": 0.8921056985855103, \"emotion_loss\": 1.3892595767974854, \"time_take\": 41.901949405670166}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.1373252868652344, \"arousal_loss\": 0.7988255023956299, \"emotion_loss\": 1.1083489656448364, \"time_take\": 42.18907141685486}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.0550172328948975, \"arousal_loss\": 0.8953373432159424, \"emotion_loss\": 0.9560455083847046, \"time_take\": 42.50099849700928}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9772063493728638, \"arousal_loss\": 0.861148476600647, \"emotion_loss\": 1.4092938899993896, \"time_take\": 42.83118462562561}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.1216349601745605, \"arousal_loss\": 0.8465245366096497, \"emotion_loss\": 1.58031165599823, \"time_take\": 43.150206327438354}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.15034818649292, \"arousal_loss\": 0.8512396812438965, \"emotion_loss\": 1.1926780939102173, \"time_take\": 43.36236047744751}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0005077123641968, \"arousal_loss\": 0.74896240234375, \"emotion_loss\": 1.4147441387176514, \"time_take\": 43.69379115104675}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8480247855186462, \"arousal_loss\": 0.60365229845047, \"emotion_loss\": 1.247532844543457, \"time_take\": 43.92796301841736}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.5848499536514282, \"arousal_loss\": 0.6002101302146912, \"emotion_loss\": 1.3923381567001343, \"time_take\": 44.1665313243866}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.7787156105041504, \"arousal_loss\": 0.5708515644073486, \"emotion_loss\": 1.3789618015289307, \"time_take\": 44.44538331031799}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.348069429397583, \"arousal_loss\": 1.092576503753662, \"emotion_loss\": 1.447956919670105, \"time_take\": 44.67123484611511}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.3935186862945557, \"arousal_loss\": 1.057047724723816, \"emotion_loss\": 1.484399676322937, \"time_take\": 44.89333248138428}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9426829218864441, \"arousal_loss\": 0.7235440015792847, \"emotion_loss\": 1.3624553680419922, \"time_take\": 45.1900532245636}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.2310460805892944, \"arousal_loss\": 0.9223940968513489, \"emotion_loss\": 1.07253098487854, \"time_take\": 45.44725322723389}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.7465293407440186, \"arousal_loss\": 0.6858989000320435, \"emotion_loss\": 1.3877131938934326, \"time_take\": 45.682193994522095}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.172694206237793, \"arousal_loss\": 1.0071532726287842, \"emotion_loss\": 1.4330573081970215, \"time_take\": 45.94418025016785}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9766409397125244, \"arousal_loss\": 0.6927485466003418, \"emotion_loss\": 1.2689664363861084, \"time_take\": 46.1659791469574}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.0116081237792969, \"arousal_loss\": 1.0275335311889648, \"emotion_loss\": 1.7504968643188477, \"time_take\": 46.36290383338928}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.9771113395690918, \"arousal_loss\": 0.6899375915527344, \"emotion_loss\": 1.0235103368759155, \"time_take\": 46.656344175338745}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9346521496772766, \"arousal_loss\": 0.8265164494514465, \"emotion_loss\": 1.5363783836364746, \"time_take\": 46.951547622680664}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.7819007635116577, \"arousal_loss\": 0.7674006223678589, \"emotion_loss\": 1.4864826202392578, \"time_take\": 47.17012977600098}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.0811541080474854, \"arousal_loss\": 1.051474690437317, \"emotion_loss\": 1.6276624202728271, \"time_take\": 47.36529731750488}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.035061001777649, \"arousal_loss\": 0.8501118421554565, \"emotion_loss\": 1.4409699440002441, \"time_take\": 47.6189124584198}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.9637913703918457, \"arousal_loss\": 0.8847140073776245, \"emotion_loss\": 1.4248570203781128, \"time_take\": 47.940537452697754}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9706258177757263, \"arousal_loss\": 0.7701870203018188, \"emotion_loss\": 1.2405160665512085, \"time_take\": 48.165207862854004}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.8654673099517822, \"arousal_loss\": 0.5389280915260315, \"emotion_loss\": 1.424361228942871, \"time_take\": 48.4439857006073}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.4766192436218262, \"arousal_loss\": 1.1194911003112793, \"emotion_loss\": 1.1853902339935303, \"time_take\": 48.67462182044983}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.101696252822876, \"arousal_loss\": 0.9055762887001038, \"emotion_loss\": 1.2680349349975586, \"time_take\": 48.94568467140198}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.1340007781982422, \"arousal_loss\": 1.0834342241287231, \"emotion_loss\": 1.0493505001068115, \"time_take\": 49.177740812301636}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.81241375207901, \"arousal_loss\": 0.6822904348373413, \"emotion_loss\": 1.612077236175537, \"time_take\": 49.413753271102905}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9168798923492432, \"arousal_loss\": 0.6188321113586426, \"emotion_loss\": 1.3101086616516113, \"time_take\": 49.71176481246948}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.9510670900344849, \"arousal_loss\": 0.8037450909614563, \"emotion_loss\": 1.5767987966537476, \"time_take\": 50.217230558395386}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.2607452869415283, \"arousal_loss\": 1.0273029804229736, \"emotion_loss\": 0.9381897449493408, \"time_take\": 50.41525864601135}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.1786999702453613, \"arousal_loss\": 0.8515411615371704, \"emotion_loss\": 1.040784478187561, \"time_take\": 50.6771137714386}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.027649998664856, \"arousal_loss\": 0.9891904592514038, \"emotion_loss\": 1.474621295928955, \"time_take\": 50.926851749420166}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8823927640914917, \"arousal_loss\": 0.7559491395950317, \"emotion_loss\": 1.3214058876037598, \"time_take\": 51.23751950263977}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9437199831008911, \"arousal_loss\": 0.7957077026367188, \"emotion_loss\": 1.3016732931137085, \"time_take\": 51.46791338920593}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.3664133548736572, \"arousal_loss\": 1.1467182636260986, \"emotion_loss\": 1.1869672536849976, \"time_take\": 51.773839473724365}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8031901121139526, \"arousal_loss\": 0.7257084846496582, \"emotion_loss\": 1.3255354166030884, \"time_take\": 52.086790800094604}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9199886322021484, \"arousal_loss\": 0.7632986903190613, \"emotion_loss\": 1.2125189304351807, \"time_take\": 52.40397763252258}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9061601161956787, \"arousal_loss\": 0.8030860424041748, \"emotion_loss\": 1.2908477783203125, \"time_take\": 52.596261501312256}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.8509013652801514, \"arousal_loss\": 0.5323800444602966, \"emotion_loss\": 1.3392380475997925, \"time_take\": 52.82958102226257}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8200164437294006, \"arousal_loss\": 0.669581413269043, \"emotion_loss\": 1.282392144203186, \"time_take\": 53.06975197792053}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9066872000694275, \"arousal_loss\": 0.7268310189247131, \"emotion_loss\": 1.460233449935913, \"time_take\": 53.33095049858093}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.5907028913497925, \"arousal_loss\": 1.2609211206436157, \"emotion_loss\": 1.1726142168045044, \"time_take\": 53.71831130981445}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9699397087097168, \"arousal_loss\": 0.757647693157196, \"emotion_loss\": 1.155256748199463, \"time_take\": 53.97740864753723}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8424865007400513, \"arousal_loss\": 0.7923278212547302, \"emotion_loss\": 1.4579368829727173, \"time_take\": 54.21399402618408}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0196577310562134, \"arousal_loss\": 0.93108069896698, \"emotion_loss\": 1.386181116104126, \"time_take\": 54.48776626586914}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8946373462677002, \"arousal_loss\": 0.7269231081008911, \"emotion_loss\": 1.208390474319458, \"time_take\": 54.70667624473572}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2141170501708984, \"arousal_loss\": 0.8956661820411682, \"emotion_loss\": 1.0970829725265503, \"time_take\": 55.038875102996826}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.936637282371521, \"arousal_loss\": 0.7238386869430542, \"emotion_loss\": 0.9982385039329529, \"time_take\": 55.28449869155884}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9637715220451355, \"arousal_loss\": 0.7820143103599548, \"emotion_loss\": 1.12025785446167, \"time_take\": 55.49804997444153}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.990353524684906, \"arousal_loss\": 0.7444453835487366, \"emotion_loss\": 1.1912013292312622, \"time_take\": 55.68486261367798}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.1530190706253052, \"arousal_loss\": 0.9717841148376465, \"emotion_loss\": 1.1680567264556885, \"time_take\": 55.98106646537781}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.8947045207023621, \"arousal_loss\": 0.9065790176391602, \"emotion_loss\": 1.58381986618042, \"time_take\": 56.20139741897583}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2180888652801514, \"arousal_loss\": 0.9599458575248718, \"emotion_loss\": 1.298576831817627, \"time_take\": 56.5926570892334}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8326045274734497, \"arousal_loss\": 0.7877482175827026, \"emotion_loss\": 1.5167466402053833, \"time_take\": 56.88458061218262}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.7725374698638916, \"arousal_loss\": 0.6690112352371216, \"emotion_loss\": 1.0448939800262451, \"time_take\": 57.10827016830444}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8371511697769165, \"arousal_loss\": 0.8792153596878052, \"emotion_loss\": 1.3714526891708374, \"time_take\": 57.443092823028564}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.2072265148162842, \"arousal_loss\": 0.9675835371017456, \"emotion_loss\": 0.9432225823402405, \"time_take\": 57.739051818847656}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.1894689798355103, \"arousal_loss\": 0.9412394762039185, \"emotion_loss\": 1.1110444068908691, \"time_take\": 58.003416776657104}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8744723796844482, \"arousal_loss\": 0.756059467792511, \"emotion_loss\": 1.207165241241455, \"time_take\": 58.25943970680237}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.7535510063171387, \"arousal_loss\": 0.4027858078479767, \"emotion_loss\": 1.0291842222213745, \"time_take\": 58.541441202163696}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 0.5552327036857605, \"arousal_loss\": 0.3358636200428009, \"emotion_loss\": 1.0274052619934082, \"time_take\": 58.84446430206299}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.9515863060951233, \"arousal_loss\": 0.8071097731590271, \"emotion_loss\": 1.445624828338623, \"time_take\": 59.160988330841064}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.47312942147254944, \"arousal_loss\": 0.24690395593643188, \"emotion_loss\": 1.2843825817108154, \"time_take\": 59.505741119384766}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.9953017234802246, \"arousal_loss\": 0.6915818452835083, \"emotion_loss\": 1.220219612121582, \"time_take\": 59.801063776016235}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.2588263750076294, \"arousal_loss\": 1.1511223316192627, \"emotion_loss\": 1.5995452404022217, \"time_take\": 60.06197714805603}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9938292503356934, \"arousal_loss\": 0.7749858498573303, \"emotion_loss\": 1.2265253067016602, \"time_take\": 60.29817080497742}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.3313381671905518, \"arousal_loss\": 0.9895331859588623, \"emotion_loss\": 1.3306397199630737, \"time_take\": 60.493836879730225}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.1605079174041748, \"arousal_loss\": 0.9472945928573608, \"emotion_loss\": 1.4693446159362793, \"time_take\": 60.75948786735535}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 0.7897642850875854, \"arousal_loss\": 0.5363885164260864, \"emotion_loss\": 1.080759048461914, \"time_take\": 61.065587520599365}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.7468669414520264, \"arousal_loss\": 0.4979737102985382, \"emotion_loss\": 1.1953824758529663, \"time_take\": 61.28905653953552}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.9064878821372986, \"arousal_loss\": 0.5987415313720703, \"emotion_loss\": 0.870692253112793, \"time_take\": 61.61705040931702}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8037381172180176, \"arousal_loss\": 0.6856884956359863, \"emotion_loss\": 1.2887130975723267, \"time_take\": 61.91313815116882}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.3908817768096924, \"arousal_loss\": 1.1588609218597412, \"emotion_loss\": 1.3030098676681519, \"time_take\": 62.163071155548096}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.058504581451416, \"arousal_loss\": 0.8708724975585938, \"emotion_loss\": 1.393214464187622, \"time_take\": 62.37874674797058}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.5629206895828247, \"arousal_loss\": 0.4300118088722229, \"emotion_loss\": 1.366220235824585, \"time_take\": 62.585331201553345}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.9879864454269409, \"arousal_loss\": 0.8359452486038208, \"emotion_loss\": 1.768244743347168, \"time_take\": 62.85914444923401}\n"
     ]
    }
   ],
   "source": [
    "from telegram_notifier import send_message\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_step = 0\n",
    "    total_emotion_correct = 0\n",
    "    total_valence_loss = 0\n",
    "    total_arousal_loss = 0\n",
    "    total_emotion_loss = 0\n",
    "    total_process = 0\n",
    "    for step, row in enumerate(DataFrameBatchIterator(train_df, batch_size=batch_size)):\n",
    "\n",
    "        imgs = row.subDirectory_filePath.apply(lambda x: cv2.resize(\n",
    "            cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2RGB), (224, 224)))\n",
    "        img_array = np.array(list(imgs))\n",
    "\n",
    "        y_valence = np.array(row.valence)\n",
    "        y_arousal = np.array(row.arousal)\n",
    "        y_emotion = np.array(row.expression)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(img_array, training=True)\n",
    "\n",
    "            pred_valence = logits[0]\n",
    "            pred_arousal = logits[1]\n",
    "            pred_emotion = logits[2]\n",
    "\n",
    "            valence_loss = MSE_loss(y_valence, pred_valence)\n",
    "            arousal_loss = MSE_loss(y_arousal, pred_arousal)\n",
    "            emotion_loss = SCC_loss(y_emotion, pred_emotion)\n",
    "\n",
    "            loss = valence_loss + arousal_loss + emotion_loss\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_weights)\n",
    "\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        total_loss += float(loss)\n",
    "        total_step += 1\n",
    "        \n",
    "        total_process += len(row)\n",
    "\n",
    "        valence_loss = float(valence_loss)\n",
    "        arousal_loss = float(arousal_loss)\n",
    "        emotion_loss = float(emotion_loss)\n",
    "        \n",
    "        total_valence_loss += valence_loss\n",
    "        total_arousal_loss += arousal_loss\n",
    "        total_emotion_loss += emotion_loss\n",
    "        \n",
    "        emotion_correct = int(sum(pred_emotion.numpy().argmax(axis = 1) == y_emotion))\n",
    "        total_emotion_correct += emotion_correct\n",
    "        \n",
    "        log = {\n",
    "            'emotion_correct': emotion_correct,\n",
    "            'valence_loss': valence_loss,\n",
    "            'arousal_loss': arousal_loss,\n",
    "            'emotion_loss': emotion_loss,\n",
    "            'time_take': time.time() - start_time\n",
    "        }\n",
    "        log = json.dumps(log)\n",
    "        lprint(log)\n",
    "    save_model_path = f\"models/{now_time_string}_{description}_epoch{epoch}_batch_{batch_size}\"\n",
    "    model.save(save_model_path)\n",
    "    lprint(f\"Save {save_model_path}\")\n",
    "    send_message(f\"Save {save_model_path}\\nepoch {epoch} is finish\")\n",
    "    log = {\n",
    "        'model_path': save_model_path,\n",
    "        'total_emotion_correct': total_emotion_correct,\n",
    "        'total_loss': total_loss,\n",
    "        'total_valence_loss': total_valence_loss,\n",
    "        'total_arousal_loss': total_arousal_loss,\n",
    "        'total_emotion_loss': total_emotion_loss,\n",
    "        'total_process': total_process,\n",
    "        'time_take': time.time() - start_time\n",
    "    }\n",
    "    log = json.dumps(log)\n",
    "    lprint(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "tf27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
