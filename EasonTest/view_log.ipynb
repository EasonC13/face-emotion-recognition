{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:10:32.575728Z",
     "start_time": "2022-01-20T03:10:32.120673Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:00:47.882528Z",
     "start_time": "2022-01-20T03:00:47.875522Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./01_19_22:57:20.log\") as f:\n",
    "    logs = f.readlines()\n",
    "    logs = logs[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:00:48.150859Z",
     "start_time": "2022-01-20T03:00:48.145176Z"
    }
   },
   "outputs": [],
   "source": [
    "logs = \"\\n\".join(logs)\n",
    "logs = logs.split('img this iter ---\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:00:50.128159Z",
     "start_time": "2022-01-20T03:00:50.124511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5085"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:01:14.778008Z",
     "start_time": "2022-01-20T03:01:14.773428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:09:38.377423Z",
     "start_time": "2022-01-20T03:09:38.375035Z"
    }
   },
   "outputs": [],
   "source": [
    "log = logs[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:16:18.599668Z",
     "start_time": "2022-01-20T03:16:18.595803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:17:23.122820Z",
     "start_time": "2022-01-20T03:17:22.572531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_19_22:57:23 Training loss at epoch 0 step 0: 8.087566375732422\n",
      "\n",
      " This round's valence_loss=2.7215681076049805, arousal_loss=2.8208649158477783, emotion_loss=2.545133113861084\n",
      "\n",
      "01_19_22:57:23 Seen so far: 32 samples\n",
      "\n",
      "01_19_22:57:23 --- 2.6277694702148438 seconds for iter 1 step, each step have 32, so the model train with 32 \n",
      "01_19_22:57:25 Training loss at epoch 0 step 10: 3.6479535579681395\n",
      "\n",
      " This round's valence_loss=0.7429653406143188, arousal_loss=0.5692674517631531, emotion_loss=0.9357542991638184\n",
      "\n",
      "01_19_22:57:25 Seen so far: 352 samples\n",
      "\n",
      "01_19_22:57:25 --- 2.347302198410034 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:28 Training loss at epoch 0 step 20: 3.7847675561904905\n",
      "\n",
      " This round's valence_loss=1.137237310409546, arousal_loss=0.9827213287353516, emotion_loss=1.3837642669677734\n",
      "\n",
      "01_19_22:57:28 Seen so far: 672 samples\n",
      "\n",
      "01_19_22:57:28 --- 2.1026318073272705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:30 Training loss at epoch 0 step 30: 3.559966230392456\n",
      "\n",
      " This round's valence_loss=1.1112358570098877, arousal_loss=0.962652325630188, emotion_loss=1.4571177959442139\n",
      "\n",
      "01_19_22:57:30 Seen so far: 992 samples\n",
      "\n",
      "01_19_22:57:30 --- 2.027730941772461 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:32 Training loss at epoch 0 step 40: 3.605144238471985\n",
      "\n",
      " This round's valence_loss=0.9650636315345764, arousal_loss=0.8533121943473816, emotion_loss=1.5421113967895508\n",
      "\n",
      "01_19_22:57:32 Seen so far: 1312 samples\n",
      "\n",
      "01_19_22:57:32 --- 2.1885528564453125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:34 Training loss at epoch 0 step 50: 3.2378413677215576\n",
      "\n",
      " This round's valence_loss=1.343108892440796, arousal_loss=1.2203395366668701, emotion_loss=1.4118895530700684\n",
      "\n",
      "01_19_22:57:34 Seen so far: 1632 samples\n",
      "\n",
      "01_19_22:57:34 --- 1.9736065864562988 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:36 Training loss at epoch 0 step 60: 3.3942621469497682\n",
      "\n",
      " This round's valence_loss=0.9488053321838379, arousal_loss=0.8699268102645874, emotion_loss=1.139660358428955\n",
      "\n",
      "01_19_22:57:36 Seen so far: 1952 samples\n",
      "\n",
      "01_19_22:57:36 --- 2.0629007816314697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:38 Training loss at epoch 0 step 70: 2.9871278285980223\n",
      "\n",
      " This round's valence_loss=0.5894240140914917, arousal_loss=0.34761083126068115, emotion_loss=0.9487240314483643\n",
      "\n",
      "01_19_22:57:38 Seen so far: 2272 samples\n",
      "\n",
      "01_19_22:57:38 --- 1.982588291168213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:40 Training loss at epoch 0 step 80: 3.44778391122818\n",
      "\n",
      " This round's valence_loss=1.8049993515014648, arousal_loss=1.7222485542297363, emotion_loss=1.1974027156829834\n",
      "\n",
      "01_19_22:57:40 Seen so far: 2592 samples\n",
      "\n",
      "01_19_22:57:40 --- 1.9894287586212158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:42 Training loss at epoch 0 step 90: 3.1803644418716432\n",
      "\n",
      " This round's valence_loss=1.3217469453811646, arousal_loss=1.1781771183013916, emotion_loss=1.0100326538085938\n",
      "\n",
      "01_19_22:57:42 Seen so far: 2912 samples\n",
      "\n",
      "01_19_22:57:42 --- 1.8811063766479492 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:44 Training loss at epoch 0 step 100: 3.3524526596069335\n",
      "\n",
      " This round's valence_loss=0.595697283744812, arousal_loss=0.4894208312034607, emotion_loss=1.3029413223266602\n",
      "\n",
      "01_19_22:57:44 Seen so far: 3232 samples\n",
      "\n",
      "01_19_22:57:44 --- 1.9817016124725342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:46 Training loss at epoch 0 step 110: 3.534974217414856\n",
      "\n",
      " This round's valence_loss=1.2486215829849243, arousal_loss=1.09438157081604, emotion_loss=1.3239243030548096\n",
      "\n",
      "01_19_22:57:46 Seen so far: 3552 samples\n",
      "\n",
      "01_19_22:57:46 --- 2.0937514305114746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:48 Training loss at epoch 0 step 120: 3.4369171380996706\n",
      "\n",
      " This round's valence_loss=1.0703883171081543, arousal_loss=0.9782328605651855, emotion_loss=1.7222354412078857\n",
      "\n",
      "01_19_22:57:48 Seen so far: 3872 samples\n",
      "\n",
      "01_19_22:57:48 --- 1.9621241092681885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:49 Training loss at epoch 0 step 130: 3.206628608703613\n",
      "\n",
      " This round's valence_loss=0.5922397971153259, arousal_loss=0.3440098464488983, emotion_loss=1.1992560625076294\n",
      "\n",
      "01_19_22:57:49 Seen so far: 4192 samples\n",
      "\n",
      "01_19_22:57:49 --- 1.7759284973144531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:52 Training loss at epoch 0 step 140: 3.4076441049575807\n",
      "\n",
      " This round's valence_loss=1.3408281803131104, arousal_loss=1.2309372425079346, emotion_loss=1.1256663799285889\n",
      "\n",
      "01_19_22:57:52 Seen so far: 4512 samples\n",
      "\n",
      "01_19_22:57:52 --- 2.194783926010132 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:54 Training loss at epoch 0 step 150: 3.2274303674697875\n",
      "\n",
      " This round's valence_loss=0.8369686603546143, arousal_loss=0.7147949934005737, emotion_loss=1.057942509651184\n",
      "\n",
      "01_19_22:57:54 Seen so far: 4832 samples\n",
      "\n",
      "01_19_22:57:54 --- 1.9551279544830322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:56 Training loss at epoch 0 step 160: 3.1769290208816527\n",
      "\n",
      " This round's valence_loss=1.0156934261322021, arousal_loss=0.9039025902748108, emotion_loss=1.3207147121429443\n",
      "\n",
      "01_19_22:57:56 Seen so far: 5152 samples\n",
      "\n",
      "01_19_22:57:56 --- 2.290714979171753 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:57:58 Training loss at epoch 0 step 170: 3.4759958267211912\n",
      "\n",
      " This round's valence_loss=1.36599862575531, arousal_loss=1.2141237258911133, emotion_loss=1.0610206127166748\n",
      "\n",
      "01_19_22:57:58 Seen so far: 5472 samples\n",
      "\n",
      "01_19_22:57:58 --- 2.1300106048583984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:00 Training loss at epoch 0 step 180: 3.455745315551758\n",
      "\n",
      " This round's valence_loss=1.0788335800170898, arousal_loss=0.9632978439331055, emotion_loss=1.431946873664856\n",
      "\n",
      "01_19_22:58:00 Seen so far: 5792 samples\n",
      "\n",
      "01_19_22:58:00 --- 1.8468396663665771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:02 Training loss at epoch 0 step 190: 3.384568929672241\n",
      "\n",
      " This round's valence_loss=1.1660685539245605, arousal_loss=0.9579459428787231, emotion_loss=1.015344262123108\n",
      "\n",
      "01_19_22:58:02 Seen so far: 6112 samples\n",
      "\n",
      "01_19_22:58:02 --- 2.1366281509399414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:04 Training loss at epoch 0 step 200: 3.1944773197174072\n",
      "\n",
      " This round's valence_loss=0.9679152369499207, arousal_loss=0.8497365117073059, emotion_loss=1.4977352619171143\n",
      "\n",
      "01_19_22:58:04 Seen so far: 6432 samples\n",
      "\n",
      "01_19_22:58:04 --- 1.9113121032714844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:06 Training loss at epoch 0 step 210: 3.3734150171279906\n",
      "\n",
      " This round's valence_loss=1.231447458267212, arousal_loss=1.10455322265625, emotion_loss=1.1575713157653809\n",
      "\n",
      "01_19_22:58:06 Seen so far: 6752 samples\n",
      "\n",
      "01_19_22:58:06 --- 1.8865702152252197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:08 Training loss at epoch 0 step 220: 2.9623408794403074\n",
      "\n",
      " This round's valence_loss=0.4893176555633545, arousal_loss=0.33298254013061523, emotion_loss=0.9862039089202881\n",
      "\n",
      "01_19_22:58:08 Seen so far: 7072 samples\n",
      "\n",
      "01_19_22:58:08 --- 1.9593520164489746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:10 Training loss at epoch 0 step 230: 3.149721956253052\n",
      "\n",
      " This round's valence_loss=0.918788492679596, arousal_loss=0.6813002824783325, emotion_loss=0.8480582237243652\n",
      "\n",
      "01_19_22:58:10 Seen so far: 7392 samples\n",
      "\n",
      "01_19_22:58:10 --- 2.025937557220459 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:12 Training loss at epoch 0 step 240: 3.2858890771865843\n",
      "\n",
      " This round's valence_loss=1.1515443325042725, arousal_loss=0.9706906080245972, emotion_loss=1.1968574523925781\n",
      "\n",
      "01_19_22:58:12 Seen so far: 7712 samples\n",
      "\n",
      "01_19_22:58:12 --- 1.8859872817993164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:14 Training loss at epoch 0 step 250: 3.558786916732788\n",
      "\n",
      " This round's valence_loss=1.326014518737793, arousal_loss=1.2610974311828613, emotion_loss=1.5456318855285645\n",
      "\n",
      "01_19_22:58:14 Seen so far: 8032 samples\n",
      "\n",
      "01_19_22:58:14 --- 1.901076078414917 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:15 Training loss at epoch 0 step 260: 3.278078866004944\n",
      "\n",
      " This round's valence_loss=0.9526187181472778, arousal_loss=0.8637655973434448, emotion_loss=1.2474005222320557\n",
      "\n",
      "01_19_22:58:15 Seen so far: 8352 samples\n",
      "\n",
      "01_19_22:58:15 --- 1.8880746364593506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:17 Training loss at epoch 0 step 270: 3.3824854612350466\n",
      "\n",
      " This round's valence_loss=1.766801357269287, arousal_loss=1.6548329591751099, emotion_loss=1.4955649375915527\n",
      "\n",
      "01_19_22:58:17 Seen so far: 8672 samples\n",
      "\n",
      "01_19_22:58:17 --- 1.7651243209838867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:19 Training loss at epoch 0 step 280: 3.260471153259277\n",
      "\n",
      " This round's valence_loss=1.0176067352294922, arousal_loss=0.8284751772880554, emotion_loss=1.2493603229522705\n",
      "\n",
      "01_19_22:58:19 Seen so far: 8992 samples\n",
      "\n",
      "01_19_22:58:19 --- 1.774977445602417 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:21 Training loss at epoch 0 step 290: 3.2881999015808105\n",
      "\n",
      " This round's valence_loss=1.0736452341079712, arousal_loss=1.0141819715499878, emotion_loss=1.3587772846221924\n",
      "\n",
      "01_19_22:58:21 Seen so far: 9312 samples\n",
      "\n",
      "01_19_22:58:21 --- 2.0355875492095947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:23 Training loss at epoch 0 step 300: 3.1579426765441894\n",
      "\n",
      " This round's valence_loss=1.1131407022476196, arousal_loss=0.9811697006225586, emotion_loss=1.0033588409423828\n",
      "\n",
      "01_19_22:58:23 Seen so far: 9632 samples\n",
      "\n",
      "01_19_22:58:23 --- 2.070061206817627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:25 Training loss at epoch 0 step 310: 3.2440842390060425\n",
      "\n",
      " This round's valence_loss=0.9452125430107117, arousal_loss=0.8169279098510742, emotion_loss=1.0282951593399048\n",
      "\n",
      "01_19_22:58:25 Seen so far: 9952 samples\n",
      "\n",
      "01_19_22:58:25 --- 1.8989760875701904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:27 Training loss at epoch 0 step 320: 3.369072961807251\n",
      "\n",
      " This round's valence_loss=0.8344310522079468, arousal_loss=0.6945657730102539, emotion_loss=0.9502872824668884\n",
      "\n",
      "01_19_22:58:27 Seen so far: 10272 samples\n",
      "\n",
      "01_19_22:58:27 --- 2.0530648231506348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:29 Training loss at epoch 0 step 330: 3.161016511917114\n",
      "\n",
      " This round's valence_loss=0.9921647310256958, arousal_loss=0.7942370176315308, emotion_loss=1.2408456802368164\n",
      "\n",
      "01_19_22:58:29 Seen so far: 10592 samples\n",
      "\n",
      "01_19_22:58:29 --- 2.0144588947296143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:31 Training loss at epoch 0 step 340: 3.379632830619812\n",
      "\n",
      " This round's valence_loss=1.2603778839111328, arousal_loss=1.065676212310791, emotion_loss=1.3062140941619873\n",
      "\n",
      "01_19_22:58:31 Seen so far: 10912 samples\n",
      "\n",
      "01_19_22:58:31 --- 1.9976186752319336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:33 Training loss at epoch 0 step 350: 3.1216281175613405\n",
      "\n",
      " This round's valence_loss=1.3009133338928223, arousal_loss=1.2102919816970825, emotion_loss=1.5379770994186401\n",
      "\n",
      "01_19_22:58:33 Seen so far: 11232 samples\n",
      "\n",
      "01_19_22:58:33 --- 2.038238525390625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:35 Training loss at epoch 0 step 360: 3.669617199897766\n",
      "\n",
      " This round's valence_loss=1.0927438735961914, arousal_loss=1.0121325254440308, emotion_loss=1.4343669414520264\n",
      "\n",
      "01_19_22:58:35 Seen so far: 11552 samples\n",
      "\n",
      "01_19_22:58:35 --- 1.7833571434020996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:37 Training loss at epoch 0 step 370: 3.421248435974121\n",
      "\n",
      " This round's valence_loss=1.359622597694397, arousal_loss=1.2299437522888184, emotion_loss=1.1183524131774902\n",
      "\n",
      "01_19_22:58:37 Seen so far: 11872 samples\n",
      "\n",
      "01_19_22:58:37 --- 2.202838897705078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:39 Training loss at epoch 0 step 380: 3.513794493675232\n",
      "\n",
      " This round's valence_loss=1.127530574798584, arousal_loss=0.9353821277618408, emotion_loss=1.4678891897201538\n",
      "\n",
      "01_19_22:58:39 Seen so far: 12192 samples\n",
      "\n",
      "01_19_22:58:39 --- 1.8790674209594727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:41 Training loss at epoch 0 step 390: 3.3661821365356444\n",
      "\n",
      " This round's valence_loss=1.1661107540130615, arousal_loss=0.980734646320343, emotion_loss=1.351022720336914\n",
      "\n",
      "01_19_22:58:41 Seen so far: 12512 samples\n",
      "\n",
      "01_19_22:58:41 --- 1.8669819831848145 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:43 Training loss at epoch 0 step 400: 3.0600129127502442\n",
      "\n",
      " This round's valence_loss=1.0058308839797974, arousal_loss=0.8799483776092529, emotion_loss=0.972283124923706\n",
      "\n",
      "01_19_22:58:43 Seen so far: 12832 samples\n",
      "\n",
      "01_19_22:58:43 --- 1.9436109066009521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:45 Training loss at epoch 0 step 410: 3.283511018753052\n",
      "\n",
      " This round's valence_loss=1.2404444217681885, arousal_loss=1.0877900123596191, emotion_loss=1.5632036924362183\n",
      "\n",
      "01_19_22:58:45 Seen so far: 13152 samples\n",
      "\n",
      "01_19_22:58:45 --- 2.059277057647705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:47 Training loss at epoch 0 step 420: 3.638983726501465\n",
      "\n",
      " This round's valence_loss=1.1098421812057495, arousal_loss=0.9332726001739502, emotion_loss=1.1177420616149902\n",
      "\n",
      "01_19_22:58:47 Seen so far: 13472 samples\n",
      "\n",
      "01_19_22:58:47 --- 1.973938226699829 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:49 Training loss at epoch 0 step 430: 3.0157044887542725\n",
      "\n",
      " This round's valence_loss=0.7456310987472534, arousal_loss=0.5789509415626526, emotion_loss=1.7950934171676636\n",
      "\n",
      "01_19_22:58:49 Seen so far: 13792 samples\n",
      "\n",
      "01_19_22:58:49 --- 1.999014139175415 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:51 Training loss at epoch 0 step 440: 3.1830994129180907\n",
      "\n",
      " This round's valence_loss=0.43567776679992676, arousal_loss=0.235545814037323, emotion_loss=0.9360005855560303\n",
      "\n",
      "01_19_22:58:51 Seen so far: 14112 samples\n",
      "\n",
      "01_19_22:58:51 --- 1.96004056930542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:53 Training loss at epoch 0 step 450: 3.478993558883667\n",
      "\n",
      " This round's valence_loss=1.374651312828064, arousal_loss=1.2665327787399292, emotion_loss=1.7339003086090088\n",
      "\n",
      "01_19_22:58:53 Seen so far: 14432 samples\n",
      "\n",
      "01_19_22:58:53 --- 1.953763723373413 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:55 Training loss at epoch 0 step 460: 3.4402928590774535\n",
      "\n",
      " This round's valence_loss=1.063598871231079, arousal_loss=0.9514806270599365, emotion_loss=0.9901179075241089\n",
      "\n",
      "01_19_22:58:55 Seen so far: 14752 samples\n",
      "\n",
      "01_19_22:58:55 --- 1.8292958736419678 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:56 Training loss at epoch 0 step 470: 3.5810205936431885\n",
      "\n",
      " This round's valence_loss=1.2105529308319092, arousal_loss=1.071655511856079, emotion_loss=1.4296467304229736\n",
      "\n",
      "01_19_22:58:56 Seen so far: 15072 samples\n",
      "\n",
      "01_19_22:58:56 --- 1.8406150341033936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:58:58 Training loss at epoch 0 step 480: 3.2610467672348022\n",
      "\n",
      " This round's valence_loss=0.835120677947998, arousal_loss=0.7793155908584595, emotion_loss=1.8824353218078613\n",
      "\n",
      "01_19_22:58:58 Seen so far: 15392 samples\n",
      "\n",
      "01_19_22:58:58 --- 1.977672815322876 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:00 Training loss at epoch 0 step 490: 3.0053256273269655\n",
      "\n",
      " This round's valence_loss=1.006301999092102, arousal_loss=0.8050929307937622, emotion_loss=1.3613073825836182\n",
      "\n",
      "01_19_22:59:00 Seen so far: 15712 samples\n",
      "\n",
      "01_19_22:59:00 --- 1.7801449298858643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:02 Training loss at epoch 0 step 500: 3.46353542804718\n",
      "\n",
      " This round's valence_loss=0.7780333757400513, arousal_loss=0.5994935035705566, emotion_loss=1.324258804321289\n",
      "\n",
      "01_19_22:59:02 Seen so far: 16032 samples\n",
      "\n",
      "01_19_22:59:02 --- 2.213635206222534 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:04 Training loss at epoch 0 step 510: 3.498139238357544\n",
      "\n",
      " This round's valence_loss=1.5061415433883667, arousal_loss=1.340101957321167, emotion_loss=1.0868754386901855\n",
      "\n",
      "01_19_22:59:04 Seen so far: 16352 samples\n",
      "\n",
      "01_19_22:59:04 --- 2.0485880374908447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:06 Training loss at epoch 0 step 520: 3.301868033409119\n",
      "\n",
      " This round's valence_loss=1.0156890153884888, arousal_loss=0.8212178945541382, emotion_loss=1.0520787239074707\n",
      "\n",
      "01_19_22:59:06 Seen so far: 16672 samples\n",
      "\n",
      "01_19_22:59:06 --- 2.0464303493499756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:08 Training loss at epoch 0 step 530: 3.1456849336624146\n",
      "\n",
      " This round's valence_loss=0.8508754968643188, arousal_loss=0.7267066836357117, emotion_loss=1.5627813339233398\n",
      "\n",
      "01_19_22:59:08 Seen so far: 16992 samples\n",
      "\n",
      "01_19_22:59:08 --- 1.9956815242767334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:10 Training loss at epoch 0 step 540: 3.445493221282959\n",
      "\n",
      " This round's valence_loss=1.1362687349319458, arousal_loss=0.9950169324874878, emotion_loss=0.9947799444198608\n",
      "\n",
      "01_19_22:59:10 Seen so far: 17312 samples\n",
      "\n",
      "01_19_22:59:10 --- 1.989992380142212 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:13 Training loss at epoch 0 step 550: 3.386140012741089\n",
      "\n",
      " This round's valence_loss=0.7352956533432007, arousal_loss=0.6083176136016846, emotion_loss=1.2839012145996094\n",
      "\n",
      "01_19_22:59:13 Seen so far: 17632 samples\n",
      "\n",
      "01_19_22:59:13 --- 2.1147918701171875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:15 Training loss at epoch 0 step 560: 2.986514449119568\n",
      "\n",
      " This round's valence_loss=0.9072864055633545, arousal_loss=0.7544097900390625, emotion_loss=1.1697443723678589\n",
      "\n",
      "01_19_22:59:15 Seen so far: 17952 samples\n",
      "\n",
      "01_19_22:59:15 --- 2.0671448707580566 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:17 Training loss at epoch 0 step 570: 2.9676950454711912\n",
      "\n",
      " This round's valence_loss=0.8722290992736816, arousal_loss=0.6871706247329712, emotion_loss=1.0987142324447632\n",
      "\n",
      "01_19_22:59:17 Seen so far: 18272 samples\n",
      "\n",
      "01_19_22:59:17 --- 1.893279790878296 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:19 Training loss at epoch 0 step 580: 3.1453047513961794\n",
      "\n",
      " This round's valence_loss=1.2704355716705322, arousal_loss=1.1273090839385986, emotion_loss=1.3119845390319824\n",
      "\n",
      "01_19_22:59:19 Seen so far: 18592 samples\n",
      "\n",
      "01_19_22:59:19 --- 2.0901730060577393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:21 Training loss at epoch 0 step 590: 3.223522257804871\n",
      "\n",
      " This round's valence_loss=1.2215425968170166, arousal_loss=1.0670363903045654, emotion_loss=1.316657304763794\n",
      "\n",
      "01_19_22:59:21 Seen so far: 18912 samples\n",
      "\n",
      "01_19_22:59:21 --- 1.9910624027252197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:22 Training loss at epoch 0 step 600: 3.2179028749465943\n",
      "\n",
      " This round's valence_loss=1.172487497329712, arousal_loss=1.0911202430725098, emotion_loss=1.320852518081665\n",
      "\n",
      "01_19_22:59:22 Seen so far: 19232 samples\n",
      "\n",
      "01_19_22:59:22 --- 1.7910785675048828 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:24 Training loss at epoch 0 step 610: 3.443307662010193\n",
      "\n",
      " This round's valence_loss=0.7344193458557129, arousal_loss=0.6365041136741638, emotion_loss=1.4473488330841064\n",
      "\n",
      "01_19_22:59:24 Seen so far: 19552 samples\n",
      "\n",
      "01_19_22:59:24 --- 2.0055580139160156 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:27 Training loss at epoch 0 step 620: 3.1548829078674316\n",
      "\n",
      " This round's valence_loss=1.0035433769226074, arousal_loss=0.9488627910614014, emotion_loss=1.4520126581192017\n",
      "\n",
      "01_19_22:59:27 Seen so far: 19872 samples\n",
      "\n",
      "01_19_22:59:27 --- 2.0978965759277344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:28 Training loss at epoch 0 step 630: 3.3150168895721435\n",
      "\n",
      " This round's valence_loss=1.5406603813171387, arousal_loss=1.45261812210083, emotion_loss=1.3924660682678223\n",
      "\n",
      "01_19_22:59:28 Seen so far: 20192 samples\n",
      "\n",
      "01_19_22:59:28 --- 1.8558013439178467 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:30 Training loss at epoch 0 step 640: 3.161048436164856\n",
      "\n",
      " This round's valence_loss=0.7067769169807434, arousal_loss=0.4942416846752167, emotion_loss=1.7988450527191162\n",
      "\n",
      "01_19_22:59:30 Seen so far: 20512 samples\n",
      "\n",
      "01_19_22:59:30 --- 2.0239715576171875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:32 Training loss at epoch 0 step 650: 3.34282124042511\n",
      "\n",
      " This round's valence_loss=0.8845331072807312, arousal_loss=0.7301611304283142, emotion_loss=1.1061832904815674\n",
      "\n",
      "01_19_22:59:32 Seen so far: 20832 samples\n",
      "\n",
      "01_19_22:59:32 --- 1.9714248180389404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:34 Training loss at epoch 0 step 660: 3.1643991231918336\n",
      "\n",
      " This round's valence_loss=1.0486125946044922, arousal_loss=0.9560879468917847, emotion_loss=1.1258244514465332\n",
      "\n",
      "01_19_22:59:34 Seen so far: 21152 samples\n",
      "\n",
      "01_19_22:59:34 --- 2.002176523208618 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:36 Training loss at epoch 0 step 670: 3.3460370540618896\n",
      "\n",
      " This round's valence_loss=1.138892650604248, arousal_loss=1.1358901262283325, emotion_loss=1.3060722351074219\n",
      "\n",
      "01_19_22:59:36 Seen so far: 21472 samples\n",
      "\n",
      "01_19_22:59:36 --- 1.8840796947479248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:39 Training loss at epoch 0 step 680: 3.3619484186172484\n",
      "\n",
      " This round's valence_loss=0.8393707275390625, arousal_loss=0.7700772881507874, emotion_loss=1.4988915920257568\n",
      "\n",
      "01_19_22:59:39 Seen so far: 21792 samples\n",
      "\n",
      "01_19_22:59:39 --- 2.3309218883514404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:41 Training loss at epoch 0 step 690: 3.438751459121704\n",
      "\n",
      " This round's valence_loss=1.3354218006134033, arousal_loss=1.2595412731170654, emotion_loss=0.9388067722320557\n",
      "\n",
      "01_19_22:59:41 Seen so far: 22112 samples\n",
      "\n",
      "01_19_22:59:41 --- 1.9661600589752197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:42 Training loss at epoch 0 step 700: 3.1718835830688477\n",
      "\n",
      " This round's valence_loss=0.640946626663208, arousal_loss=0.4519999027252197, emotion_loss=1.2482471466064453\n",
      "\n",
      "01_19_22:59:42 Seen so far: 22432 samples\n",
      "\n",
      "01_19_22:59:42 --- 1.9074053764343262 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:45 Training loss at epoch 0 step 710: 2.924969458580017\n",
      "\n",
      " This round's valence_loss=1.4901611804962158, arousal_loss=1.34284245967865, emotion_loss=1.4494800567626953\n",
      "\n",
      "01_19_22:59:45 Seen so far: 22752 samples\n",
      "\n",
      "01_19_22:59:45 --- 2.060350179672241 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:47 Training loss at epoch 0 step 720: 3.3788684844970702\n",
      "\n",
      " This round's valence_loss=1.1894170045852661, arousal_loss=1.181516408920288, emotion_loss=1.2783671617507935\n",
      "\n",
      "01_19_22:59:47 Seen so far: 23072 samples\n",
      "\n",
      "01_19_22:59:47 --- 2.0100228786468506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:49 Training loss at epoch 0 step 730: 3.1570069789886475\n",
      "\n",
      " This round's valence_loss=0.8808239698410034, arousal_loss=0.7625248432159424, emotion_loss=1.0643625259399414\n",
      "\n",
      "01_19_22:59:49 Seen so far: 23392 samples\n",
      "\n",
      "01_19_22:59:49 --- 2.315798282623291 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:51 Training loss at epoch 0 step 740: 3.2835306882858277\n",
      "\n",
      " This round's valence_loss=1.2547955513000488, arousal_loss=1.2296557426452637, emotion_loss=0.8449018001556396\n",
      "\n",
      "01_19_22:59:51 Seen so far: 23712 samples\n",
      "\n",
      "01_19_22:59:51 --- 2.410170555114746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:53 Training loss at epoch 0 step 750: 3.314895248413086\n",
      "\n",
      " This round's valence_loss=1.1956467628479004, arousal_loss=1.0859153270721436, emotion_loss=0.9491601586341858\n",
      "\n",
      "01_19_22:59:53 Seen so far: 24032 samples\n",
      "\n",
      "01_19_22:59:53 --- 1.930377721786499 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:55 Training loss at epoch 0 step 760: 3.3441988706588743\n",
      "\n",
      " This round's valence_loss=0.7481282353401184, arousal_loss=0.5931876301765442, emotion_loss=1.3561501502990723\n",
      "\n",
      "01_19_22:59:55 Seen so far: 24352 samples\n",
      "\n",
      "01_19_22:59:55 --- 2.0958075523376465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_22:59:57 Training loss at epoch 0 step 770: 3.4891204595565797\n",
      "\n",
      " This round's valence_loss=0.9773037433624268, arousal_loss=0.8466554880142212, emotion_loss=1.169921875\n",
      "\n",
      "01_19_22:59:57 Seen so far: 24672 samples\n",
      "\n",
      "01_19_22:59:57 --- 2.0983340740203857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:00 Training loss at epoch 0 step 780: 3.1656967401504517\n",
      "\n",
      " This round's valence_loss=1.1069599390029907, arousal_loss=0.9956779479980469, emotion_loss=1.1934239864349365\n",
      "\n",
      "01_19_23:00:00 Seen so far: 24992 samples\n",
      "\n",
      "01_19_23:00:00 --- 2.150980234146118 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:01 Training loss at epoch 0 step 790: 3.1638551235198973\n",
      "\n",
      " This round's valence_loss=1.1660418510437012, arousal_loss=0.95545494556427, emotion_loss=1.0243499279022217\n",
      "\n",
      "01_19_23:00:01 Seen so far: 25312 samples\n",
      "\n",
      "01_19_23:00:01 --- 1.965341329574585 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:03 Training loss at epoch 0 step 800: 3.587383508682251\n",
      "\n",
      " This round's valence_loss=1.3619606494903564, arousal_loss=1.1556859016418457, emotion_loss=0.9949426651000977\n",
      "\n",
      "01_19_23:00:03 Seen so far: 25632 samples\n",
      "\n",
      "01_19_23:00:03 --- 1.90846586227417 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:05 Training loss at epoch 0 step 810: 3.3035515546798706\n",
      "\n",
      " This round's valence_loss=1.2322994470596313, arousal_loss=1.1154744625091553, emotion_loss=1.0038278102874756\n",
      "\n",
      "01_19_23:00:05 Seen so far: 25952 samples\n",
      "\n",
      "01_19_23:00:05 --- 1.917351484298706 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:07 Training loss at epoch 0 step 820: 3.163360929489136\n",
      "\n",
      " This round's valence_loss=0.7372069358825684, arousal_loss=0.6016767024993896, emotion_loss=0.9740736484527588\n",
      "\n",
      "01_19_23:00:07 Seen so far: 26272 samples\n",
      "\n",
      "01_19_23:00:07 --- 2.024641275405884 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:10 Training loss at epoch 0 step 830: 3.3418861627578735\n",
      "\n",
      " This round's valence_loss=1.0979671478271484, arousal_loss=0.9984208345413208, emotion_loss=1.405035138130188\n",
      "\n",
      "01_19_23:00:10 Seen so far: 26592 samples\n",
      "\n",
      "01_19_23:00:10 --- 2.1814355850219727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:12 Training loss at epoch 0 step 840: 3.0316550731658936\n",
      "\n",
      " This round's valence_loss=1.311279535293579, arousal_loss=1.229320764541626, emotion_loss=1.6260415315628052\n",
      "\n",
      "01_19_23:00:12 Seen so far: 26912 samples\n",
      "\n",
      "01_19_23:00:12 --- 1.980647325515747 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:14 Training loss at epoch 0 step 850: 3.1862192153930664\n",
      "\n",
      " This round's valence_loss=1.135603427886963, arousal_loss=0.9333689212799072, emotion_loss=1.459993839263916\n",
      "\n",
      "01_19_23:00:14 Seen so far: 27232 samples\n",
      "\n",
      "01_19_23:00:14 --- 2.09848952293396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:16 Training loss at epoch 0 step 860: 3.0078798294067384\n",
      "\n",
      " This round's valence_loss=0.8032330870628357, arousal_loss=0.6268638372421265, emotion_loss=1.2157459259033203\n",
      "\n",
      "01_19_23:00:16 Seen so far: 27552 samples\n",
      "\n",
      "01_19_23:00:16 --- 2.15883731842041 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:18 Training loss at epoch 0 step 870: 3.096631407737732\n",
      "\n",
      " This round's valence_loss=1.31723153591156, arousal_loss=1.226097583770752, emotion_loss=1.5454673767089844\n",
      "\n",
      "01_19_23:00:18 Seen so far: 27872 samples\n",
      "\n",
      "01_19_23:00:18 --- 2.3426475524902344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:20 Training loss at epoch 0 step 880: 3.521804165840149\n",
      "\n",
      " This round's valence_loss=1.0334093570709229, arousal_loss=0.8376044034957886, emotion_loss=1.2326133251190186\n",
      "\n",
      "01_19_23:00:20 Seen so far: 28192 samples\n",
      "\n",
      "01_19_23:00:20 --- 2.148927688598633 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:22 Training loss at epoch 0 step 890: 3.6159743785858156\n",
      "\n",
      " This round's valence_loss=0.750411868095398, arousal_loss=0.6305384635925293, emotion_loss=1.2153706550598145\n",
      "\n",
      "01_19_23:00:22 Seen so far: 28512 samples\n",
      "\n",
      "01_19_23:00:22 --- 1.978017807006836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:24 Training loss at epoch 0 step 900: 3.054220962524414\n",
      "\n",
      " This round's valence_loss=0.8051067590713501, arousal_loss=0.5603939890861511, emotion_loss=1.0995498895645142\n",
      "\n",
      "01_19_23:00:24 Seen so far: 28832 samples\n",
      "\n",
      "01_19_23:00:24 --- 2.0651495456695557 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:26 Training loss at epoch 0 step 910: 3.3910849332809447\n",
      "\n",
      " This round's valence_loss=1.6621490716934204, arousal_loss=1.564924955368042, emotion_loss=1.3285746574401855\n",
      "\n",
      "01_19_23:00:26 Seen so far: 29152 samples\n",
      "\n",
      "01_19_23:00:26 --- 2.0120575428009033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:28 Training loss at epoch 0 step 920: 3.729701042175293\n",
      "\n",
      " This round's valence_loss=1.2361462116241455, arousal_loss=1.0752145051956177, emotion_loss=1.2087101936340332\n",
      "\n",
      "01_19_23:00:28 Seen so far: 29472 samples\n",
      "\n",
      "01_19_23:00:28 --- 2.117304801940918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:31 Training loss at epoch 0 step 930: 3.2390817642211913\n",
      "\n",
      " This round's valence_loss=0.9645428657531738, arousal_loss=0.8643183708190918, emotion_loss=1.2692292928695679\n",
      "\n",
      "01_19_23:00:31 Seen so far: 29792 samples\n",
      "\n",
      "01_19_23:00:31 --- 2.143615245819092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:33 Training loss at epoch 0 step 940: 3.378171920776367\n",
      "\n",
      " This round's valence_loss=1.4760291576385498, arousal_loss=1.3547632694244385, emotion_loss=1.066230297088623\n",
      "\n",
      "01_19_23:00:33 Seen so far: 30112 samples\n",
      "\n",
      "01_19_23:00:33 --- 2.223684549331665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:35 Training loss at epoch 0 step 950: 3.3782742261886596\n",
      "\n",
      " This round's valence_loss=1.1473801136016846, arousal_loss=0.9348827600479126, emotion_loss=1.0060501098632812\n",
      "\n",
      "01_19_23:00:35 Seen so far: 30432 samples\n",
      "\n",
      "01_19_23:00:35 --- 1.9470787048339844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:37 Training loss at epoch 0 step 960: 3.1618802309036256\n",
      "\n",
      " This round's valence_loss=1.3226994276046753, arousal_loss=1.2442817687988281, emotion_loss=1.2518270015716553\n",
      "\n",
      "01_19_23:00:37 Seen so far: 30752 samples\n",
      "\n",
      "01_19_23:00:37 --- 1.9805023670196533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:39 Training loss at epoch 0 step 970: 3.304709792137146\n",
      "\n",
      " This round's valence_loss=1.2246296405792236, arousal_loss=1.0309035778045654, emotion_loss=1.20574951171875\n",
      "\n",
      "01_19_23:00:39 Seen so far: 31072 samples\n",
      "\n",
      "01_19_23:00:39 --- 2.0965194702148438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:41 Training loss at epoch 0 step 980: 3.144751048088074\n",
      "\n",
      " This round's valence_loss=1.0306090116500854, arousal_loss=0.9927172064781189, emotion_loss=1.7549092769622803\n",
      "\n",
      "01_19_23:00:41 Seen so far: 31392 samples\n",
      "\n",
      "01_19_23:00:41 --- 1.9624760150909424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:43 Training loss at epoch 0 step 990: 2.990368700027466\n",
      "\n",
      " This round's valence_loss=0.4964717626571655, arousal_loss=0.32961779832839966, emotion_loss=1.064563274383545\n",
      "\n",
      "01_19_23:00:43 Seen so far: 31712 samples\n",
      "\n",
      "01_19_23:00:43 --- 2.1593856811523438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:45 Training loss at epoch 0 step 1000: 2.9736733198165894\n",
      "\n",
      " This round's valence_loss=0.8489959239959717, arousal_loss=0.7032953500747681, emotion_loss=0.6811754703521729\n",
      "\n",
      "01_19_23:00:45 Seen so far: 32032 samples\n",
      "\n",
      "01_19_23:00:45 --- 2.257448673248291 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:48 Training loss at epoch 0 step 1010: 3.2085395574569704\n",
      "\n",
      " This round's valence_loss=0.9953920245170593, arousal_loss=0.8167097568511963, emotion_loss=0.891083300113678\n",
      "\n",
      "01_19_23:00:48 Seen so far: 32352 samples\n",
      "\n",
      "01_19_23:00:48 --- 2.407160520553589 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:50 Training loss at epoch 0 step 1020: 3.1275394916534425\n",
      "\n",
      " This round's valence_loss=1.3949007987976074, arousal_loss=1.185147762298584, emotion_loss=1.3098163604736328\n",
      "\n",
      "01_19_23:00:50 Seen so far: 32672 samples\n",
      "\n",
      "01_19_23:00:50 --- 1.9545533657073975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:52 Training loss at epoch 0 step 1030: 3.0333823680877687\n",
      "\n",
      " This round's valence_loss=0.4762107729911804, arousal_loss=0.36428436636924744, emotion_loss=1.4604769945144653\n",
      "\n",
      "01_19_23:00:52 Seen so far: 32992 samples\n",
      "\n",
      "01_19_23:00:52 --- 2.195712089538574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:54 Training loss at epoch 0 step 1040: 3.2386630535125733\n",
      "\n",
      " This round's valence_loss=0.8615974187850952, arousal_loss=0.7149229049682617, emotion_loss=0.8977656960487366\n",
      "\n",
      "01_19_23:00:54 Seen so far: 33312 samples\n",
      "\n",
      "01_19_23:00:54 --- 2.0402987003326416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:56 Training loss at epoch 0 step 1050: 3.2481592416763307\n",
      "\n",
      " This round's valence_loss=1.4076383113861084, arousal_loss=1.3533093929290771, emotion_loss=1.340837001800537\n",
      "\n",
      "01_19_23:00:56 Seen so far: 33632 samples\n",
      "\n",
      "01_19_23:00:56 --- 2.0865561962127686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:00:58 Training loss at epoch 0 step 1060: 3.5242714643478394\n",
      "\n",
      " This round's valence_loss=1.2125630378723145, arousal_loss=1.0615581274032593, emotion_loss=1.107292652130127\n",
      "\n",
      "01_19_23:00:58 Seen so far: 33952 samples\n",
      "\n",
      "01_19_23:00:58 --- 2.050292730331421 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:00 Training loss at epoch 0 step 1070: 3.1848062753677366\n",
      "\n",
      " This round's valence_loss=1.507725477218628, arousal_loss=1.3248991966247559, emotion_loss=1.49515962600708\n",
      "\n",
      "01_19_23:01:00 Seen so far: 34272 samples\n",
      "\n",
      "01_19_23:01:00 --- 2.3291046619415283 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:02 Training loss at epoch 0 step 1080: 3.1610056877136232\n",
      "\n",
      " This round's valence_loss=1.1389448642730713, arousal_loss=0.7768023610115051, emotion_loss=0.6172281503677368\n",
      "\n",
      "01_19_23:01:02 Seen so far: 34592 samples\n",
      "\n",
      "01_19_23:01:02 --- 2.0734705924987793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:04 Training loss at epoch 0 step 1090: 3.2980948448181153\n",
      "\n",
      " This round's valence_loss=1.1768447160720825, arousal_loss=1.0445328950881958, emotion_loss=1.2438234090805054\n",
      "\n",
      "01_19_23:01:04 Seen so far: 34912 samples\n",
      "\n",
      "01_19_23:01:04 --- 1.9245061874389648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:06 Training loss at epoch 0 step 1100: 3.592083215713501\n",
      "\n",
      " This round's valence_loss=0.9362441301345825, arousal_loss=0.7245868444442749, emotion_loss=1.4743337631225586\n",
      "\n",
      "01_19_23:01:06 Seen so far: 35232 samples\n",
      "\n",
      "01_19_23:01:06 --- 2.1187751293182373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:08 Training loss at epoch 0 step 1110: 2.8877240896224974\n",
      "\n",
      " This round's valence_loss=0.8554946780204773, arousal_loss=0.6995639801025391, emotion_loss=0.9532885551452637\n",
      "\n",
      "01_19_23:01:08 Seen so far: 35552 samples\n",
      "\n",
      "01_19_23:01:08 --- 2.083737850189209 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:10 Training loss at epoch 0 step 1120: 3.222668981552124\n",
      "\n",
      " This round's valence_loss=1.4073593616485596, arousal_loss=1.3106502294540405, emotion_loss=1.3030405044555664\n",
      "\n",
      "01_19_23:01:10 Seen so far: 35872 samples\n",
      "\n",
      "01_19_23:01:10 --- 1.902761697769165 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:13 Training loss at epoch 0 step 1130: 3.1291423559188845\n",
      "\n",
      " This round's valence_loss=1.0580203533172607, arousal_loss=0.9395569562911987, emotion_loss=1.5516819953918457\n",
      "\n",
      "01_19_23:01:13 Seen so far: 36192 samples\n",
      "\n",
      "01_19_23:01:13 --- 2.3656527996063232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:15 Training loss at epoch 0 step 1140: 3.2672363758087157\n",
      "\n",
      " This round's valence_loss=1.2509982585906982, arousal_loss=1.072031021118164, emotion_loss=0.9802342057228088\n",
      "\n",
      "01_19_23:01:15 Seen so far: 36512 samples\n",
      "\n",
      "01_19_23:01:15 --- 2.0836546421051025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:17 Training loss at epoch 0 step 1150: 2.8886257886886595\n",
      "\n",
      " This round's valence_loss=1.1131515502929688, arousal_loss=0.9757075905799866, emotion_loss=1.0929358005523682\n",
      "\n",
      "01_19_23:01:17 Seen so far: 36832 samples\n",
      "\n",
      "01_19_23:01:17 --- 1.9739770889282227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:19 Training loss at epoch 0 step 1160: 3.082308125495911\n",
      "\n",
      " This round's valence_loss=0.7326692342758179, arousal_loss=0.6194736957550049, emotion_loss=1.1875556707382202\n",
      "\n",
      "01_19_23:01:19 Seen so far: 37152 samples\n",
      "\n",
      "01_19_23:01:19 --- 1.993816614151001 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:21 Training loss at epoch 0 step 1170: 3.0636003494262694\n",
      "\n",
      " This round's valence_loss=1.2273601293563843, arousal_loss=1.1087665557861328, emotion_loss=0.8178092241287231\n",
      "\n",
      "01_19_23:01:21 Seen so far: 37472 samples\n",
      "\n",
      "01_19_23:01:21 --- 1.9517266750335693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:23 Training loss at epoch 0 step 1180: 3.1636302709579467\n",
      "\n",
      " This round's valence_loss=0.8957425951957703, arousal_loss=0.6781877279281616, emotion_loss=0.9655523300170898\n",
      "\n",
      "01_19_23:01:23 Seen so far: 37792 samples\n",
      "\n",
      "01_19_23:01:23 --- 1.9750473499298096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:25 Training loss at epoch 0 step 1190: 3.0760413885116575\n",
      "\n",
      " This round's valence_loss=1.3399434089660645, arousal_loss=1.1893792152404785, emotion_loss=0.8638991117477417\n",
      "\n",
      "01_19_23:01:25 Seen so far: 38112 samples\n",
      "\n",
      "01_19_23:01:25 --- 1.9544179439544678 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:27 Training loss at epoch 0 step 1200: 2.978622627258301\n",
      "\n",
      " This round's valence_loss=0.7163692116737366, arousal_loss=0.6701375246047974, emotion_loss=1.0006219148635864\n",
      "\n",
      "01_19_23:01:27 Seen so far: 38432 samples\n",
      "\n",
      "01_19_23:01:27 --- 2.256577253341675 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:29 Training loss at epoch 0 step 1210: 3.086173915863037\n",
      "\n",
      " This round's valence_loss=0.8854325413703918, arousal_loss=0.7265951633453369, emotion_loss=1.0399744510650635\n",
      "\n",
      "01_19_23:01:29 Seen so far: 38752 samples\n",
      "\n",
      "01_19_23:01:29 --- 2.14892578125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:31 Training loss at epoch 0 step 1220: 3.195118546485901\n",
      "\n",
      " This round's valence_loss=0.9884002208709717, arousal_loss=0.8341848850250244, emotion_loss=1.0606026649475098\n",
      "\n",
      "01_19_23:01:31 Seen so far: 39072 samples\n",
      "\n",
      "01_19_23:01:31 --- 1.9468753337860107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:33 Training loss at epoch 0 step 1230: 3.2815876245498656\n",
      "\n",
      " This round's valence_loss=0.8414261341094971, arousal_loss=0.7368858456611633, emotion_loss=1.228701114654541\n",
      "\n",
      "01_19_23:01:33 Seen so far: 39392 samples\n",
      "\n",
      "01_19_23:01:33 --- 2.0507664680480957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:35 Training loss at epoch 0 step 1240: 3.246482086181641\n",
      "\n",
      " This round's valence_loss=1.1490962505340576, arousal_loss=0.9765481948852539, emotion_loss=1.4573369026184082\n",
      "\n",
      "01_19_23:01:35 Seen so far: 39712 samples\n",
      "\n",
      "01_19_23:01:35 --- 2.1274731159210205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:37 Training loss at epoch 0 step 1250: 3.414119529724121\n",
      "\n",
      " This round's valence_loss=1.4431895017623901, arousal_loss=1.1852233409881592, emotion_loss=0.9102030992507935\n",
      "\n",
      "01_19_23:01:37 Seen so far: 40032 samples\n",
      "\n",
      "01_19_23:01:37 --- 2.223421573638916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:40 Training loss at epoch 0 step 1260: 3.4214745283126833\n",
      "\n",
      " This round's valence_loss=1.0573241710662842, arousal_loss=0.9944254159927368, emotion_loss=1.2019948959350586\n",
      "\n",
      "01_19_23:01:40 Seen so far: 40352 samples\n",
      "\n",
      "01_19_23:01:40 --- 2.184675931930542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:42 Training loss at epoch 0 step 1270: 3.1960925579071047\n",
      "\n",
      " This round's valence_loss=0.9051109552383423, arousal_loss=0.6719487905502319, emotion_loss=1.0270172357559204\n",
      "\n",
      "01_19_23:01:42 Seen so far: 40672 samples\n",
      "\n",
      "01_19_23:01:42 --- 1.9482147693634033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:44 Training loss at epoch 0 step 1280: 2.934773325920105\n",
      "\n",
      " This round's valence_loss=0.7451128363609314, arousal_loss=0.613437294960022, emotion_loss=1.1147046089172363\n",
      "\n",
      "01_19_23:01:44 Seen so far: 40992 samples\n",
      "\n",
      "01_19_23:01:44 --- 1.9593470096588135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:46 Training loss at epoch 0 step 1290: 3.098127245903015\n",
      "\n",
      " This round's valence_loss=0.619510293006897, arousal_loss=0.5978814363479614, emotion_loss=1.3991966247558594\n",
      "\n",
      "01_19_23:01:46 Seen so far: 41312 samples\n",
      "\n",
      "01_19_23:01:46 --- 2.133824348449707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:48 Training loss at epoch 0 step 1300: 3.4164596796035767\n",
      "\n",
      " This round's valence_loss=1.251333236694336, arousal_loss=1.0675206184387207, emotion_loss=1.231259822845459\n",
      "\n",
      "01_19_23:01:48 Seen so far: 41632 samples\n",
      "\n",
      "01_19_23:01:48 --- 2.18045973777771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:50 Training loss at epoch 0 step 1310: 3.1433493852615357\n",
      "\n",
      " This round's valence_loss=1.2450194358825684, arousal_loss=1.052484154701233, emotion_loss=1.0253899097442627\n",
      "\n",
      "01_19_23:01:50 Seen so far: 41952 samples\n",
      "\n",
      "01_19_23:01:50 --- 2.0572738647460938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:52 Training loss at epoch 0 step 1320: 3.206512975692749\n",
      "\n",
      " This round's valence_loss=1.5903117656707764, arousal_loss=1.4310027360916138, emotion_loss=1.0924689769744873\n",
      "\n",
      "01_19_23:01:52 Seen so far: 42272 samples\n",
      "\n",
      "01_19_23:01:52 --- 2.0660386085510254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:54 Training loss at epoch 0 step 1330: 3.472590613365173\n",
      "\n",
      " This round's valence_loss=0.931456446647644, arousal_loss=0.7119486331939697, emotion_loss=0.8943824768066406\n",
      "\n",
      "01_19_23:01:54 Seen so far: 42592 samples\n",
      "\n",
      "01_19_23:01:54 --- 2.234320640563965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:56 Training loss at epoch 0 step 1340: 3.3791339874267576\n",
      "\n",
      " This round's valence_loss=1.165201187133789, arousal_loss=1.1103156805038452, emotion_loss=1.3316377401351929\n",
      "\n",
      "01_19_23:01:56 Seen so far: 42912 samples\n",
      "\n",
      "01_19_23:01:56 --- 2.2011356353759766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:01:59 Training loss at epoch 0 step 1350: 3.3883347272872926\n",
      "\n",
      " This round's valence_loss=1.0842310190200806, arousal_loss=0.9839168787002563, emotion_loss=1.053055763244629\n",
      "\n",
      "01_19_23:01:59 Seen so far: 43232 samples\n",
      "\n",
      "01_19_23:01:59 --- 2.1247127056121826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:01 Training loss at epoch 0 step 1360: 3.3554540872573853\n",
      "\n",
      " This round's valence_loss=0.8642067909240723, arousal_loss=0.7129296064376831, emotion_loss=1.1251091957092285\n",
      "\n",
      "01_19_23:02:01 Seen so far: 43552 samples\n",
      "\n",
      "01_19_23:02:01 --- 2.2354934215545654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:03 Training loss at epoch 0 step 1370: 2.824901294708252\n",
      "\n",
      " This round's valence_loss=0.5661934614181519, arousal_loss=0.32925015687942505, emotion_loss=1.068795919418335\n",
      "\n",
      "01_19_23:02:03 Seen so far: 43872 samples\n",
      "\n",
      "01_19_23:02:03 --- 1.946441888809204 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:05 Training loss at epoch 0 step 1380: 3.1795827627182005\n",
      "\n",
      " This round's valence_loss=1.5708590745925903, arousal_loss=1.4501309394836426, emotion_loss=0.9895051717758179\n",
      "\n",
      "01_19_23:02:05 Seen so far: 44192 samples\n",
      "\n",
      "01_19_23:02:05 --- 2.085662603378296 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:07 Training loss at epoch 0 step 1390: 3.1652299642562864\n",
      "\n",
      " This round's valence_loss=0.9980104565620422, arousal_loss=0.804000735282898, emotion_loss=1.0496878623962402\n",
      "\n",
      "01_19_23:02:07 Seen so far: 44512 samples\n",
      "\n",
      "01_19_23:02:07 --- 2.286839246749878 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:09 Training loss at epoch 0 step 1400: 3.3936586141586305\n",
      "\n",
      " This round's valence_loss=1.8260486125946045, arousal_loss=1.6602919101715088, emotion_loss=1.0318291187286377\n",
      "\n",
      "01_19_23:02:09 Seen so far: 44832 samples\n",
      "\n",
      "01_19_23:02:09 --- 2.0256474018096924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:11 Training loss at epoch 0 step 1410: 3.0422192096710203\n",
      "\n",
      " This round's valence_loss=0.9896329045295715, arousal_loss=0.892151951789856, emotion_loss=0.909633994102478\n",
      "\n",
      "01_19_23:02:11 Seen so far: 45152 samples\n",
      "\n",
      "01_19_23:02:11 --- 1.894315242767334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:13 Training loss at epoch 0 step 1420: 3.1158956050872804\n",
      "\n",
      " This round's valence_loss=1.5708469152450562, arousal_loss=1.4465610980987549, emotion_loss=1.4636573791503906\n",
      "\n",
      "01_19_23:02:13 Seen so far: 45472 samples\n",
      "\n",
      "01_19_23:02:13 --- 2.1162145137786865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:15 Training loss at epoch 0 step 1430: 3.3635184288024904\n",
      "\n",
      " This round's valence_loss=1.3640424013137817, arousal_loss=1.2226974964141846, emotion_loss=1.342761516571045\n",
      "\n",
      "01_19_23:02:15 Seen so far: 45792 samples\n",
      "\n",
      "01_19_23:02:15 --- 2.1223034858703613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:17 Training loss at epoch 0 step 1440: 3.4089224576950072\n",
      "\n",
      " This round's valence_loss=1.240026593208313, arousal_loss=1.0599520206451416, emotion_loss=1.0329921245574951\n",
      "\n",
      "01_19_23:02:17 Seen so far: 46112 samples\n",
      "\n",
      "01_19_23:02:17 --- 2.1977546215057373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:19 Training loss at epoch 0 step 1450: 3.3727207660675047\n",
      "\n",
      " This round's valence_loss=1.0650722980499268, arousal_loss=0.9704725742340088, emotion_loss=0.9484732151031494\n",
      "\n",
      "01_19_23:02:19 Seen so far: 46432 samples\n",
      "\n",
      "01_19_23:02:19 --- 2.0546250343322754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:22 Training loss at epoch 0 step 1460: 3.510720443725586\n",
      "\n",
      " This round's valence_loss=1.031009316444397, arousal_loss=0.9546922445297241, emotion_loss=1.3592934608459473\n",
      "\n",
      "01_19_23:02:22 Seen so far: 46752 samples\n",
      "\n",
      "01_19_23:02:22 --- 2.177325487136841 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:24 Training loss at epoch 0 step 1470: 3.023834705352783\n",
      "\n",
      " This round's valence_loss=0.7042516469955444, arousal_loss=0.44208958745002747, emotion_loss=0.8365288972854614\n",
      "\n",
      "01_19_23:02:24 Seen so far: 47072 samples\n",
      "\n",
      "01_19_23:02:24 --- 2.0202949047088623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:26 Training loss at epoch 0 step 1480: 3.3814698457717896\n",
      "\n",
      " This round's valence_loss=1.1224758625030518, arousal_loss=0.9382878541946411, emotion_loss=0.9636857509613037\n",
      "\n",
      "01_19_23:02:26 Seen so far: 47392 samples\n",
      "\n",
      "01_19_23:02:26 --- 1.9461743831634521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:28 Training loss at epoch 0 step 1490: 3.2960595369338987\n",
      "\n",
      " This round's valence_loss=0.5618955492973328, arousal_loss=0.48388755321502686, emotion_loss=1.083290696144104\n",
      "\n",
      "01_19_23:02:28 Seen so far: 47712 samples\n",
      "\n",
      "01_19_23:02:28 --- 1.9727082252502441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:30 Training loss at epoch 0 step 1500: 3.0110278367996215\n",
      "\n",
      " This round's valence_loss=1.193293571472168, arousal_loss=1.0594151020050049, emotion_loss=1.467846155166626\n",
      "\n",
      "01_19_23:02:30 Seen so far: 48032 samples\n",
      "\n",
      "01_19_23:02:30 --- 2.1955130100250244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:32 Training loss at epoch 0 step 1510: 3.055217170715332\n",
      "\n",
      " This round's valence_loss=1.2146209478378296, arousal_loss=1.0693591833114624, emotion_loss=1.1378200054168701\n",
      "\n",
      "01_19_23:02:32 Seen so far: 48352 samples\n",
      "\n",
      "01_19_23:02:32 --- 1.8999440670013428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:34 Training loss at epoch 0 step 1520: 3.451144814491272\n",
      "\n",
      " This round's valence_loss=1.3376271724700928, arousal_loss=1.172919511795044, emotion_loss=1.0902273654937744\n",
      "\n",
      "01_19_23:02:34 Seen so far: 48672 samples\n",
      "\n",
      "01_19_23:02:34 --- 1.9513413906097412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:36 Training loss at epoch 0 step 1530: 3.307666301727295\n",
      "\n",
      " This round's valence_loss=0.9965334534645081, arousal_loss=0.8720937967300415, emotion_loss=1.7337549924850464\n",
      "\n",
      "01_19_23:02:36 Seen so far: 48992 samples\n",
      "\n",
      "01_19_23:02:36 --- 2.274595260620117 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:38 Training loss at epoch 0 step 1540: 3.2649296522140503\n",
      "\n",
      " This round's valence_loss=1.2185007333755493, arousal_loss=1.1246168613433838, emotion_loss=1.2632050514221191\n",
      "\n",
      "01_19_23:02:38 Seen so far: 49312 samples\n",
      "\n",
      "01_19_23:02:38 --- 2.3706881999969482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:40 Training loss at epoch 0 step 1550: 3.16804621219635\n",
      "\n",
      " This round's valence_loss=1.1632237434387207, arousal_loss=1.1157280206680298, emotion_loss=1.1884760856628418\n",
      "\n",
      "01_19_23:02:40 Seen so far: 49632 samples\n",
      "\n",
      "01_19_23:02:40 --- 2.097980260848999 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:42 Training loss at epoch 0 step 1560: 3.058993601799011\n",
      "\n",
      " This round's valence_loss=1.3083696365356445, arousal_loss=1.1841453313827515, emotion_loss=1.229445457458496\n",
      "\n",
      "01_19_23:02:42 Seen so far: 49952 samples\n",
      "\n",
      "01_19_23:02:42 --- 1.956183910369873 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:44 Training loss at epoch 0 step 1570: 3.2217450857162477\n",
      "\n",
      " This round's valence_loss=0.9610849022865295, arousal_loss=0.8877381086349487, emotion_loss=1.394308090209961\n",
      "\n",
      "01_19_23:02:44 Seen so far: 50272 samples\n",
      "\n",
      "01_19_23:02:44 --- 1.8494212627410889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:46 Training loss at epoch 0 step 1580: 3.104703426361084\n",
      "\n",
      " This round's valence_loss=1.600123405456543, arousal_loss=1.4297304153442383, emotion_loss=1.328969955444336\n",
      "\n",
      "01_19_23:02:46 Seen so far: 50592 samples\n",
      "\n",
      "01_19_23:02:46 --- 2.191786050796509 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:48 Training loss at epoch 0 step 1590: 2.968610978126526\n",
      "\n",
      " This round's valence_loss=0.7765671014785767, arousal_loss=0.5623686909675598, emotion_loss=0.7180774807929993\n",
      "\n",
      "01_19_23:02:48 Seen so far: 50912 samples\n",
      "\n",
      "01_19_23:02:48 --- 1.8044626712799072 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:50 Training loss at epoch 0 step 1600: 3.221069025993347\n",
      "\n",
      " This round's valence_loss=1.2827351093292236, arousal_loss=1.1949983835220337, emotion_loss=1.4458014965057373\n",
      "\n",
      "01_19_23:02:50 Seen so far: 51232 samples\n",
      "\n",
      "01_19_23:02:50 --- 2.117495536804199 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:52 Training loss at epoch 0 step 1610: 3.1089587211608887\n",
      "\n",
      " This round's valence_loss=1.151529312133789, arousal_loss=0.9230101108551025, emotion_loss=1.1620514392852783\n",
      "\n",
      "01_19_23:02:52 Seen so far: 51552 samples\n",
      "\n",
      "01_19_23:02:52 --- 2.132505178451538 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:54 Training loss at epoch 0 step 1620: 2.978286337852478\n",
      "\n",
      " This round's valence_loss=0.8007357716560364, arousal_loss=0.551806628704071, emotion_loss=0.9147526621818542\n",
      "\n",
      "01_19_23:02:54 Seen so far: 51872 samples\n",
      "\n",
      "01_19_23:02:54 --- 1.8694312572479248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:56 Training loss at epoch 0 step 1630: 3.2985822677612306\n",
      "\n",
      " This round's valence_loss=0.860379695892334, arousal_loss=0.7090890407562256, emotion_loss=0.7377045154571533\n",
      "\n",
      "01_19_23:02:56 Seen so far: 52192 samples\n",
      "\n",
      "01_19_23:02:56 --- 2.1029839515686035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:02:59 Training loss at epoch 0 step 1640: 3.0489986896514893\n",
      "\n",
      " This round's valence_loss=0.9631485939025879, arousal_loss=0.8679187297821045, emotion_loss=1.256782054901123\n",
      "\n",
      "01_19_23:02:59 Seen so far: 52512 samples\n",
      "\n",
      "01_19_23:02:59 --- 2.1278769969940186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:01 Training loss at epoch 0 step 1650: 2.971040499210358\n",
      "\n",
      " This round's valence_loss=0.9566908478736877, arousal_loss=0.8800989389419556, emotion_loss=1.337376356124878\n",
      "\n",
      "01_19_23:03:01 Seen so far: 52832 samples\n",
      "\n",
      "01_19_23:03:01 --- 2.0981884002685547 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:03 Training loss at epoch 0 step 1660: 3.2609047412872316\n",
      "\n",
      " This round's valence_loss=1.3308913707733154, arousal_loss=1.2153055667877197, emotion_loss=1.1899335384368896\n",
      "\n",
      "01_19_23:03:03 Seen so far: 53152 samples\n",
      "\n",
      "01_19_23:03:03 --- 2.0598480701446533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:05 Training loss at epoch 0 step 1670: 3.278952693939209\n",
      "\n",
      " This round's valence_loss=0.9043588638305664, arousal_loss=0.6891384124755859, emotion_loss=0.9353519678115845\n",
      "\n",
      "01_19_23:03:05 Seen so far: 53472 samples\n",
      "\n",
      "01_19_23:03:05 --- 2.0023491382598877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:07 Training loss at epoch 0 step 1680: 2.9875601530075073\n",
      "\n",
      " This round's valence_loss=0.8072734475135803, arousal_loss=0.6283619403839111, emotion_loss=0.8312751054763794\n",
      "\n",
      "01_19_23:03:07 Seen so far: 53792 samples\n",
      "\n",
      "01_19_23:03:07 --- 2.134481191635132 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:09 Training loss at epoch 0 step 1690: 3.002217173576355\n",
      "\n",
      " This round's valence_loss=0.689245343208313, arousal_loss=0.5028823614120483, emotion_loss=0.9315738081932068\n",
      "\n",
      "01_19_23:03:09 Seen so far: 54112 samples\n",
      "\n",
      "01_19_23:03:09 --- 1.8555705547332764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:11 Training loss at epoch 0 step 1700: 3.1651481866836546\n",
      "\n",
      " This round's valence_loss=1.0906459093093872, arousal_loss=0.9377496242523193, emotion_loss=1.1031410694122314\n",
      "\n",
      "01_19_23:03:11 Seen so far: 54432 samples\n",
      "\n",
      "01_19_23:03:11 --- 2.060638189315796 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:13 Training loss at epoch 0 step 1710: 3.051493835449219\n",
      "\n",
      " This round's valence_loss=0.9169421792030334, arousal_loss=0.7323088645935059, emotion_loss=1.029518485069275\n",
      "\n",
      "01_19_23:03:13 Seen so far: 54752 samples\n",
      "\n",
      "01_19_23:03:13 --- 1.9514403343200684 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:15 Training loss at epoch 0 step 1720: 3.705153727531433\n",
      "\n",
      " This round's valence_loss=1.0605601072311401, arousal_loss=0.9587377309799194, emotion_loss=1.1070245504379272\n",
      "\n",
      "01_19_23:03:15 Seen so far: 55072 samples\n",
      "\n",
      "01_19_23:03:15 --- 1.9722366333007812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:17 Training loss at epoch 0 step 1730: 3.391974687576294\n",
      "\n",
      " This round's valence_loss=1.3603973388671875, arousal_loss=1.1873021125793457, emotion_loss=1.2310776710510254\n",
      "\n",
      "01_19_23:03:17 Seen so far: 55392 samples\n",
      "\n",
      "01_19_23:03:17 --- 1.9874897003173828 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:19 Training loss at epoch 0 step 1740: 3.279944372177124\n",
      "\n",
      " This round's valence_loss=0.9645785093307495, arousal_loss=0.818381130695343, emotion_loss=0.9253576397895813\n",
      "\n",
      "01_19_23:03:19 Seen so far: 55712 samples\n",
      "\n",
      "01_19_23:03:19 --- 2.10341215133667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:21 Training loss at epoch 0 step 1750: 3.015392231941223\n",
      "\n",
      " This round's valence_loss=1.1186994314193726, arousal_loss=0.9608001708984375, emotion_loss=1.1587095260620117\n",
      "\n",
      "01_19_23:03:21 Seen so far: 56032 samples\n",
      "\n",
      "01_19_23:03:21 --- 1.9313395023345947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:23 Training loss at epoch 0 step 1760: 3.200153923034668\n",
      "\n",
      " This round's valence_loss=0.910831093788147, arousal_loss=0.8666390180587769, emotion_loss=1.18304443359375\n",
      "\n",
      "01_19_23:03:23 Seen so far: 56352 samples\n",
      "\n",
      "01_19_23:03:23 --- 2.043074131011963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:25 Training loss at epoch 0 step 1770: 2.830683135986328\n",
      "\n",
      " This round's valence_loss=1.103865385055542, arousal_loss=1.0131285190582275, emotion_loss=1.7407010793685913\n",
      "\n",
      "01_19_23:03:25 Seen so far: 56672 samples\n",
      "\n",
      "01_19_23:03:25 --- 2.062929630279541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:27 Training loss at epoch 0 step 1780: 3.132966494560242\n",
      "\n",
      " This round's valence_loss=0.9281949400901794, arousal_loss=0.8269487619400024, emotion_loss=0.9146361351013184\n",
      "\n",
      "01_19_23:03:27 Seen so far: 56992 samples\n",
      "\n",
      "01_19_23:03:27 --- 1.9344079494476318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:29 Training loss at epoch 0 step 1790: 3.1293794393539427\n",
      "\n",
      " This round's valence_loss=0.9841247797012329, arousal_loss=0.8523516654968262, emotion_loss=1.020176887512207\n",
      "\n",
      "01_19_23:03:29 Seen so far: 57312 samples\n",
      "\n",
      "01_19_23:03:29 --- 2.134345054626465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:31 Training loss at epoch 0 step 1800: 3.5145684242248536\n",
      "\n",
      " This round's valence_loss=1.0189096927642822, arousal_loss=0.8311076760292053, emotion_loss=1.0803108215332031\n",
      "\n",
      "01_19_23:03:31 Seen so far: 57632 samples\n",
      "\n",
      "01_19_23:03:31 --- 2.2061824798583984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:33 Training loss at epoch 0 step 1810: 3.2296236753463745\n",
      "\n",
      " This round's valence_loss=1.252555012702942, arousal_loss=1.129270315170288, emotion_loss=0.9053706526756287\n",
      "\n",
      "01_19_23:03:33 Seen so far: 57952 samples\n",
      "\n",
      "01_19_23:03:33 --- 2.1152496337890625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:35 Training loss at epoch 0 step 1820: 2.9150179982185365\n",
      "\n",
      " This round's valence_loss=0.850396990776062, arousal_loss=0.7284543514251709, emotion_loss=1.0659006834030151\n",
      "\n",
      "01_19_23:03:35 Seen so far: 58272 samples\n",
      "\n",
      "01_19_23:03:35 --- 2.0314383506774902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:37 Training loss at epoch 0 step 1830: 3.3994519472122193\n",
      "\n",
      " This round's valence_loss=0.7966318130493164, arousal_loss=0.7002928853034973, emotion_loss=1.4528899192810059\n",
      "\n",
      "01_19_23:03:37 Seen so far: 58592 samples\n",
      "\n",
      "01_19_23:03:37 --- 2.102766275405884 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:39 Training loss at epoch 0 step 1840: 3.3587138414382935\n",
      "\n",
      " This round's valence_loss=1.103655219078064, arousal_loss=0.9631465673446655, emotion_loss=1.0983946323394775\n",
      "\n",
      "01_19_23:03:39 Seen so far: 58912 samples\n",
      "\n",
      "01_19_23:03:39 --- 2.0029523372650146 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:41 Training loss at epoch 0 step 1850: 3.473278117179871\n",
      "\n",
      " This round's valence_loss=1.2308368682861328, arousal_loss=1.1076065301895142, emotion_loss=1.1237009763717651\n",
      "\n",
      "01_19_23:03:41 Seen so far: 59232 samples\n",
      "\n",
      "01_19_23:03:41 --- 2.116899013519287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:43 Training loss at epoch 0 step 1860: 3.1159332513809206\n",
      "\n",
      " This round's valence_loss=0.8742166757583618, arousal_loss=0.6958595514297485, emotion_loss=1.2668423652648926\n",
      "\n",
      "01_19_23:03:43 Seen so far: 59552 samples\n",
      "\n",
      "01_19_23:03:43 --- 1.8411815166473389 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:45 Training loss at epoch 0 step 1870: 3.1309257984161376\n",
      "\n",
      " This round's valence_loss=1.6562762260437012, arousal_loss=1.5889110565185547, emotion_loss=1.5059436559677124\n",
      "\n",
      "01_19_23:03:45 Seen so far: 59872 samples\n",
      "\n",
      "01_19_23:03:45 --- 1.9027032852172852 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:47 Training loss at epoch 0 step 1880: 3.1714834213256835\n",
      "\n",
      " This round's valence_loss=1.0605995655059814, arousal_loss=0.9958404302597046, emotion_loss=1.0148050785064697\n",
      "\n",
      "01_19_23:03:47 Seen so far: 60192 samples\n",
      "\n",
      "01_19_23:03:47 --- 2.1724441051483154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:49 Training loss at epoch 0 step 1890: 3.2305743932724\n",
      "\n",
      " This round's valence_loss=1.3398962020874023, arousal_loss=1.2230981588363647, emotion_loss=1.2164833545684814\n",
      "\n",
      "01_19_23:03:49 Seen so far: 60512 samples\n",
      "\n",
      "01_19_23:03:49 --- 1.9146864414215088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:51 Training loss at epoch 0 step 1900: 3.115878200531006\n",
      "\n",
      " This round's valence_loss=1.2926124334335327, arousal_loss=1.2086962461471558, emotion_loss=1.038865327835083\n",
      "\n",
      "01_19_23:03:51 Seen so far: 60832 samples\n",
      "\n",
      "01_19_23:03:51 --- 1.8334734439849854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:53 Training loss at epoch 0 step 1910: 3.3166001081466674\n",
      "\n",
      " This round's valence_loss=0.7960917353630066, arousal_loss=0.582388699054718, emotion_loss=1.0802078247070312\n",
      "\n",
      "01_19_23:03:53 Seen so far: 61152 samples\n",
      "\n",
      "01_19_23:03:53 --- 2.134369373321533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:55 Training loss at epoch 0 step 1920: 3.045070505142212\n",
      "\n",
      " This round's valence_loss=1.554186224937439, arousal_loss=1.473921298980713, emotion_loss=1.6631834506988525\n",
      "\n",
      "01_19_23:03:55 Seen so far: 61472 samples\n",
      "\n",
      "01_19_23:03:55 --- 1.8009865283966064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:57 Training loss at epoch 0 step 1930: 3.060296058654785\n",
      "\n",
      " This round's valence_loss=0.879375159740448, arousal_loss=0.7099562287330627, emotion_loss=1.1512089967727661\n",
      "\n",
      "01_19_23:03:57 Seen so far: 61792 samples\n",
      "\n",
      "01_19_23:03:57 --- 2.1771278381347656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:03:59 Training loss at epoch 0 step 1940: 3.192804288864136\n",
      "\n",
      " This round's valence_loss=1.175462245941162, arousal_loss=0.9610561728477478, emotion_loss=1.2044086456298828\n",
      "\n",
      "01_19_23:03:59 Seen so far: 62112 samples\n",
      "\n",
      "01_19_23:03:59 --- 1.9783236980438232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:01 Training loss at epoch 0 step 1950: 3.2024813175201414\n",
      "\n",
      " This round's valence_loss=1.236731767654419, arousal_loss=1.093093752861023, emotion_loss=1.4497435092926025\n",
      "\n",
      "01_19_23:04:01 Seen so far: 62432 samples\n",
      "\n",
      "01_19_23:04:01 --- 2.037494659423828 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:03 Training loss at epoch 0 step 1960: 3.356396746635437\n",
      "\n",
      " This round's valence_loss=0.8217875361442566, arousal_loss=0.6125792860984802, emotion_loss=1.225155234336853\n",
      "\n",
      "01_19_23:04:03 Seen so far: 62752 samples\n",
      "\n",
      "01_19_23:04:03 --- 2.0664451122283936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:05 Training loss at epoch 0 step 1970: 3.1921674728393556\n",
      "\n",
      " This round's valence_loss=1.1880149841308594, arousal_loss=1.078010082244873, emotion_loss=0.8539596796035767\n",
      "\n",
      "01_19_23:04:05 Seen so far: 63072 samples\n",
      "\n",
      "01_19_23:04:05 --- 2.1253795623779297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:07 Training loss at epoch 0 step 1980: 3.0523839235305785\n",
      "\n",
      " This round's valence_loss=1.0662423372268677, arousal_loss=0.9803438186645508, emotion_loss=1.5169882774353027\n",
      "\n",
      "01_19_23:04:07 Seen so far: 63392 samples\n",
      "\n",
      "01_19_23:04:07 --- 1.9525573253631592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:10 Training loss at epoch 0 step 1990: 3.397824239730835\n",
      "\n",
      " This round's valence_loss=1.7054595947265625, arousal_loss=1.558256983757019, emotion_loss=1.2966346740722656\n",
      "\n",
      "01_19_23:04:10 Seen so far: 63712 samples\n",
      "\n",
      "01_19_23:04:10 --- 2.1228199005126953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:12 Training loss at epoch 0 step 2000: 3.415435314178467\n",
      "\n",
      " This round's valence_loss=1.7084431648254395, arousal_loss=1.5406367778778076, emotion_loss=0.9148650169372559\n",
      "\n",
      "01_19_23:04:12 Seen so far: 64032 samples\n",
      "\n",
      "01_19_23:04:12 --- 2.1087191104888916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:14 Training loss at epoch 0 step 2010: 3.512963652610779\n",
      "\n",
      " This round's valence_loss=1.405379295349121, arousal_loss=1.319305419921875, emotion_loss=1.2748239040374756\n",
      "\n",
      "01_19_23:04:14 Seen so far: 64352 samples\n",
      "\n",
      "01_19_23:04:14 --- 2.069669485092163 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:16 Training loss at epoch 0 step 2020: 2.9083046674728394\n",
      "\n",
      " This round's valence_loss=1.087753176689148, arousal_loss=0.9371742010116577, emotion_loss=0.945495069026947\n",
      "\n",
      "01_19_23:04:16 Seen so far: 64672 samples\n",
      "\n",
      "01_19_23:04:16 --- 1.9667079448699951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:18 Training loss at epoch 0 step 2030: 3.0847429990768434\n",
      "\n",
      " This round's valence_loss=0.8241785764694214, arousal_loss=0.6035293340682983, emotion_loss=0.8214795589447021\n",
      "\n",
      "01_19_23:04:18 Seen so far: 64992 samples\n",
      "\n",
      "01_19_23:04:18 --- 2.308743715286255 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:20 Training loss at epoch 0 step 2040: 3.1622026920318604\n",
      "\n",
      " This round's valence_loss=0.8520580530166626, arousal_loss=0.7180007696151733, emotion_loss=1.0714309215545654\n",
      "\n",
      "01_19_23:04:20 Seen so far: 65312 samples\n",
      "\n",
      "01_19_23:04:20 --- 2.1643691062927246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:22 Training loss at epoch 0 step 2050: 3.007783031463623\n",
      "\n",
      " This round's valence_loss=0.9526327848434448, arousal_loss=0.8598208427429199, emotion_loss=1.0321614742279053\n",
      "\n",
      "01_19_23:04:22 Seen so far: 65632 samples\n",
      "\n",
      "01_19_23:04:22 --- 2.1904942989349365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:24 Training loss at epoch 0 step 2060: 2.901289868354797\n",
      "\n",
      " This round's valence_loss=1.125887393951416, arousal_loss=0.9182856678962708, emotion_loss=1.2327299118041992\n",
      "\n",
      "01_19_23:04:24 Seen so far: 65952 samples\n",
      "\n",
      "01_19_23:04:24 --- 2.066744804382324 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:26 Training loss at epoch 0 step 2070: 3.40459566116333\n",
      "\n",
      " This round's valence_loss=1.0652344226837158, arousal_loss=0.9834005236625671, emotion_loss=1.2402148246765137\n",
      "\n",
      "01_19_23:04:26 Seen so far: 66272 samples\n",
      "\n",
      "01_19_23:04:26 --- 1.9687576293945312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:29 Training loss at epoch 0 step 2080: 3.4370208978652954\n",
      "\n",
      " This round's valence_loss=1.312317132949829, arousal_loss=1.0679532289505005, emotion_loss=1.1541014909744263\n",
      "\n",
      "01_19_23:04:29 Seen so far: 66592 samples\n",
      "\n",
      "01_19_23:04:29 --- 2.200087070465088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:30 Training loss at epoch 0 step 2090: 3.4399030447006225\n",
      "\n",
      " This round's valence_loss=1.279051661491394, arousal_loss=1.0535807609558105, emotion_loss=1.0129876136779785\n",
      "\n",
      "01_19_23:04:30 Seen so far: 66912 samples\n",
      "\n",
      "01_19_23:04:30 --- 1.9243569374084473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:32 Training loss at epoch 0 step 2100: 3.2962597370147706\n",
      "\n",
      " This round's valence_loss=0.6388332843780518, arousal_loss=0.5543183088302612, emotion_loss=1.621182918548584\n",
      "\n",
      "01_19_23:04:32 Seen so far: 67232 samples\n",
      "\n",
      "01_19_23:04:32 --- 1.8378081321716309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:34 Training loss at epoch 0 step 2110: 3.2888543009757996\n",
      "\n",
      " This round's valence_loss=1.458483099937439, arousal_loss=1.3346869945526123, emotion_loss=1.3339953422546387\n",
      "\n",
      "01_19_23:04:34 Seen so far: 67552 samples\n",
      "\n",
      "01_19_23:04:34 --- 2.097203254699707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:36 Training loss at epoch 0 step 2120: 3.2520985841751098\n",
      "\n",
      " This round's valence_loss=1.7856428623199463, arousal_loss=1.688529133796692, emotion_loss=1.2597010135650635\n",
      "\n",
      "01_19_23:04:36 Seen so far: 67872 samples\n",
      "\n",
      "01_19_23:04:36 --- 2.048909902572632 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:39 Training loss at epoch 0 step 2130: 3.609469842910767\n",
      "\n",
      " This round's valence_loss=0.7074668407440186, arousal_loss=0.609114408493042, emotion_loss=1.4393815994262695\n",
      "\n",
      "01_19_23:04:39 Seen so far: 68192 samples\n",
      "\n",
      "01_19_23:04:39 --- 2.0378570556640625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:41 Training loss at epoch 0 step 2140: 3.7687984704971313\n",
      "\n",
      " This round's valence_loss=1.047929286956787, arousal_loss=0.8373159170150757, emotion_loss=1.5344045162200928\n",
      "\n",
      "01_19_23:04:41 Seen so far: 68512 samples\n",
      "\n",
      "01_19_23:04:41 --- 2.292685031890869 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:43 Training loss at epoch 0 step 2150: 3.3740604639053347\n",
      "\n",
      " This round's valence_loss=1.4580835103988647, arousal_loss=1.3463009595870972, emotion_loss=1.1687233448028564\n",
      "\n",
      "01_19_23:04:43 Seen so far: 68832 samples\n",
      "\n",
      "01_19_23:04:43 --- 2.078476905822754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:45 Training loss at epoch 0 step 2160: 3.2917267322540282\n",
      "\n",
      " This round's valence_loss=1.3400602340698242, arousal_loss=1.19859778881073, emotion_loss=1.2044603824615479\n",
      "\n",
      "01_19_23:04:45 Seen so far: 69152 samples\n",
      "\n",
      "01_19_23:04:45 --- 2.104112386703491 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:47 Training loss at epoch 0 step 2170: 2.948284149169922\n",
      "\n",
      " This round's valence_loss=1.0252904891967773, arousal_loss=0.8254290819168091, emotion_loss=1.1824791431427002\n",
      "\n",
      "01_19_23:04:47 Seen so far: 69472 samples\n",
      "\n",
      "01_19_23:04:47 --- 1.9859447479248047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:49 Training loss at epoch 0 step 2180: 3.429772472381592\n",
      "\n",
      " This round's valence_loss=1.4224861860275269, arousal_loss=1.3547098636627197, emotion_loss=1.1510955095291138\n",
      "\n",
      "01_19_23:04:49 Seen so far: 69792 samples\n",
      "\n",
      "01_19_23:04:49 --- 1.9990386962890625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:51 Training loss at epoch 0 step 2190: 3.110537815093994\n",
      "\n",
      " This round's valence_loss=0.9979744553565979, arousal_loss=0.8468663692474365, emotion_loss=0.7395572662353516\n",
      "\n",
      "01_19_23:04:51 Seen so far: 70112 samples\n",
      "\n",
      "01_19_23:04:51 --- 2.082005739212036 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:53 Training loss at epoch 0 step 2200: 2.6446032881736756\n",
      "\n",
      " This round's valence_loss=1.082425594329834, arousal_loss=0.9264999032020569, emotion_loss=0.9982922077178955\n",
      "\n",
      "01_19_23:04:53 Seen so far: 70432 samples\n",
      "\n",
      "01_19_23:04:53 --- 2.064197063446045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:55 Training loss at epoch 0 step 2210: 3.141065740585327\n",
      "\n",
      " This round's valence_loss=0.8723902702331543, arousal_loss=0.7277826070785522, emotion_loss=0.8609228134155273\n",
      "\n",
      "01_19_23:04:55 Seen so far: 70752 samples\n",
      "\n",
      "01_19_23:04:55 --- 2.2241711616516113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:04:58 Training loss at epoch 0 step 2220: 3.140521740913391\n",
      "\n",
      " This round's valence_loss=0.9852913618087769, arousal_loss=0.8812370896339417, emotion_loss=0.9576364755630493\n",
      "\n",
      "01_19_23:04:58 Seen so far: 71072 samples\n",
      "\n",
      "01_19_23:04:58 --- 2.295260429382324 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:00 Training loss at epoch 0 step 2230: 3.401386260986328\n",
      "\n",
      " This round's valence_loss=1.4605798721313477, arousal_loss=1.393081545829773, emotion_loss=1.2125170230865479\n",
      "\n",
      "01_19_23:05:00 Seen so far: 71392 samples\n",
      "\n",
      "01_19_23:05:00 --- 2.082623243331909 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:02 Training loss at epoch 0 step 2240: 2.963719701766968\n",
      "\n",
      " This round's valence_loss=0.5757672786712646, arousal_loss=0.33769696950912476, emotion_loss=1.2839810848236084\n",
      "\n",
      "01_19_23:05:02 Seen so far: 71712 samples\n",
      "\n",
      "01_19_23:05:02 --- 2.097189426422119 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:04 Training loss at epoch 0 step 2250: 3.370215892791748\n",
      "\n",
      " This round's valence_loss=0.8254497647285461, arousal_loss=0.7423242330551147, emotion_loss=1.3040708303451538\n",
      "\n",
      "01_19_23:05:04 Seen so far: 72032 samples\n",
      "\n",
      "01_19_23:05:04 --- 2.206084728240967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:06 Training loss at epoch 0 step 2260: 3.0445218682289124\n",
      "\n",
      " This round's valence_loss=1.2152032852172852, arousal_loss=1.1342030763626099, emotion_loss=1.166002631187439\n",
      "\n",
      "01_19_23:05:06 Seen so far: 72352 samples\n",
      "\n",
      "01_19_23:05:06 --- 2.0978012084960938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:08 Training loss at epoch 0 step 2270: 3.2409038066864015\n",
      "\n",
      " This round's valence_loss=1.2704989910125732, arousal_loss=1.0718605518341064, emotion_loss=1.154374122619629\n",
      "\n",
      "01_19_23:05:08 Seen so far: 72672 samples\n",
      "\n",
      "01_19_23:05:08 --- 2.1291065216064453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:10 Training loss at epoch 0 step 2280: 3.128719425201416\n",
      "\n",
      " This round's valence_loss=1.1097931861877441, arousal_loss=0.9574217796325684, emotion_loss=1.2470946311950684\n",
      "\n",
      "01_19_23:05:10 Seen so far: 72992 samples\n",
      "\n",
      "01_19_23:05:10 --- 2.151184558868408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:12 Training loss at epoch 0 step 2290: 3.397994136810303\n",
      "\n",
      " This round's valence_loss=1.218043565750122, arousal_loss=1.106184720993042, emotion_loss=1.2989318370819092\n",
      "\n",
      "01_19_23:05:12 Seen so far: 73312 samples\n",
      "\n",
      "01_19_23:05:12 --- 1.9342036247253418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:14 Training loss at epoch 0 step 2300: 3.2097827434539794\n",
      "\n",
      " This round's valence_loss=0.8382102251052856, arousal_loss=0.6864622831344604, emotion_loss=1.1774505376815796\n",
      "\n",
      "01_19_23:05:14 Seen so far: 73632 samples\n",
      "\n",
      "01_19_23:05:14 --- 1.957688808441162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:16 Training loss at epoch 0 step 2310: 2.952312672138214\n",
      "\n",
      " This round's valence_loss=1.2232213020324707, arousal_loss=1.112856388092041, emotion_loss=1.0025620460510254\n",
      "\n",
      "01_19_23:05:16 Seen so far: 73952 samples\n",
      "\n",
      "01_19_23:05:16 --- 1.978727102279663 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:18 Training loss at epoch 0 step 2320: 2.9693866968154907\n",
      "\n",
      " This round's valence_loss=0.8675450086593628, arousal_loss=0.7253910899162292, emotion_loss=1.1233210563659668\n",
      "\n",
      "01_19_23:05:18 Seen so far: 74272 samples\n",
      "\n",
      "01_19_23:05:18 --- 2.108067035675049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:20 Training loss at epoch 0 step 2330: 3.2294634342193604\n",
      "\n",
      " This round's valence_loss=0.9979192614555359, arousal_loss=0.8755127191543579, emotion_loss=1.0018856525421143\n",
      "\n",
      "01_19_23:05:20 Seen so far: 74592 samples\n",
      "\n",
      "01_19_23:05:20 --- 2.074336051940918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:23 Training loss at epoch 0 step 2340: 3.2682847023010253\n",
      "\n",
      " This round's valence_loss=1.62916100025177, arousal_loss=1.566115140914917, emotion_loss=1.059090495109558\n",
      "\n",
      "01_19_23:05:23 Seen so far: 74912 samples\n",
      "\n",
      "01_19_23:05:23 --- 2.1115825176239014 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:25 Training loss at epoch 0 step 2350: 3.1024011373519897\n",
      "\n",
      " This round's valence_loss=0.9994460344314575, arousal_loss=0.8348114490509033, emotion_loss=0.762939453125\n",
      "\n",
      "01_19_23:05:25 Seen so far: 75232 samples\n",
      "\n",
      "01_19_23:05:25 --- 2.1129865646362305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:27 Training loss at epoch 0 step 2360: 3.268454432487488\n",
      "\n",
      " This round's valence_loss=1.340963363647461, arousal_loss=1.204644799232483, emotion_loss=1.3557497262954712\n",
      "\n",
      "01_19_23:05:27 Seen so far: 75552 samples\n",
      "\n",
      "01_19_23:05:27 --- 1.932246446609497 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:29 Training loss at epoch 0 step 2370: 2.8786785125732424\n",
      "\n",
      " This round's valence_loss=0.5955935120582581, arousal_loss=0.3309001624584198, emotion_loss=0.819855272769928\n",
      "\n",
      "01_19_23:05:29 Seen so far: 75872 samples\n",
      "\n",
      "01_19_23:05:29 --- 2.072659730911255 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:31 Training loss at epoch 0 step 2380: 2.782844090461731\n",
      "\n",
      " This round's valence_loss=0.9670698046684265, arousal_loss=0.8002543449401855, emotion_loss=0.927310585975647\n",
      "\n",
      "01_19_23:05:31 Seen so far: 76192 samples\n",
      "\n",
      "01_19_23:05:31 --- 2.0236196517944336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:33 Training loss at epoch 0 step 2390: 3.531733202934265\n",
      "\n",
      " This round's valence_loss=1.0922446250915527, arousal_loss=0.9600862264633179, emotion_loss=0.8955336213111877\n",
      "\n",
      "01_19_23:05:33 Seen so far: 76512 samples\n",
      "\n",
      "01_19_23:05:33 --- 1.8775227069854736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:35 Training loss at epoch 0 step 2400: 2.9463836908340455\n",
      "\n",
      " This round's valence_loss=0.8727824091911316, arousal_loss=0.7575472593307495, emotion_loss=0.8441876173019409\n",
      "\n",
      "01_19_23:05:35 Seen so far: 76832 samples\n",
      "\n",
      "01_19_23:05:35 --- 2.1185739040374756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:37 Training loss at epoch 0 step 2410: 3.1010770082473753\n",
      "\n",
      " This round's valence_loss=0.9857162237167358, arousal_loss=0.7917261123657227, emotion_loss=0.767796516418457\n",
      "\n",
      "01_19_23:05:37 Seen so far: 77152 samples\n",
      "\n",
      "01_19_23:05:37 --- 2.150294065475464 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:39 Training loss at epoch 0 step 2420: 3.312538743019104\n",
      "\n",
      " This round's valence_loss=1.424573540687561, arousal_loss=1.3215675354003906, emotion_loss=0.9763245582580566\n",
      "\n",
      "01_19_23:05:39 Seen so far: 77472 samples\n",
      "\n",
      "01_19_23:05:39 --- 2.2722389698028564 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:41 Training loss at epoch 0 step 2430: 3.424069619178772\n",
      "\n",
      " This round's valence_loss=1.2247400283813477, arousal_loss=1.0991636514663696, emotion_loss=1.1799275875091553\n",
      "\n",
      "01_19_23:05:41 Seen so far: 77792 samples\n",
      "\n",
      "01_19_23:05:41 --- 1.9440174102783203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:43 Training loss at epoch 0 step 2440: 3.2334378480911257\n",
      "\n",
      " This round's valence_loss=0.9268887042999268, arousal_loss=0.8055632710456848, emotion_loss=1.2741906642913818\n",
      "\n",
      "01_19_23:05:43 Seen so far: 78112 samples\n",
      "\n",
      "01_19_23:05:43 --- 1.8765947818756104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:45 Training loss at epoch 0 step 2450: 3.220488166809082\n",
      "\n",
      " This round's valence_loss=0.878755509853363, arousal_loss=0.7534756660461426, emotion_loss=1.2915863990783691\n",
      "\n",
      "01_19_23:05:45 Seen so far: 78432 samples\n",
      "\n",
      "01_19_23:05:45 --- 2.073209047317505 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:47 Training loss at epoch 0 step 2460: 3.208450365066528\n",
      "\n",
      " This round's valence_loss=1.1186625957489014, arousal_loss=0.9617694616317749, emotion_loss=1.377021312713623\n",
      "\n",
      "01_19_23:05:47 Seen so far: 78752 samples\n",
      "\n",
      "01_19_23:05:47 --- 2.1190080642700195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:49 Training loss at epoch 0 step 2470: 3.2294270038604735\n",
      "\n",
      " This round's valence_loss=0.9852269887924194, arousal_loss=0.8639388084411621, emotion_loss=1.1914693117141724\n",
      "\n",
      "01_19_23:05:49 Seen so far: 79072 samples\n",
      "\n",
      "01_19_23:05:49 --- 2.1679623126983643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:51 Training loss at epoch 0 step 2480: 3.1372401475906373\n",
      "\n",
      " This round's valence_loss=0.9804602861404419, arousal_loss=0.8465965986251831, emotion_loss=1.128598928451538\n",
      "\n",
      "01_19_23:05:51 Seen so far: 79392 samples\n",
      "\n",
      "01_19_23:05:51 --- 2.1417906284332275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:53 Training loss at epoch 0 step 2490: 2.577194595336914\n",
      "\n",
      " This round's valence_loss=0.8789405822753906, arousal_loss=0.7096782922744751, emotion_loss=0.76592618227005\n",
      "\n",
      "01_19_23:05:53 Seen so far: 79712 samples\n",
      "\n",
      "01_19_23:05:53 --- 2.004216194152832 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:55 Training loss at epoch 0 step 2500: 3.359228515625\n",
      "\n",
      " This round's valence_loss=1.1594645977020264, arousal_loss=0.906497597694397, emotion_loss=0.9844356179237366\n",
      "\n",
      "01_19_23:05:55 Seen so far: 80032 samples\n",
      "\n",
      "01_19_23:05:55 --- 1.985783338546753 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:05:57 Training loss at epoch 0 step 2510: 3.4983218193054197\n",
      "\n",
      " This round's valence_loss=1.121117115020752, arousal_loss=0.9603219032287598, emotion_loss=1.2194013595581055\n",
      "\n",
      "01_19_23:05:57 Seen so far: 80352 samples\n",
      "\n",
      "01_19_23:05:57 --- 2.0343480110168457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:00 Training loss at epoch 0 step 2520: 3.3812411308288572\n",
      "\n",
      " This round's valence_loss=1.324998378753662, arousal_loss=1.2291715145111084, emotion_loss=1.1729422807693481\n",
      "\n",
      "01_19_23:06:00 Seen so far: 80672 samples\n",
      "\n",
      "01_19_23:06:00 --- 2.0541577339172363 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:01 Training loss at epoch 0 step 2530: 3.223024916648865\n",
      "\n",
      " This round's valence_loss=1.0183894634246826, arousal_loss=0.8099198341369629, emotion_loss=1.1915512084960938\n",
      "\n",
      "01_19_23:06:01 Seen so far: 80992 samples\n",
      "\n",
      "01_19_23:06:01 --- 1.9348256587982178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:03 Training loss at epoch 0 step 2540: 3.236564302444458\n",
      "\n",
      " This round's valence_loss=0.9908026456832886, arousal_loss=0.8441004753112793, emotion_loss=0.9747439622879028\n",
      "\n",
      "01_19_23:06:03 Seen so far: 81312 samples\n",
      "\n",
      "01_19_23:06:03 --- 1.9715609550476074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:05 Training loss at epoch 0 step 2550: 3.2777660131454467\n",
      "\n",
      " This round's valence_loss=1.4265105724334717, arousal_loss=1.3060359954833984, emotion_loss=1.318443775177002\n",
      "\n",
      "01_19_23:06:05 Seen so far: 81632 samples\n",
      "\n",
      "01_19_23:06:05 --- 2.0352423191070557 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:07 Training loss at epoch 0 step 2560: 3.04686598777771\n",
      "\n",
      " This round's valence_loss=0.9324315786361694, arousal_loss=0.7154039740562439, emotion_loss=1.1742279529571533\n",
      "\n",
      "01_19_23:06:07 Seen so far: 81952 samples\n",
      "\n",
      "01_19_23:06:07 --- 1.9874813556671143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:10 Training loss at epoch 0 step 2570: 3.20612895488739\n",
      "\n",
      " This round's valence_loss=0.8015824556350708, arousal_loss=0.6313145160675049, emotion_loss=1.1364169120788574\n",
      "\n",
      "01_19_23:06:10 Seen so far: 82272 samples\n",
      "\n",
      "01_19_23:06:10 --- 2.07065486907959 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:11 Training loss at epoch 0 step 2580: 2.8644707918167116\n",
      "\n",
      " This round's valence_loss=1.5919890403747559, arousal_loss=1.439774990081787, emotion_loss=1.1358455419540405\n",
      "\n",
      "01_19_23:06:11 Seen so far: 82592 samples\n",
      "\n",
      "01_19_23:06:11 --- 1.8646628856658936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:13 Training loss at epoch 0 step 2590: 3.1809982776641847\n",
      "\n",
      " This round's valence_loss=0.899747371673584, arousal_loss=0.6703879833221436, emotion_loss=0.8116998672485352\n",
      "\n",
      "01_19_23:06:13 Seen so far: 82912 samples\n",
      "\n",
      "01_19_23:06:13 --- 1.9921000003814697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:16 Training loss at epoch 0 step 2600: 3.029141902923584\n",
      "\n",
      " This round's valence_loss=0.5268834233283997, arousal_loss=0.33925795555114746, emotion_loss=1.1036239862442017\n",
      "\n",
      "01_19_23:06:16 Seen so far: 83232 samples\n",
      "\n",
      "01_19_23:06:16 --- 2.2887802124023438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:17 Training loss at epoch 0 step 2610: 3.0660598039627076\n",
      "\n",
      " This round's valence_loss=1.06361722946167, arousal_loss=0.9394692182540894, emotion_loss=0.9876984357833862\n",
      "\n",
      "01_19_23:06:17 Seen so far: 83552 samples\n",
      "\n",
      "01_19_23:06:17 --- 1.7541217803955078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:20 Training loss at epoch 0 step 2620: 3.5859098196029664\n",
      "\n",
      " This round's valence_loss=1.4980769157409668, arousal_loss=1.3364522457122803, emotion_loss=1.1482070684432983\n",
      "\n",
      "01_19_23:06:20 Seen so far: 83872 samples\n",
      "\n",
      "01_19_23:06:20 --- 2.0709493160247803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:22 Training loss at epoch 0 step 2630: 2.952557682991028\n",
      "\n",
      " This round's valence_loss=1.1253550052642822, arousal_loss=0.9999657273292542, emotion_loss=1.2420848608016968\n",
      "\n",
      "01_19_23:06:22 Seen so far: 84192 samples\n",
      "\n",
      "01_19_23:06:22 --- 2.0819826126098633 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:24 Training loss at epoch 0 step 2640: 3.200096845626831\n",
      "\n",
      " This round's valence_loss=1.0521557331085205, arousal_loss=0.8322887420654297, emotion_loss=1.009666085243225\n",
      "\n",
      "01_19_23:06:24 Seen so far: 84512 samples\n",
      "\n",
      "01_19_23:06:24 --- 2.2261509895324707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:26 Training loss at epoch 0 step 2650: 3.064520335197449\n",
      "\n",
      " This round's valence_loss=0.8691461682319641, arousal_loss=0.6825684905052185, emotion_loss=1.1783039569854736\n",
      "\n",
      "01_19_23:06:26 Seen so far: 84832 samples\n",
      "\n",
      "01_19_23:06:26 --- 2.2015459537506104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:28 Training loss at epoch 0 step 2660: 3.1637707233428953\n",
      "\n",
      " This round's valence_loss=1.147108554840088, arousal_loss=0.9346888065338135, emotion_loss=0.9865210652351379\n",
      "\n",
      "01_19_23:06:28 Seen so far: 85152 samples\n",
      "\n",
      "01_19_23:06:28 --- 2.2878975868225098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:30 Training loss at epoch 0 step 2670: 3.3435948848724366\n",
      "\n",
      " This round's valence_loss=1.0071760416030884, arousal_loss=0.6892021894454956, emotion_loss=0.8718540668487549\n",
      "\n",
      "01_19_23:06:30 Seen so far: 85472 samples\n",
      "\n",
      "01_19_23:06:30 --- 2.039956569671631 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:32 Training loss at epoch 0 step 2680: 3.26629958152771\n",
      "\n",
      " This round's valence_loss=1.2273075580596924, arousal_loss=1.0516576766967773, emotion_loss=0.9494806528091431\n",
      "\n",
      "01_19_23:06:32 Seen so far: 85792 samples\n",
      "\n",
      "01_19_23:06:32 --- 1.992722749710083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:34 Training loss at epoch 0 step 2690: 3.1000803470611573\n",
      "\n",
      " This round's valence_loss=1.2534940242767334, arousal_loss=1.0466551780700684, emotion_loss=0.8631249666213989\n",
      "\n",
      "01_19_23:06:34 Seen so far: 86112 samples\n",
      "\n",
      "01_19_23:06:34 --- 1.9597465991973877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:36 Training loss at epoch 0 step 2700: 3.3201873779296873\n",
      "\n",
      " This round's valence_loss=0.9257665872573853, arousal_loss=0.8284530639648438, emotion_loss=1.1230640411376953\n",
      "\n",
      "01_19_23:06:36 Seen so far: 86432 samples\n",
      "\n",
      "01_19_23:06:36 --- 1.9754886627197266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:38 Training loss at epoch 0 step 2710: 3.564190697669983\n",
      "\n",
      " This round's valence_loss=1.350118637084961, arousal_loss=1.2068417072296143, emotion_loss=1.2464001178741455\n",
      "\n",
      "01_19_23:06:38 Seen so far: 86752 samples\n",
      "\n",
      "01_19_23:06:38 --- 1.8790361881256104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:40 Training loss at epoch 0 step 2720: 3.1114734649658202\n",
      "\n",
      " This round's valence_loss=1.4440398216247559, arousal_loss=1.3267199993133545, emotion_loss=0.8307974934577942\n",
      "\n",
      "01_19_23:06:40 Seen so far: 87072 samples\n",
      "\n",
      "01_19_23:06:40 --- 2.0778276920318604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:42 Training loss at epoch 0 step 2730: 3.303501510620117\n",
      "\n",
      " This round's valence_loss=0.8989834189414978, arousal_loss=0.841541588306427, emotion_loss=1.5673491954803467\n",
      "\n",
      "01_19_23:06:42 Seen so far: 87392 samples\n",
      "\n",
      "01_19_23:06:42 --- 1.939074993133545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:44 Training loss at epoch 0 step 2740: 3.3236266374588013\n",
      "\n",
      " This round's valence_loss=1.2882626056671143, arousal_loss=1.1755684614181519, emotion_loss=1.1266330480575562\n",
      "\n",
      "01_19_23:06:44 Seen so far: 87712 samples\n",
      "\n",
      "01_19_23:06:44 --- 1.962085247039795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:46 Training loss at epoch 0 step 2750: 3.4706812620162966\n",
      "\n",
      " This round's valence_loss=1.3637073040008545, arousal_loss=1.1889359951019287, emotion_loss=0.9758689403533936\n",
      "\n",
      "01_19_23:06:46 Seen so far: 88032 samples\n",
      "\n",
      "01_19_23:06:46 --- 2.035557746887207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:48 Training loss at epoch 0 step 2760: 3.0732828617095946\n",
      "\n",
      " This round's valence_loss=1.164745569229126, arousal_loss=1.074467420578003, emotion_loss=1.0831568241119385\n",
      "\n",
      "01_19_23:06:48 Seen so far: 88352 samples\n",
      "\n",
      "01_19_23:06:48 --- 1.996406078338623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:50 Training loss at epoch 0 step 2770: 3.23655366897583\n",
      "\n",
      " This round's valence_loss=0.9694119691848755, arousal_loss=0.8065441846847534, emotion_loss=1.118004322052002\n",
      "\n",
      "01_19_23:06:50 Seen so far: 88672 samples\n",
      "\n",
      "01_19_23:06:50 --- 2.0771467685699463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:52 Training loss at epoch 0 step 2780: 3.1346802711486816\n",
      "\n",
      " This round's valence_loss=1.353423833847046, arousal_loss=1.2209197282791138, emotion_loss=1.182837963104248\n",
      "\n",
      "01_19_23:06:52 Seen so far: 88992 samples\n",
      "\n",
      "01_19_23:06:52 --- 2.1996092796325684 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:55 Training loss at epoch 0 step 2790: 3.3781792640686037\n",
      "\n",
      " This round's valence_loss=1.191856861114502, arousal_loss=1.1123371124267578, emotion_loss=1.2782807350158691\n",
      "\n",
      "01_19_23:06:55 Seen so far: 89312 samples\n",
      "\n",
      "01_19_23:06:55 --- 2.1601150035858154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:57 Training loss at epoch 0 step 2800: 3.2389107942581177\n",
      "\n",
      " This round's valence_loss=1.1784807443618774, arousal_loss=1.0863726139068604, emotion_loss=1.1967623233795166\n",
      "\n",
      "01_19_23:06:57 Seen so far: 89632 samples\n",
      "\n",
      "01_19_23:06:57 --- 2.0210604667663574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:06:59 Training loss at epoch 0 step 2810: 3.062483882904053\n",
      "\n",
      " This round's valence_loss=1.265453815460205, arousal_loss=1.0724563598632812, emotion_loss=0.7900280356407166\n",
      "\n",
      "01_19_23:06:59 Seen so far: 89952 samples\n",
      "\n",
      "01_19_23:06:59 --- 2.075197696685791 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:01 Training loss at epoch 0 step 2820: 2.8884124040603636\n",
      "\n",
      " This round's valence_loss=0.43862295150756836, arousal_loss=0.36934542655944824, emotion_loss=1.2633497714996338\n",
      "\n",
      "01_19_23:07:01 Seen so far: 90272 samples\n",
      "\n",
      "01_19_23:07:01 --- 2.1764886379241943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:03 Training loss at epoch 0 step 2830: 3.3668569803237913\n",
      "\n",
      " This round's valence_loss=1.6425148248672485, arousal_loss=1.464830756187439, emotion_loss=1.331304669380188\n",
      "\n",
      "01_19_23:07:03 Seen so far: 90592 samples\n",
      "\n",
      "01_19_23:07:03 --- 1.8492624759674072 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:05 Training loss at epoch 0 step 2840: 2.9999050378799437\n",
      "\n",
      " This round's valence_loss=1.0943357944488525, arousal_loss=0.9583312273025513, emotion_loss=0.898652970790863\n",
      "\n",
      "01_19_23:07:05 Seen so far: 90912 samples\n",
      "\n",
      "01_19_23:07:05 --- 1.9711098670959473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:07 Training loss at epoch 0 step 2850: 3.2759975671768187\n",
      "\n",
      " This round's valence_loss=0.7962402105331421, arousal_loss=0.5730015635490417, emotion_loss=1.032813549041748\n",
      "\n",
      "01_19_23:07:07 Seen so far: 91232 samples\n",
      "\n",
      "01_19_23:07:07 --- 2.077592611312866 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:09 Training loss at epoch 0 step 2860: 3.309956669807434\n",
      "\n",
      " This round's valence_loss=1.1142795085906982, arousal_loss=1.0190942287445068, emotion_loss=1.3762764930725098\n",
      "\n",
      "01_19_23:07:09 Seen so far: 91552 samples\n",
      "\n",
      "01_19_23:07:09 --- 1.8684704303741455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:11 Training loss at epoch 0 step 2870: 3.2498312473297117\n",
      "\n",
      " This round's valence_loss=1.3886289596557617, arousal_loss=1.3403240442276, emotion_loss=1.2173898220062256\n",
      "\n",
      "01_19_23:07:11 Seen so far: 91872 samples\n",
      "\n",
      "01_19_23:07:11 --- 2.1091785430908203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:13 Training loss at epoch 0 step 2880: 3.612417531013489\n",
      "\n",
      " This round's valence_loss=1.4224125146865845, arousal_loss=1.349433422088623, emotion_loss=1.2458854913711548\n",
      "\n",
      "01_19_23:07:13 Seen so far: 92192 samples\n",
      "\n",
      "01_19_23:07:13 --- 1.9654192924499512 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:15 Training loss at epoch 0 step 2890: 3.1346920013427733\n",
      "\n",
      " This round's valence_loss=1.5648109912872314, arousal_loss=1.488320231437683, emotion_loss=1.3866660594940186\n",
      "\n",
      "01_19_23:07:15 Seen so far: 92512 samples\n",
      "\n",
      "01_19_23:07:15 --- 2.1448450088500977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:17 Training loss at epoch 0 step 2900: 3.078962540626526\n",
      "\n",
      " This round's valence_loss=1.4260495901107788, arousal_loss=1.3203208446502686, emotion_loss=1.1673073768615723\n",
      "\n",
      "01_19_23:07:17 Seen so far: 92832 samples\n",
      "\n",
      "01_19_23:07:17 --- 2.381598472595215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:20 Training loss at epoch 0 step 2910: 3.299129319190979\n",
      "\n",
      " This round's valence_loss=1.3097195625305176, arousal_loss=1.234450340270996, emotion_loss=1.1411542892456055\n",
      "\n",
      "01_19_23:07:20 Seen so far: 93152 samples\n",
      "\n",
      "01_19_23:07:20 --- 2.341270685195923 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:22 Training loss at epoch 0 step 2920: 3.0178386688232424\n",
      "\n",
      " This round's valence_loss=1.6655762195587158, arousal_loss=1.57981538772583, emotion_loss=0.9726336598396301\n",
      "\n",
      "01_19_23:07:22 Seen so far: 93472 samples\n",
      "\n",
      "01_19_23:07:22 --- 2.551769495010376 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:24 Training loss at epoch 0 step 2930: 3.3094653844833375\n",
      "\n",
      " This round's valence_loss=1.1504132747650146, arousal_loss=1.110554575920105, emotion_loss=1.3519842624664307\n",
      "\n",
      "01_19_23:07:24 Seen so far: 93792 samples\n",
      "\n",
      "01_19_23:07:24 --- 1.9249072074890137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:26 Training loss at epoch 0 step 2940: 2.8107624530792235\n",
      "\n",
      " This round's valence_loss=1.114872694015503, arousal_loss=0.9628025889396667, emotion_loss=0.9390338063240051\n",
      "\n",
      "01_19_23:07:26 Seen so far: 94112 samples\n",
      "\n",
      "01_19_23:07:26 --- 2.3345706462860107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:28 Training loss at epoch 0 step 2950: 3.326038146018982\n",
      "\n",
      " This round's valence_loss=1.2444864511489868, arousal_loss=1.087886095046997, emotion_loss=1.0464930534362793\n",
      "\n",
      "01_19_23:07:28 Seen so far: 94432 samples\n",
      "\n",
      "01_19_23:07:28 --- 2.0737812519073486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:30 Training loss at epoch 0 step 2960: 3.454543685913086\n",
      "\n",
      " This round's valence_loss=1.515438437461853, arousal_loss=1.4784257411956787, emotion_loss=1.0947097539901733\n",
      "\n",
      "01_19_23:07:30 Seen so far: 94752 samples\n",
      "\n",
      "01_19_23:07:30 --- 1.923691987991333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:32 Training loss at epoch 0 step 2970: 3.4178469657897947\n",
      "\n",
      " This round's valence_loss=1.027516484260559, arousal_loss=0.8459857702255249, emotion_loss=1.3085956573486328\n",
      "\n",
      "01_19_23:07:32 Seen so far: 95072 samples\n",
      "\n",
      "01_19_23:07:32 --- 1.9682307243347168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:34 Training loss at epoch 0 step 2980: 3.2933018684387205\n",
      "\n",
      " This round's valence_loss=1.4577840566635132, arousal_loss=1.3164355754852295, emotion_loss=1.0306637287139893\n",
      "\n",
      "01_19_23:07:34 Seen so far: 95392 samples\n",
      "\n",
      "01_19_23:07:34 --- 2.0742440223693848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:36 Training loss at epoch 0 step 2990: 2.998060774803162\n",
      "\n",
      " This round's valence_loss=1.0947039127349854, arousal_loss=0.9632108807563782, emotion_loss=1.2299838066101074\n",
      "\n",
      "01_19_23:07:36 Seen so far: 95712 samples\n",
      "\n",
      "01_19_23:07:36 --- 1.8982014656066895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:38 Training loss at epoch 0 step 3000: 3.126501727104187\n",
      "\n",
      " This round's valence_loss=0.8719257712364197, arousal_loss=0.6792716979980469, emotion_loss=1.2094361782073975\n",
      "\n",
      "01_19_23:07:38 Seen so far: 96032 samples\n",
      "\n",
      "01_19_23:07:38 --- 2.082329034805298 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:40 Training loss at epoch 0 step 3010: 3.161544585227966\n",
      "\n",
      " This round's valence_loss=1.0730865001678467, arousal_loss=0.9767338037490845, emotion_loss=1.14322030544281\n",
      "\n",
      "01_19_23:07:40 Seen so far: 96352 samples\n",
      "\n",
      "01_19_23:07:40 --- 1.9911019802093506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:43 Training loss at epoch 0 step 3020: 2.943418562412262\n",
      "\n",
      " This round's valence_loss=1.2254136800765991, arousal_loss=1.0823309421539307, emotion_loss=1.0499943494796753\n",
      "\n",
      "01_19_23:07:43 Seen so far: 96672 samples\n",
      "\n",
      "01_19_23:07:43 --- 2.2374236583709717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:45 Training loss at epoch 0 step 3030: 3.3647292852401733\n",
      "\n",
      " This round's valence_loss=1.4598939418792725, arousal_loss=1.3066802024841309, emotion_loss=1.1349561214447021\n",
      "\n",
      "01_19_23:07:45 Seen so far: 96992 samples\n",
      "\n",
      "01_19_23:07:45 --- 1.8695969581604004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:46 Training loss at epoch 0 step 3040: 3.0433087944984436\n",
      "\n",
      " This round's valence_loss=1.096081018447876, arousal_loss=0.9618352055549622, emotion_loss=1.2397408485412598\n",
      "\n",
      "01_19_23:07:46 Seen so far: 97312 samples\n",
      "\n",
      "01_19_23:07:46 --- 1.901085615158081 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:48 Training loss at epoch 0 step 3050: 3.222784399986267\n",
      "\n",
      " This round's valence_loss=1.0357487201690674, arousal_loss=0.8200026750564575, emotion_loss=1.1813886165618896\n",
      "\n",
      "01_19_23:07:48 Seen so far: 97632 samples\n",
      "\n",
      "01_19_23:07:48 --- 2.0000693798065186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:50 Training loss at epoch 0 step 3060: 3.0646361112594604\n",
      "\n",
      " This round's valence_loss=1.0492808818817139, arousal_loss=0.9619364142417908, emotion_loss=1.2043359279632568\n",
      "\n",
      "01_19_23:07:50 Seen so far: 97952 samples\n",
      "\n",
      "01_19_23:07:50 --- 1.9692425727844238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:52 Training loss at epoch 0 step 3070: 3.2835245609283445\n",
      "\n",
      " This round's valence_loss=0.8242810964584351, arousal_loss=0.709538459777832, emotion_loss=1.0148879289627075\n",
      "\n",
      "01_19_23:07:52 Seen so far: 98272 samples\n",
      "\n",
      "01_19_23:07:52 --- 2.065758228302002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:55 Training loss at epoch 0 step 3080: 3.1738335609436037\n",
      "\n",
      " This round's valence_loss=1.0903007984161377, arousal_loss=1.0127999782562256, emotion_loss=0.8731755018234253\n",
      "\n",
      "01_19_23:07:55 Seen so far: 98592 samples\n",
      "\n",
      "01_19_23:07:55 --- 2.1783528327941895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:57 Training loss at epoch 0 step 3090: 3.172401452064514\n",
      "\n",
      " This round's valence_loss=1.5547199249267578, arousal_loss=1.4635624885559082, emotion_loss=1.0075623989105225\n",
      "\n",
      "01_19_23:07:57 Seen so far: 98912 samples\n",
      "\n",
      "01_19_23:07:57 --- 2.0527145862579346 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:07:59 Training loss at epoch 0 step 3100: 3.1118479490280153\n",
      "\n",
      " This round's valence_loss=0.8291260600090027, arousal_loss=0.6967065930366516, emotion_loss=1.0904512405395508\n",
      "\n",
      "01_19_23:07:59 Seen so far: 99232 samples\n",
      "\n",
      "01_19_23:07:59 --- 2.2602713108062744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:01 Training loss at epoch 0 step 3110: 3.1080140829086305\n",
      "\n",
      " This round's valence_loss=0.9577802419662476, arousal_loss=0.8463363647460938, emotion_loss=1.1995055675506592\n",
      "\n",
      "01_19_23:08:01 Seen so far: 99552 samples\n",
      "\n",
      "01_19_23:08:01 --- 1.9640476703643799 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:03 Training loss at epoch 0 step 3120: 3.415172266960144\n",
      "\n",
      " This round's valence_loss=1.4839465618133545, arousal_loss=1.2804734706878662, emotion_loss=0.8789459466934204\n",
      "\n",
      "01_19_23:08:03 Seen so far: 99872 samples\n",
      "\n",
      "01_19_23:08:03 --- 2.0137860774993896 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:05 Training loss at epoch 0 step 3130: 3.3609259128570557\n",
      "\n",
      " This round's valence_loss=1.1306445598602295, arousal_loss=0.9510110020637512, emotion_loss=1.3234660625457764\n",
      "\n",
      "01_19_23:08:05 Seen so far: 100192 samples\n",
      "\n",
      "01_19_23:08:05 --- 1.8675308227539062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:07 Training loss at epoch 0 step 3140: 3.1663017511367797\n",
      "\n",
      " This round's valence_loss=1.0995569229125977, arousal_loss=0.9843405485153198, emotion_loss=1.0999743938446045\n",
      "\n",
      "01_19_23:08:07 Seen so far: 100512 samples\n",
      "\n",
      "01_19_23:08:07 --- 1.9448671340942383 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:09 Training loss at epoch 0 step 3150: 3.270608139038086\n",
      "\n",
      " This round's valence_loss=1.1028742790222168, arousal_loss=0.985986053943634, emotion_loss=1.4191440343856812\n",
      "\n",
      "01_19_23:08:09 Seen so far: 100832 samples\n",
      "\n",
      "01_19_23:08:09 --- 1.9029293060302734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:11 Training loss at epoch 0 step 3160: 2.9184418678283692\n",
      "\n",
      " This round's valence_loss=1.1665675640106201, arousal_loss=0.973670482635498, emotion_loss=1.3729465007781982\n",
      "\n",
      "01_19_23:08:11 Seen so far: 101152 samples\n",
      "\n",
      "01_19_23:08:11 --- 1.9858908653259277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:13 Training loss at epoch 0 step 3170: 3.2789815187454225\n",
      "\n",
      " This round's valence_loss=0.8499157428741455, arousal_loss=0.7066056728363037, emotion_loss=1.418157696723938\n",
      "\n",
      "01_19_23:08:13 Seen so far: 101472 samples\n",
      "\n",
      "01_19_23:08:13 --- 1.892491102218628 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:14 Training loss at epoch 0 step 3180: 3.1105074167251585\n",
      "\n",
      " This round's valence_loss=0.6647741198539734, arousal_loss=0.44458621740341187, emotion_loss=1.1965947151184082\n",
      "\n",
      "01_19_23:08:14 Seen so far: 101792 samples\n",
      "\n",
      "01_19_23:08:14 --- 1.9467682838439941 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:17 Training loss at epoch 0 step 3190: 3.1175256729125977\n",
      "\n",
      " This round's valence_loss=0.9631954431533813, arousal_loss=0.856673002243042, emotion_loss=1.0288314819335938\n",
      "\n",
      "01_19_23:08:17 Seen so far: 102112 samples\n",
      "\n",
      "01_19_23:08:17 --- 2.0248100757598877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:18 Training loss at epoch 0 step 3200: 3.498651146888733\n",
      "\n",
      " This round's valence_loss=1.4080220460891724, arousal_loss=1.3151143789291382, emotion_loss=1.1084909439086914\n",
      "\n",
      "01_19_23:08:18 Seen so far: 102432 samples\n",
      "\n",
      "01_19_23:08:18 --- 1.9420042037963867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:20 Training loss at epoch 0 step 3210: 3.625235891342163\n",
      "\n",
      " This round's valence_loss=1.1980628967285156, arousal_loss=0.9588919878005981, emotion_loss=0.7996582984924316\n",
      "\n",
      "01_19_23:08:20 Seen so far: 102752 samples\n",
      "\n",
      "01_19_23:08:20 --- 1.983065128326416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:23 Training loss at epoch 0 step 3220: 3.3994613885879517\n",
      "\n",
      " This round's valence_loss=1.4012290239334106, arousal_loss=1.3227615356445312, emotion_loss=1.6137739419937134\n",
      "\n",
      "01_19_23:08:23 Seen so far: 103072 samples\n",
      "\n",
      "01_19_23:08:23 --- 2.0974128246307373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:25 Training loss at epoch 0 step 3230: 3.188668417930603\n",
      "\n",
      " This round's valence_loss=1.1826971769332886, arousal_loss=0.920963704586029, emotion_loss=0.8551067113876343\n",
      "\n",
      "01_19_23:08:25 Seen so far: 103392 samples\n",
      "\n",
      "01_19_23:08:25 --- 1.9969744682312012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:27 Training loss at epoch 0 step 3240: 3.4113696813583374\n",
      "\n",
      " This round's valence_loss=1.2003823518753052, arousal_loss=1.0947363376617432, emotion_loss=0.7909061312675476\n",
      "\n",
      "01_19_23:08:27 Seen so far: 103712 samples\n",
      "\n",
      "01_19_23:08:27 --- 2.08738374710083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:29 Training loss at epoch 0 step 3250: 3.1101914405822755\n",
      "\n",
      " This round's valence_loss=0.8636970520019531, arousal_loss=0.6917277574539185, emotion_loss=1.4079999923706055\n",
      "\n",
      "01_19_23:08:29 Seen so far: 104032 samples\n",
      "\n",
      "01_19_23:08:29 --- 2.03110933303833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:31 Training loss at epoch 0 step 3260: 3.189101219177246\n",
      "\n",
      " This round's valence_loss=1.2212433815002441, arousal_loss=1.082944631576538, emotion_loss=1.0009288787841797\n",
      "\n",
      "01_19_23:08:31 Seen so far: 104352 samples\n",
      "\n",
      "01_19_23:08:31 --- 2.172086238861084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:33 Training loss at epoch 0 step 3270: 3.174545168876648\n",
      "\n",
      " This round's valence_loss=0.6972317099571228, arousal_loss=0.5960241556167603, emotion_loss=1.2174301147460938\n",
      "\n",
      "01_19_23:08:33 Seen so far: 104672 samples\n",
      "\n",
      "01_19_23:08:33 --- 2.1865687370300293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:35 Training loss at epoch 0 step 3280: 3.119414520263672\n",
      "\n",
      " This round's valence_loss=1.142122507095337, arousal_loss=0.9487159848213196, emotion_loss=0.9859069585800171\n",
      "\n",
      "01_19_23:08:35 Seen so far: 104992 samples\n",
      "\n",
      "01_19_23:08:35 --- 2.0752389430999756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:37 Training loss at epoch 0 step 3290: 3.2250564813613893\n",
      "\n",
      " This round's valence_loss=0.9354149103164673, arousal_loss=0.8839951157569885, emotion_loss=1.4729735851287842\n",
      "\n",
      "01_19_23:08:37 Seen so far: 105312 samples\n",
      "\n",
      "01_19_23:08:37 --- 2.001472234725952 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:39 Training loss at epoch 0 step 3300: 2.9470871925354003\n",
      "\n",
      " This round's valence_loss=1.3325399160385132, arousal_loss=1.1621084213256836, emotion_loss=1.0873925685882568\n",
      "\n",
      "01_19_23:08:39 Seen so far: 105632 samples\n",
      "\n",
      "01_19_23:08:39 --- 1.8983535766601562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:41 Training loss at epoch 0 step 3310: 3.063602566719055\n",
      "\n",
      " This round's valence_loss=1.1262223720550537, arousal_loss=0.9944424033164978, emotion_loss=1.3797564506530762\n",
      "\n",
      "01_19_23:08:41 Seen so far: 105952 samples\n",
      "\n",
      "01_19_23:08:41 --- 1.8806138038635254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:43 Training loss at epoch 0 step 3320: 3.5513614892959593\n",
      "\n",
      " This round's valence_loss=1.34415602684021, arousal_loss=1.1950098276138306, emotion_loss=0.9073754549026489\n",
      "\n",
      "01_19_23:08:43 Seen so far: 106272 samples\n",
      "\n",
      "01_19_23:08:43 --- 2.0403857231140137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:45 Training loss at epoch 0 step 3330: 3.006757140159607\n",
      "\n",
      " This round's valence_loss=1.0379763841629028, arousal_loss=0.8325619697570801, emotion_loss=1.030491590499878\n",
      "\n",
      "01_19_23:08:45 Seen so far: 106592 samples\n",
      "\n",
      "01_19_23:08:45 --- 2.082528591156006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:47 Training loss at epoch 0 step 3340: 3.2670314073562623\n",
      "\n",
      " This round's valence_loss=1.1651867628097534, arousal_loss=0.9654662609100342, emotion_loss=0.8868781328201294\n",
      "\n",
      "01_19_23:08:47 Seen so far: 106912 samples\n",
      "\n",
      "01_19_23:08:47 --- 2.1509952545166016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:49 Training loss at epoch 0 step 3350: 3.3279097080230713\n",
      "\n",
      " This round's valence_loss=0.982122004032135, arousal_loss=0.8906495571136475, emotion_loss=1.2032747268676758\n",
      "\n",
      "01_19_23:08:49 Seen so far: 107232 samples\n",
      "\n",
      "01_19_23:08:49 --- 1.9466524124145508 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:51 Training loss at epoch 0 step 3360: 3.2354921102523804\n",
      "\n",
      " This round's valence_loss=1.0592000484466553, arousal_loss=0.8606403470039368, emotion_loss=1.535757303237915\n",
      "\n",
      "01_19_23:08:51 Seen so far: 107552 samples\n",
      "\n",
      "01_19_23:08:51 --- 1.9718832969665527 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:53 Training loss at epoch 0 step 3370: 3.185546565055847\n",
      "\n",
      " This round's valence_loss=0.9642086029052734, arousal_loss=0.8761162757873535, emotion_loss=0.9608669877052307\n",
      "\n",
      "01_19_23:08:53 Seen so far: 107872 samples\n",
      "\n",
      "01_19_23:08:53 --- 2.228686571121216 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:55 Training loss at epoch 0 step 3380: 2.890356421470642\n",
      "\n",
      " This round's valence_loss=0.9442411661148071, arousal_loss=0.8607749938964844, emotion_loss=1.405306100845337\n",
      "\n",
      "01_19_23:08:55 Seen so far: 108192 samples\n",
      "\n",
      "01_19_23:08:55 --- 2.092958927154541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:08:57 Training loss at epoch 0 step 3390: 3.129551959037781\n",
      "\n",
      " This round's valence_loss=0.6916199326515198, arousal_loss=0.4680631160736084, emotion_loss=1.2304470539093018\n",
      "\n",
      "01_19_23:08:57 Seen so far: 108512 samples\n",
      "\n",
      "01_19_23:08:57 --- 2.103358268737793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:00 Training loss at epoch 0 step 3400: 3.2354080438613892\n",
      "\n",
      " This round's valence_loss=1.3677122592926025, arousal_loss=1.2245577573776245, emotion_loss=1.348982810974121\n",
      "\n",
      "01_19_23:09:00 Seen so far: 108832 samples\n",
      "\n",
      "01_19_23:09:00 --- 2.0642967224121094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:02 Training loss at epoch 0 step 3410: 3.4782617807388307\n",
      "\n",
      " This round's valence_loss=0.8054440021514893, arousal_loss=0.708615779876709, emotion_loss=1.0860702991485596\n",
      "\n",
      "01_19_23:09:02 Seen so far: 109152 samples\n",
      "\n",
      "01_19_23:09:02 --- 2.021540880203247 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:04 Training loss at epoch 0 step 3420: 3.6701355934143067\n",
      "\n",
      " This round's valence_loss=1.6526530981063843, arousal_loss=1.5256412029266357, emotion_loss=0.7939489483833313\n",
      "\n",
      "01_19_23:09:04 Seen so far: 109472 samples\n",
      "\n",
      "01_19_23:09:04 --- 2.410226345062256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:06 Training loss at epoch 0 step 3430: 3.2428287506103515\n",
      "\n",
      " This round's valence_loss=1.5806066989898682, arousal_loss=1.585518717765808, emotion_loss=0.9100013971328735\n",
      "\n",
      "01_19_23:09:06 Seen so far: 109792 samples\n",
      "\n",
      "01_19_23:09:06 --- 2.059598922729492 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:08 Training loss at epoch 0 step 3440: 3.4273935079574587\n",
      "\n",
      " This round's valence_loss=0.7610577940940857, arousal_loss=0.6521833539009094, emotion_loss=1.2764432430267334\n",
      "\n",
      "01_19_23:09:08 Seen so far: 110112 samples\n",
      "\n",
      "01_19_23:09:08 --- 2.005675792694092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:10 Training loss at epoch 0 step 3450: 3.4487681865692137\n",
      "\n",
      " This round's valence_loss=1.3708970546722412, arousal_loss=1.320208191871643, emotion_loss=1.445481538772583\n",
      "\n",
      "01_19_23:09:10 Seen so far: 110432 samples\n",
      "\n",
      "01_19_23:09:10 --- 1.9678523540496826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:12 Training loss at epoch 0 step 3460: 3.4664007902145384\n",
      "\n",
      " This round's valence_loss=1.2978711128234863, arousal_loss=1.2026649713516235, emotion_loss=1.0816669464111328\n",
      "\n",
      "01_19_23:09:12 Seen so far: 110752 samples\n",
      "\n",
      "01_19_23:09:12 --- 2.019745349884033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:14 Training loss at epoch 0 step 3470: 3.1382342100143434\n",
      "\n",
      " This round's valence_loss=0.6779941320419312, arousal_loss=0.6142224073410034, emotion_loss=1.2099374532699585\n",
      "\n",
      "01_19_23:09:14 Seen so far: 111072 samples\n",
      "\n",
      "01_19_23:09:14 --- 1.9775278568267822 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:16 Training loss at epoch 0 step 3480: 3.1713165521621702\n",
      "\n",
      " This round's valence_loss=0.9139119386672974, arousal_loss=0.8647345900535583, emotion_loss=1.2495272159576416\n",
      "\n",
      "01_19_23:09:16 Seen so far: 111392 samples\n",
      "\n",
      "01_19_23:09:16 --- 2.1493947505950928 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:18 Training loss at epoch 0 step 3490: 2.9254173278808593\n",
      "\n",
      " This round's valence_loss=0.9233391284942627, arousal_loss=0.8523722290992737, emotion_loss=1.0430153608322144\n",
      "\n",
      "01_19_23:09:18 Seen so far: 111712 samples\n",
      "\n",
      "01_19_23:09:18 --- 2.1727144718170166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:20 Training loss at epoch 0 step 3500: 2.919662618637085\n",
      "\n",
      " This round's valence_loss=1.1460163593292236, arousal_loss=0.9932821989059448, emotion_loss=1.269209384918213\n",
      "\n",
      "01_19_23:09:20 Seen so far: 112032 samples\n",
      "\n",
      "01_19_23:09:20 --- 2.027979850769043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:22 Training loss at epoch 0 step 3510: 3.056072449684143\n",
      "\n",
      " This round's valence_loss=0.7407490015029907, arousal_loss=0.6426008343696594, emotion_loss=1.3543436527252197\n",
      "\n",
      "01_19_23:09:22 Seen so far: 112352 samples\n",
      "\n",
      "01_19_23:09:22 --- 1.898374319076538 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:24 Training loss at epoch 0 step 3520: 3.604405426979065\n",
      "\n",
      " This round's valence_loss=1.103803277015686, arousal_loss=0.9612566232681274, emotion_loss=1.2403959035873413\n",
      "\n",
      "01_19_23:09:24 Seen so far: 112672 samples\n",
      "\n",
      "01_19_23:09:24 --- 2.1782474517822266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:26 Training loss at epoch 0 step 3530: 2.939981245994568\n",
      "\n",
      " This round's valence_loss=0.7557500600814819, arousal_loss=0.6326920986175537, emotion_loss=1.24739408493042\n",
      "\n",
      "01_19_23:09:26 Seen so far: 112992 samples\n",
      "\n",
      "01_19_23:09:26 --- 1.897075891494751 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:28 Training loss at epoch 0 step 3540: 2.8238322496414185\n",
      "\n",
      " This round's valence_loss=0.8855416178703308, arousal_loss=0.6696020364761353, emotion_loss=1.1310813426971436\n",
      "\n",
      "01_19_23:09:28 Seen so far: 113312 samples\n",
      "\n",
      "01_19_23:09:28 --- 2.1389172077178955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:31 Training loss at epoch 0 step 3550: 2.862725019454956\n",
      "\n",
      " This round's valence_loss=0.7245835065841675, arousal_loss=0.6028753519058228, emotion_loss=1.0169368982315063\n",
      "\n",
      "01_19_23:09:31 Seen so far: 113632 samples\n",
      "\n",
      "01_19_23:09:31 --- 2.32289981842041 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:33 Training loss at epoch 0 step 3560: 3.704569387435913\n",
      "\n",
      " This round's valence_loss=1.4535690546035767, arousal_loss=1.2957655191421509, emotion_loss=1.1536328792572021\n",
      "\n",
      "01_19_23:09:33 Seen so far: 113952 samples\n",
      "\n",
      "01_19_23:09:33 --- 1.9913883209228516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:35 Training loss at epoch 0 step 3570: 3.2113328695297243\n",
      "\n",
      " This round's valence_loss=1.0162993669509888, arousal_loss=0.9357537031173706, emotion_loss=1.2028473615646362\n",
      "\n",
      "01_19_23:09:35 Seen so far: 114272 samples\n",
      "\n",
      "01_19_23:09:35 --- 1.9615647792816162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:37 Training loss at epoch 0 step 3580: 2.977144551277161\n",
      "\n",
      " This round's valence_loss=0.769975483417511, arousal_loss=0.5844993591308594, emotion_loss=1.0668531656265259\n",
      "\n",
      "01_19_23:09:37 Seen so far: 114592 samples\n",
      "\n",
      "01_19_23:09:37 --- 2.2524256706237793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:39 Training loss at epoch 0 step 3590: 3.255680775642395\n",
      "\n",
      " This round's valence_loss=1.1329251527786255, arousal_loss=1.0219595432281494, emotion_loss=1.3638193607330322\n",
      "\n",
      "01_19_23:09:39 Seen so far: 114912 samples\n",
      "\n",
      "01_19_23:09:39 --- 1.8478474617004395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:41 Training loss at epoch 0 step 3600: 3.686281108856201\n",
      "\n",
      " This round's valence_loss=1.6914212703704834, arousal_loss=1.5562738180160522, emotion_loss=1.0173169374465942\n",
      "\n",
      "01_19_23:09:41 Seen so far: 115232 samples\n",
      "\n",
      "01_19_23:09:41 --- 2.1040456295013428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:43 Training loss at epoch 0 step 3610: 3.2218546152114866\n",
      "\n",
      " This round's valence_loss=1.369768738746643, arousal_loss=1.3504306077957153, emotion_loss=1.3369638919830322\n",
      "\n",
      "01_19_23:09:43 Seen so far: 115552 samples\n",
      "\n",
      "01_19_23:09:43 --- 1.8248915672302246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:45 Training loss at epoch 0 step 3620: 3.1450206995010377\n",
      "\n",
      " This round's valence_loss=0.5243414044380188, arousal_loss=0.36559224128723145, emotion_loss=1.3642867803573608\n",
      "\n",
      "01_19_23:09:45 Seen so far: 115872 samples\n",
      "\n",
      "01_19_23:09:45 --- 2.1003568172454834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:47 Training loss at epoch 0 step 3630: 3.318675708770752\n",
      "\n",
      " This round's valence_loss=1.0843956470489502, arousal_loss=1.004220962524414, emotion_loss=1.294659972190857\n",
      "\n",
      "01_19_23:09:47 Seen so far: 116192 samples\n",
      "\n",
      "01_19_23:09:47 --- 1.9260122776031494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:49 Training loss at epoch 0 step 3640: 3.096846675872803\n",
      "\n",
      " This round's valence_loss=0.6142652034759521, arousal_loss=0.4778848886489868, emotion_loss=1.0418345928192139\n",
      "\n",
      "01_19_23:09:49 Seen so far: 116512 samples\n",
      "\n",
      "01_19_23:09:49 --- 2.091825485229492 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:51 Training loss at epoch 0 step 3650: 3.1326377391815186\n",
      "\n",
      " This round's valence_loss=0.9586225152015686, arousal_loss=0.837404727935791, emotion_loss=1.4818072319030762\n",
      "\n",
      "01_19_23:09:51 Seen so far: 116832 samples\n",
      "\n",
      "01_19_23:09:51 --- 1.8978571891784668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:53 Training loss at epoch 0 step 3660: 2.999368095397949\n",
      "\n",
      " This round's valence_loss=0.8507211208343506, arousal_loss=0.6869303584098816, emotion_loss=0.9575061798095703\n",
      "\n",
      "01_19_23:09:53 Seen so far: 117152 samples\n",
      "\n",
      "01_19_23:09:53 --- 2.1244585514068604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:55 Training loss at epoch 0 step 3670: 2.9647502660751344\n",
      "\n",
      " This round's valence_loss=0.6024404764175415, arousal_loss=0.4720626175403595, emotion_loss=1.0806829929351807\n",
      "\n",
      "01_19_23:09:55 Seen so far: 117472 samples\n",
      "\n",
      "01_19_23:09:55 --- 2.0979344844818115 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:57 Training loss at epoch 0 step 3680: 3.1759692907333372\n",
      "\n",
      " This round's valence_loss=1.001145601272583, arousal_loss=0.9249832630157471, emotion_loss=1.1321278810501099\n",
      "\n",
      "01_19_23:09:57 Seen so far: 117792 samples\n",
      "\n",
      "01_19_23:09:57 --- 2.031827449798584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:09:59 Training loss at epoch 0 step 3690: 3.408896780014038\n",
      "\n",
      " This round's valence_loss=1.5524698495864868, arousal_loss=1.465208888053894, emotion_loss=1.0821374654769897\n",
      "\n",
      "01_19_23:09:59 Seen so far: 118112 samples\n",
      "\n",
      "01_19_23:09:59 --- 1.9628195762634277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:01 Training loss at epoch 0 step 3700: 3.084602975845337\n",
      "\n",
      " This round's valence_loss=1.2712347507476807, arousal_loss=1.0244829654693604, emotion_loss=0.6949053406715393\n",
      "\n",
      "01_19_23:10:01 Seen so far: 118432 samples\n",
      "\n",
      "01_19_23:10:01 --- 2.036006212234497 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:03 Training loss at epoch 0 step 3710: 3.3772155046463013\n",
      "\n",
      " This round's valence_loss=1.1479244232177734, arousal_loss=0.9354683756828308, emotion_loss=1.1202466487884521\n",
      "\n",
      "01_19_23:10:03 Seen so far: 118752 samples\n",
      "\n",
      "01_19_23:10:03 --- 2.0951614379882812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:05 Training loss at epoch 0 step 3720: 3.230711007118225\n",
      "\n",
      " This round's valence_loss=1.3175476789474487, arousal_loss=1.2403967380523682, emotion_loss=1.076615810394287\n",
      "\n",
      "01_19_23:10:05 Seen so far: 119072 samples\n",
      "\n",
      "01_19_23:10:05 --- 2.069817304611206 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:07 Training loss at epoch 0 step 3730: 3.1448999643325806\n",
      "\n",
      " This round's valence_loss=0.9562970995903015, arousal_loss=0.7185704708099365, emotion_loss=0.9056302309036255\n",
      "\n",
      "01_19_23:10:07 Seen so far: 119392 samples\n",
      "\n",
      "01_19_23:10:07 --- 1.9907646179199219 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:09 Training loss at epoch 0 step 3740: 3.1179682493209837\n",
      "\n",
      " This round's valence_loss=1.3672246932983398, arousal_loss=1.1500167846679688, emotion_loss=1.1946762800216675\n",
      "\n",
      "01_19_23:10:09 Seen so far: 119712 samples\n",
      "\n",
      "01_19_23:10:09 --- 1.8944458961486816 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:11 Training loss at epoch 0 step 3750: 3.0633501768112184\n",
      "\n",
      " This round's valence_loss=0.8452876806259155, arousal_loss=0.6045764088630676, emotion_loss=1.3437455892562866\n",
      "\n",
      "01_19_23:10:11 Seen so far: 120032 samples\n",
      "\n",
      "01_19_23:10:11 --- 1.9748799800872803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:13 Training loss at epoch 0 step 3760: 3.4349183320999144\n",
      "\n",
      " This round's valence_loss=1.2119240760803223, arousal_loss=1.081995964050293, emotion_loss=0.8752918839454651\n",
      "\n",
      "01_19_23:10:13 Seen so far: 120352 samples\n",
      "\n",
      "01_19_23:10:13 --- 2.179551124572754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:15 Training loss at epoch 0 step 3770: 3.35031898021698\n",
      "\n",
      " This round's valence_loss=1.185126781463623, arousal_loss=1.0494890213012695, emotion_loss=0.7760841846466064\n",
      "\n",
      "01_19_23:10:15 Seen so far: 120672 samples\n",
      "\n",
      "01_19_23:10:15 --- 1.9864115715026855 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:18 Training loss at epoch 0 step 3780: 3.3353413105010987\n",
      "\n",
      " This round's valence_loss=1.1952165365219116, arousal_loss=1.069185733795166, emotion_loss=0.9978071451187134\n",
      "\n",
      "01_19_23:10:18 Seen so far: 120992 samples\n",
      "\n",
      "01_19_23:10:18 --- 2.3041443824768066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:20 Training loss at epoch 0 step 3790: 2.9678975343704224\n",
      "\n",
      " This round's valence_loss=0.8206264972686768, arousal_loss=0.715525209903717, emotion_loss=1.0702157020568848\n",
      "\n",
      "01_19_23:10:20 Seen so far: 121312 samples\n",
      "\n",
      "01_19_23:10:20 --- 2.0276107788085938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:22 Training loss at epoch 0 step 3800: 3.093914198875427\n",
      "\n",
      " This round's valence_loss=1.3890599012374878, arousal_loss=1.1610208749771118, emotion_loss=1.0620195865631104\n",
      "\n",
      "01_19_23:10:22 Seen so far: 121632 samples\n",
      "\n",
      "01_19_23:10:22 --- 2.0739521980285645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:24 Training loss at epoch 0 step 3810: 3.150424265861511\n",
      "\n",
      " This round's valence_loss=0.6638721823692322, arousal_loss=0.5564404726028442, emotion_loss=1.2670633792877197\n",
      "\n",
      "01_19_23:10:24 Seen so far: 121952 samples\n",
      "\n",
      "01_19_23:10:24 --- 2.0482776165008545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:26 Training loss at epoch 0 step 3820: 3.4843159198760985\n",
      "\n",
      " This round's valence_loss=1.180153727531433, arousal_loss=1.0882513523101807, emotion_loss=0.9796406626701355\n",
      "\n",
      "01_19_23:10:26 Seen so far: 122272 samples\n",
      "\n",
      "01_19_23:10:26 --- 2.2478160858154297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:28 Training loss at epoch 0 step 3830: 2.6883222222328187\n",
      "\n",
      " This round's valence_loss=1.0929311513900757, arousal_loss=1.021005630493164, emotion_loss=1.1193861961364746\n",
      "\n",
      "01_19_23:10:28 Seen so far: 122592 samples\n",
      "\n",
      "01_19_23:10:28 --- 2.0370609760284424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:30 Training loss at epoch 0 step 3840: 3.131087613105774\n",
      "\n",
      " This round's valence_loss=0.925647497177124, arousal_loss=0.8769931197166443, emotion_loss=1.3535230159759521\n",
      "\n",
      "01_19_23:10:30 Seen so far: 122912 samples\n",
      "\n",
      "01_19_23:10:30 --- 2.0119998455047607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:32 Training loss at epoch 0 step 3850: 3.2820571660995483\n",
      "\n",
      " This round's valence_loss=1.2057313919067383, arousal_loss=1.0996063947677612, emotion_loss=1.058914303779602\n",
      "\n",
      "01_19_23:10:32 Seen so far: 123232 samples\n",
      "\n",
      "01_19_23:10:32 --- 1.9355006217956543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:34 Training loss at epoch 0 step 3860: 3.2360328912734984\n",
      "\n",
      " This round's valence_loss=1.1126726865768433, arousal_loss=0.9783624410629272, emotion_loss=1.2036610841751099\n",
      "\n",
      "01_19_23:10:34 Seen so far: 123552 samples\n",
      "\n",
      "01_19_23:10:34 --- 2.071471691131592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:36 Training loss at epoch 0 step 3870: 2.8608996152877806\n",
      "\n",
      " This round's valence_loss=1.2931315898895264, arousal_loss=1.2765357494354248, emotion_loss=1.1376123428344727\n",
      "\n",
      "01_19_23:10:36 Seen so far: 123872 samples\n",
      "\n",
      "01_19_23:10:36 --- 2.0404562950134277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:38 Training loss at epoch 0 step 3880: 3.5104275941848755\n",
      "\n",
      " This round's valence_loss=1.0033947229385376, arousal_loss=0.8176714181900024, emotion_loss=1.0103368759155273\n",
      "\n",
      "01_19_23:10:38 Seen so far: 124192 samples\n",
      "\n",
      "01_19_23:10:38 --- 2.1982128620147705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:40 Training loss at epoch 0 step 3890: 3.0200931787490846\n",
      "\n",
      " This round's valence_loss=1.2661802768707275, arousal_loss=1.1042368412017822, emotion_loss=1.4218887090682983\n",
      "\n",
      "01_19_23:10:40 Seen so far: 124512 samples\n",
      "\n",
      "01_19_23:10:40 --- 1.8310086727142334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:42 Training loss at epoch 0 step 3900: 3.2214688539505003\n",
      "\n",
      " This round's valence_loss=1.3331718444824219, arousal_loss=1.2114629745483398, emotion_loss=0.9917558431625366\n",
      "\n",
      "01_19_23:10:42 Seen so far: 124832 samples\n",
      "\n",
      "01_19_23:10:42 --- 2.113193988800049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:44 Training loss at epoch 0 step 3910: 3.2988311767578127\n",
      "\n",
      " This round's valence_loss=1.409975290298462, arousal_loss=1.3283281326293945, emotion_loss=1.2568142414093018\n",
      "\n",
      "01_19_23:10:44 Seen so far: 125152 samples\n",
      "\n",
      "01_19_23:10:44 --- 1.8820927143096924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:46 Training loss at epoch 0 step 3920: 3.3539820671081544\n",
      "\n",
      " This round's valence_loss=1.1990749835968018, arousal_loss=1.0883342027664185, emotion_loss=1.0582510232925415\n",
      "\n",
      "01_19_23:10:46 Seen so far: 125472 samples\n",
      "\n",
      "01_19_23:10:46 --- 2.1064155101776123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:48 Training loss at epoch 0 step 3930: 3.106444549560547\n",
      "\n",
      " This round's valence_loss=1.0978729724884033, arousal_loss=0.9592584371566772, emotion_loss=1.168395757675171\n",
      "\n",
      "01_19_23:10:48 Seen so far: 125792 samples\n",
      "\n",
      "01_19_23:10:48 --- 1.9846203327178955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:50 Training loss at epoch 0 step 3940: 3.5096811771392824\n",
      "\n",
      " This round's valence_loss=1.3408279418945312, arousal_loss=1.2060420513153076, emotion_loss=1.0580649375915527\n",
      "\n",
      "01_19_23:10:50 Seen so far: 126112 samples\n",
      "\n",
      "01_19_23:10:50 --- 2.1435656547546387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:52 Training loss at epoch 0 step 3950: 3.0522697448730467\n",
      "\n",
      " This round's valence_loss=0.9550702571868896, arousal_loss=0.8639693260192871, emotion_loss=1.3247283697128296\n",
      "\n",
      "01_19_23:10:52 Seen so far: 126432 samples\n",
      "\n",
      "01_19_23:10:52 --- 1.853389024734497 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:54 Training loss at epoch 0 step 3960: 2.9520636320114138\n",
      "\n",
      " This round's valence_loss=0.9221909046173096, arousal_loss=0.8743098378181458, emotion_loss=1.4319443702697754\n",
      "\n",
      "01_19_23:10:54 Seen so far: 126752 samples\n",
      "\n",
      "01_19_23:10:54 --- 2.102020263671875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:56 Training loss at epoch 0 step 3970: 3.1564199686050416\n",
      "\n",
      " This round's valence_loss=1.1728347539901733, arousal_loss=1.0875102281570435, emotion_loss=1.3915024995803833\n",
      "\n",
      "01_19_23:10:56 Seen so far: 127072 samples\n",
      "\n",
      "01_19_23:10:56 --- 1.9622290134429932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:10:58 Training loss at epoch 0 step 3980: 3.1940448760986326\n",
      "\n",
      " This round's valence_loss=1.3350056409835815, arousal_loss=1.179321527481079, emotion_loss=1.1113722324371338\n",
      "\n",
      "01_19_23:10:58 Seen so far: 127392 samples\n",
      "\n",
      "01_19_23:10:58 --- 1.8724398612976074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:00 Training loss at epoch 0 step 3990: 3.250716733932495\n",
      "\n",
      " This round's valence_loss=1.1783382892608643, arousal_loss=1.0626088380813599, emotion_loss=1.1941841840744019\n",
      "\n",
      "01_19_23:11:00 Seen so far: 127712 samples\n",
      "\n",
      "01_19_23:11:00 --- 1.859605073928833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:02 Training loss at epoch 0 step 4000: 2.9642014503479004\n",
      "\n",
      " This round's valence_loss=1.543203592300415, arousal_loss=1.4476799964904785, emotion_loss=0.9449462890625\n",
      "\n",
      "01_19_23:11:02 Seen so far: 128032 samples\n",
      "\n",
      "01_19_23:11:02 --- 2.011770248413086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:04 Training loss at epoch 0 step 4010: 3.0924625277519224\n",
      "\n",
      " This round's valence_loss=1.7351250648498535, arousal_loss=1.5622851848602295, emotion_loss=0.8210653066635132\n",
      "\n",
      "01_19_23:11:04 Seen so far: 128352 samples\n",
      "\n",
      "01_19_23:11:04 --- 2.037069082260132 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:06 Training loss at epoch 0 step 4020: 3.301266312599182\n",
      "\n",
      " This round's valence_loss=1.0777512788772583, arousal_loss=0.9652038812637329, emotion_loss=1.3975766897201538\n",
      "\n",
      "01_19_23:11:06 Seen so far: 128672 samples\n",
      "\n",
      "01_19_23:11:06 --- 2.1139016151428223 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:08 Training loss at epoch 0 step 4030: 2.9443737268447876\n",
      "\n",
      " This round's valence_loss=0.5089232921600342, arousal_loss=0.3406292796134949, emotion_loss=0.9965091943740845\n",
      "\n",
      "01_19_23:11:08 Seen so far: 128992 samples\n",
      "\n",
      "01_19_23:11:08 --- 2.1056253910064697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:10 Training loss at epoch 0 step 4040: 2.9808785915374756\n",
      "\n",
      " This round's valence_loss=1.0110368728637695, arousal_loss=0.8774816989898682, emotion_loss=1.319333553314209\n",
      "\n",
      "01_19_23:11:10 Seen so far: 129312 samples\n",
      "\n",
      "01_19_23:11:10 --- 2.110039710998535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:12 Training loss at epoch 0 step 4050: 2.981132411956787\n",
      "\n",
      " This round's valence_loss=0.9649913311004639, arousal_loss=0.8808854818344116, emotion_loss=1.0086026191711426\n",
      "\n",
      "01_19_23:11:12 Seen so far: 129632 samples\n",
      "\n",
      "01_19_23:11:12 --- 1.9876410961151123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:14 Training loss at epoch 0 step 4060: 3.4902169942855834\n",
      "\n",
      " This round's valence_loss=0.9315195679664612, arousal_loss=0.7052725553512573, emotion_loss=0.9173065423965454\n",
      "\n",
      "01_19_23:11:14 Seen so far: 129952 samples\n",
      "\n",
      "01_19_23:11:14 --- 2.100313663482666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:16 Training loss at epoch 0 step 4070: 2.916378402709961\n",
      "\n",
      " This round's valence_loss=0.7928056120872498, arousal_loss=0.5721182823181152, emotion_loss=0.8949742913246155\n",
      "\n",
      "01_19_23:11:16 Seen so far: 130272 samples\n",
      "\n",
      "01_19_23:11:16 --- 1.94566011428833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:19 Training loss at epoch 0 step 4080: 3.3316075086593626\n",
      "\n",
      " This round's valence_loss=1.1495559215545654, arousal_loss=0.9589906930923462, emotion_loss=1.07159423828125\n",
      "\n",
      "01_19_23:11:19 Seen so far: 130592 samples\n",
      "\n",
      "01_19_23:11:19 --- 2.1593706607818604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:21 Training loss at epoch 0 step 4090: 3.127900409698486\n",
      "\n",
      " This round's valence_loss=0.9586229920387268, arousal_loss=0.8564053773880005, emotion_loss=1.030954122543335\n",
      "\n",
      "01_19_23:11:21 Seen so far: 130912 samples\n",
      "\n",
      "01_19_23:11:21 --- 1.9907677173614502 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:22 Training loss at epoch 0 step 4100: 3.1608659982681275\n",
      "\n",
      " This round's valence_loss=0.7603388428688049, arousal_loss=0.6185424327850342, emotion_loss=1.075519323348999\n",
      "\n",
      "01_19_23:11:22 Seen so far: 131232 samples\n",
      "\n",
      "01_19_23:11:22 --- 1.8439185619354248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:24 Training loss at epoch 0 step 4110: 3.1094207882881166\n",
      "\n",
      " This round's valence_loss=1.3068337440490723, arousal_loss=1.163383960723877, emotion_loss=1.0090223550796509\n",
      "\n",
      "01_19_23:11:24 Seen so far: 131552 samples\n",
      "\n",
      "01_19_23:11:24 --- 2.0905580520629883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:26 Training loss at epoch 0 step 4120: 3.2511153697967528\n",
      "\n",
      " This round's valence_loss=1.281665325164795, arousal_loss=1.2490825653076172, emotion_loss=1.3214815855026245\n",
      "\n",
      "01_19_23:11:26 Seen so far: 131872 samples\n",
      "\n",
      "01_19_23:11:26 --- 1.9119024276733398 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:28 Training loss at epoch 0 step 4130: 2.8466662883758547\n",
      "\n",
      " This round's valence_loss=0.8870499730110168, arousal_loss=0.771884560585022, emotion_loss=1.0083428621292114\n",
      "\n",
      "01_19_23:11:28 Seen so far: 132192 samples\n",
      "\n",
      "01_19_23:11:28 --- 2.019536256790161 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:30 Training loss at epoch 0 step 4140: 3.484202241897583\n",
      "\n",
      " This round's valence_loss=1.3100119829177856, arousal_loss=1.2171335220336914, emotion_loss=0.8881462216377258\n",
      "\n",
      "01_19_23:11:30 Seen so far: 132512 samples\n",
      "\n",
      "01_19_23:11:30 --- 2.0948069095611572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:32 Training loss at epoch 0 step 4150: 3.503804159164429\n",
      "\n",
      " This round's valence_loss=1.3988959789276123, arousal_loss=1.3525886535644531, emotion_loss=0.8695195317268372\n",
      "\n",
      "01_19_23:11:32 Seen so far: 132832 samples\n",
      "\n",
      "01_19_23:11:32 --- 1.938525676727295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:35 Training loss at epoch 0 step 4160: 3.0713919401168823\n",
      "\n",
      " This round's valence_loss=1.0785568952560425, arousal_loss=1.0072569847106934, emotion_loss=1.462443232536316\n",
      "\n",
      "01_19_23:11:35 Seen so far: 133152 samples\n",
      "\n",
      "01_19_23:11:35 --- 2.1220767498016357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:37 Training loss at epoch 0 step 4170: 3.261934423446655\n",
      "\n",
      " This round's valence_loss=1.2100987434387207, arousal_loss=1.0499002933502197, emotion_loss=1.3569517135620117\n",
      "\n",
      "01_19_23:11:37 Seen so far: 133472 samples\n",
      "\n",
      "01_19_23:11:37 --- 2.188750982284546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:39 Training loss at epoch 0 step 4180: 3.134809935092926\n",
      "\n",
      " This round's valence_loss=1.4231879711151123, arousal_loss=1.30482816696167, emotion_loss=1.1245319843292236\n",
      "\n",
      "01_19_23:11:39 Seen so far: 133792 samples\n",
      "\n",
      "01_19_23:11:39 --- 2.1832823753356934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:41 Training loss at epoch 0 step 4190: 3.242327880859375\n",
      "\n",
      " This round's valence_loss=0.8725060224533081, arousal_loss=0.7612060308456421, emotion_loss=1.1160727739334106\n",
      "\n",
      "01_19_23:11:41 Seen so far: 134112 samples\n",
      "\n",
      "01_19_23:11:41 --- 2.0490777492523193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:43 Training loss at epoch 0 step 4200: 3.222064161300659\n",
      "\n",
      " This round's valence_loss=0.9375389814376831, arousal_loss=0.6756026744842529, emotion_loss=0.7051036357879639\n",
      "\n",
      "01_19_23:11:43 Seen so far: 134432 samples\n",
      "\n",
      "01_19_23:11:43 --- 1.991445779800415 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:45 Training loss at epoch 0 step 4210: 3.0518474340438844\n",
      "\n",
      " This round's valence_loss=1.0463424921035767, arousal_loss=0.819656491279602, emotion_loss=1.0906522274017334\n",
      "\n",
      "01_19_23:11:45 Seen so far: 134752 samples\n",
      "\n",
      "01_19_23:11:45 --- 1.9424479007720947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:47 Training loss at epoch 0 step 4220: 3.13488883972168\n",
      "\n",
      " This round's valence_loss=0.7281712293624878, arousal_loss=0.6329120397567749, emotion_loss=1.1522096395492554\n",
      "\n",
      "01_19_23:11:47 Seen so far: 135072 samples\n",
      "\n",
      "01_19_23:11:47 --- 2.0794103145599365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:49 Training loss at epoch 0 step 4230: 3.393259620666504\n",
      "\n",
      " This round's valence_loss=1.145620584487915, arousal_loss=0.9456944465637207, emotion_loss=1.5534298419952393\n",
      "\n",
      "01_19_23:11:49 Seen so far: 135392 samples\n",
      "\n",
      "01_19_23:11:49 --- 2.0005714893341064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:51 Training loss at epoch 0 step 4240: 3.1410128355026243\n",
      "\n",
      " This round's valence_loss=0.7212996482849121, arousal_loss=0.4555034637451172, emotion_loss=1.3705674409866333\n",
      "\n",
      "01_19_23:11:51 Seen so far: 135712 samples\n",
      "\n",
      "01_19_23:11:51 --- 1.9866552352905273 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:53 Training loss at epoch 0 step 4250: 3.4974119424819947\n",
      "\n",
      " This round's valence_loss=0.8958646059036255, arousal_loss=0.82381272315979, emotion_loss=1.5620672702789307\n",
      "\n",
      "01_19_23:11:53 Seen so far: 136032 samples\n",
      "\n",
      "01_19_23:11:53 --- 2.034423351287842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:55 Training loss at epoch 0 step 4260: 3.231268572807312\n",
      "\n",
      " This round's valence_loss=1.4448976516723633, arousal_loss=1.280802845954895, emotion_loss=1.3148906230926514\n",
      "\n",
      "01_19_23:11:55 Seen so far: 136352 samples\n",
      "\n",
      "01_19_23:11:55 --- 2.0521585941314697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:57 Training loss at epoch 0 step 4270: 3.414420962333679\n",
      "\n",
      " This round's valence_loss=1.025694727897644, arousal_loss=0.8785195350646973, emotion_loss=1.4147858619689941\n",
      "\n",
      "01_19_23:11:57 Seen so far: 136672 samples\n",
      "\n",
      "01_19_23:11:57 --- 2.0652408599853516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:11:59 Training loss at epoch 0 step 4280: 3.1743459701538086\n",
      "\n",
      " This round's valence_loss=1.3794536590576172, arousal_loss=1.2190642356872559, emotion_loss=0.7567951679229736\n",
      "\n",
      "01_19_23:11:59 Seen so far: 136992 samples\n",
      "\n",
      "01_19_23:11:59 --- 2.181713104248047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:01 Training loss at epoch 0 step 4290: 3.54345498085022\n",
      "\n",
      " This round's valence_loss=1.064102292060852, arousal_loss=0.9743319749832153, emotion_loss=1.4062764644622803\n",
      "\n",
      "01_19_23:12:01 Seen so far: 137312 samples\n",
      "\n",
      "01_19_23:12:01 --- 1.9946582317352295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:03 Training loss at epoch 0 step 4300: 3.2897204399108886\n",
      "\n",
      " This round's valence_loss=1.2014105319976807, arousal_loss=1.0806405544281006, emotion_loss=1.1509883403778076\n",
      "\n",
      "01_19_23:12:03 Seen so far: 137632 samples\n",
      "\n",
      "01_19_23:12:03 --- 1.9458019733428955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:05 Training loss at epoch 0 step 4310: 3.008787512779236\n",
      "\n",
      " This round's valence_loss=1.0083969831466675, arousal_loss=0.8259321451187134, emotion_loss=0.8952242136001587\n",
      "\n",
      "01_19_23:12:05 Seen so far: 137952 samples\n",
      "\n",
      "01_19_23:12:05 --- 2.088782787322998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:07 Training loss at epoch 0 step 4320: 3.197191071510315\n",
      "\n",
      " This round's valence_loss=1.8016612529754639, arousal_loss=1.7174975872039795, emotion_loss=0.9175198078155518\n",
      "\n",
      "01_19_23:12:07 Seen so far: 138272 samples\n",
      "\n",
      "01_19_23:12:07 --- 2.0583083629608154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:10 Training loss at epoch 0 step 4330: 3.139434552192688\n",
      "\n",
      " This round's valence_loss=1.0854895114898682, arousal_loss=0.9771720170974731, emotion_loss=1.3451471328735352\n",
      "\n",
      "01_19_23:12:10 Seen so far: 138592 samples\n",
      "\n",
      "01_19_23:12:10 --- 2.1318469047546387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:12 Training loss at epoch 0 step 4340: 3.4592572689056396\n",
      "\n",
      " This round's valence_loss=1.4670298099517822, arousal_loss=1.2959275245666504, emotion_loss=0.9580636024475098\n",
      "\n",
      "01_19_23:12:12 Seen so far: 138912 samples\n",
      "\n",
      "01_19_23:12:12 --- 2.1595847606658936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:14 Training loss at epoch 0 step 4350: 3.158034896850586\n",
      "\n",
      " This round's valence_loss=1.0807256698608398, arousal_loss=1.0313862562179565, emotion_loss=1.1490943431854248\n",
      "\n",
      "01_19_23:12:14 Seen so far: 139232 samples\n",
      "\n",
      "01_19_23:12:14 --- 2.073573350906372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:16 Training loss at epoch 0 step 4360: 3.1321719169616697\n",
      "\n",
      " This round's valence_loss=1.2130614519119263, arousal_loss=1.061195969581604, emotion_loss=1.0462510585784912\n",
      "\n",
      "01_19_23:12:16 Seen so far: 139552 samples\n",
      "\n",
      "01_19_23:12:16 --- 2.1676290035247803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:18 Training loss at epoch 0 step 4370: 3.177073860168457\n",
      "\n",
      " This round's valence_loss=0.6522870659828186, arousal_loss=0.5234088897705078, emotion_loss=1.4536678791046143\n",
      "\n",
      "01_19_23:12:18 Seen so far: 139872 samples\n",
      "\n",
      "01_19_23:12:18 --- 2.0768332481384277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:20 Training loss at epoch 0 step 4380: 3.605179047584534\n",
      "\n",
      " This round's valence_loss=1.095261573791504, arousal_loss=0.9122190475463867, emotion_loss=1.3854880332946777\n",
      "\n",
      "01_19_23:12:20 Seen so far: 140192 samples\n",
      "\n",
      "01_19_23:12:20 --- 1.860645055770874 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:22 Training loss at epoch 0 step 4390: 3.4598440408706663\n",
      "\n",
      " This round's valence_loss=0.9603285789489746, arousal_loss=0.7203834056854248, emotion_loss=1.3764501810073853\n",
      "\n",
      "01_19_23:12:22 Seen so far: 140512 samples\n",
      "\n",
      "01_19_23:12:22 --- 2.0774600505828857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:24 Training loss at epoch 0 step 4400: 3.023841118812561\n",
      "\n",
      " This round's valence_loss=1.6810002326965332, arousal_loss=1.5415949821472168, emotion_loss=1.259995937347412\n",
      "\n",
      "01_19_23:12:24 Seen so far: 140832 samples\n",
      "\n",
      "01_19_23:12:24 --- 2.0092852115631104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:26 Training loss at epoch 0 step 4410: 2.9671652555465697\n",
      "\n",
      " This round's valence_loss=0.7877941727638245, arousal_loss=0.611609697341919, emotion_loss=1.370807409286499\n",
      "\n",
      "01_19_23:12:26 Seen so far: 141152 samples\n",
      "\n",
      "01_19_23:12:26 --- 2.0610551834106445 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:28 Training loss at epoch 0 step 4420: 3.0308942556381226\n",
      "\n",
      " This round's valence_loss=1.176951289176941, arousal_loss=1.0622026920318604, emotion_loss=1.2596137523651123\n",
      "\n",
      "01_19_23:12:28 Seen so far: 141472 samples\n",
      "\n",
      "01_19_23:12:28 --- 2.004567861557007 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:30 Training loss at epoch 0 step 4430: 3.526459288597107\n",
      "\n",
      " This round's valence_loss=1.302232027053833, arousal_loss=1.1729190349578857, emotion_loss=1.4050484895706177\n",
      "\n",
      "01_19_23:12:30 Seen so far: 141792 samples\n",
      "\n",
      "01_19_23:12:30 --- 1.8651998043060303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:32 Training loss at epoch 0 step 4440: 3.0493526220321656\n",
      "\n",
      " This round's valence_loss=1.228705644607544, arousal_loss=1.0992703437805176, emotion_loss=1.0715501308441162\n",
      "\n",
      "01_19_23:12:32 Seen so far: 142112 samples\n",
      "\n",
      "01_19_23:12:32 --- 2.184884786605835 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:34 Training loss at epoch 0 step 4450: 3.2684536457061766\n",
      "\n",
      " This round's valence_loss=0.9648501873016357, arousal_loss=0.8060889840126038, emotion_loss=1.0201325416564941\n",
      "\n",
      "01_19_23:12:34 Seen so far: 142432 samples\n",
      "\n",
      "01_19_23:12:34 --- 2.09179949760437 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:36 Training loss at epoch 0 step 4460: 3.453276491165161\n",
      "\n",
      " This round's valence_loss=1.802274465560913, arousal_loss=1.655672311782837, emotion_loss=1.1729652881622314\n",
      "\n",
      "01_19_23:12:36 Seen so far: 142752 samples\n",
      "\n",
      "01_19_23:12:36 --- 1.9771308898925781 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:38 Training loss at epoch 0 step 4470: 2.888476610183716\n",
      "\n",
      " This round's valence_loss=0.8734534382820129, arousal_loss=0.738795280456543, emotion_loss=0.8312283754348755\n",
      "\n",
      "01_19_23:12:38 Seen so far: 143072 samples\n",
      "\n",
      "01_19_23:12:38 --- 1.851513147354126 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:40 Training loss at epoch 0 step 4480: 2.9649442195892335\n",
      "\n",
      " This round's valence_loss=1.2000460624694824, arousal_loss=1.1116750240325928, emotion_loss=1.007843255996704\n",
      "\n",
      "01_19_23:12:40 Seen so far: 143392 samples\n",
      "\n",
      "01_19_23:12:40 --- 1.8783156871795654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:42 Training loss at epoch 0 step 4490: 3.173296904563904\n",
      "\n",
      " This round's valence_loss=0.9727538824081421, arousal_loss=0.7949800491333008, emotion_loss=0.7739155888557434\n",
      "\n",
      "01_19_23:12:42 Seen so far: 143712 samples\n",
      "\n",
      "01_19_23:12:42 --- 1.8412277698516846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:44 Training loss at epoch 0 step 4500: 2.818233609199524\n",
      "\n",
      " This round's valence_loss=1.128920078277588, arousal_loss=0.9836050271987915, emotion_loss=0.9946229457855225\n",
      "\n",
      "01_19_23:12:44 Seen so far: 144032 samples\n",
      "\n",
      "01_19_23:12:44 --- 1.9991073608398438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:46 Training loss at epoch 0 step 4510: 3.2733118891716004\n",
      "\n",
      " This round's valence_loss=1.0190876722335815, arousal_loss=0.8296961784362793, emotion_loss=1.0005276203155518\n",
      "\n",
      "01_19_23:12:46 Seen so far: 144352 samples\n",
      "\n",
      "01_19_23:12:46 --- 2.302837371826172 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:48 Training loss at epoch 0 step 4520: 3.0630552053451536\n",
      "\n",
      " This round's valence_loss=1.105778455734253, arousal_loss=0.9882113933563232, emotion_loss=0.9608330726623535\n",
      "\n",
      "01_19_23:12:48 Seen so far: 144672 samples\n",
      "\n",
      "01_19_23:12:48 --- 2.3080532550811768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:50 Training loss at epoch 0 step 4530: 2.866196036338806\n",
      "\n",
      " This round's valence_loss=0.8569484949111938, arousal_loss=0.5838468074798584, emotion_loss=1.1056499481201172\n",
      "\n",
      "01_19_23:12:50 Seen so far: 144992 samples\n",
      "\n",
      "01_19_23:12:50 --- 2.0928666591644287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:53 Training loss at epoch 0 step 4540: 3.3181316375732424\n",
      "\n",
      " This round's valence_loss=0.7537285089492798, arousal_loss=0.5901023149490356, emotion_loss=1.377288579940796\n",
      "\n",
      "01_19_23:12:53 Seen so far: 145312 samples\n",
      "\n",
      "01_19_23:12:53 --- 2.2415332794189453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:55 Training loss at epoch 0 step 4550: 3.0843440532684325\n",
      "\n",
      " This round's valence_loss=1.292597770690918, arousal_loss=1.082897663116455, emotion_loss=1.0427641868591309\n",
      "\n",
      "01_19_23:12:55 Seen so far: 145632 samples\n",
      "\n",
      "01_19_23:12:55 --- 2.1594948768615723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:57 Training loss at epoch 0 step 4560: 2.8921921253204346\n",
      "\n",
      " This round's valence_loss=0.6441671848297119, arousal_loss=0.4961550831794739, emotion_loss=1.1142406463623047\n",
      "\n",
      "01_19_23:12:57 Seen so far: 145952 samples\n",
      "\n",
      "01_19_23:12:57 --- 1.942338228225708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:12:59 Training loss at epoch 0 step 4570: 2.952084755897522\n",
      "\n",
      " This round's valence_loss=1.1355003118515015, arousal_loss=0.9906567335128784, emotion_loss=1.0787389278411865\n",
      "\n",
      "01_19_23:12:59 Seen so far: 146272 samples\n",
      "\n",
      "01_19_23:12:59 --- 2.0017340183258057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:01 Training loss at epoch 0 step 4580: 2.8854165196418764\n",
      "\n",
      " This round's valence_loss=0.775360107421875, arousal_loss=0.7403782606124878, emotion_loss=1.1631953716278076\n",
      "\n",
      "01_19_23:13:01 Seen so far: 146592 samples\n",
      "\n",
      "01_19_23:13:01 --- 1.9763116836547852 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:03 Training loss at epoch 0 step 4590: 3.013728678226471\n",
      "\n",
      " This round's valence_loss=1.6386128664016724, arousal_loss=1.4364798069000244, emotion_loss=0.9883760213851929\n",
      "\n",
      "01_19_23:13:03 Seen so far: 146912 samples\n",
      "\n",
      "01_19_23:13:03 --- 1.8736066818237305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:05 Training loss at epoch 0 step 4600: 3.120255398750305\n",
      "\n",
      " This round's valence_loss=1.0268363952636719, arousal_loss=0.8251302242279053, emotion_loss=1.153122901916504\n",
      "\n",
      "01_19_23:13:05 Seen so far: 147232 samples\n",
      "\n",
      "01_19_23:13:05 --- 2.0003135204315186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:07 Training loss at epoch 0 step 4610: 2.9609121561050413\n",
      "\n",
      " This round's valence_loss=0.6044603586196899, arousal_loss=0.3216599225997925, emotion_loss=0.9514027237892151\n",
      "\n",
      "01_19_23:13:07 Seen so far: 147552 samples\n",
      "\n",
      "01_19_23:13:07 --- 1.9776349067687988 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:09 Training loss at epoch 0 step 4620: 2.877248454093933\n",
      "\n",
      " This round's valence_loss=0.6287963390350342, arousal_loss=0.42802372574806213, emotion_loss=0.9817593097686768\n",
      "\n",
      "01_19_23:13:09 Seen so far: 147872 samples\n",
      "\n",
      "01_19_23:13:09 --- 1.9986052513122559 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:11 Training loss at epoch 0 step 4630: 3.2630950450897216\n",
      "\n",
      " This round's valence_loss=1.5246578454971313, arousal_loss=1.4194114208221436, emotion_loss=1.074852705001831\n",
      "\n",
      "01_19_23:13:11 Seen so far: 148192 samples\n",
      "\n",
      "01_19_23:13:11 --- 1.9896528720855713 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:13 Training loss at epoch 0 step 4640: 3.276855540275574\n",
      "\n",
      " This round's valence_loss=1.383897066116333, arousal_loss=1.3616420030593872, emotion_loss=1.0246169567108154\n",
      "\n",
      "01_19_23:13:13 Seen so far: 148512 samples\n",
      "\n",
      "01_19_23:13:13 --- 2.366071939468384 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:15 Training loss at epoch 0 step 4650: 2.9892573952674866\n",
      "\n",
      " This round's valence_loss=1.0885652303695679, arousal_loss=0.9450600147247314, emotion_loss=1.1370811462402344\n",
      "\n",
      "01_19_23:13:15 Seen so far: 148832 samples\n",
      "\n",
      "01_19_23:13:15 --- 2.2281653881073 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:17 Training loss at epoch 0 step 4660: 3.135332727432251\n",
      "\n",
      " This round's valence_loss=1.3264142274856567, arousal_loss=1.2044243812561035, emotion_loss=1.2079216241836548\n",
      "\n",
      "01_19_23:13:17 Seen so far: 149152 samples\n",
      "\n",
      "01_19_23:13:17 --- 2.2906363010406494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:20 Training loss at epoch 0 step 4670: 3.1072863340377808\n",
      "\n",
      " This round's valence_loss=1.0570621490478516, arousal_loss=0.9845224618911743, emotion_loss=1.3634871244430542\n",
      "\n",
      "01_19_23:13:20 Seen so far: 149472 samples\n",
      "\n",
      "01_19_23:13:20 --- 2.1347763538360596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:22 Training loss at epoch 0 step 4680: 3.398443508148193\n",
      "\n",
      " This round's valence_loss=0.8534625768661499, arousal_loss=0.726317286491394, emotion_loss=0.9989340305328369\n",
      "\n",
      "01_19_23:13:22 Seen so far: 149792 samples\n",
      "\n",
      "01_19_23:13:22 --- 2.081721305847168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:24 Training loss at epoch 0 step 4690: 3.206958842277527\n",
      "\n",
      " This round's valence_loss=0.7414349317550659, arousal_loss=0.5952051877975464, emotion_loss=1.2763769626617432\n",
      "\n",
      "01_19_23:13:24 Seen so far: 150112 samples\n",
      "\n",
      "01_19_23:13:24 --- 2.0493762493133545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:26 Training loss at epoch 0 step 4700: 2.9217005491256716\n",
      "\n",
      " This round's valence_loss=1.247609257698059, arousal_loss=1.071714162826538, emotion_loss=0.9964645504951477\n",
      "\n",
      "01_19_23:13:26 Seen so far: 150432 samples\n",
      "\n",
      "01_19_23:13:26 --- 1.9906294345855713 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:28 Training loss at epoch 0 step 4710: 3.373900580406189\n",
      "\n",
      " This round's valence_loss=0.8626959919929504, arousal_loss=0.6685490608215332, emotion_loss=1.1201483011245728\n",
      "\n",
      "01_19_23:13:28 Seen so far: 150752 samples\n",
      "\n",
      "01_19_23:13:28 --- 1.9286935329437256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:30 Training loss at epoch 0 step 4720: 3.234683632850647\n",
      "\n",
      " This round's valence_loss=0.8987104892730713, arousal_loss=0.8350182771682739, emotion_loss=1.304664134979248\n",
      "\n",
      "01_19_23:13:30 Seen so far: 151072 samples\n",
      "\n",
      "01_19_23:13:30 --- 2.128347396850586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:32 Training loss at epoch 0 step 4730: 3.1375723838806153\n",
      "\n",
      " This round's valence_loss=0.8237497806549072, arousal_loss=0.7535891532897949, emotion_loss=1.610378384590149\n",
      "\n",
      "01_19_23:13:32 Seen so far: 151392 samples\n",
      "\n",
      "01_19_23:13:32 --- 1.9447693824768066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:34 Training loss at epoch 0 step 4740: 3.0367588996887207\n",
      "\n",
      " This round's valence_loss=1.315701961517334, arousal_loss=1.2554357051849365, emotion_loss=1.0929776430130005\n",
      "\n",
      "01_19_23:13:34 Seen so far: 151712 samples\n",
      "\n",
      "01_19_23:13:34 --- 1.9430019855499268 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:36 Training loss at epoch 0 step 4750: 3.2867379665374754\n",
      "\n",
      " This round's valence_loss=1.0478973388671875, arousal_loss=1.0093276500701904, emotion_loss=1.277423620223999\n",
      "\n",
      "01_19_23:13:36 Seen so far: 152032 samples\n",
      "\n",
      "01_19_23:13:36 --- 1.989231824874878 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:38 Training loss at epoch 0 step 4760: 3.555855083465576\n",
      "\n",
      " This round's valence_loss=1.2284817695617676, arousal_loss=1.077460765838623, emotion_loss=1.1056430339813232\n",
      "\n",
      "01_19_23:13:38 Seen so far: 152352 samples\n",
      "\n",
      "01_19_23:13:38 --- 2.144911050796509 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:40 Training loss at epoch 0 step 4770: 3.28054416179657\n",
      "\n",
      " This round's valence_loss=1.119767427444458, arousal_loss=0.9618061780929565, emotion_loss=1.124709129333496\n",
      "\n",
      "01_19_23:13:40 Seen so far: 152672 samples\n",
      "\n",
      "01_19_23:13:40 --- 1.9597704410552979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:42 Training loss at epoch 0 step 4780: 3.2035736322402952\n",
      "\n",
      " This round's valence_loss=0.8253504037857056, arousal_loss=0.6641472578048706, emotion_loss=1.2051069736480713\n",
      "\n",
      "01_19_23:13:42 Seen so far: 152992 samples\n",
      "\n",
      "01_19_23:13:42 --- 1.9813365936279297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:44 Training loss at epoch 0 step 4790: 3.6119003534317016\n",
      "\n",
      " This round's valence_loss=1.5419034957885742, arousal_loss=1.4511775970458984, emotion_loss=1.0171144008636475\n",
      "\n",
      "01_19_23:13:44 Seen so far: 153312 samples\n",
      "\n",
      "01_19_23:13:44 --- 2.193207263946533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:46 Training loss at epoch 0 step 4800: 3.089905595779419\n",
      "\n",
      " This round's valence_loss=1.274854302406311, arousal_loss=1.0861066579818726, emotion_loss=0.9792581796646118\n",
      "\n",
      "01_19_23:13:46 Seen so far: 153632 samples\n",
      "\n",
      "01_19_23:13:46 --- 1.9713680744171143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:48 Training loss at epoch 0 step 4810: 3.2720826148986815\n",
      "\n",
      " This round's valence_loss=0.9881747961044312, arousal_loss=0.8712713718414307, emotion_loss=1.1832716464996338\n",
      "\n",
      "01_19_23:13:48 Seen so far: 153952 samples\n",
      "\n",
      "01_19_23:13:48 --- 2.00309419631958 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:50 Training loss at epoch 0 step 4820: 3.2078453063964845\n",
      "\n",
      " This round's valence_loss=1.0408639907836914, arousal_loss=0.8257876038551331, emotion_loss=1.2351188659667969\n",
      "\n",
      "01_19_23:13:50 Seen so far: 154272 samples\n",
      "\n",
      "01_19_23:13:50 --- 1.9510364532470703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:52 Training loss at epoch 0 step 4830: 3.2273768186569214\n",
      "\n",
      " This round's valence_loss=1.4677883386611938, arousal_loss=1.3485691547393799, emotion_loss=1.2981022596359253\n",
      "\n",
      "01_19_23:13:52 Seen so far: 154592 samples\n",
      "\n",
      "01_19_23:13:52 --- 2.027860641479492 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:54 Training loss at epoch 0 step 4840: 3.222105360031128\n",
      "\n",
      " This round's valence_loss=1.0166914463043213, arousal_loss=0.8815534114837646, emotion_loss=1.395430088043213\n",
      "\n",
      "01_19_23:13:54 Seen so far: 154912 samples\n",
      "\n",
      "01_19_23:13:54 --- 2.022010564804077 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:56 Training loss at epoch 0 step 4850: 3.170124053955078\n",
      "\n",
      " This round's valence_loss=1.0652434825897217, arousal_loss=1.0025684833526611, emotion_loss=0.981751561164856\n",
      "\n",
      "01_19_23:13:56 Seen so far: 155232 samples\n",
      "\n",
      "01_19_23:13:56 --- 2.058485269546509 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:13:58 Training loss at epoch 0 step 4860: 3.2058983564376833\n",
      "\n",
      " This round's valence_loss=0.8888455629348755, arousal_loss=0.6988916397094727, emotion_loss=1.1618245840072632\n",
      "\n",
      "01_19_23:13:58 Seen so far: 155552 samples\n",
      "\n",
      "01_19_23:13:58 --- 2.043426752090454 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:00 Training loss at epoch 0 step 4870: 3.0737681150436402\n",
      "\n",
      " This round's valence_loss=0.9751273989677429, arousal_loss=0.8797458410263062, emotion_loss=1.1142860651016235\n",
      "\n",
      "01_19_23:14:00 Seen so far: 155872 samples\n",
      "\n",
      "01_19_23:14:00 --- 2.413351058959961 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:03 Training loss at epoch 0 step 4880: 2.8708933115005495\n",
      "\n",
      " This round's valence_loss=1.062457799911499, arousal_loss=1.018969178199768, emotion_loss=1.378932237625122\n",
      "\n",
      "01_19_23:14:03 Seen so far: 156192 samples\n",
      "\n",
      "01_19_23:14:03 --- 2.201108694076538 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:04 Training loss at epoch 0 step 4890: 2.9934222221374513\n",
      "\n",
      " This round's valence_loss=1.4286329746246338, arousal_loss=1.3424460887908936, emotion_loss=1.4607659578323364\n",
      "\n",
      "01_19_23:14:04 Seen so far: 156512 samples\n",
      "\n",
      "01_19_23:14:04 --- 1.813776969909668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:07 Training loss at epoch 0 step 4900: 3.068303632736206\n",
      "\n",
      " This round's valence_loss=0.6666432619094849, arousal_loss=0.5248725414276123, emotion_loss=1.024711012840271\n",
      "\n",
      "01_19_23:14:07 Seen so far: 156832 samples\n",
      "\n",
      "01_19_23:14:07 --- 2.166680335998535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:09 Training loss at epoch 0 step 4910: 3.402629566192627\n",
      "\n",
      " This round's valence_loss=0.6130788922309875, arousal_loss=0.4967895746231079, emotion_loss=0.9649286270141602\n",
      "\n",
      "01_19_23:14:09 Seen so far: 157152 samples\n",
      "\n",
      "01_19_23:14:09 --- 2.0628128051757812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:11 Training loss at epoch 0 step 4920: 3.2617971181869505\n",
      "\n",
      " This round's valence_loss=0.9742147922515869, arousal_loss=0.8739601969718933, emotion_loss=1.2713384628295898\n",
      "\n",
      "01_19_23:14:11 Seen so far: 157472 samples\n",
      "\n",
      "01_19_23:14:11 --- 2.186065435409546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:13 Training loss at epoch 0 step 4930: 2.839521050453186\n",
      "\n",
      " This round's valence_loss=0.8719192743301392, arousal_loss=0.7548357248306274, emotion_loss=0.8002030849456787\n",
      "\n",
      "01_19_23:14:13 Seen so far: 157792 samples\n",
      "\n",
      "01_19_23:14:13 --- 2.271409273147583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:15 Training loss at epoch 0 step 4940: 3.014914631843567\n",
      "\n",
      " This round's valence_loss=1.105948805809021, arousal_loss=0.9940694570541382, emotion_loss=1.1218147277832031\n",
      "\n",
      "01_19_23:14:15 Seen so far: 158112 samples\n",
      "\n",
      "01_19_23:14:15 --- 2.031428098678589 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:17 Training loss at epoch 0 step 4950: 3.2899110555648803\n",
      "\n",
      " This round's valence_loss=1.4746325016021729, arousal_loss=1.3512264490127563, emotion_loss=1.3662090301513672\n",
      "\n",
      "01_19_23:14:17 Seen so far: 158432 samples\n",
      "\n",
      "01_19_23:14:17 --- 2.1023366451263428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:19 Training loss at epoch 0 step 4960: 3.349026846885681\n",
      "\n",
      " This round's valence_loss=1.2039778232574463, arousal_loss=1.117384672164917, emotion_loss=1.0672630071640015\n",
      "\n",
      "01_19_23:14:19 Seen so far: 158752 samples\n",
      "\n",
      "01_19_23:14:19 --- 2.1106536388397217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:22 Training loss at epoch 0 step 4970: 2.762545442581177\n",
      "\n",
      " This round's valence_loss=1.2257097959518433, arousal_loss=1.0942018032073975, emotion_loss=1.085951328277588\n",
      "\n",
      "01_19_23:14:22 Seen so far: 159072 samples\n",
      "\n",
      "01_19_23:14:22 --- 2.168290853500366 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:24 Training loss at epoch 0 step 4980: 3.371898579597473\n",
      "\n",
      " This round's valence_loss=1.7669670581817627, arousal_loss=1.6693694591522217, emotion_loss=1.3983571529388428\n",
      "\n",
      "01_19_23:14:24 Seen so far: 159392 samples\n",
      "\n",
      "01_19_23:14:24 --- 2.3504254817962646 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:26 Training loss at epoch 0 step 4990: 2.9468037843704225\n",
      "\n",
      " This round's valence_loss=0.7595165371894836, arousal_loss=0.6022459864616394, emotion_loss=1.4352850914001465\n",
      "\n",
      "01_19_23:14:26 Seen so far: 159712 samples\n",
      "\n",
      "01_19_23:14:26 --- 1.9612886905670166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:28 Training loss at epoch 0 step 5000: 3.056084704399109\n",
      "\n",
      " This round's valence_loss=1.2152009010314941, arousal_loss=1.0667095184326172, emotion_loss=0.8991589546203613\n",
      "\n",
      "01_19_23:14:28 Seen so far: 160032 samples\n",
      "\n",
      "01_19_23:14:28 --- 2.018085479736328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:30 Training loss at epoch 0 step 5010: 3.135209321975708\n",
      "\n",
      " This round's valence_loss=1.2839992046356201, arousal_loss=1.1996934413909912, emotion_loss=1.3273499011993408\n",
      "\n",
      "01_19_23:14:30 Seen so far: 160352 samples\n",
      "\n",
      "01_19_23:14:30 --- 1.7987313270568848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:32 Training loss at epoch 0 step 5020: 3.0985145568847656\n",
      "\n",
      " This round's valence_loss=1.1240317821502686, arousal_loss=0.9777470231056213, emotion_loss=1.2337788343429565\n",
      "\n",
      "01_19_23:14:32 Seen so far: 160672 samples\n",
      "\n",
      "01_19_23:14:32 --- 2.107177734375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:34 Training loss at epoch 0 step 5030: 3.2162806510925295\n",
      "\n",
      " This round's valence_loss=1.201777458190918, arousal_loss=1.1047366857528687, emotion_loss=1.3666658401489258\n",
      "\n",
      "01_19_23:14:34 Seen so far: 160992 samples\n",
      "\n",
      "01_19_23:14:34 --- 2.0618205070495605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:36 Training loss at epoch 0 step 5040: 3.2722158908843992\n",
      "\n",
      " This round's valence_loss=1.0658562183380127, arousal_loss=0.8330659866333008, emotion_loss=1.0003222227096558\n",
      "\n",
      "01_19_23:14:36 Seen so far: 161312 samples\n",
      "\n",
      "01_19_23:14:36 --- 1.9549202919006348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:38 Training loss at epoch 0 step 5050: 3.228419637680054\n",
      "\n",
      " This round's valence_loss=1.1941275596618652, arousal_loss=1.0031020641326904, emotion_loss=0.9923871159553528\n",
      "\n",
      "01_19_23:14:38 Seen so far: 161632 samples\n",
      "\n",
      "01_19_23:14:38 --- 2.0061957836151123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:40 Training loss at epoch 0 step 5060: 3.096100616455078\n",
      "\n",
      " This round's valence_loss=0.9689574241638184, arousal_loss=0.8366599082946777, emotion_loss=0.8983628749847412\n",
      "\n",
      "01_19_23:14:40 Seen so far: 161952 samples\n",
      "\n",
      "01_19_23:14:40 --- 1.9526009559631348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:42 Training loss at epoch 0 step 5070: 3.401479148864746\n",
      "\n",
      " This round's valence_loss=0.9336422681808472, arousal_loss=0.8778827786445618, emotion_loss=1.7233145236968994\n",
      "\n",
      "01_19_23:14:42 Seen so far: 162272 samples\n",
      "\n",
      "01_19_23:14:42 --- 1.9291870594024658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:44 Training loss at epoch 0 step 5080: 3.1746169567108153\n",
      "\n",
      " This round's valence_loss=0.7467840909957886, arousal_loss=0.6643089652061462, emotion_loss=1.212599515914917\n",
      "\n",
      "01_19_23:14:44 Seen so far: 162592 samples\n",
      "\n",
      "01_19_23:14:44 --- 1.939347505569458 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:46 Training loss at epoch 0 step 5090: 3.025883746147156\n",
      "\n",
      " This round's valence_loss=1.1067121028900146, arousal_loss=0.9964488744735718, emotion_loss=0.97921222448349\n",
      "\n",
      "01_19_23:14:46 Seen so far: 162912 samples\n",
      "\n",
      "01_19_23:14:46 --- 2.205822467803955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:48 Training loss at epoch 0 step 5100: 3.4363552808761595\n",
      "\n",
      " This round's valence_loss=1.640345573425293, arousal_loss=1.5712162256240845, emotion_loss=1.69728684425354\n",
      "\n",
      "01_19_23:14:48 Seen so far: 163232 samples\n",
      "\n",
      "01_19_23:14:48 --- 2.0787432193756104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:50 Training loss at epoch 0 step 5110: 3.6045642375946043\n",
      "\n",
      " This round's valence_loss=1.9711453914642334, arousal_loss=1.9675445556640625, emotion_loss=1.3908406496047974\n",
      "\n",
      "01_19_23:14:50 Seen so far: 163552 samples\n",
      "\n",
      "01_19_23:14:50 --- 2.0736260414123535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:52 Training loss at epoch 0 step 5120: 2.877218770980835\n",
      "\n",
      " This round's valence_loss=0.9367290139198303, arousal_loss=0.7334696650505066, emotion_loss=0.8797898888587952\n",
      "\n",
      "01_19_23:14:52 Seen so far: 163872 samples\n",
      "\n",
      "01_19_23:14:52 --- 2.037623405456543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:54 Training loss at epoch 0 step 5130: 3.4890595197677614\n",
      "\n",
      " This round's valence_loss=1.5499868392944336, arousal_loss=1.3419630527496338, emotion_loss=1.2439892292022705\n",
      "\n",
      "01_19_23:14:54 Seen so far: 164192 samples\n",
      "\n",
      "01_19_23:14:54 --- 2.2383997440338135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:56 Training loss at epoch 0 step 5140: 3.2758939981460573\n",
      "\n",
      " This round's valence_loss=1.2721645832061768, arousal_loss=1.0662922859191895, emotion_loss=1.1432267427444458\n",
      "\n",
      "01_19_23:14:56 Seen so far: 164512 samples\n",
      "\n",
      "01_19_23:14:56 --- 2.186837911605835 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:14:58 Training loss at epoch 0 step 5150: 3.1685477256774903\n",
      "\n",
      " This round's valence_loss=1.201225996017456, arousal_loss=1.1015053987503052, emotion_loss=1.2637939453125\n",
      "\n",
      "01_19_23:14:58 Seen so far: 164832 samples\n",
      "\n",
      "01_19_23:14:58 --- 2.035090208053589 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:01 Training loss at epoch 0 step 5160: 3.3736472368240356\n",
      "\n",
      " This round's valence_loss=1.249927043914795, arousal_loss=1.0861036777496338, emotion_loss=0.9935387372970581\n",
      "\n",
      "01_19_23:15:01 Seen so far: 165152 samples\n",
      "\n",
      "01_19_23:15:01 --- 2.1112313270568848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:03 Training loss at epoch 0 step 5170: 3.324304223060608\n",
      "\n",
      " This round's valence_loss=1.1850229501724243, arousal_loss=1.0564215183258057, emotion_loss=1.167646884918213\n",
      "\n",
      "01_19_23:15:03 Seen so far: 165472 samples\n",
      "\n",
      "01_19_23:15:03 --- 2.309221029281616 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:05 Training loss at epoch 0 step 5180: 3.2247650384902955\n",
      "\n",
      " This round's valence_loss=1.3485249280929565, arousal_loss=1.207853078842163, emotion_loss=0.9448837041854858\n",
      "\n",
      "01_19_23:15:05 Seen so far: 165792 samples\n",
      "\n",
      "01_19_23:15:05 --- 2.140789031982422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:07 Training loss at epoch 0 step 5190: 3.4205294847488403\n",
      "\n",
      " This round's valence_loss=1.261567234992981, arousal_loss=1.114187240600586, emotion_loss=1.2716845273971558\n",
      "\n",
      "01_19_23:15:07 Seen so far: 166112 samples\n",
      "\n",
      "01_19_23:15:07 --- 2.063575506210327 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:09 Training loss at epoch 0 step 5200: 2.9329614281654357\n",
      "\n",
      " This round's valence_loss=0.9459661245346069, arousal_loss=0.8121312856674194, emotion_loss=1.0852437019348145\n",
      "\n",
      "01_19_23:15:09 Seen so far: 166432 samples\n",
      "\n",
      "01_19_23:15:09 --- 1.9424145221710205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:11 Training loss at epoch 0 step 5210: 3.3142969846725463\n",
      "\n",
      " This round's valence_loss=0.7400001287460327, arousal_loss=0.6087515950202942, emotion_loss=1.1568446159362793\n",
      "\n",
      "01_19_23:15:11 Seen so far: 166752 samples\n",
      "\n",
      "01_19_23:15:11 --- 2.005056142807007 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:13 Training loss at epoch 0 step 5220: 3.2735775470733643\n",
      "\n",
      " This round's valence_loss=0.9888343811035156, arousal_loss=0.8568826913833618, emotion_loss=1.06132173538208\n",
      "\n",
      "01_19_23:15:13 Seen so far: 167072 samples\n",
      "\n",
      "01_19_23:15:13 --- 2.000978946685791 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:15 Training loss at epoch 0 step 5230: 3.4975884675979616\n",
      "\n",
      " This round's valence_loss=0.6449080109596252, arousal_loss=0.49243223667144775, emotion_loss=0.803596556186676\n",
      "\n",
      "01_19_23:15:15 Seen so far: 167392 samples\n",
      "\n",
      "01_19_23:15:15 --- 1.8306689262390137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:17 Training loss at epoch 0 step 5240: 3.3145015954971315\n",
      "\n",
      " This round's valence_loss=1.566619873046875, arousal_loss=1.4731438159942627, emotion_loss=1.3938331604003906\n",
      "\n",
      "01_19_23:15:17 Seen so far: 167712 samples\n",
      "\n",
      "01_19_23:15:17 --- 1.9282312393188477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:19 Training loss at epoch 0 step 5250: 3.054589557647705\n",
      "\n",
      " This round's valence_loss=0.5217998027801514, arousal_loss=0.3643031120300293, emotion_loss=0.9984222054481506\n",
      "\n",
      "01_19_23:15:19 Seen so far: 168032 samples\n",
      "\n",
      "01_19_23:15:19 --- 2.3122544288635254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:21 Training loss at epoch 0 step 5260: 3.1201899766922\n",
      "\n",
      " This round's valence_loss=1.520994782447815, arousal_loss=1.3334949016571045, emotion_loss=1.2182841300964355\n",
      "\n",
      "01_19_23:15:21 Seen so far: 168352 samples\n",
      "\n",
      "01_19_23:15:21 --- 2.265777349472046 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:24 Training loss at epoch 0 step 5270: 3.0251882791519167\n",
      "\n",
      " This round's valence_loss=0.6806848049163818, arousal_loss=0.46465879678726196, emotion_loss=1.0585352182388306\n",
      "\n",
      "01_19_23:15:24 Seen so far: 168672 samples\n",
      "\n",
      "01_19_23:15:24 --- 2.116499662399292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:26 Training loss at epoch 0 step 5280: 3.1904717922210692\n",
      "\n",
      " This round's valence_loss=1.0076513290405273, arousal_loss=0.8852123022079468, emotion_loss=1.4273064136505127\n",
      "\n",
      "01_19_23:15:26 Seen so far: 168992 samples\n",
      "\n",
      "01_19_23:15:26 --- 2.2295405864715576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:28 Training loss at epoch 0 step 5290: 3.186798119544983\n",
      "\n",
      " This round's valence_loss=1.2224807739257812, arousal_loss=1.0651127099990845, emotion_loss=1.1021034717559814\n",
      "\n",
      "01_19_23:15:28 Seen so far: 169312 samples\n",
      "\n",
      "01_19_23:15:28 --- 2.0608725547790527 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:30 Training loss at epoch 0 step 5300: 2.9318082332611084\n",
      "\n",
      " This round's valence_loss=1.337246298789978, arousal_loss=1.2010465860366821, emotion_loss=1.4234352111816406\n",
      "\n",
      "01_19_23:15:30 Seen so far: 169632 samples\n",
      "\n",
      "01_19_23:15:30 --- 2.1995298862457275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:32 Training loss at epoch 0 step 5310: 2.8506702899932863\n",
      "\n",
      " This round's valence_loss=0.7989234924316406, arousal_loss=0.725690484046936, emotion_loss=1.2689534425735474\n",
      "\n",
      "01_19_23:15:32 Seen so far: 169952 samples\n",
      "\n",
      "01_19_23:15:32 --- 2.1074976921081543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:34 Training loss at epoch 0 step 5320: 3.0952707290649415\n",
      "\n",
      " This round's valence_loss=0.7589138746261597, arousal_loss=0.586189866065979, emotion_loss=1.0201327800750732\n",
      "\n",
      "01_19_23:15:34 Seen so far: 170272 samples\n",
      "\n",
      "01_19_23:15:34 --- 1.9309446811676025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:36 Training loss at epoch 0 step 5330: 3.678435182571411\n",
      "\n",
      " This round's valence_loss=0.87562096118927, arousal_loss=0.7498951554298401, emotion_loss=1.304774284362793\n",
      "\n",
      "01_19_23:15:36 Seen so far: 170592 samples\n",
      "\n",
      "01_19_23:15:36 --- 1.8462107181549072 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:38 Training loss at epoch 0 step 5340: 3.1308841466903687\n",
      "\n",
      " This round's valence_loss=0.8167901039123535, arousal_loss=0.5549254417419434, emotion_loss=0.8601006865501404\n",
      "\n",
      "01_19_23:15:38 Seen so far: 170912 samples\n",
      "\n",
      "01_19_23:15:38 --- 1.7575886249542236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:40 Training loss at epoch 0 step 5350: 2.826514983177185\n",
      "\n",
      " This round's valence_loss=0.8320550322532654, arousal_loss=0.7221066951751709, emotion_loss=0.8860512375831604\n",
      "\n",
      "01_19_23:15:40 Seen so far: 171232 samples\n",
      "\n",
      "01_19_23:15:40 --- 1.962388515472412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:42 Training loss at epoch 0 step 5360: 3.1368185758590696\n",
      "\n",
      " This round's valence_loss=0.8739109039306641, arousal_loss=0.7219969630241394, emotion_loss=1.025848150253296\n",
      "\n",
      "01_19_23:15:42 Seen so far: 171552 samples\n",
      "\n",
      "01_19_23:15:42 --- 2.127577304840088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:44 Training loss at epoch 0 step 5370: 2.903890037536621\n",
      "\n",
      " This round's valence_loss=0.9671030640602112, arousal_loss=0.7964293956756592, emotion_loss=0.8854480981826782\n",
      "\n",
      "01_19_23:15:44 Seen so far: 171872 samples\n",
      "\n",
      "01_19_23:15:44 --- 2.175624132156372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:46 Training loss at epoch 0 step 5380: 3.1537761449813844\n",
      "\n",
      " This round's valence_loss=0.7723644971847534, arousal_loss=0.5943618416786194, emotion_loss=1.1396863460540771\n",
      "\n",
      "01_19_23:15:46 Seen so far: 172192 samples\n",
      "\n",
      "01_19_23:15:46 --- 1.9589807987213135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:48 Training loss at epoch 0 step 5390: 3.2872116804122924\n",
      "\n",
      " This round's valence_loss=1.7584381103515625, arousal_loss=1.6564884185791016, emotion_loss=1.2892969846725464\n",
      "\n",
      "01_19_23:15:48 Seen so far: 172512 samples\n",
      "\n",
      "01_19_23:15:48 --- 2.058441400527954 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:50 Training loss at epoch 0 step 5400: 3.045388627052307\n",
      "\n",
      " This round's valence_loss=0.858498215675354, arousal_loss=0.7058119177818298, emotion_loss=1.1502718925476074\n",
      "\n",
      "01_19_23:15:50 Seen so far: 172832 samples\n",
      "\n",
      "01_19_23:15:50 --- 2.059718608856201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:52 Training loss at epoch 0 step 5410: 3.14335298538208\n",
      "\n",
      " This round's valence_loss=1.2273187637329102, arousal_loss=1.1090164184570312, emotion_loss=1.4562203884124756\n",
      "\n",
      "01_19_23:15:52 Seen so far: 173152 samples\n",
      "\n",
      "01_19_23:15:52 --- 1.9693756103515625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:54 Training loss at epoch 0 step 5420: 2.9665025949478148\n",
      "\n",
      " This round's valence_loss=1.6125611066818237, arousal_loss=1.451404333114624, emotion_loss=1.0516656637191772\n",
      "\n",
      "01_19_23:15:54 Seen so far: 173472 samples\n",
      "\n",
      "01_19_23:15:54 --- 2.021836757659912 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:56 Training loss at epoch 0 step 5430: 2.815402364730835\n",
      "\n",
      " This round's valence_loss=1.1146715879440308, arousal_loss=0.9635962843894958, emotion_loss=1.0734541416168213\n",
      "\n",
      "01_19_23:15:56 Seen so far: 173792 samples\n",
      "\n",
      "01_19_23:15:56 --- 1.941904067993164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:15:58 Training loss at epoch 0 step 5440: 2.834619474411011\n",
      "\n",
      " This round's valence_loss=1.2333793640136719, arousal_loss=1.0515291690826416, emotion_loss=1.1337306499481201\n",
      "\n",
      "01_19_23:15:58 Seen so far: 174112 samples\n",
      "\n",
      "01_19_23:15:58 --- 1.957237958908081 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:00 Training loss at epoch 0 step 5450: 3.0141584992408754\n",
      "\n",
      " This round's valence_loss=0.6219907999038696, arousal_loss=0.5406930446624756, emotion_loss=0.8521270751953125\n",
      "\n",
      "01_19_23:16:00 Seen so far: 174432 samples\n",
      "\n",
      "01_19_23:16:00 --- 2.010190010070801 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:02 Training loss at epoch 0 step 5460: 2.9430906534194947\n",
      "\n",
      " This round's valence_loss=0.6599942445755005, arousal_loss=0.5267446041107178, emotion_loss=1.273622751235962\n",
      "\n",
      "01_19_23:16:02 Seen so far: 174752 samples\n",
      "\n",
      "01_19_23:16:02 --- 2.0795717239379883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:04 Training loss at epoch 0 step 5470: 3.283900833129883\n",
      "\n",
      " This round's valence_loss=1.4572114944458008, arousal_loss=1.3040310144424438, emotion_loss=0.7631081938743591\n",
      "\n",
      "01_19_23:16:04 Seen so far: 175072 samples\n",
      "\n",
      "01_19_23:16:04 --- 2.268078088760376 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:06 Training loss at epoch 0 step 5480: 3.2393821239471436\n",
      "\n",
      " This round's valence_loss=1.3427393436431885, arousal_loss=1.220795750617981, emotion_loss=1.3653476238250732\n",
      "\n",
      "01_19_23:16:06 Seen so far: 175392 samples\n",
      "\n",
      "01_19_23:16:06 --- 2.0104241371154785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:08 Training loss at epoch 0 step 5490: 3.0917648911476134\n",
      "\n",
      " This round's valence_loss=1.2432961463928223, arousal_loss=1.127136468887329, emotion_loss=1.0874738693237305\n",
      "\n",
      "01_19_23:16:08 Seen so far: 175712 samples\n",
      "\n",
      "01_19_23:16:08 --- 2.1459832191467285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:11 Training loss at epoch 0 step 5500: 3.2933648109436033\n",
      "\n",
      " This round's valence_loss=1.2825798988342285, arousal_loss=1.1808092594146729, emotion_loss=1.0714383125305176\n",
      "\n",
      "01_19_23:16:11 Seen so far: 176032 samples\n",
      "\n",
      "01_19_23:16:11 --- 2.3305554389953613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:13 Training loss at epoch 0 step 5510: 2.825781321525574\n",
      "\n",
      " This round's valence_loss=0.5235626697540283, arousal_loss=0.33741962909698486, emotion_loss=0.8272165656089783\n",
      "\n",
      "01_19_23:16:13 Seen so far: 176352 samples\n",
      "\n",
      "01_19_23:16:13 --- 2.2786829471588135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:15 Training loss at epoch 0 step 5520: 2.970809507369995\n",
      "\n",
      " This round's valence_loss=0.9486984014511108, arousal_loss=0.8399585485458374, emotion_loss=1.1531959772109985\n",
      "\n",
      "01_19_23:16:15 Seen so far: 176672 samples\n",
      "\n",
      "01_19_23:16:15 --- 2.0648903846740723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:17 Training loss at epoch 0 step 5530: 3.148927998542786\n",
      "\n",
      " This round's valence_loss=1.1488323211669922, arousal_loss=0.9481199979782104, emotion_loss=0.9162482023239136\n",
      "\n",
      "01_19_23:16:17 Seen so far: 176992 samples\n",
      "\n",
      "01_19_23:16:17 --- 2.0173277854919434 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:19 Training loss at epoch 0 step 5540: 3.585403394699097\n",
      "\n",
      " This round's valence_loss=1.296335220336914, arousal_loss=1.205774188041687, emotion_loss=1.2049518823623657\n",
      "\n",
      "01_19_23:16:19 Seen so far: 177312 samples\n",
      "\n",
      "01_19_23:16:19 --- 2.039283514022827 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:21 Training loss at epoch 0 step 5550: 3.216119170188904\n",
      "\n",
      " This round's valence_loss=1.221665859222412, arousal_loss=1.0993530750274658, emotion_loss=1.370190978050232\n",
      "\n",
      "01_19_23:16:21 Seen so far: 177632 samples\n",
      "\n",
      "01_19_23:16:21 --- 1.9943630695343018 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:23 Training loss at epoch 0 step 5560: 3.1306824922561645\n",
      "\n",
      " This round's valence_loss=0.9766581654548645, arousal_loss=0.8530548214912415, emotion_loss=1.0630916357040405\n",
      "\n",
      "01_19_23:16:23 Seen so far: 177952 samples\n",
      "\n",
      "01_19_23:16:23 --- 2.053300380706787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:25 Training loss at epoch 0 step 5570: 3.394431161880493\n",
      "\n",
      " This round's valence_loss=0.8007652759552002, arousal_loss=0.7798054218292236, emotion_loss=1.3297207355499268\n",
      "\n",
      "01_19_23:16:25 Seen so far: 178272 samples\n",
      "\n",
      "01_19_23:16:25 --- 2.2421715259552 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:28 Training loss at epoch 0 step 5580: 3.4411222457885744\n",
      "\n",
      " This round's valence_loss=1.2757854461669922, arousal_loss=1.1189689636230469, emotion_loss=0.7155081033706665\n",
      "\n",
      "01_19_23:16:28 Seen so far: 178592 samples\n",
      "\n",
      "01_19_23:16:28 --- 2.1393494606018066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:30 Training loss at epoch 0 step 5590: 3.358632755279541\n",
      "\n",
      " This round's valence_loss=1.0967200994491577, arousal_loss=0.955378532409668, emotion_loss=1.0098001956939697\n",
      "\n",
      "01_19_23:16:30 Seen so far: 178912 samples\n",
      "\n",
      "01_19_23:16:30 --- 2.089245319366455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:32 Training loss at epoch 0 step 5600: 3.0720396518707274\n",
      "\n",
      " This round's valence_loss=0.7935616970062256, arousal_loss=0.5868691205978394, emotion_loss=0.9812519550323486\n",
      "\n",
      "01_19_23:16:32 Seen so far: 179232 samples\n",
      "\n",
      "01_19_23:16:32 --- 1.9177966117858887 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:34 Training loss at epoch 0 step 5610: 3.35696165561676\n",
      "\n",
      " This round's valence_loss=1.6092334985733032, arousal_loss=1.4837493896484375, emotion_loss=1.1853185892105103\n",
      "\n",
      "01_19_23:16:34 Seen so far: 179552 samples\n",
      "\n",
      "01_19_23:16:34 --- 2.1582069396972656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:36 Training loss at epoch 0 step 5620: 3.0864832639694213\n",
      "\n",
      " This round's valence_loss=1.0561411380767822, arousal_loss=0.990612268447876, emotion_loss=1.385404109954834\n",
      "\n",
      "01_19_23:16:36 Seen so far: 179872 samples\n",
      "\n",
      "01_19_23:16:36 --- 2.0852608680725098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:38 Training loss at epoch 0 step 5630: 3.5050437450408936\n",
      "\n",
      " This round's valence_loss=1.2032400369644165, arousal_loss=1.0835325717926025, emotion_loss=1.3560173511505127\n",
      "\n",
      "01_19_23:16:38 Seen so far: 180192 samples\n",
      "\n",
      "01_19_23:16:38 --- 1.957101583480835 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:40 Training loss at epoch 0 step 5640: 2.946712517738342\n",
      "\n",
      " This round's valence_loss=1.0053218603134155, arousal_loss=0.964033842086792, emotion_loss=0.9486721158027649\n",
      "\n",
      "01_19_23:16:40 Seen so far: 180512 samples\n",
      "\n",
      "01_19_23:16:40 --- 1.9834463596343994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:42 Training loss at epoch 0 step 5650: 3.3184683084487916\n",
      "\n",
      " This round's valence_loss=1.1907329559326172, arousal_loss=1.1124191284179688, emotion_loss=1.4615615606307983\n",
      "\n",
      "01_19_23:16:42 Seen so far: 180832 samples\n",
      "\n",
      "01_19_23:16:42 --- 2.0288968086242676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:44 Training loss at epoch 0 step 5660: 2.9222605228424072\n",
      "\n",
      " This round's valence_loss=1.0278599262237549, arousal_loss=0.875831663608551, emotion_loss=1.199406623840332\n",
      "\n",
      "01_19_23:16:44 Seen so far: 181152 samples\n",
      "\n",
      "01_19_23:16:44 --- 2.0050480365753174 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:46 Training loss at epoch 0 step 5670: 3.688449430465698\n",
      "\n",
      " This round's valence_loss=1.3789081573486328, arousal_loss=1.237576961517334, emotion_loss=1.0079777240753174\n",
      "\n",
      "01_19_23:16:46 Seen so far: 181472 samples\n",
      "\n",
      "01_19_23:16:46 --- 1.8931360244750977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:48 Training loss at epoch 0 step 5680: 3.066598629951477\n",
      "\n",
      " This round's valence_loss=1.4560331106185913, arousal_loss=1.3049933910369873, emotion_loss=0.9467704892158508\n",
      "\n",
      "01_19_23:16:48 Seen so far: 181792 samples\n",
      "\n",
      "01_19_23:16:48 --- 1.9608509540557861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:50 Training loss at epoch 0 step 5690: 2.951371192932129\n",
      "\n",
      " This round's valence_loss=1.3097105026245117, arousal_loss=1.0215429067611694, emotion_loss=0.9469391107559204\n",
      "\n",
      "01_19_23:16:50 Seen so far: 182112 samples\n",
      "\n",
      "01_19_23:16:50 --- 1.9907822608947754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:52 Training loss at epoch 0 step 5700: 3.5157567739486693\n",
      "\n",
      " This round's valence_loss=0.7083027362823486, arousal_loss=0.6144323348999023, emotion_loss=1.192612886428833\n",
      "\n",
      "01_19_23:16:52 Seen so far: 182432 samples\n",
      "\n",
      "01_19_23:16:52 --- 2.066622257232666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:54 Training loss at epoch 0 step 5710: 3.0827463150024412\n",
      "\n",
      " This round's valence_loss=1.1153466701507568, arousal_loss=0.9797909259796143, emotion_loss=0.7914700508117676\n",
      "\n",
      "01_19_23:16:54 Seen so far: 182752 samples\n",
      "\n",
      "01_19_23:16:54 --- 2.0136067867279053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:56 Training loss at epoch 0 step 5720: 3.290021300315857\n",
      "\n",
      " This round's valence_loss=1.7768561840057373, arousal_loss=1.7083463668823242, emotion_loss=1.3804463148117065\n",
      "\n",
      "01_19_23:16:56 Seen so far: 183072 samples\n",
      "\n",
      "01_19_23:16:56 --- 2.0027377605438232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:16:58 Training loss at epoch 0 step 5730: 3.4299013137817385\n",
      "\n",
      " This round's valence_loss=0.9842569231987, arousal_loss=0.8726198673248291, emotion_loss=0.9031237363815308\n",
      "\n",
      "01_19_23:16:58 Seen so far: 183392 samples\n",
      "\n",
      "01_19_23:16:58 --- 2.1424529552459717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:00 Training loss at epoch 0 step 5740: 3.294053649902344\n",
      "\n",
      " This round's valence_loss=1.1474145650863647, arousal_loss=0.9312177896499634, emotion_loss=0.9525446891784668\n",
      "\n",
      "01_19_23:17:00 Seen so far: 183712 samples\n",
      "\n",
      "01_19_23:17:00 --- 1.9637248516082764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:02 Training loss at epoch 0 step 5750: 3.178859758377075\n",
      "\n",
      " This round's valence_loss=1.1965606212615967, arousal_loss=0.8970396518707275, emotion_loss=0.718629002571106\n",
      "\n",
      "01_19_23:17:02 Seen so far: 184032 samples\n",
      "\n",
      "01_19_23:17:02 --- 1.9933619499206543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:04 Training loss at epoch 0 step 5760: 3.0816089153289794\n",
      "\n",
      " This round's valence_loss=1.1054060459136963, arousal_loss=0.9319645166397095, emotion_loss=1.0608105659484863\n",
      "\n",
      "01_19_23:17:04 Seen so far: 184352 samples\n",
      "\n",
      "01_19_23:17:04 --- 2.1091763973236084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:06 Training loss at epoch 0 step 5770: 3.3537999868392943\n",
      "\n",
      " This round's valence_loss=1.0485152006149292, arousal_loss=1.0348669290542603, emotion_loss=1.5958467721939087\n",
      "\n",
      "01_19_23:17:06 Seen so far: 184672 samples\n",
      "\n",
      "01_19_23:17:06 --- 1.9358632564544678 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:08 Training loss at epoch 0 step 5780: 2.8271309614181517\n",
      "\n",
      " This round's valence_loss=0.9776924848556519, arousal_loss=0.8500779271125793, emotion_loss=0.9958931803703308\n",
      "\n",
      "01_19_23:17:08 Seen so far: 184992 samples\n",
      "\n",
      "01_19_23:17:08 --- 2.1471593379974365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:10 Training loss at epoch 0 step 5790: 3.0507686614990233\n",
      "\n",
      " This round's valence_loss=1.4739956855773926, arousal_loss=1.3113281726837158, emotion_loss=1.07614004611969\n",
      "\n",
      "01_19_23:17:10 Seen so far: 185312 samples\n",
      "\n",
      "01_19_23:17:10 --- 1.9666986465454102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:12 Training loss at epoch 0 step 5800: 2.7481032609939575\n",
      "\n",
      " This round's valence_loss=1.0847766399383545, arousal_loss=0.9529397487640381, emotion_loss=0.8734291791915894\n",
      "\n",
      "01_19_23:17:12 Seen so far: 185632 samples\n",
      "\n",
      "01_19_23:17:12 --- 1.921229600906372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:14 Training loss at epoch 0 step 5810: 3.4376830101013183\n",
      "\n",
      " This round's valence_loss=1.2175060510635376, arousal_loss=1.078481674194336, emotion_loss=1.3265882730484009\n",
      "\n",
      "01_19_23:17:14 Seen so far: 185952 samples\n",
      "\n",
      "01_19_23:17:14 --- 2.217393159866333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:16 Training loss at epoch 0 step 5820: 3.2623634815216063\n",
      "\n",
      " This round's valence_loss=1.4493792057037354, arousal_loss=1.350123643875122, emotion_loss=0.7830919027328491\n",
      "\n",
      "01_19_23:17:16 Seen so far: 186272 samples\n",
      "\n",
      "01_19_23:17:16 --- 2.169537305831909 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:18 Training loss at epoch 0 step 5830: 3.377513027191162\n",
      "\n",
      " This round's valence_loss=1.3670871257781982, arousal_loss=1.1825141906738281, emotion_loss=1.0814273357391357\n",
      "\n",
      "01_19_23:17:18 Seen so far: 186592 samples\n",
      "\n",
      "01_19_23:17:18 --- 2.0362415313720703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:20 Training loss at epoch 0 step 5840: 2.913429832458496\n",
      "\n",
      " This round's valence_loss=0.6140551567077637, arousal_loss=0.5248963832855225, emotion_loss=1.0724091529846191\n",
      "\n",
      "01_19_23:17:20 Seen so far: 186912 samples\n",
      "\n",
      "01_19_23:17:20 --- 1.9601058959960938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:22 Training loss at epoch 0 step 5850: 3.1829099655151367\n",
      "\n",
      " This round's valence_loss=0.5850459337234497, arousal_loss=0.47836732864379883, emotion_loss=1.29345703125\n",
      "\n",
      "01_19_23:17:22 Seen so far: 187232 samples\n",
      "\n",
      "01_19_23:17:22 --- 1.9321749210357666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:24 Training loss at epoch 0 step 5860: 3.240461277961731\n",
      "\n",
      " This round's valence_loss=0.644249677658081, arousal_loss=0.5130259394645691, emotion_loss=1.1825289726257324\n",
      "\n",
      "01_19_23:17:24 Seen so far: 187552 samples\n",
      "\n",
      "01_19_23:17:24 --- 2.0149643421173096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:26 Training loss at epoch 0 step 5870: 3.223877120018005\n",
      "\n",
      " This round's valence_loss=0.8804060220718384, arousal_loss=0.7352423667907715, emotion_loss=0.8748351335525513\n",
      "\n",
      "01_19_23:17:26 Seen so far: 187872 samples\n",
      "\n",
      "01_19_23:17:26 --- 1.8699533939361572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:28 Training loss at epoch 0 step 5880: 3.11461181640625\n",
      "\n",
      " This round's valence_loss=0.8714790344238281, arousal_loss=0.7190914154052734, emotion_loss=1.1043132543563843\n",
      "\n",
      "01_19_23:17:28 Seen so far: 188192 samples\n",
      "\n",
      "01_19_23:17:28 --- 1.813852071762085 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:30 Training loss at epoch 0 step 5890: 3.2113336324691772\n",
      "\n",
      " This round's valence_loss=1.7268190383911133, arousal_loss=1.6002002954483032, emotion_loss=1.175096869468689\n",
      "\n",
      "01_19_23:17:30 Seen so far: 188512 samples\n",
      "\n",
      "01_19_23:17:30 --- 2.0712451934814453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:32 Training loss at epoch 0 step 5900: 3.033761239051819\n",
      "\n",
      " This round's valence_loss=0.8799504637718201, arousal_loss=0.7127895951271057, emotion_loss=0.8703821897506714\n",
      "\n",
      "01_19_23:17:32 Seen so far: 188832 samples\n",
      "\n",
      "01_19_23:17:32 --- 1.9228732585906982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:34 Training loss at epoch 0 step 5910: 3.112451434135437\n",
      "\n",
      " This round's valence_loss=0.9092847108840942, arousal_loss=0.7612056136131287, emotion_loss=0.9532904624938965\n",
      "\n",
      "01_19_23:17:34 Seen so far: 189152 samples\n",
      "\n",
      "01_19_23:17:34 --- 2.054863929748535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:36 Training loss at epoch 0 step 5920: 3.2463497638702394\n",
      "\n",
      " This round's valence_loss=1.3084425926208496, arousal_loss=1.082230567932129, emotion_loss=1.1583194732666016\n",
      "\n",
      "01_19_23:17:36 Seen so far: 189472 samples\n",
      "\n",
      "01_19_23:17:36 --- 2.0608012676239014 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:38 Training loss at epoch 0 step 5930: 3.2297235488891602\n",
      "\n",
      " This round's valence_loss=1.4235864877700806, arousal_loss=1.336222529411316, emotion_loss=1.1672618389129639\n",
      "\n",
      "01_19_23:17:38 Seen so far: 189792 samples\n",
      "\n",
      "01_19_23:17:38 --- 1.941251516342163 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:40 Training loss at epoch 0 step 5940: 3.098514723777771\n",
      "\n",
      " This round's valence_loss=0.8490016460418701, arousal_loss=0.718542218208313, emotion_loss=0.9484179019927979\n",
      "\n",
      "01_19_23:17:40 Seen so far: 190112 samples\n",
      "\n",
      "01_19_23:17:40 --- 1.9093341827392578 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:42 Training loss at epoch 0 step 5950: 3.0651264667510985\n",
      "\n",
      " This round's valence_loss=0.9486851692199707, arousal_loss=0.8653456568717957, emotion_loss=1.5215208530426025\n",
      "\n",
      "01_19_23:17:42 Seen so far: 190432 samples\n",
      "\n",
      "01_19_23:17:42 --- 1.9487054347991943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:44 Training loss at epoch 0 step 5960: 3.1147379875183105\n",
      "\n",
      " This round's valence_loss=0.992302417755127, arousal_loss=0.8892130851745605, emotion_loss=1.021201491355896\n",
      "\n",
      "01_19_23:17:44 Seen so far: 190752 samples\n",
      "\n",
      "01_19_23:17:44 --- 2.0063869953155518 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:46 Training loss at epoch 0 step 5970: 3.3713754415512085\n",
      "\n",
      " This round's valence_loss=1.1205763816833496, arousal_loss=0.9734628200531006, emotion_loss=1.2961231470108032\n",
      "\n",
      "01_19_23:17:46 Seen so far: 191072 samples\n",
      "\n",
      "01_19_23:17:46 --- 2.099752426147461 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:48 Training loss at epoch 0 step 5980: 3.0881378173828127\n",
      "\n",
      " This round's valence_loss=0.710254430770874, arousal_loss=0.6992069482803345, emotion_loss=1.320521354675293\n",
      "\n",
      "01_19_23:17:48 Seen so far: 191392 samples\n",
      "\n",
      "01_19_23:17:48 --- 2.177483081817627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:50 Training loss at epoch 0 step 5990: 2.9109711050987244\n",
      "\n",
      " This round's valence_loss=0.5368854999542236, arousal_loss=0.4236786663532257, emotion_loss=1.1409175395965576\n",
      "\n",
      "01_19_23:17:50 Seen so far: 191712 samples\n",
      "\n",
      "01_19_23:17:50 --- 1.9638268947601318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:52 Training loss at epoch 0 step 6000: 3.101805830001831\n",
      "\n",
      " This round's valence_loss=0.9926176071166992, arousal_loss=0.8163538575172424, emotion_loss=1.0848569869995117\n",
      "\n",
      "01_19_23:17:52 Seen so far: 192032 samples\n",
      "\n",
      "01_19_23:17:52 --- 2.04597806930542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:54 Training loss at epoch 0 step 6010: 3.385683798789978\n",
      "\n",
      " This round's valence_loss=1.4727199077606201, arousal_loss=1.3633991479873657, emotion_loss=1.1869828701019287\n",
      "\n",
      "01_19_23:17:54 Seen so far: 192352 samples\n",
      "\n",
      "01_19_23:17:54 --- 1.9829256534576416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:56 Training loss at epoch 0 step 6020: 3.221718978881836\n",
      "\n",
      " This round's valence_loss=1.2115782499313354, arousal_loss=0.9694981575012207, emotion_loss=1.0054736137390137\n",
      "\n",
      "01_19_23:17:56 Seen so far: 192672 samples\n",
      "\n",
      "01_19_23:17:56 --- 1.9182617664337158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:17:58 Training loss at epoch 0 step 6030: 3.3177674531936647\n",
      "\n",
      " This round's valence_loss=1.1600234508514404, arousal_loss=1.1399586200714111, emotion_loss=1.3968743085861206\n",
      "\n",
      "01_19_23:17:58 Seen so far: 192992 samples\n",
      "\n",
      "01_19_23:17:58 --- 2.01987886428833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:00 Training loss at epoch 0 step 6040: 2.968833494186401\n",
      "\n",
      " This round's valence_loss=1.4950318336486816, arousal_loss=1.3483203649520874, emotion_loss=1.0704851150512695\n",
      "\n",
      "01_19_23:18:00 Seen so far: 193312 samples\n",
      "\n",
      "01_19_23:18:00 --- 1.788346529006958 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:02 Training loss at epoch 0 step 6050: 2.942819333076477\n",
      "\n",
      " This round's valence_loss=1.1320546865463257, arousal_loss=0.9545879364013672, emotion_loss=1.2029999494552612\n",
      "\n",
      "01_19_23:18:02 Seen so far: 193632 samples\n",
      "\n",
      "01_19_23:18:02 --- 2.1862592697143555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:04 Training loss at epoch 0 step 6060: 3.532007598876953\n",
      "\n",
      " This round's valence_loss=1.2235312461853027, arousal_loss=1.070685863494873, emotion_loss=1.354376196861267\n",
      "\n",
      "01_19_23:18:04 Seen so far: 193952 samples\n",
      "\n",
      "01_19_23:18:04 --- 2.140211343765259 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:06 Training loss at epoch 0 step 6070: 2.9779054880142213\n",
      "\n",
      " This round's valence_loss=0.6322375535964966, arousal_loss=0.4737704396247864, emotion_loss=1.0456066131591797\n",
      "\n",
      "01_19_23:18:06 Seen so far: 194272 samples\n",
      "\n",
      "01_19_23:18:06 --- 2.007728099822998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:08 Training loss at epoch 0 step 6080: 3.261655068397522\n",
      "\n",
      " This round's valence_loss=0.9660234451293945, arousal_loss=0.8528501987457275, emotion_loss=1.118107795715332\n",
      "\n",
      "01_19_23:18:08 Seen so far: 194592 samples\n",
      "\n",
      "01_19_23:18:08 --- 1.9946753978729248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:10 Training loss at epoch 0 step 6090: 3.018115293979645\n",
      "\n",
      " This round's valence_loss=0.740763783454895, arousal_loss=0.4635085463523865, emotion_loss=0.7867919206619263\n",
      "\n",
      "01_19_23:18:10 Seen so far: 194912 samples\n",
      "\n",
      "01_19_23:18:10 --- 1.9151623249053955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:12 Training loss at epoch 0 step 6100: 3.0000129461288454\n",
      "\n",
      " This round's valence_loss=1.9206644296646118, arousal_loss=1.817596197128296, emotion_loss=1.0603280067443848\n",
      "\n",
      "01_19_23:18:12 Seen so far: 195232 samples\n",
      "\n",
      "01_19_23:18:12 --- 1.9887285232543945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:14 Training loss at epoch 0 step 6110: 3.0204997420310975\n",
      "\n",
      " This round's valence_loss=1.2344262599945068, arousal_loss=1.0261958837509155, emotion_loss=0.7267078161239624\n",
      "\n",
      "01_19_23:18:14 Seen so far: 195552 samples\n",
      "\n",
      "01_19_23:18:14 --- 2.105682611465454 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:16 Training loss at epoch 0 step 6120: 3.20132896900177\n",
      "\n",
      " This round's valence_loss=1.349867343902588, arousal_loss=1.2228256464004517, emotion_loss=0.7745349407196045\n",
      "\n",
      "01_19_23:18:16 Seen so far: 195872 samples\n",
      "\n",
      "01_19_23:18:16 --- 1.9995977878570557 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:18 Training loss at epoch 0 step 6130: 2.9602808475494387\n",
      "\n",
      " This round's valence_loss=0.966198205947876, arousal_loss=0.6724803447723389, emotion_loss=0.909307599067688\n",
      "\n",
      "01_19_23:18:18 Seen so far: 196192 samples\n",
      "\n",
      "01_19_23:18:18 --- 2.102226495742798 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:20 Training loss at epoch 0 step 6140: 3.005160355567932\n",
      "\n",
      " This round's valence_loss=1.3747475147247314, arousal_loss=1.2230911254882812, emotion_loss=0.8346133232116699\n",
      "\n",
      "01_19_23:18:20 Seen so far: 196512 samples\n",
      "\n",
      "01_19_23:18:20 --- 1.9814670085906982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:22 Training loss at epoch 0 step 6150: 3.170823311805725\n",
      "\n",
      " This round's valence_loss=0.7395808696746826, arousal_loss=0.6376849412918091, emotion_loss=1.4036941528320312\n",
      "\n",
      "01_19_23:18:22 Seen so far: 196832 samples\n",
      "\n",
      "01_19_23:18:22 --- 1.9828836917877197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:24 Training loss at epoch 0 step 6160: 2.9841804265975953\n",
      "\n",
      " This round's valence_loss=1.3389880657196045, arousal_loss=1.1793642044067383, emotion_loss=1.076278567314148\n",
      "\n",
      "01_19_23:18:24 Seen so far: 197152 samples\n",
      "\n",
      "01_19_23:18:24 --- 2.0651233196258545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:26 Training loss at epoch 0 step 6170: 3.081907606124878\n",
      "\n",
      " This round's valence_loss=0.6856821775436401, arousal_loss=0.5934351682662964, emotion_loss=1.107212781906128\n",
      "\n",
      "01_19_23:18:26 Seen so far: 197472 samples\n",
      "\n",
      "01_19_23:18:26 --- 1.719937801361084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:28 Training loss at epoch 0 step 6180: 3.1898161649703978\n",
      "\n",
      " This round's valence_loss=1.0880227088928223, arousal_loss=0.9837892055511475, emotion_loss=1.1137208938598633\n",
      "\n",
      "01_19_23:18:28 Seen so far: 197792 samples\n",
      "\n",
      "01_19_23:18:28 --- 1.9885659217834473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:30 Training loss at epoch 0 step 6190: 3.062961554527283\n",
      "\n",
      " This round's valence_loss=1.2562201023101807, arousal_loss=1.1044979095458984, emotion_loss=1.07733154296875\n",
      "\n",
      "01_19_23:18:30 Seen so far: 198112 samples\n",
      "\n",
      "01_19_23:18:30 --- 2.098891019821167 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:32 Training loss at epoch 0 step 6200: 3.4339077711105346\n",
      "\n",
      " This round's valence_loss=0.8829902410507202, arousal_loss=0.7428684830665588, emotion_loss=1.1678400039672852\n",
      "\n",
      "01_19_23:18:32 Seen so far: 198432 samples\n",
      "\n",
      "01_19_23:18:32 --- 2.1078431606292725 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:34 Training loss at epoch 0 step 6210: 3.375894784927368\n",
      "\n",
      " This round's valence_loss=1.4410350322723389, arousal_loss=1.3506354093551636, emotion_loss=1.250868320465088\n",
      "\n",
      "01_19_23:18:34 Seen so far: 198752 samples\n",
      "\n",
      "01_19_23:18:34 --- 2.0248947143554688 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:36 Training loss at epoch 0 step 6220: 3.5060052394866945\n",
      "\n",
      " This round's valence_loss=1.2119299173355103, arousal_loss=1.1060121059417725, emotion_loss=1.4815585613250732\n",
      "\n",
      "01_19_23:18:36 Seen so far: 199072 samples\n",
      "\n",
      "01_19_23:18:36 --- 1.8997046947479248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:38 Training loss at epoch 0 step 6230: 3.1197499990463258\n",
      "\n",
      " This round's valence_loss=1.2493484020233154, arousal_loss=1.1168248653411865, emotion_loss=1.232250690460205\n",
      "\n",
      "01_19_23:18:38 Seen so far: 199392 samples\n",
      "\n",
      "01_19_23:18:38 --- 1.8707988262176514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:40 Training loss at epoch 0 step 6240: 3.474633526802063\n",
      "\n",
      " This round's valence_loss=0.778267502784729, arousal_loss=0.551892876625061, emotion_loss=1.0417848825454712\n",
      "\n",
      "01_19_23:18:40 Seen so far: 199712 samples\n",
      "\n",
      "01_19_23:18:40 --- 2.023965835571289 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:42 Training loss at epoch 0 step 6250: 3.327453780174255\n",
      "\n",
      " This round's valence_loss=1.3768200874328613, arousal_loss=1.313502311706543, emotion_loss=1.4732929468154907\n",
      "\n",
      "01_19_23:18:42 Seen so far: 200032 samples\n",
      "\n",
      "01_19_23:18:42 --- 2.186199188232422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:44 Training loss at epoch 0 step 6260: 3.1265494346618654\n",
      "\n",
      " This round's valence_loss=0.880427896976471, arousal_loss=0.6750115752220154, emotion_loss=0.9376091957092285\n",
      "\n",
      "01_19_23:18:44 Seen so far: 200352 samples\n",
      "\n",
      "01_19_23:18:44 --- 2.168698787689209 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:46 Training loss at epoch 0 step 6270: 2.9299559950828553\n",
      "\n",
      " This round's valence_loss=0.7456285357475281, arousal_loss=0.5806823968887329, emotion_loss=0.7765684127807617\n",
      "\n",
      "01_19_23:18:46 Seen so far: 200672 samples\n",
      "\n",
      "01_19_23:18:46 --- 2.075443983078003 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:49 Training loss at epoch 0 step 6280: 2.8644358634948732\n",
      "\n",
      " This round's valence_loss=1.1591054201126099, arousal_loss=1.0931247472763062, emotion_loss=1.0433058738708496\n",
      "\n",
      "01_19_23:18:49 Seen so far: 200992 samples\n",
      "\n",
      "01_19_23:18:49 --- 2.172795534133911 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:51 Training loss at epoch 0 step 6290: 2.995597171783447\n",
      "\n",
      " This round's valence_loss=0.7133175134658813, arousal_loss=0.6371897459030151, emotion_loss=1.146629810333252\n",
      "\n",
      "01_19_23:18:51 Seen so far: 201312 samples\n",
      "\n",
      "01_19_23:18:51 --- 1.9177310466766357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:53 Training loss at epoch 0 step 6300: 3.410529899597168\n",
      "\n",
      " This round's valence_loss=1.2517664432525635, arousal_loss=1.0795466899871826, emotion_loss=1.0785613059997559\n",
      "\n",
      "01_19_23:18:53 Seen so far: 201632 samples\n",
      "\n",
      "01_19_23:18:53 --- 1.9720137119293213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:54 Training loss at epoch 0 step 6310: 2.9860400557518005\n",
      "\n",
      " This round's valence_loss=0.9850932955741882, arousal_loss=0.8779982328414917, emotion_loss=1.231506586074829\n",
      "\n",
      "01_19_23:18:54 Seen so far: 201952 samples\n",
      "\n",
      "01_19_23:18:54 --- 1.9082586765289307 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:56 Training loss at epoch 0 step 6320: 3.2755722522735597\n",
      "\n",
      " This round's valence_loss=0.967591404914856, arousal_loss=0.8159464597702026, emotion_loss=0.9711192846298218\n",
      "\n",
      "01_19_23:18:56 Seen so far: 202272 samples\n",
      "\n",
      "01_19_23:18:56 --- 1.7540016174316406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:18:58 Training loss at epoch 0 step 6330: 2.977799892425537\n",
      "\n",
      " This round's valence_loss=1.247449517250061, arousal_loss=1.0637784004211426, emotion_loss=1.1175258159637451\n",
      "\n",
      "01_19_23:18:58 Seen so far: 202592 samples\n",
      "\n",
      "01_19_23:18:58 --- 1.9923429489135742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:00 Training loss at epoch 0 step 6340: 3.4078108072280884\n",
      "\n",
      " This round's valence_loss=0.598239541053772, arousal_loss=0.5338820815086365, emotion_loss=0.9467784762382507\n",
      "\n",
      "01_19_23:19:00 Seen so far: 202912 samples\n",
      "\n",
      "01_19_23:19:00 --- 2.200920581817627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:02 Training loss at epoch 0 step 6350: 2.8587467312812804\n",
      "\n",
      " This round's valence_loss=0.5829368233680725, arousal_loss=0.42835062742233276, emotion_loss=0.8868294954299927\n",
      "\n",
      "01_19_23:19:02 Seen so far: 203232 samples\n",
      "\n",
      "01_19_23:19:02 --- 2.090376615524292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:04 Training loss at epoch 0 step 6360: 3.0163858771324157\n",
      "\n",
      " This round's valence_loss=0.9765832424163818, arousal_loss=0.820926308631897, emotion_loss=1.0532503128051758\n",
      "\n",
      "01_19_23:19:04 Seen so far: 203552 samples\n",
      "\n",
      "01_19_23:19:04 --- 1.785184383392334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:06 Training loss at epoch 0 step 6370: 3.2954604387283326\n",
      "\n",
      " This round's valence_loss=1.5593658685684204, arousal_loss=1.435353398323059, emotion_loss=0.8622843027114868\n",
      "\n",
      "01_19_23:19:06 Seen so far: 203872 samples\n",
      "\n",
      "01_19_23:19:06 --- 1.8807313442230225 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:08 Training loss at epoch 0 step 6380: 3.2304535150527953\n",
      "\n",
      " This round's valence_loss=0.929700493812561, arousal_loss=0.8618379831314087, emotion_loss=1.489091396331787\n",
      "\n",
      "01_19_23:19:08 Seen so far: 204192 samples\n",
      "\n",
      "01_19_23:19:08 --- 1.9281635284423828 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:10 Training loss at epoch 0 step 6390: 3.1993810653686525\n",
      "\n",
      " This round's valence_loss=1.1281566619873047, arousal_loss=1.0124292373657227, emotion_loss=1.0294268131256104\n",
      "\n",
      "01_19_23:19:10 Seen so far: 204512 samples\n",
      "\n",
      "01_19_23:19:10 --- 1.8683993816375732 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:12 Training loss at epoch 0 step 6400: 3.450301456451416\n",
      "\n",
      " This round's valence_loss=0.8649947047233582, arousal_loss=0.7108044624328613, emotion_loss=1.401484489440918\n",
      "\n",
      "01_19_23:19:12 Seen so far: 204832 samples\n",
      "\n",
      "01_19_23:19:12 --- 2.2665774822235107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:14 Training loss at epoch 0 step 6410: 3.0909198999404905\n",
      "\n",
      " This round's valence_loss=1.4227185249328613, arousal_loss=1.385042428970337, emotion_loss=1.0561468601226807\n",
      "\n",
      "01_19_23:19:14 Seen so far: 205152 samples\n",
      "\n",
      "01_19_23:19:14 --- 2.015475034713745 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:16 Training loss at epoch 0 step 6420: 3.268920373916626\n",
      "\n",
      " This round's valence_loss=1.125462532043457, arousal_loss=1.0295791625976562, emotion_loss=1.2220385074615479\n",
      "\n",
      "01_19_23:19:16 Seen so far: 205472 samples\n",
      "\n",
      "01_19_23:19:16 --- 2.0810306072235107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:18 Training loss at epoch 0 step 6430: 3.0196832180023194\n",
      "\n",
      " This round's valence_loss=1.3376904726028442, arousal_loss=1.2023043632507324, emotion_loss=1.0481314659118652\n",
      "\n",
      "01_19_23:19:18 Seen so far: 205792 samples\n",
      "\n",
      "01_19_23:19:18 --- 1.9351704120635986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:20 Training loss at epoch 0 step 6440: 2.9415887355804444\n",
      "\n",
      " This round's valence_loss=1.500492811203003, arousal_loss=1.4756107330322266, emotion_loss=1.1157360076904297\n",
      "\n",
      "01_19_23:19:20 Seen so far: 206112 samples\n",
      "\n",
      "01_19_23:19:20 --- 1.862004280090332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:22 Training loss at epoch 0 step 6450: 3.3435129880905152\n",
      "\n",
      " This round's valence_loss=1.055037498474121, arousal_loss=0.9710185527801514, emotion_loss=1.148120403289795\n",
      "\n",
      "01_19_23:19:22 Seen so far: 206432 samples\n",
      "\n",
      "01_19_23:19:22 --- 1.9654934406280518 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:24 Training loss at epoch 0 step 6460: 3.0984543323516847\n",
      "\n",
      " This round's valence_loss=0.8950119018554688, arousal_loss=0.6965185403823853, emotion_loss=0.9911109805107117\n",
      "\n",
      "01_19_23:19:24 Seen so far: 206752 samples\n",
      "\n",
      "01_19_23:19:24 --- 1.8206470012664795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:26 Training loss at epoch 0 step 6470: 3.2333065032958985\n",
      "\n",
      " This round's valence_loss=1.048738718032837, arousal_loss=0.9682154655456543, emotion_loss=1.0651698112487793\n",
      "\n",
      "01_19_23:19:26 Seen so far: 207072 samples\n",
      "\n",
      "01_19_23:19:26 --- 2.0486981868743896 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:28 Training loss at epoch 0 step 6480: 3.147269606590271\n",
      "\n",
      " This round's valence_loss=0.8582163453102112, arousal_loss=0.7126878499984741, emotion_loss=1.137486457824707\n",
      "\n",
      "01_19_23:19:28 Seen so far: 207392 samples\n",
      "\n",
      "01_19_23:19:28 --- 2.0174999237060547 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:30 Training loss at epoch 0 step 6490: 3.08529155254364\n",
      "\n",
      " This round's valence_loss=1.3405543565750122, arousal_loss=1.176387071609497, emotion_loss=1.1470165252685547\n",
      "\n",
      "01_19_23:19:30 Seen so far: 207712 samples\n",
      "\n",
      "01_19_23:19:30 --- 2.1307151317596436 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:32 Training loss at epoch 0 step 6500: 3.306941270828247\n",
      "\n",
      " This round's valence_loss=1.0910142660140991, arousal_loss=1.001884937286377, emotion_loss=1.0268046855926514\n",
      "\n",
      "01_19_23:19:32 Seen so far: 208032 samples\n",
      "\n",
      "01_19_23:19:32 --- 1.975783109664917 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:34 Training loss at epoch 0 step 6510: 2.916509175300598\n",
      "\n",
      " This round's valence_loss=1.274308204650879, arousal_loss=1.0853573083877563, emotion_loss=1.0426777601242065\n",
      "\n",
      "01_19_23:19:34 Seen so far: 208352 samples\n",
      "\n",
      "01_19_23:19:34 --- 2.0501315593719482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:36 Training loss at epoch 0 step 6520: 2.962166166305542\n",
      "\n",
      " This round's valence_loss=0.9179381132125854, arousal_loss=0.7026081085205078, emotion_loss=0.7408910989761353\n",
      "\n",
      "01_19_23:19:36 Seen so far: 208672 samples\n",
      "\n",
      "01_19_23:19:36 --- 2.0649311542510986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:39 Training loss at epoch 0 step 6530: 2.945525026321411\n",
      "\n",
      " This round's valence_loss=0.88138747215271, arousal_loss=0.7019965648651123, emotion_loss=1.0515602827072144\n",
      "\n",
      "01_19_23:19:39 Seen so far: 208992 samples\n",
      "\n",
      "01_19_23:19:39 --- 2.3487205505371094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:41 Training loss at epoch 0 step 6540: 3.0146297931671144\n",
      "\n",
      " This round's valence_loss=0.8856449127197266, arousal_loss=0.7170266509056091, emotion_loss=0.8334869742393494\n",
      "\n",
      "01_19_23:19:41 Seen so far: 209312 samples\n",
      "\n",
      "01_19_23:19:41 --- 2.035689115524292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:42 Training loss at epoch 0 step 6550: 3.0470484495162964\n",
      "\n",
      " This round's valence_loss=0.8937973976135254, arousal_loss=0.6784964799880981, emotion_loss=1.0614975690841675\n",
      "\n",
      "01_19_23:19:42 Seen so far: 209632 samples\n",
      "\n",
      "01_19_23:19:42 --- 1.929255485534668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:44 Training loss at epoch 0 step 6560: 3.076478135585785\n",
      "\n",
      " This round's valence_loss=0.9826902151107788, arousal_loss=0.8432904481887817, emotion_loss=1.3488891124725342\n",
      "\n",
      "01_19_23:19:44 Seen so far: 209952 samples\n",
      "\n",
      "01_19_23:19:44 --- 1.9680750370025635 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:47 Training loss at epoch 0 step 6570: 2.9728394746780396\n",
      "\n",
      " This round's valence_loss=0.9941544532775879, arousal_loss=0.824591875076294, emotion_loss=0.5821361541748047\n",
      "\n",
      "01_19_23:19:47 Seen so far: 210272 samples\n",
      "\n",
      "01_19_23:19:47 --- 2.142751693725586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:49 Training loss at epoch 0 step 6580: 3.015343713760376\n",
      "\n",
      " This round's valence_loss=0.9172497987747192, arousal_loss=0.8556562066078186, emotion_loss=1.0996253490447998\n",
      "\n",
      "01_19_23:19:49 Seen so far: 210592 samples\n",
      "\n",
      "01_19_23:19:49 --- 1.9511785507202148 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:51 Training loss at epoch 0 step 6590: 2.713486909866333\n",
      "\n",
      " This round's valence_loss=0.7819311618804932, arousal_loss=0.6052901148796082, emotion_loss=1.0178799629211426\n",
      "\n",
      "01_19_23:19:51 Seen so far: 210912 samples\n",
      "\n",
      "01_19_23:19:51 --- 2.0167417526245117 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:52 Training loss at epoch 0 step 6600: 3.110284852981567\n",
      "\n",
      " This round's valence_loss=0.7993533611297607, arousal_loss=0.7043464779853821, emotion_loss=1.2542073726654053\n",
      "\n",
      "01_19_23:19:52 Seen so far: 211232 samples\n",
      "\n",
      "01_19_23:19:52 --- 1.715569019317627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:54 Training loss at epoch 0 step 6610: 3.1206632614135743\n",
      "\n",
      " This round's valence_loss=1.4617880582809448, arousal_loss=1.345266580581665, emotion_loss=1.1030316352844238\n",
      "\n",
      "01_19_23:19:54 Seen so far: 211552 samples\n",
      "\n",
      "01_19_23:19:54 --- 2.21405291557312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:56 Training loss at epoch 0 step 6620: 3.008039712905884\n",
      "\n",
      " This round's valence_loss=1.3009793758392334, arousal_loss=1.2167893648147583, emotion_loss=1.2134881019592285\n",
      "\n",
      "01_19_23:19:56 Seen so far: 211872 samples\n",
      "\n",
      "01_19_23:19:56 --- 1.8402595520019531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:19:59 Training loss at epoch 0 step 6630: 3.032195520401001\n",
      "\n",
      " This round's valence_loss=1.399374008178711, arousal_loss=1.2343082427978516, emotion_loss=1.1972386837005615\n",
      "\n",
      "01_19_23:19:59 Seen so far: 212192 samples\n",
      "\n",
      "01_19_23:19:59 --- 2.337519645690918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:01 Training loss at epoch 0 step 6640: 3.2023317337036135\n",
      "\n",
      " This round's valence_loss=0.7333651781082153, arousal_loss=0.5659664869308472, emotion_loss=0.9251565933227539\n",
      "\n",
      "01_19_23:20:01 Seen so far: 212512 samples\n",
      "\n",
      "01_19_23:20:01 --- 2.1748762130737305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:03 Training loss at epoch 0 step 6650: 3.123418188095093\n",
      "\n",
      " This round's valence_loss=1.296968698501587, arousal_loss=1.0453826189041138, emotion_loss=1.2535715103149414\n",
      "\n",
      "01_19_23:20:03 Seen so far: 212832 samples\n",
      "\n",
      "01_19_23:20:03 --- 1.9279413223266602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:05 Training loss at epoch 0 step 6660: 3.4460912466049196\n",
      "\n",
      " This round's valence_loss=1.1890451908111572, arousal_loss=1.1507456302642822, emotion_loss=1.495004653930664\n",
      "\n",
      "01_19_23:20:05 Seen so far: 213152 samples\n",
      "\n",
      "01_19_23:20:05 --- 1.974731206893921 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:07 Training loss at epoch 0 step 6670: 3.5122134685516357\n",
      "\n",
      " This round's valence_loss=1.170559287071228, arousal_loss=1.077692985534668, emotion_loss=1.008086085319519\n",
      "\n",
      "01_19_23:20:07 Seen so far: 213472 samples\n",
      "\n",
      "01_19_23:20:07 --- 1.8211491107940674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:09 Training loss at epoch 0 step 6680: 3.2686485052108765\n",
      "\n",
      " This round's valence_loss=0.685097336769104, arousal_loss=0.645890474319458, emotion_loss=1.5608389377593994\n",
      "\n",
      "01_19_23:20:09 Seen so far: 213792 samples\n",
      "\n",
      "01_19_23:20:09 --- 2.182356595993042 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:11 Training loss at epoch 0 step 6690: 3.07127902507782\n",
      "\n",
      " This round's valence_loss=1.0212554931640625, arousal_loss=0.8728532791137695, emotion_loss=0.9767531156539917\n",
      "\n",
      "01_19_23:20:11 Seen so far: 214112 samples\n",
      "\n",
      "01_19_23:20:11 --- 1.898892879486084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:13 Training loss at epoch 0 step 6700: 3.4602373600006104\n",
      "\n",
      " This round's valence_loss=1.061263918876648, arousal_loss=0.9507714509963989, emotion_loss=1.0003598928451538\n",
      "\n",
      "01_19_23:20:13 Seen so far: 214432 samples\n",
      "\n",
      "01_19_23:20:13 --- 1.9238557815551758 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:15 Training loss at epoch 0 step 6710: 3.458851671218872\n",
      "\n",
      " This round's valence_loss=0.7604084014892578, arousal_loss=0.7912225723266602, emotion_loss=1.2825772762298584\n",
      "\n",
      "01_19_23:20:15 Seen so far: 214752 samples\n",
      "\n",
      "01_19_23:20:15 --- 2.0695607662200928 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:17 Training loss at epoch 0 step 6720: 3.3157126903533936\n",
      "\n",
      " This round's valence_loss=0.8463212251663208, arousal_loss=0.7204028367996216, emotion_loss=1.1611404418945312\n",
      "\n",
      "01_19_23:20:17 Seen so far: 215072 samples\n",
      "\n",
      "01_19_23:20:17 --- 2.1533238887786865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:19 Training loss at epoch 0 step 6730: 3.3214948415756225\n",
      "\n",
      " This round's valence_loss=1.4298975467681885, arousal_loss=1.3318257331848145, emotion_loss=1.1427040100097656\n",
      "\n",
      "01_19_23:20:19 Seen so far: 215392 samples\n",
      "\n",
      "01_19_23:20:19 --- 2.0049874782562256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:21 Training loss at epoch 0 step 6740: 2.8041148662567137\n",
      "\n",
      " This round's valence_loss=0.8957468271255493, arousal_loss=0.7187974452972412, emotion_loss=0.8827531337738037\n",
      "\n",
      "01_19_23:20:21 Seen so far: 215712 samples\n",
      "\n",
      "01_19_23:20:21 --- 2.1633331775665283 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:23 Training loss at epoch 0 step 6750: 3.047650384902954\n",
      "\n",
      " This round's valence_loss=0.7864043116569519, arousal_loss=0.5540463328361511, emotion_loss=0.9730710387229919\n",
      "\n",
      "01_19_23:20:23 Seen so far: 216032 samples\n",
      "\n",
      "01_19_23:20:23 --- 1.9766275882720947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:25 Training loss at epoch 0 step 6760: 3.184132528305054\n",
      "\n",
      " This round's valence_loss=1.166501522064209, arousal_loss=1.1006226539611816, emotion_loss=1.112401008605957\n",
      "\n",
      "01_19_23:20:25 Seen so far: 216352 samples\n",
      "\n",
      "01_19_23:20:25 --- 2.086334228515625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:27 Training loss at epoch 0 step 6770: 2.892016315460205\n",
      "\n",
      " This round's valence_loss=1.2957921028137207, arousal_loss=1.087810754776001, emotion_loss=0.8521671295166016\n",
      "\n",
      "01_19_23:20:27 Seen so far: 216672 samples\n",
      "\n",
      "01_19_23:20:27 --- 1.9852328300476074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:29 Training loss at epoch 0 step 6780: 3.1616750240325926\n",
      "\n",
      " This round's valence_loss=1.1742222309112549, arousal_loss=1.0600194931030273, emotion_loss=1.370732307434082\n",
      "\n",
      "01_19_23:20:29 Seen so far: 216992 samples\n",
      "\n",
      "01_19_23:20:29 --- 2.079665422439575 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:31 Training loss at epoch 0 step 6790: 3.14526162147522\n",
      "\n",
      " This round's valence_loss=1.0514155626296997, arousal_loss=0.9571653604507446, emotion_loss=1.0520522594451904\n",
      "\n",
      "01_19_23:20:31 Seen so far: 217312 samples\n",
      "\n",
      "01_19_23:20:31 --- 2.011864185333252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:33 Training loss at epoch 0 step 6800: 3.2397935152053834\n",
      "\n",
      " This round's valence_loss=1.0158209800720215, arousal_loss=0.8208099603652954, emotion_loss=1.037217617034912\n",
      "\n",
      "01_19_23:20:33 Seen so far: 217632 samples\n",
      "\n",
      "01_19_23:20:33 --- 1.9348773956298828 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:35 Training loss at epoch 0 step 6810: 2.9831218004226683\n",
      "\n",
      " This round's valence_loss=1.1989257335662842, arousal_loss=1.1255985498428345, emotion_loss=1.5636563301086426\n",
      "\n",
      "01_19_23:20:35 Seen so far: 217952 samples\n",
      "\n",
      "01_19_23:20:35 --- 1.898529291152954 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:37 Training loss at epoch 0 step 6820: 3.28839225769043\n",
      "\n",
      " This round's valence_loss=1.2436552047729492, arousal_loss=1.0882376432418823, emotion_loss=1.1123260259628296\n",
      "\n",
      "01_19_23:20:37 Seen so far: 218272 samples\n",
      "\n",
      "01_19_23:20:37 --- 1.9029252529144287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:39 Training loss at epoch 0 step 6830: 3.168335199356079\n",
      "\n",
      " This round's valence_loss=0.6758354306221008, arousal_loss=0.5776037573814392, emotion_loss=1.0387587547302246\n",
      "\n",
      "01_19_23:20:39 Seen so far: 218592 samples\n",
      "\n",
      "01_19_23:20:39 --- 1.8412144184112549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:41 Training loss at epoch 0 step 6840: 3.0662054300308226\n",
      "\n",
      " This round's valence_loss=0.8251389265060425, arousal_loss=0.7020391821861267, emotion_loss=0.8134852051734924\n",
      "\n",
      "01_19_23:20:41 Seen so far: 218912 samples\n",
      "\n",
      "01_19_23:20:41 --- 2.1190567016601562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:43 Training loss at epoch 0 step 6850: 3.3475431203842163\n",
      "\n",
      " This round's valence_loss=0.6619176864624023, arousal_loss=0.6893867254257202, emotion_loss=1.3575997352600098\n",
      "\n",
      "01_19_23:20:43 Seen so far: 219232 samples\n",
      "\n",
      "01_19_23:20:43 --- 2.192436695098877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:45 Training loss at epoch 0 step 6860: 3.22164990901947\n",
      "\n",
      " This round's valence_loss=0.817184567451477, arousal_loss=0.6792166233062744, emotion_loss=1.0332609415054321\n",
      "\n",
      "01_19_23:20:45 Seen so far: 219552 samples\n",
      "\n",
      "01_19_23:20:45 --- 2.0860445499420166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:47 Training loss at epoch 0 step 6870: 3.017959940433502\n",
      "\n",
      " This round's valence_loss=0.7497844696044922, arousal_loss=0.5954228043556213, emotion_loss=1.2207756042480469\n",
      "\n",
      "01_19_23:20:47 Seen so far: 219872 samples\n",
      "\n",
      "01_19_23:20:47 --- 1.9941985607147217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:49 Training loss at epoch 0 step 6880: 3.053691554069519\n",
      "\n",
      " This round's valence_loss=0.8837776780128479, arousal_loss=0.6936981678009033, emotion_loss=0.7725168466567993\n",
      "\n",
      "01_19_23:20:49 Seen so far: 220192 samples\n",
      "\n",
      "01_19_23:20:49 --- 2.0622923374176025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:51 Training loss at epoch 0 step 6890: 3.2284923076629637\n",
      "\n",
      " This round's valence_loss=1.4080443382263184, arousal_loss=1.3085931539535522, emotion_loss=1.2770787477493286\n",
      "\n",
      "01_19_23:20:51 Seen so far: 220512 samples\n",
      "\n",
      "01_19_23:20:51 --- 2.14113712310791 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:53 Training loss at epoch 0 step 6900: 3.2238778591156008\n",
      "\n",
      " This round's valence_loss=0.6568641662597656, arousal_loss=0.4839353561401367, emotion_loss=0.9471637606620789\n",
      "\n",
      "01_19_23:20:53 Seen so far: 220832 samples\n",
      "\n",
      "01_19_23:20:53 --- 1.938127040863037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:55 Training loss at epoch 0 step 6910: 2.9508564472198486\n",
      "\n",
      " This round's valence_loss=0.8852179050445557, arousal_loss=0.7295669317245483, emotion_loss=0.9587182998657227\n",
      "\n",
      "01_19_23:20:55 Seen so far: 221152 samples\n",
      "\n",
      "01_19_23:20:55 --- 2.1015923023223877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:57 Training loss at epoch 0 step 6920: 3.10777804851532\n",
      "\n",
      " This round's valence_loss=1.3952308893203735, arousal_loss=1.269728660583496, emotion_loss=0.7692543268203735\n",
      "\n",
      "01_19_23:20:57 Seen so far: 221472 samples\n",
      "\n",
      "01_19_23:20:57 --- 2.026979923248291 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:20:59 Training loss at epoch 0 step 6930: 3.1204345703125\n",
      "\n",
      " This round's valence_loss=0.9583148956298828, arousal_loss=0.8247233629226685, emotion_loss=1.078088641166687\n",
      "\n",
      "01_19_23:20:59 Seen so far: 221792 samples\n",
      "\n",
      "01_19_23:20:59 --- 2.0331521034240723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:01 Training loss at epoch 0 step 6940: 3.227922797203064\n",
      "\n",
      " This round's valence_loss=0.7006456255912781, arousal_loss=0.6547667980194092, emotion_loss=1.4185025691986084\n",
      "\n",
      "01_19_23:21:01 Seen so far: 222112 samples\n",
      "\n",
      "01_19_23:21:01 --- 1.8322927951812744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:03 Training loss at epoch 0 step 6950: 3.3630050897598265\n",
      "\n",
      " This round's valence_loss=0.9162303805351257, arousal_loss=0.6913052201271057, emotion_loss=1.0719552040100098\n",
      "\n",
      "01_19_23:21:03 Seen so far: 222432 samples\n",
      "\n",
      "01_19_23:21:03 --- 1.8148338794708252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:05 Training loss at epoch 0 step 6960: 3.3624024868011473\n",
      "\n",
      " This round's valence_loss=1.200748324394226, arousal_loss=1.1110804080963135, emotion_loss=1.6031310558319092\n",
      "\n",
      "01_19_23:21:05 Seen so far: 222752 samples\n",
      "\n",
      "01_19_23:21:05 --- 1.9960432052612305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:07 Training loss at epoch 0 step 6970: 3.204727625846863\n",
      "\n",
      " This round's valence_loss=0.9556303024291992, arousal_loss=0.8257250785827637, emotion_loss=1.396270990371704\n",
      "\n",
      "01_19_23:21:07 Seen so far: 223072 samples\n",
      "\n",
      "01_19_23:21:07 --- 2.062622547149658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:09 Training loss at epoch 0 step 6980: 3.21672842502594\n",
      "\n",
      " This round's valence_loss=1.2632942199707031, arousal_loss=1.0465281009674072, emotion_loss=0.982807457447052\n",
      "\n",
      "01_19_23:21:09 Seen so far: 223392 samples\n",
      "\n",
      "01_19_23:21:09 --- 1.979058027267456 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:11 Training loss at epoch 0 step 6990: 3.1742690086364744\n",
      "\n",
      " This round's valence_loss=1.075602412223816, arousal_loss=0.9565151333808899, emotion_loss=1.1390814781188965\n",
      "\n",
      "01_19_23:21:11 Seen so far: 223712 samples\n",
      "\n",
      "01_19_23:21:11 --- 1.966280221939087 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:13 Training loss at epoch 0 step 7000: 3.0648288488388062\n",
      "\n",
      " This round's valence_loss=0.7520570755004883, arousal_loss=0.5980117321014404, emotion_loss=0.9663910269737244\n",
      "\n",
      "01_19_23:21:13 Seen so far: 224032 samples\n",
      "\n",
      "01_19_23:21:13 --- 2.062253475189209 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:15 Training loss at epoch 0 step 7010: 3.1105531215667725\n",
      "\n",
      " This round's valence_loss=1.037174940109253, arousal_loss=0.802499532699585, emotion_loss=0.8534499406814575\n",
      "\n",
      "01_19_23:21:15 Seen so far: 224352 samples\n",
      "\n",
      "01_19_23:21:15 --- 2.1587719917297363 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:17 Training loss at epoch 0 step 7020: 3.0690889596939086\n",
      "\n",
      " This round's valence_loss=1.0138254165649414, arousal_loss=0.8983293175697327, emotion_loss=1.139986276626587\n",
      "\n",
      "01_19_23:21:17 Seen so far: 224672 samples\n",
      "\n",
      "01_19_23:21:17 --- 2.1605334281921387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:19 Training loss at epoch 0 step 7030: 2.903855633735657\n",
      "\n",
      " This round's valence_loss=1.2374519109725952, arousal_loss=1.067488431930542, emotion_loss=1.1421809196472168\n",
      "\n",
      "01_19_23:21:19 Seen so far: 224992 samples\n",
      "\n",
      "01_19_23:21:19 --- 2.0008087158203125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:22 Training loss at epoch 0 step 7040: 3.17999005317688\n",
      "\n",
      " This round's valence_loss=0.9568595290184021, arousal_loss=0.7010505199432373, emotion_loss=1.2753524780273438\n",
      "\n",
      "01_19_23:21:22 Seen so far: 225312 samples\n",
      "\n",
      "01_19_23:21:22 --- 2.089197874069214 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:24 Training loss at epoch 0 step 7050: 3.0564616918563843\n",
      "\n",
      " This round's valence_loss=0.9316766262054443, arousal_loss=0.7559958696365356, emotion_loss=1.2349653244018555\n",
      "\n",
      "01_19_23:21:24 Seen so far: 225632 samples\n",
      "\n",
      "01_19_23:21:24 --- 2.0264663696289062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:26 Training loss at epoch 0 step 7060: 2.869141674041748\n",
      "\n",
      " This round's valence_loss=1.4117095470428467, arousal_loss=1.302431583404541, emotion_loss=1.1666810512542725\n",
      "\n",
      "01_19_23:21:26 Seen so far: 225952 samples\n",
      "\n",
      "01_19_23:21:26 --- 2.1583170890808105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:28 Training loss at epoch 0 step 7070: 2.9309918165206907\n",
      "\n",
      " This round's valence_loss=1.216705560684204, arousal_loss=1.0845980644226074, emotion_loss=0.6613580584526062\n",
      "\n",
      "01_19_23:21:28 Seen so far: 226272 samples\n",
      "\n",
      "01_19_23:21:28 --- 1.8538076877593994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:29 Training loss at epoch 0 step 7080: 3.1130571603775024\n",
      "\n",
      " This round's valence_loss=0.9218361377716064, arousal_loss=0.9600181579589844, emotion_loss=1.0683739185333252\n",
      "\n",
      "01_19_23:21:29 Seen so far: 226592 samples\n",
      "\n",
      "01_19_23:21:29 --- 1.9442298412322998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:32 Training loss at epoch 0 step 7090: 3.234696388244629\n",
      "\n",
      " This round's valence_loss=1.804527759552002, arousal_loss=1.7477024793624878, emotion_loss=1.239263653755188\n",
      "\n",
      "01_19_23:21:32 Seen so far: 226912 samples\n",
      "\n",
      "01_19_23:21:32 --- 2.0319533348083496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:33 Training loss at epoch 0 step 7100: 2.768339920043945\n",
      "\n",
      " This round's valence_loss=1.0294636487960815, arousal_loss=0.8465662002563477, emotion_loss=1.1443023681640625\n",
      "\n",
      "01_19_23:21:33 Seen so far: 227232 samples\n",
      "\n",
      "01_19_23:21:33 --- 1.8871557712554932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:35 Training loss at epoch 0 step 7110: 3.3934831619262695\n",
      "\n",
      " This round's valence_loss=1.043267011642456, arousal_loss=0.9329134225845337, emotion_loss=1.0215816497802734\n",
      "\n",
      "01_19_23:21:35 Seen so far: 227552 samples\n",
      "\n",
      "01_19_23:21:35 --- 2.034445285797119 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:38 Training loss at epoch 0 step 7120: 3.037310171127319\n",
      "\n",
      " This round's valence_loss=0.7412879467010498, arousal_loss=0.5921475291252136, emotion_loss=1.241328477859497\n",
      "\n",
      "01_19_23:21:38 Seen so far: 227872 samples\n",
      "\n",
      "01_19_23:21:38 --- 2.1301369667053223 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:40 Training loss at epoch 0 step 7130: 2.9519733428955077\n",
      "\n",
      " This round's valence_loss=1.540287971496582, arousal_loss=1.4493305683135986, emotion_loss=1.2308353185653687\n",
      "\n",
      "01_19_23:21:40 Seen so far: 228192 samples\n",
      "\n",
      "01_19_23:21:40 --- 2.2243173122406006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:42 Training loss at epoch 0 step 7140: 3.0432975053787232\n",
      "\n",
      " This round's valence_loss=0.8068561553955078, arousal_loss=0.6094142198562622, emotion_loss=0.8365702629089355\n",
      "\n",
      "01_19_23:21:42 Seen so far: 228512 samples\n",
      "\n",
      "01_19_23:21:42 --- 2.136622428894043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:44 Training loss at epoch 0 step 7150: 3.5120137453079225\n",
      "\n",
      " This round's valence_loss=1.1778072118759155, arousal_loss=1.0320883989334106, emotion_loss=0.8713651895523071\n",
      "\n",
      "01_19_23:21:44 Seen so far: 228832 samples\n",
      "\n",
      "01_19_23:21:44 --- 1.9917290210723877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:46 Training loss at epoch 0 step 7160: 3.1971288442611696\n",
      "\n",
      " This round's valence_loss=1.2764099836349487, arousal_loss=1.2044744491577148, emotion_loss=1.0304034948349\n",
      "\n",
      "01_19_23:21:46 Seen so far: 229152 samples\n",
      "\n",
      "01_19_23:21:46 --- 1.9238617420196533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:48 Training loss at epoch 0 step 7170: 3.1046462297439574\n",
      "\n",
      " This round's valence_loss=0.7508230209350586, arousal_loss=0.6177886724472046, emotion_loss=1.1831835508346558\n",
      "\n",
      "01_19_23:21:48 Seen so far: 229472 samples\n",
      "\n",
      "01_19_23:21:48 --- 2.146851062774658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:50 Training loss at epoch 0 step 7180: 3.7528501033782957\n",
      "\n",
      " This round's valence_loss=1.1974706649780273, arousal_loss=1.16887629032135, emotion_loss=1.0529600381851196\n",
      "\n",
      "01_19_23:21:50 Seen so far: 229792 samples\n",
      "\n",
      "01_19_23:21:50 --- 2.017711639404297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:52 Training loss at epoch 0 step 7190: 3.354534864425659\n",
      "\n",
      " This round's valence_loss=1.1545419692993164, arousal_loss=0.8995422124862671, emotion_loss=0.9900021553039551\n",
      "\n",
      "01_19_23:21:52 Seen so far: 230112 samples\n",
      "\n",
      "01_19_23:21:52 --- 2.197330951690674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:54 Training loss at epoch 0 step 7200: 3.27095890045166\n",
      "\n",
      " This round's valence_loss=1.1968588829040527, arousal_loss=1.0752792358398438, emotion_loss=1.022383213043213\n",
      "\n",
      "01_19_23:21:54 Seen so far: 230432 samples\n",
      "\n",
      "01_19_23:21:54 --- 1.9900696277618408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:56 Training loss at epoch 0 step 7210: 3.0059907913208006\n",
      "\n",
      " This round's valence_loss=1.2602965831756592, arousal_loss=1.0566529035568237, emotion_loss=1.2929155826568604\n",
      "\n",
      "01_19_23:21:56 Seen so far: 230752 samples\n",
      "\n",
      "01_19_23:21:56 --- 1.8775913715362549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:21:58 Training loss at epoch 0 step 7220: 3.084075379371643\n",
      "\n",
      " This round's valence_loss=1.2572426795959473, arousal_loss=1.0445791482925415, emotion_loss=0.6592231392860413\n",
      "\n",
      "01_19_23:21:58 Seen so far: 231072 samples\n",
      "\n",
      "01_19_23:21:58 --- 2.081047534942627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:00 Training loss at epoch 0 step 7230: 3.0954330921173097\n",
      "\n",
      " This round's valence_loss=1.257345199584961, arousal_loss=1.2279908657073975, emotion_loss=1.2547035217285156\n",
      "\n",
      "01_19_23:22:00 Seen so far: 231392 samples\n",
      "\n",
      "01_19_23:22:00 --- 1.9389839172363281 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:02 Training loss at epoch 0 step 7240: 2.8921372413635256\n",
      "\n",
      " This round's valence_loss=0.673404335975647, arousal_loss=0.45037251710891724, emotion_loss=0.9740140438079834\n",
      "\n",
      "01_19_23:22:02 Seen so far: 231712 samples\n",
      "\n",
      "01_19_23:22:02 --- 2.0826520919799805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:04 Training loss at epoch 0 step 7250: 3.0308207273483276\n",
      "\n",
      " This round's valence_loss=0.923211395740509, arousal_loss=0.7326112985610962, emotion_loss=1.39385187625885\n",
      "\n",
      "01_19_23:22:04 Seen so far: 232032 samples\n",
      "\n",
      "01_19_23:22:04 --- 2.124756097793579 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:06 Training loss at epoch 0 step 7260: 3.327040672302246\n",
      "\n",
      " This round's valence_loss=0.7148481011390686, arousal_loss=0.6384257078170776, emotion_loss=0.9411594271659851\n",
      "\n",
      "01_19_23:22:06 Seen so far: 232352 samples\n",
      "\n",
      "01_19_23:22:06 --- 1.9187963008880615 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:08 Training loss at epoch 0 step 7270: 2.983440268039703\n",
      "\n",
      " This round's valence_loss=0.7118991613388062, arousal_loss=0.6282216310501099, emotion_loss=1.4893467426300049\n",
      "\n",
      "01_19_23:22:08 Seen so far: 232672 samples\n",
      "\n",
      "01_19_23:22:08 --- 2.150136709213257 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:10 Training loss at epoch 0 step 7280: 3.2095670223236086\n",
      "\n",
      " This round's valence_loss=0.7050673961639404, arousal_loss=0.6146788597106934, emotion_loss=1.259744644165039\n",
      "\n",
      "01_19_23:22:10 Seen so far: 232992 samples\n",
      "\n",
      "01_19_23:22:10 --- 1.9445819854736328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:12 Training loss at epoch 0 step 7290: 3.1125043869018554\n",
      "\n",
      " This round's valence_loss=1.0814658403396606, arousal_loss=1.0249930620193481, emotion_loss=1.2071037292480469\n",
      "\n",
      "01_19_23:22:12 Seen so far: 233312 samples\n",
      "\n",
      "01_19_23:22:12 --- 2.1078648567199707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:14 Training loss at epoch 0 step 7300: 3.1789767742156982\n",
      "\n",
      " This round's valence_loss=1.0742716789245605, arousal_loss=0.9801210165023804, emotion_loss=1.1402831077575684\n",
      "\n",
      "01_19_23:22:14 Seen so far: 233632 samples\n",
      "\n",
      "01_19_23:22:14 --- 2.0353288650512695 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:17 Training loss at epoch 0 step 7310: 3.6527525424957275\n",
      "\n",
      " This round's valence_loss=1.4048593044281006, arousal_loss=1.2287299633026123, emotion_loss=1.016417384147644\n",
      "\n",
      "01_19_23:22:17 Seen so far: 233952 samples\n",
      "\n",
      "01_19_23:22:17 --- 2.088360548019409 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:19 Training loss at epoch 0 step 7320: 2.929947566986084\n",
      "\n",
      " This round's valence_loss=0.9514977931976318, arousal_loss=0.8571926951408386, emotion_loss=1.253610610961914\n",
      "\n",
      "01_19_23:22:19 Seen so far: 234272 samples\n",
      "\n",
      "01_19_23:22:19 --- 2.162454843521118 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:21 Training loss at epoch 0 step 7330: 3.121195650100708\n",
      "\n",
      " This round's valence_loss=1.225914478302002, arousal_loss=1.0770593881607056, emotion_loss=0.945216178894043\n",
      "\n",
      "01_19_23:22:21 Seen so far: 234592 samples\n",
      "\n",
      "01_19_23:22:21 --- 2.3185477256774902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:23 Training loss at epoch 0 step 7340: 3.16596577167511\n",
      "\n",
      " This round's valence_loss=1.2966883182525635, arousal_loss=1.050140619277954, emotion_loss=0.9660186767578125\n",
      "\n",
      "01_19_23:22:23 Seen so far: 234912 samples\n",
      "\n",
      "01_19_23:22:23 --- 1.9541971683502197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:25 Training loss at epoch 0 step 7350: 3.137523579597473\n",
      "\n",
      " This round's valence_loss=0.7088469862937927, arousal_loss=0.6283044815063477, emotion_loss=1.1731747388839722\n",
      "\n",
      "01_19_23:22:25 Seen so far: 235232 samples\n",
      "\n",
      "01_19_23:22:25 --- 2.071028709411621 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:27 Training loss at epoch 0 step 7360: 3.015191745758057\n",
      "\n",
      " This round's valence_loss=1.1004564762115479, arousal_loss=0.9457950592041016, emotion_loss=0.8592433333396912\n",
      "\n",
      "01_19_23:22:27 Seen so far: 235552 samples\n",
      "\n",
      "01_19_23:22:27 --- 1.9064552783966064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:29 Training loss at epoch 0 step 7370: 3.167959117889404\n",
      "\n",
      " This round's valence_loss=1.0195207595825195, arousal_loss=0.8713040351867676, emotion_loss=1.37239670753479\n",
      "\n",
      "01_19_23:22:29 Seen so far: 235872 samples\n",
      "\n",
      "01_19_23:22:29 --- 2.1217851638793945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:31 Training loss at epoch 0 step 7380: 3.078832674026489\n",
      "\n",
      " This round's valence_loss=0.677415132522583, arousal_loss=0.48243680596351624, emotion_loss=1.1806414127349854\n",
      "\n",
      "01_19_23:22:31 Seen so far: 236192 samples\n",
      "\n",
      "01_19_23:22:31 --- 1.967339038848877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:33 Training loss at epoch 0 step 7390: 3.279187798500061\n",
      "\n",
      " This round's valence_loss=1.1965471506118774, arousal_loss=1.1321923732757568, emotion_loss=1.6743264198303223\n",
      "\n",
      "01_19_23:22:33 Seen so far: 236512 samples\n",
      "\n",
      "01_19_23:22:33 --- 1.9111297130584717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:35 Training loss at epoch 0 step 7400: 3.009280967712402\n",
      "\n",
      " This round's valence_loss=0.7062113285064697, arousal_loss=0.6119492053985596, emotion_loss=1.2717411518096924\n",
      "\n",
      "01_19_23:22:35 Seen so far: 236832 samples\n",
      "\n",
      "01_19_23:22:35 --- 1.9222784042358398 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:37 Training loss at epoch 0 step 7410: 3.020618510246277\n",
      "\n",
      " This round's valence_loss=0.8914939165115356, arousal_loss=0.7259345054626465, emotion_loss=0.8559255599975586\n",
      "\n",
      "01_19_23:22:37 Seen so far: 237152 samples\n",
      "\n",
      "01_19_23:22:37 --- 2.140279531478882 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:39 Training loss at epoch 0 step 7420: 3.3114736080169678\n",
      "\n",
      " This round's valence_loss=0.7803714275360107, arousal_loss=0.7452536821365356, emotion_loss=1.0076966285705566\n",
      "\n",
      "01_19_23:22:39 Seen so far: 237472 samples\n",
      "\n",
      "01_19_23:22:39 --- 2.158111810684204 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:41 Training loss at epoch 0 step 7430: 3.1355219721794128\n",
      "\n",
      " This round's valence_loss=0.7706846594810486, arousal_loss=0.570397675037384, emotion_loss=1.018549919128418\n",
      "\n",
      "01_19_23:22:41 Seen so far: 237792 samples\n",
      "\n",
      "01_19_23:22:41 --- 2.084019184112549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:43 Training loss at epoch 0 step 7440: 3.4162010669708254\n",
      "\n",
      " This round's valence_loss=1.4916768074035645, arousal_loss=1.4368816614151, emotion_loss=0.9789025783538818\n",
      "\n",
      "01_19_23:22:43 Seen so far: 238112 samples\n",
      "\n",
      "01_19_23:22:43 --- 1.8304262161254883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:45 Training loss at epoch 0 step 7450: 3.0923552751541137\n",
      "\n",
      " This round's valence_loss=0.8257776498794556, arousal_loss=0.7314459085464478, emotion_loss=1.174368143081665\n",
      "\n",
      "01_19_23:22:45 Seen so far: 238432 samples\n",
      "\n",
      "01_19_23:22:45 --- 2.200582265853882 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:47 Training loss at epoch 0 step 7460: 3.0491607427597045\n",
      "\n",
      " This round's valence_loss=0.7504260540008545, arousal_loss=0.6231511831283569, emotion_loss=1.1302542686462402\n",
      "\n",
      "01_19_23:22:47 Seen so far: 238752 samples\n",
      "\n",
      "01_19_23:22:47 --- 2.0604031085968018 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:50 Training loss at epoch 0 step 7470: 3.310874843597412\n",
      "\n",
      " This round's valence_loss=1.2188013792037964, arousal_loss=1.1396689414978027, emotion_loss=1.4216116666793823\n",
      "\n",
      "01_19_23:22:50 Seen so far: 239072 samples\n",
      "\n",
      "01_19_23:22:50 --- 2.3285982608795166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:52 Training loss at epoch 0 step 7480: 2.9351367115974427\n",
      "\n",
      " This round's valence_loss=1.3623837232589722, arousal_loss=1.3252134323120117, emotion_loss=1.5765341520309448\n",
      "\n",
      "01_19_23:22:52 Seen so far: 239392 samples\n",
      "\n",
      "01_19_23:22:52 --- 1.945824146270752 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:54 Training loss at epoch 0 step 7490: 3.4213204383850098\n",
      "\n",
      " This round's valence_loss=1.2990970611572266, arousal_loss=1.1791582107543945, emotion_loss=1.0830752849578857\n",
      "\n",
      "01_19_23:22:54 Seen so far: 239712 samples\n",
      "\n",
      "01_19_23:22:54 --- 1.9801242351531982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:56 Training loss at epoch 0 step 7500: 3.2577678203582763\n",
      "\n",
      " This round's valence_loss=1.300450325012207, arousal_loss=1.2614110708236694, emotion_loss=0.9631932973861694\n",
      "\n",
      "01_19_23:22:56 Seen so far: 240032 samples\n",
      "\n",
      "01_19_23:22:56 --- 1.9876267910003662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:58 Training loss at epoch 0 step 7510: 2.9938875675201415\n",
      "\n",
      " This round's valence_loss=1.1645903587341309, arousal_loss=0.9740428924560547, emotion_loss=1.3666398525238037\n",
      "\n",
      "01_19_23:22:58 Seen so far: 240352 samples\n",
      "\n",
      "01_19_23:22:58 --- 2.0004076957702637 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:22:59 Training loss at epoch 0 step 7520: 3.172935724258423\n",
      "\n",
      " This round's valence_loss=1.1553559303283691, arousal_loss=1.1476296186447144, emotion_loss=1.2441598176956177\n",
      "\n",
      "01_19_23:22:59 Seen so far: 240672 samples\n",
      "\n",
      "01_19_23:22:59 --- 1.7766540050506592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:01 Training loss at epoch 0 step 7530: 2.972939944267273\n",
      "\n",
      " This round's valence_loss=0.9856418371200562, arousal_loss=0.8130361437797546, emotion_loss=0.8354002237319946\n",
      "\n",
      "01_19_23:23:01 Seen so far: 240992 samples\n",
      "\n",
      "01_19_23:23:01 --- 2.017557382583618 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:03 Training loss at epoch 0 step 7540: 3.1848589181900024\n",
      "\n",
      " This round's valence_loss=1.5896884202957153, arousal_loss=1.4924566745758057, emotion_loss=1.1329691410064697\n",
      "\n",
      "01_19_23:23:03 Seen so far: 241312 samples\n",
      "\n",
      "01_19_23:23:03 --- 1.7657694816589355 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:05 Training loss at epoch 0 step 7550: 3.1723072052001955\n",
      "\n",
      " This round's valence_loss=1.3069722652435303, arousal_loss=1.2257683277130127, emotion_loss=0.8129405975341797\n",
      "\n",
      "01_19_23:23:05 Seen so far: 241632 samples\n",
      "\n",
      "01_19_23:23:05 --- 1.9089319705963135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:07 Training loss at epoch 0 step 7560: 3.1075226068496704\n",
      "\n",
      " This round's valence_loss=1.2913768291473389, arousal_loss=1.0565807819366455, emotion_loss=1.0218409299850464\n",
      "\n",
      "01_19_23:23:07 Seen so far: 241952 samples\n",
      "\n",
      "01_19_23:23:07 --- 1.9216904640197754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:09 Training loss at epoch 0 step 7570: 3.229373550415039\n",
      "\n",
      " This round's valence_loss=1.32987380027771, arousal_loss=1.1919784545898438, emotion_loss=0.9959118366241455\n",
      "\n",
      "01_19_23:23:09 Seen so far: 242272 samples\n",
      "\n",
      "01_19_23:23:09 --- 1.78985595703125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:11 Training loss at epoch 0 step 7580: 3.1541288614273073\n",
      "\n",
      " This round's valence_loss=1.124805212020874, arousal_loss=0.9370182752609253, emotion_loss=0.9102665185928345\n",
      "\n",
      "01_19_23:23:11 Seen so far: 242592 samples\n",
      "\n",
      "01_19_23:23:11 --- 1.9371240139007568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:13 Training loss at epoch 0 step 7590: 3.306184983253479\n",
      "\n",
      " This round's valence_loss=1.0129340887069702, arousal_loss=0.8639428019523621, emotion_loss=1.117526888847351\n",
      "\n",
      "01_19_23:23:13 Seen so far: 242912 samples\n",
      "\n",
      "01_19_23:23:13 --- 1.88260817527771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:15 Training loss at epoch 0 step 7600: 3.1167383670806883\n",
      "\n",
      " This round's valence_loss=1.4321680068969727, arousal_loss=1.2991912364959717, emotion_loss=1.0331430435180664\n",
      "\n",
      "01_19_23:23:15 Seen so far: 243232 samples\n",
      "\n",
      "01_19_23:23:15 --- 1.9519703388214111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:17 Training loss at epoch 0 step 7610: 3.072899651527405\n",
      "\n",
      " This round's valence_loss=1.1618341207504272, arousal_loss=0.9768356084823608, emotion_loss=0.8954055309295654\n",
      "\n",
      "01_19_23:23:17 Seen so far: 243552 samples\n",
      "\n",
      "01_19_23:23:17 --- 2.142033576965332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:19 Training loss at epoch 0 step 7620: 3.141744327545166\n",
      "\n",
      " This round's valence_loss=1.4333114624023438, arousal_loss=1.3337175846099854, emotion_loss=1.099065899848938\n",
      "\n",
      "01_19_23:23:19 Seen so far: 243872 samples\n",
      "\n",
      "01_19_23:23:19 --- 2.064509391784668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:21 Training loss at epoch 0 step 7630: 3.2422356367111207\n",
      "\n",
      " This round's valence_loss=0.9693193435668945, arousal_loss=0.8660503625869751, emotion_loss=1.3331888914108276\n",
      "\n",
      "01_19_23:23:21 Seen so far: 244192 samples\n",
      "\n",
      "01_19_23:23:21 --- 1.9462974071502686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:23 Training loss at epoch 0 step 7640: 3.061847686767578\n",
      "\n",
      " This round's valence_loss=1.1013249158859253, arousal_loss=0.9576517343521118, emotion_loss=1.020626425743103\n",
      "\n",
      "01_19_23:23:23 Seen so far: 244512 samples\n",
      "\n",
      "01_19_23:23:23 --- 1.9193966388702393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:25 Training loss at epoch 0 step 7650: 3.6140536308288573\n",
      "\n",
      " This round's valence_loss=1.3197524547576904, arousal_loss=1.2092604637145996, emotion_loss=1.259840726852417\n",
      "\n",
      "01_19_23:23:25 Seen so far: 244832 samples\n",
      "\n",
      "01_19_23:23:25 --- 1.9827754497528076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:27 Training loss at epoch 0 step 7660: 2.8547212958335875\n",
      "\n",
      " This round's valence_loss=0.9181586503982544, arousal_loss=0.8166019916534424, emotion_loss=1.2306201457977295\n",
      "\n",
      "01_19_23:23:27 Seen so far: 245152 samples\n",
      "\n",
      "01_19_23:23:27 --- 1.9650094509124756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:29 Training loss at epoch 0 step 7670: 2.9283895015716555\n",
      "\n",
      " This round's valence_loss=1.1269207000732422, arousal_loss=1.0439690351486206, emotion_loss=1.0164756774902344\n",
      "\n",
      "01_19_23:23:29 Seen so far: 245472 samples\n",
      "\n",
      "01_19_23:23:29 --- 2.000680446624756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:31 Training loss at epoch 0 step 7680: 3.142193007469177\n",
      "\n",
      " This round's valence_loss=1.0915430784225464, arousal_loss=0.9254502058029175, emotion_loss=0.9780076742172241\n",
      "\n",
      "01_19_23:23:31 Seen so far: 245792 samples\n",
      "\n",
      "01_19_23:23:31 --- 2.046428918838501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:33 Training loss at epoch 0 step 7690: 3.16643226146698\n",
      "\n",
      " This round's valence_loss=1.347883939743042, arousal_loss=1.2028074264526367, emotion_loss=1.2504091262817383\n",
      "\n",
      "01_19_23:23:33 Seen so far: 246112 samples\n",
      "\n",
      "01_19_23:23:33 --- 2.0778675079345703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:35 Training loss at epoch 0 step 7700: 3.507486343383789\n",
      "\n",
      " This round's valence_loss=0.9165605306625366, arousal_loss=0.6802068948745728, emotion_loss=0.9115577936172485\n",
      "\n",
      "01_19_23:23:35 Seen so far: 246432 samples\n",
      "\n",
      "01_19_23:23:35 --- 2.028977632522583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:37 Training loss at epoch 0 step 7710: 3.4711784601211546\n",
      "\n",
      " This round's valence_loss=1.6238129138946533, arousal_loss=1.4571386575698853, emotion_loss=1.1947022676467896\n",
      "\n",
      "01_19_23:23:37 Seen so far: 246752 samples\n",
      "\n",
      "01_19_23:23:37 --- 2.0038161277770996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:39 Training loss at epoch 0 step 7720: 2.928029549121857\n",
      "\n",
      " This round's valence_loss=1.256291389465332, arousal_loss=1.1125173568725586, emotion_loss=1.19316828250885\n",
      "\n",
      "01_19_23:23:39 Seen so far: 247072 samples\n",
      "\n",
      "01_19_23:23:39 --- 1.9341073036193848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:41 Training loss at epoch 0 step 7730: 3.1235885620117188\n",
      "\n",
      " This round's valence_loss=1.284684181213379, arousal_loss=1.0868401527404785, emotion_loss=1.056132435798645\n",
      "\n",
      "01_19_23:23:41 Seen so far: 247392 samples\n",
      "\n",
      "01_19_23:23:41 --- 1.9297642707824707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:43 Training loss at epoch 0 step 7740: 2.9642268419265747\n",
      "\n",
      " This round's valence_loss=1.2115596532821655, arousal_loss=1.063709020614624, emotion_loss=0.9360392093658447\n",
      "\n",
      "01_19_23:23:43 Seen so far: 247712 samples\n",
      "\n",
      "01_19_23:23:43 --- 1.9660618305206299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:45 Training loss at epoch 0 step 7750: 3.1832651138305663\n",
      "\n",
      " This round's valence_loss=0.8711536526679993, arousal_loss=0.737226665019989, emotion_loss=1.1176568269729614\n",
      "\n",
      "01_19_23:23:45 Seen so far: 248032 samples\n",
      "\n",
      "01_19_23:23:45 --- 2.0533251762390137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:47 Training loss at epoch 0 step 7760: 3.243141603469849\n",
      "\n",
      " This round's valence_loss=0.806873083114624, arousal_loss=0.8161650896072388, emotion_loss=1.0448846817016602\n",
      "\n",
      "01_19_23:23:47 Seen so far: 248352 samples\n",
      "\n",
      "01_19_23:23:47 --- 1.9283292293548584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:49 Training loss at epoch 0 step 7770: 3.2871819972991942\n",
      "\n",
      " This round's valence_loss=0.8341057300567627, arousal_loss=0.7271890640258789, emotion_loss=1.0790077447891235\n",
      "\n",
      "01_19_23:23:49 Seen so far: 248672 samples\n",
      "\n",
      "01_19_23:23:49 --- 2.1075613498687744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:51 Training loss at epoch 0 step 7780: 3.1172680377960207\n",
      "\n",
      " This round's valence_loss=1.3541371822357178, arousal_loss=1.2210766077041626, emotion_loss=1.0553128719329834\n",
      "\n",
      "01_19_23:23:51 Seen so far: 248992 samples\n",
      "\n",
      "01_19_23:23:51 --- 2.2487633228302 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:53 Training loss at epoch 0 step 7790: 3.088020443916321\n",
      "\n",
      " This round's valence_loss=0.9518600702285767, arousal_loss=0.8212573528289795, emotion_loss=1.17026948928833\n",
      "\n",
      "01_19_23:23:53 Seen so far: 249312 samples\n",
      "\n",
      "01_19_23:23:53 --- 2.0973775386810303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:55 Training loss at epoch 0 step 7800: 3.4419834852218627\n",
      "\n",
      " This round's valence_loss=1.4707329273223877, arousal_loss=1.3593676090240479, emotion_loss=1.4801850318908691\n",
      "\n",
      "01_19_23:23:55 Seen so far: 249632 samples\n",
      "\n",
      "01_19_23:23:55 --- 2.372230291366577 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:57 Training loss at epoch 0 step 7810: 3.0403727769851683\n",
      "\n",
      " This round's valence_loss=1.114701747894287, arousal_loss=0.9821203351020813, emotion_loss=1.0960853099822998\n",
      "\n",
      "01_19_23:23:57 Seen so far: 249952 samples\n",
      "\n",
      "01_19_23:23:57 --- 1.8946106433868408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:23:59 Training loss at epoch 0 step 7820: 3.0836026430130006\n",
      "\n",
      " This round's valence_loss=0.9235578775405884, arousal_loss=0.8628911972045898, emotion_loss=1.106592059135437\n",
      "\n",
      "01_19_23:23:59 Seen so far: 250272 samples\n",
      "\n",
      "01_19_23:23:59 --- 1.8209385871887207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:01 Training loss at epoch 0 step 7830: 2.9043949604034425\n",
      "\n",
      " This round's valence_loss=0.510094940662384, arousal_loss=0.4408080577850342, emotion_loss=1.257979393005371\n",
      "\n",
      "01_19_23:24:01 Seen so far: 250592 samples\n",
      "\n",
      "01_19_23:24:01 --- 1.9694805145263672 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:03 Training loss at epoch 0 step 7840: 3.2276525259017945\n",
      "\n",
      " This round's valence_loss=1.151853322982788, arousal_loss=0.9846605062484741, emotion_loss=1.1445567607879639\n",
      "\n",
      "01_19_23:24:03 Seen so far: 250912 samples\n",
      "\n",
      "01_19_23:24:03 --- 1.9628510475158691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:05 Training loss at epoch 0 step 7850: 3.285762000083923\n",
      "\n",
      " This round's valence_loss=1.1191539764404297, arousal_loss=0.9380857944488525, emotion_loss=1.170006275177002\n",
      "\n",
      "01_19_23:24:05 Seen so far: 251232 samples\n",
      "\n",
      "01_19_23:24:05 --- 2.1648035049438477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:07 Training loss at epoch 0 step 7860: 2.8226690769195555\n",
      "\n",
      " This round's valence_loss=0.885299801826477, arousal_loss=0.6709195375442505, emotion_loss=1.0228015184402466\n",
      "\n",
      "01_19_23:24:07 Seen so far: 251552 samples\n",
      "\n",
      "01_19_23:24:07 --- 2.113377809524536 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:09 Training loss at epoch 0 step 7870: 2.8078664779663085\n",
      "\n",
      " This round's valence_loss=0.8108648061752319, arousal_loss=0.7598717212677002, emotion_loss=1.0198335647583008\n",
      "\n",
      "01_19_23:24:09 Seen so far: 251872 samples\n",
      "\n",
      "01_19_23:24:09 --- 2.0056114196777344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:11 Training loss at epoch 0 step 7880: 3.1392515182495115\n",
      "\n",
      " This round's valence_loss=1.1034371852874756, arousal_loss=1.0137993097305298, emotion_loss=1.162384271621704\n",
      "\n",
      "01_19_23:24:11 Seen so far: 252192 samples\n",
      "\n",
      "01_19_23:24:11 --- 1.8011219501495361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:13 Training loss at epoch 0 step 7890: 3.147637438774109\n",
      "\n",
      " This round's valence_loss=1.4689136743545532, arousal_loss=1.3136918544769287, emotion_loss=0.8966540694236755\n",
      "\n",
      "01_19_23:24:13 Seen so far: 252512 samples\n",
      "\n",
      "01_19_23:24:13 --- 1.9511022567749023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:15 Training loss at epoch 0 step 7900: 3.037230896949768\n",
      "\n",
      " This round's valence_loss=0.9799821376800537, arousal_loss=0.8402245044708252, emotion_loss=0.9029833078384399\n",
      "\n",
      "01_19_23:24:15 Seen so far: 252832 samples\n",
      "\n",
      "01_19_23:24:15 --- 1.9650630950927734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:17 Training loss at epoch 0 step 7910: 3.243018698692322\n",
      "\n",
      " This round's valence_loss=1.0758578777313232, arousal_loss=0.954058051109314, emotion_loss=1.3609528541564941\n",
      "\n",
      "01_19_23:24:17 Seen so far: 253152 samples\n",
      "\n",
      "01_19_23:24:17 --- 1.974133014678955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:19 Training loss at epoch 0 step 7920: 3.2584053754806517\n",
      "\n",
      " This round's valence_loss=0.9468254446983337, arousal_loss=0.8614497184753418, emotion_loss=1.2410860061645508\n",
      "\n",
      "01_19_23:24:19 Seen so far: 253472 samples\n",
      "\n",
      "01_19_23:24:19 --- 1.955200433731079 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:21 Training loss at epoch 0 step 7930: 3.188349413871765\n",
      "\n",
      " This round's valence_loss=1.1037631034851074, arousal_loss=0.9277324080467224, emotion_loss=1.1266121864318848\n",
      "\n",
      "01_19_23:24:21 Seen so far: 253792 samples\n",
      "\n",
      "01_19_23:24:21 --- 2.1889374256134033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:23 Training loss at epoch 0 step 7940: 3.077067184448242\n",
      "\n",
      " This round's valence_loss=0.8052343726158142, arousal_loss=0.7639663219451904, emotion_loss=1.3324007987976074\n",
      "\n",
      "01_19_23:24:23 Seen so far: 254112 samples\n",
      "\n",
      "01_19_23:24:23 --- 2.1863625049591064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:25 Training loss at epoch 0 step 7950: 3.0869525194168093\n",
      "\n",
      " This round's valence_loss=0.4170975685119629, arousal_loss=0.25665968656539917, emotion_loss=1.3365073204040527\n",
      "\n",
      "01_19_23:24:25 Seen so far: 254432 samples\n",
      "\n",
      "01_19_23:24:25 --- 2.013700246810913 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:27 Training loss at epoch 0 step 7960: 2.9983479499816896\n",
      "\n",
      " This round's valence_loss=1.0923738479614258, arousal_loss=0.9734306335449219, emotion_loss=1.1029363870620728\n",
      "\n",
      "01_19_23:24:27 Seen so far: 254752 samples\n",
      "\n",
      "01_19_23:24:27 --- 1.957920789718628 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:29 Training loss at epoch 0 step 7970: 3.058826446533203\n",
      "\n",
      " This round's valence_loss=0.8944031596183777, arousal_loss=0.7723126411437988, emotion_loss=0.993861198425293\n",
      "\n",
      "01_19_23:24:29 Seen so far: 255072 samples\n",
      "\n",
      "01_19_23:24:29 --- 1.927257776260376 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:31 Training loss at epoch 0 step 7980: 3.4159141778945923\n",
      "\n",
      " This round's valence_loss=1.536076545715332, arousal_loss=1.4464895725250244, emotion_loss=1.151886224746704\n",
      "\n",
      "01_19_23:24:31 Seen so far: 255392 samples\n",
      "\n",
      "01_19_23:24:31 --- 2.0807366371154785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:33 Training loss at epoch 0 step 7990: 2.9686195850372314\n",
      "\n",
      " This round's valence_loss=0.730915904045105, arousal_loss=0.5852382183074951, emotion_loss=1.2822959423065186\n",
      "\n",
      "01_19_23:24:33 Seen so far: 255712 samples\n",
      "\n",
      "01_19_23:24:33 --- 2.05115008354187 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:35 Training loss at epoch 0 step 8000: 3.160926842689514\n",
      "\n",
      " This round's valence_loss=0.802862823009491, arousal_loss=0.7315537929534912, emotion_loss=1.255218744277954\n",
      "\n",
      "01_19_23:24:35 Seen so far: 256032 samples\n",
      "\n",
      "01_19_23:24:35 --- 1.9085147380828857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:37 Training loss at epoch 0 step 8010: 3.0867151021957397\n",
      "\n",
      " This round's valence_loss=0.8971461653709412, arousal_loss=0.7518762350082397, emotion_loss=1.0079039335250854\n",
      "\n",
      "01_19_23:24:37 Seen so far: 256352 samples\n",
      "\n",
      "01_19_23:24:37 --- 2.0207014083862305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:39 Training loss at epoch 0 step 8020: 3.2304095029830933\n",
      "\n",
      " This round's valence_loss=1.139525055885315, arousal_loss=0.9701625108718872, emotion_loss=1.0669543743133545\n",
      "\n",
      "01_19_23:24:39 Seen so far: 256672 samples\n",
      "\n",
      "01_19_23:24:39 --- 2.0339465141296387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:41 Training loss at epoch 0 step 8030: 3.2210574626922606\n",
      "\n",
      " This round's valence_loss=1.3197216987609863, arousal_loss=1.2396578788757324, emotion_loss=1.335536241531372\n",
      "\n",
      "01_19_23:24:41 Seen so far: 256992 samples\n",
      "\n",
      "01_19_23:24:41 --- 1.8088483810424805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:43 Training loss at epoch 0 step 8040: 2.8540718793869018\n",
      "\n",
      " This round's valence_loss=1.0609440803527832, arousal_loss=0.9624608755111694, emotion_loss=1.4800615310668945\n",
      "\n",
      "01_19_23:24:43 Seen so far: 257312 samples\n",
      "\n",
      "01_19_23:24:43 --- 2.0347416400909424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:45 Training loss at epoch 0 step 8050: 3.3582276821136476\n",
      "\n",
      " This round's valence_loss=1.3302247524261475, arousal_loss=1.216525673866272, emotion_loss=1.0857625007629395\n",
      "\n",
      "01_19_23:24:45 Seen so far: 257632 samples\n",
      "\n",
      "01_19_23:24:45 --- 2.196404457092285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:47 Training loss at epoch 0 step 8060: 3.1820547103881838\n",
      "\n",
      " This round's valence_loss=1.0853824615478516, arousal_loss=0.9788761734962463, emotion_loss=0.9323949813842773\n",
      "\n",
      "01_19_23:24:47 Seen so far: 257952 samples\n",
      "\n",
      "01_19_23:24:47 --- 1.9566047191619873 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:49 Training loss at epoch 0 step 8070: 2.9163257122039794\n",
      "\n",
      " This round's valence_loss=1.0629515647888184, arousal_loss=0.945960283279419, emotion_loss=1.0836782455444336\n",
      "\n",
      "01_19_23:24:49 Seen so far: 258272 samples\n",
      "\n",
      "01_19_23:24:49 --- 1.8939955234527588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:51 Training loss at epoch 0 step 8080: 3.158196139335632\n",
      "\n",
      " This round's valence_loss=1.592775583267212, arousal_loss=1.439213752746582, emotion_loss=1.1671043634414673\n",
      "\n",
      "01_19_23:24:51 Seen so far: 258592 samples\n",
      "\n",
      "01_19_23:24:51 --- 1.7427780628204346 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:53 Training loss at epoch 0 step 8090: 3.3645111560821532\n",
      "\n",
      " This round's valence_loss=0.9551799297332764, arousal_loss=0.8364269137382507, emotion_loss=1.357413411140442\n",
      "\n",
      "01_19_23:24:53 Seen so far: 258912 samples\n",
      "\n",
      "01_19_23:24:53 --- 2.0886013507843018 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:55 Training loss at epoch 0 step 8100: 2.9323078751564027\n",
      "\n",
      " This round's valence_loss=1.3474704027175903, arousal_loss=1.1998844146728516, emotion_loss=0.957324206829071\n",
      "\n",
      "01_19_23:24:55 Seen so far: 259232 samples\n",
      "\n",
      "01_19_23:24:55 --- 1.904653787612915 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:57 Training loss at epoch 0 step 8110: 3.0660860538482666\n",
      "\n",
      " This round's valence_loss=0.993598222732544, arousal_loss=0.8794960975646973, emotion_loss=1.301823616027832\n",
      "\n",
      "01_19_23:24:57 Seen so far: 259552 samples\n",
      "\n",
      "01_19_23:24:57 --- 2.029587745666504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:24:59 Training loss at epoch 0 step 8120: 3.144287848472595\n",
      "\n",
      " This round's valence_loss=1.278731346130371, arousal_loss=1.1892468929290771, emotion_loss=0.9181015491485596\n",
      "\n",
      "01_19_23:24:59 Seen so far: 259872 samples\n",
      "\n",
      "01_19_23:24:59 --- 1.9239680767059326 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:01 Training loss at epoch 0 step 8130: 3.135856604576111\n",
      "\n",
      " This round's valence_loss=0.6421356797218323, arousal_loss=0.41757071018218994, emotion_loss=1.001706600189209\n",
      "\n",
      "01_19_23:25:01 Seen so far: 260192 samples\n",
      "\n",
      "01_19_23:25:01 --- 2.1223716735839844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:03 Training loss at epoch 0 step 8140: 3.1609520316123962\n",
      "\n",
      " This round's valence_loss=0.7035547494888306, arousal_loss=0.4043542146682739, emotion_loss=0.778398871421814\n",
      "\n",
      "01_19_23:25:03 Seen so far: 260512 samples\n",
      "\n",
      "01_19_23:25:03 --- 1.8987088203430176 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:05 Training loss at epoch 0 step 8150: 2.9992902755737303\n",
      "\n",
      " This round's valence_loss=1.4882454872131348, arousal_loss=1.3129469156265259, emotion_loss=1.0552653074264526\n",
      "\n",
      "01_19_23:25:05 Seen so far: 260832 samples\n",
      "\n",
      "01_19_23:25:05 --- 2.0674679279327393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:07 Training loss at epoch 0 step 8160: 3.275833249092102\n",
      "\n",
      " This round's valence_loss=1.2067538499832153, arousal_loss=1.1030687093734741, emotion_loss=1.2384625673294067\n",
      "\n",
      "01_19_23:25:07 Seen so far: 261152 samples\n",
      "\n",
      "01_19_23:25:07 --- 1.9949264526367188 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:09 Training loss at epoch 0 step 8170: 3.1546734094619753\n",
      "\n",
      " This round's valence_loss=1.2529362440109253, arousal_loss=1.2186033725738525, emotion_loss=1.2718219757080078\n",
      "\n",
      "01_19_23:25:09 Seen so far: 261472 samples\n",
      "\n",
      "01_19_23:25:09 --- 2.0756940841674805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:11 Training loss at epoch 0 step 8180: 3.151813817024231\n",
      "\n",
      " This round's valence_loss=1.2507838010787964, arousal_loss=1.101773977279663, emotion_loss=1.0854849815368652\n",
      "\n",
      "01_19_23:25:11 Seen so far: 261792 samples\n",
      "\n",
      "01_19_23:25:11 --- 1.9796767234802246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:13 Training loss at epoch 0 step 8190: 3.292729878425598\n",
      "\n",
      " This round's valence_loss=1.2239904403686523, arousal_loss=1.0672763586044312, emotion_loss=1.0524393320083618\n",
      "\n",
      "01_19_23:25:13 Seen so far: 262112 samples\n",
      "\n",
      "01_19_23:25:13 --- 2.056999683380127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:15 Training loss at epoch 0 step 8200: 3.082572865486145\n",
      "\n",
      " This round's valence_loss=1.0930358171463013, arousal_loss=0.9920427203178406, emotion_loss=1.3909895420074463\n",
      "\n",
      "01_19_23:25:15 Seen so far: 262432 samples\n",
      "\n",
      "01_19_23:25:15 --- 2.2628893852233887 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:18 Training loss at epoch 0 step 8210: 3.285667395591736\n",
      "\n",
      " This round's valence_loss=1.2033882141113281, arousal_loss=0.9766360521316528, emotion_loss=0.7314527034759521\n",
      "\n",
      "01_19_23:25:18 Seen so far: 262752 samples\n",
      "\n",
      "01_19_23:25:18 --- 2.166851043701172 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:20 Training loss at epoch 0 step 8220: 2.7223156929016112\n",
      "\n",
      " This round's valence_loss=1.2984094619750977, arousal_loss=1.0805952548980713, emotion_loss=1.1183786392211914\n",
      "\n",
      "01_19_23:25:20 Seen so far: 263072 samples\n",
      "\n",
      "01_19_23:25:20 --- 2.054151773452759 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:22 Training loss at epoch 0 step 8230: 2.8444483041763307\n",
      "\n",
      " This round's valence_loss=1.1181952953338623, arousal_loss=0.9814139008522034, emotion_loss=1.0668330192565918\n",
      "\n",
      "01_19_23:25:22 Seen so far: 263392 samples\n",
      "\n",
      "01_19_23:25:22 --- 2.023441791534424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:24 Training loss at epoch 0 step 8240: 3.1865845680236817\n",
      "\n",
      " This round's valence_loss=0.7722700834274292, arousal_loss=0.6062577962875366, emotion_loss=0.9474561214447021\n",
      "\n",
      "01_19_23:25:24 Seen so far: 263712 samples\n",
      "\n",
      "01_19_23:25:24 --- 1.8767788410186768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:26 Training loss at epoch 0 step 8250: 3.0618785858154296\n",
      "\n",
      " This round's valence_loss=1.0306566953659058, arousal_loss=0.8099298477172852, emotion_loss=0.739914059638977\n",
      "\n",
      "01_19_23:25:26 Seen so far: 264032 samples\n",
      "\n",
      "01_19_23:25:26 --- 2.105914354324341 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:28 Training loss at epoch 0 step 8260: 3.432902979850769\n",
      "\n",
      " This round's valence_loss=1.109879970550537, arousal_loss=0.9493991136550903, emotion_loss=1.0901864767074585\n",
      "\n",
      "01_19_23:25:28 Seen so far: 264352 samples\n",
      "\n",
      "01_19_23:25:28 --- 1.970017671585083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:30 Training loss at epoch 0 step 8270: 3.0537929058074953\n",
      "\n",
      " This round's valence_loss=1.3157505989074707, arousal_loss=1.083604097366333, emotion_loss=1.0882617235183716\n",
      "\n",
      "01_19_23:25:30 Seen so far: 264672 samples\n",
      "\n",
      "01_19_23:25:30 --- 2.168051242828369 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:32 Training loss at epoch 0 step 8280: 3.358912706375122\n",
      "\n",
      " This round's valence_loss=0.7223283052444458, arousal_loss=0.5858426094055176, emotion_loss=1.0028396844863892\n",
      "\n",
      "01_19_23:25:32 Seen so far: 264992 samples\n",
      "\n",
      "01_19_23:25:32 --- 2.14138126373291 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:34 Training loss at epoch 0 step 8290: 2.966551995277405\n",
      "\n",
      " This round's valence_loss=1.0088918209075928, arousal_loss=0.853701651096344, emotion_loss=1.2517225742340088\n",
      "\n",
      "01_19_23:25:34 Seen so far: 265312 samples\n",
      "\n",
      "01_19_23:25:34 --- 1.8610279560089111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:36 Training loss at epoch 0 step 8300: 2.9762238264083862\n",
      "\n",
      " This round's valence_loss=1.433166265487671, arousal_loss=1.3363115787506104, emotion_loss=1.2993748188018799\n",
      "\n",
      "01_19_23:25:36 Seen so far: 265632 samples\n",
      "\n",
      "01_19_23:25:36 --- 2.0231058597564697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:38 Training loss at epoch 0 step 8310: 3.1221946716308593\n",
      "\n",
      " This round's valence_loss=0.9474448561668396, arousal_loss=0.7341203689575195, emotion_loss=1.0535986423492432\n",
      "\n",
      "01_19_23:25:38 Seen so far: 265952 samples\n",
      "\n",
      "01_19_23:25:38 --- 2.125600814819336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:40 Training loss at epoch 0 step 8320: 3.088366484642029\n",
      "\n",
      " This round's valence_loss=0.8176854848861694, arousal_loss=0.730329155921936, emotion_loss=1.4493217468261719\n",
      "\n",
      "01_19_23:25:40 Seen so far: 266272 samples\n",
      "\n",
      "01_19_23:25:40 --- 1.973526954650879 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:42 Training loss at epoch 0 step 8330: 3.0272507667541504\n",
      "\n",
      " This round's valence_loss=1.4327764511108398, arousal_loss=1.32694673538208, emotion_loss=1.1883176565170288\n",
      "\n",
      "01_19_23:25:42 Seen so far: 266592 samples\n",
      "\n",
      "01_19_23:25:42 --- 2.120819091796875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:44 Training loss at epoch 0 step 8340: 3.1068397045135496\n",
      "\n",
      " This round's valence_loss=0.8373083472251892, arousal_loss=0.7081683874130249, emotion_loss=1.0711421966552734\n",
      "\n",
      "01_19_23:25:44 Seen so far: 266912 samples\n",
      "\n",
      "01_19_23:25:44 --- 2.0263495445251465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:46 Training loss at epoch 0 step 8350: 2.9595637917518616\n",
      "\n",
      " This round's valence_loss=0.5447045564651489, arousal_loss=0.3775944411754608, emotion_loss=1.037360429763794\n",
      "\n",
      "01_19_23:25:46 Seen so far: 267232 samples\n",
      "\n",
      "01_19_23:25:46 --- 1.8651788234710693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:48 Training loss at epoch 0 step 8360: 2.805070638656616\n",
      "\n",
      " This round's valence_loss=0.5404964685440063, arousal_loss=0.31805992126464844, emotion_loss=0.9348694086074829\n",
      "\n",
      "01_19_23:25:48 Seen so far: 267552 samples\n",
      "\n",
      "01_19_23:25:48 --- 1.9461233615875244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:50 Training loss at epoch 0 step 8370: 3.3553053379058837\n",
      "\n",
      " This round's valence_loss=0.7951624393463135, arousal_loss=0.5884414911270142, emotion_loss=0.966415286064148\n",
      "\n",
      "01_19_23:25:50 Seen so far: 267872 samples\n",
      "\n",
      "01_19_23:25:50 --- 2.061514377593994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:52 Training loss at epoch 0 step 8380: 3.449938678741455\n",
      "\n",
      " This round's valence_loss=1.2269911766052246, arousal_loss=1.0919097661972046, emotion_loss=0.9783539772033691\n",
      "\n",
      "01_19_23:25:52 Seen so far: 268192 samples\n",
      "\n",
      "01_19_23:25:52 --- 1.7666537761688232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:54 Training loss at epoch 0 step 8390: 3.1586403369903566\n",
      "\n",
      " This round's valence_loss=1.126641035079956, arousal_loss=0.9887120723724365, emotion_loss=0.918708086013794\n",
      "\n",
      "01_19_23:25:54 Seen so far: 268512 samples\n",
      "\n",
      "01_19_23:25:54 --- 1.9109866619110107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:56 Training loss at epoch 0 step 8400: 3.3432003974914553\n",
      "\n",
      " This round's valence_loss=1.04111909866333, arousal_loss=0.8129504919052124, emotion_loss=0.8932479619979858\n",
      "\n",
      "01_19_23:25:56 Seen so far: 268832 samples\n",
      "\n",
      "01_19_23:25:56 --- 1.9526119232177734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:57 Training loss at epoch 0 step 8410: 2.9191548109054564\n",
      "\n",
      " This round's valence_loss=0.7224510312080383, arousal_loss=0.49366825819015503, emotion_loss=0.9801887273788452\n",
      "\n",
      "01_19_23:25:57 Seen so far: 269152 samples\n",
      "\n",
      "01_19_23:25:57 --- 1.7948243618011475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:25:59 Training loss at epoch 0 step 8420: 3.3870029926300047\n",
      "\n",
      " This round's valence_loss=1.4617109298706055, arousal_loss=1.315256118774414, emotion_loss=1.0908844470977783\n",
      "\n",
      "01_19_23:25:59 Seen so far: 269472 samples\n",
      "\n",
      "01_19_23:25:59 --- 1.7637543678283691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:01 Training loss at epoch 0 step 8430: 3.196322703361511\n",
      "\n",
      " This round's valence_loss=1.3132985830307007, arousal_loss=1.0446492433547974, emotion_loss=1.144395351409912\n",
      "\n",
      "01_19_23:26:01 Seen so far: 269792 samples\n",
      "\n",
      "01_19_23:26:01 --- 1.8215296268463135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:03 Training loss at epoch 0 step 8440: 3.194458556175232\n",
      "\n",
      " This round's valence_loss=1.1317685842514038, arousal_loss=0.9621918201446533, emotion_loss=0.675946831703186\n",
      "\n",
      "01_19_23:26:03 Seen so far: 270112 samples\n",
      "\n",
      "01_19_23:26:03 --- 2.111137866973877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:05 Training loss at epoch 0 step 8450: 3.238684296607971\n",
      "\n",
      " This round's valence_loss=0.6946688890457153, arousal_loss=0.5622853636741638, emotion_loss=1.2733006477355957\n",
      "\n",
      "01_19_23:26:05 Seen so far: 270432 samples\n",
      "\n",
      "01_19_23:26:05 --- 1.9416613578796387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:07 Training loss at epoch 0 step 8460: 3.0331053733825684\n",
      "\n",
      " This round's valence_loss=0.8187969923019409, arousal_loss=0.7288778424263, emotion_loss=1.6144930124282837\n",
      "\n",
      "01_19_23:26:07 Seen so far: 270752 samples\n",
      "\n",
      "01_19_23:26:07 --- 2.0492403507232666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:09 Training loss at epoch 0 step 8470: 3.309946823120117\n",
      "\n",
      " This round's valence_loss=0.876602292060852, arousal_loss=0.7089515924453735, emotion_loss=1.079067349433899\n",
      "\n",
      "01_19_23:26:09 Seen so far: 271072 samples\n",
      "\n",
      "01_19_23:26:09 --- 1.8800334930419922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:11 Training loss at epoch 0 step 8480: 3.093946075439453\n",
      "\n",
      " This round's valence_loss=1.079815149307251, arousal_loss=1.0024367570877075, emotion_loss=1.0412437915802002\n",
      "\n",
      "01_19_23:26:11 Seen so far: 271392 samples\n",
      "\n",
      "01_19_23:26:11 --- 1.9966516494750977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:13 Training loss at epoch 0 step 8490: 2.735779619216919\n",
      "\n",
      " This round's valence_loss=0.8080311417579651, arousal_loss=0.7317061424255371, emotion_loss=1.2684948444366455\n",
      "\n",
      "01_19_23:26:13 Seen so far: 271712 samples\n",
      "\n",
      "01_19_23:26:13 --- 1.9319047927856445 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:15 Training loss at epoch 0 step 8500: 3.190321135520935\n",
      "\n",
      " This round's valence_loss=1.324711561203003, arousal_loss=1.1854641437530518, emotion_loss=0.999995768070221\n",
      "\n",
      "01_19_23:26:15 Seen so far: 272032 samples\n",
      "\n",
      "01_19_23:26:15 --- 2.1916937828063965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:17 Training loss at epoch 0 step 8510: 2.8218746185302734\n",
      "\n",
      " This round's valence_loss=0.5902727842330933, arousal_loss=0.5111839771270752, emotion_loss=1.1284523010253906\n",
      "\n",
      "01_19_23:26:17 Seen so far: 272352 samples\n",
      "\n",
      "01_19_23:26:17 --- 1.9322748184204102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:19 Training loss at epoch 0 step 8520: 3.24592125415802\n",
      "\n",
      " This round's valence_loss=0.8661393523216248, arousal_loss=0.6936215162277222, emotion_loss=1.1490943431854248\n",
      "\n",
      "01_19_23:26:19 Seen so far: 272672 samples\n",
      "\n",
      "01_19_23:26:19 --- 1.9171326160430908 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:21 Training loss at epoch 0 step 8530: 2.9742360591888426\n",
      "\n",
      " This round's valence_loss=1.3120121955871582, arousal_loss=1.1936042308807373, emotion_loss=0.9956184029579163\n",
      "\n",
      "01_19_23:26:21 Seen so far: 272992 samples\n",
      "\n",
      "01_19_23:26:21 --- 1.9800786972045898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:23 Training loss at epoch 0 step 8540: 3.118200397491455\n",
      "\n",
      " This round's valence_loss=0.953426718711853, arousal_loss=0.8339873552322388, emotion_loss=1.0324978828430176\n",
      "\n",
      "01_19_23:26:23 Seen so far: 273312 samples\n",
      "\n",
      "01_19_23:26:23 --- 2.1938130855560303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:25 Training loss at epoch 0 step 8550: 3.0601906299591066\n",
      "\n",
      " This round's valence_loss=1.3458207845687866, arousal_loss=1.2008998394012451, emotion_loss=0.9087793827056885\n",
      "\n",
      "01_19_23:26:25 Seen so far: 273632 samples\n",
      "\n",
      "01_19_23:26:25 --- 1.9854211807250977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:27 Training loss at epoch 0 step 8560: 3.287090849876404\n",
      "\n",
      " This round's valence_loss=1.2973946332931519, arousal_loss=1.1814874410629272, emotion_loss=0.6192072033882141\n",
      "\n",
      "01_19_23:26:27 Seen so far: 273952 samples\n",
      "\n",
      "01_19_23:26:27 --- 1.932844877243042 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:29 Training loss at epoch 0 step 8570: 2.896645450592041\n",
      "\n",
      " This round's valence_loss=0.8969453573226929, arousal_loss=0.7333716154098511, emotion_loss=0.9014406204223633\n",
      "\n",
      "01_19_23:26:29 Seen so far: 274272 samples\n",
      "\n",
      "01_19_23:26:29 --- 2.0395469665527344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:31 Training loss at epoch 0 step 8580: 3.1923723459243774\n",
      "\n",
      " This round's valence_loss=0.8621522188186646, arousal_loss=0.7450985908508301, emotion_loss=1.455703616142273\n",
      "\n",
      "01_19_23:26:31 Seen so far: 274592 samples\n",
      "\n",
      "01_19_23:26:31 --- 1.8375976085662842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:33 Training loss at epoch 0 step 8590: 2.7761095643043516\n",
      "\n",
      " This round's valence_loss=1.4226505756378174, arousal_loss=1.3276478052139282, emotion_loss=0.8002016544342041\n",
      "\n",
      "01_19_23:26:33 Seen so far: 274912 samples\n",
      "\n",
      "01_19_23:26:33 --- 1.8402578830718994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:35 Training loss at epoch 0 step 8600: 3.1268163204193113\n",
      "\n",
      " This round's valence_loss=0.899470329284668, arousal_loss=0.7484019994735718, emotion_loss=1.072914958000183\n",
      "\n",
      "01_19_23:26:35 Seen so far: 275232 samples\n",
      "\n",
      "01_19_23:26:35 --- 2.1832940578460693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:37 Training loss at epoch 0 step 8610: 3.185130476951599\n",
      "\n",
      " This round's valence_loss=0.8957831859588623, arousal_loss=0.6890532374382019, emotion_loss=0.7338398098945618\n",
      "\n",
      "01_19_23:26:37 Seen so far: 275552 samples\n",
      "\n",
      "01_19_23:26:37 --- 1.9590497016906738 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:39 Training loss at epoch 0 step 8620: 3.2802825689315798\n",
      "\n",
      " This round's valence_loss=0.9372116327285767, arousal_loss=0.8920652270317078, emotion_loss=1.112170696258545\n",
      "\n",
      "01_19_23:26:39 Seen so far: 275872 samples\n",
      "\n",
      "01_19_23:26:39 --- 2.1983933448791504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:41 Training loss at epoch 0 step 8630: 3.1148943662643434\n",
      "\n",
      " This round's valence_loss=1.5811628103256226, arousal_loss=1.525161623954773, emotion_loss=1.0670669078826904\n",
      "\n",
      "01_19_23:26:41 Seen so far: 276192 samples\n",
      "\n",
      "01_19_23:26:41 --- 1.8275787830352783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:43 Training loss at epoch 0 step 8640: 3.0358412504196166\n",
      "\n",
      " This round's valence_loss=0.9616571664810181, arousal_loss=0.8748674392700195, emotion_loss=1.0857279300689697\n",
      "\n",
      "01_19_23:26:43 Seen so far: 276512 samples\n",
      "\n",
      "01_19_23:26:43 --- 2.180185556411743 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:45 Training loss at epoch 0 step 8650: 2.80172518491745\n",
      "\n",
      " This round's valence_loss=0.615760862827301, arousal_loss=0.4771265983581543, emotion_loss=0.8649541139602661\n",
      "\n",
      "01_19_23:26:45 Seen so far: 276832 samples\n",
      "\n",
      "01_19_23:26:45 --- 2.302532196044922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:47 Training loss at epoch 0 step 8660: 3.1949919700622558\n",
      "\n",
      " This round's valence_loss=1.1228652000427246, arousal_loss=0.9474003314971924, emotion_loss=1.462667465209961\n",
      "\n",
      "01_19_23:26:47 Seen so far: 277152 samples\n",
      "\n",
      "01_19_23:26:47 --- 1.9810638427734375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:49 Training loss at epoch 0 step 8670: 2.969231653213501\n",
      "\n",
      " This round's valence_loss=0.7445173263549805, arousal_loss=0.6206387281417847, emotion_loss=1.2419426441192627\n",
      "\n",
      "01_19_23:26:49 Seen so far: 277472 samples\n",
      "\n",
      "01_19_23:26:49 --- 2.1226463317871094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:52 Training loss at epoch 0 step 8680: 2.978202772140503\n",
      "\n",
      " This round's valence_loss=1.0701963901519775, arousal_loss=1.0083496570587158, emotion_loss=1.1946420669555664\n",
      "\n",
      "01_19_23:26:52 Seen so far: 277792 samples\n",
      "\n",
      "01_19_23:26:52 --- 2.2951974868774414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:54 Training loss at epoch 0 step 8690: 2.914379835128784\n",
      "\n",
      " This round's valence_loss=0.9167211055755615, arousal_loss=0.7335530519485474, emotion_loss=1.0047942399978638\n",
      "\n",
      "01_19_23:26:54 Seen so far: 278112 samples\n",
      "\n",
      "01_19_23:26:54 --- 1.9016318321228027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:56 Training loss at epoch 0 step 8700: 3.2383684635162355\n",
      "\n",
      " This round's valence_loss=1.3078267574310303, arousal_loss=1.2068653106689453, emotion_loss=1.1694576740264893\n",
      "\n",
      "01_19_23:26:56 Seen so far: 278432 samples\n",
      "\n",
      "01_19_23:26:56 --- 1.9084880352020264 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:26:57 Training loss at epoch 0 step 8710: 3.2872973442077638\n",
      "\n",
      " This round's valence_loss=1.097095012664795, arousal_loss=1.0439857244491577, emotion_loss=1.1141510009765625\n",
      "\n",
      "01_19_23:26:57 Seen so far: 278752 samples\n",
      "\n",
      "01_19_23:26:57 --- 1.8895306587219238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:00 Training loss at epoch 0 step 8720: 3.0350765228271483\n",
      "\n",
      " This round's valence_loss=1.7409824132919312, arousal_loss=1.5397918224334717, emotion_loss=1.4647852182388306\n",
      "\n",
      "01_19_23:27:00 Seen so far: 279072 samples\n",
      "\n",
      "01_19_23:27:00 --- 2.167975902557373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:02 Training loss at epoch 0 step 8730: 3.000437045097351\n",
      "\n",
      " This round's valence_loss=0.9559815526008606, arousal_loss=0.715637743473053, emotion_loss=0.8865141868591309\n",
      "\n",
      "01_19_23:27:02 Seen so far: 279392 samples\n",
      "\n",
      "01_19_23:27:02 --- 1.9640452861785889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:04 Training loss at epoch 0 step 8740: 3.2062217950820924\n",
      "\n",
      " This round's valence_loss=1.0701768398284912, arousal_loss=1.0024425983428955, emotion_loss=1.1393256187438965\n",
      "\n",
      "01_19_23:27:04 Seen so far: 279712 samples\n",
      "\n",
      "01_19_23:27:04 --- 1.9772989749908447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:06 Training loss at epoch 0 step 8750: 3.2065125465393067\n",
      "\n",
      " This round's valence_loss=0.9520552158355713, arousal_loss=0.8418782949447632, emotion_loss=1.3481018543243408\n",
      "\n",
      "01_19_23:27:06 Seen so far: 280032 samples\n",
      "\n",
      "01_19_23:27:06 --- 2.199469566345215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:08 Training loss at epoch 0 step 8760: 3.0295721769332884\n",
      "\n",
      " This round's valence_loss=1.1408154964447021, arousal_loss=1.1004714965820312, emotion_loss=1.1351065635681152\n",
      "\n",
      "01_19_23:27:08 Seen so far: 280352 samples\n",
      "\n",
      "01_19_23:27:08 --- 1.9926643371582031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:10 Training loss at epoch 0 step 8770: 3.2676045417785646\n",
      "\n",
      " This round's valence_loss=0.8150326013565063, arousal_loss=0.8208303451538086, emotion_loss=1.1011806726455688\n",
      "\n",
      "01_19_23:27:10 Seen so far: 280672 samples\n",
      "\n",
      "01_19_23:27:10 --- 1.929197072982788 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:11 Training loss at epoch 0 step 8780: 2.9316057920455934\n",
      "\n",
      " This round's valence_loss=0.8460797667503357, arousal_loss=0.7046467065811157, emotion_loss=1.4715633392333984\n",
      "\n",
      "01_19_23:27:11 Seen so far: 280992 samples\n",
      "\n",
      "01_19_23:27:11 --- 1.8133132457733154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:13 Training loss at epoch 0 step 8790: 3.1220528364181517\n",
      "\n",
      " This round's valence_loss=1.3255943059921265, arousal_loss=1.2284939289093018, emotion_loss=1.1296806335449219\n",
      "\n",
      "01_19_23:27:13 Seen so far: 281312 samples\n",
      "\n",
      "01_19_23:27:13 --- 1.8225066661834717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:15 Training loss at epoch 0 step 8800: 3.246438217163086\n",
      "\n",
      " This round's valence_loss=1.087172269821167, arousal_loss=1.0162861347198486, emotion_loss=0.9528130292892456\n",
      "\n",
      "01_19_23:27:15 Seen so far: 281632 samples\n",
      "\n",
      "01_19_23:27:15 --- 1.8927247524261475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:17 Training loss at epoch 0 step 8810: 3.0121346712112427\n",
      "\n",
      " This round's valence_loss=1.3359243869781494, arousal_loss=1.205418348312378, emotion_loss=0.9284738898277283\n",
      "\n",
      "01_19_23:27:17 Seen so far: 281952 samples\n",
      "\n",
      "01_19_23:27:17 --- 1.8290154933929443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:19 Training loss at epoch 0 step 8820: 3.0971949338912963\n",
      "\n",
      " This round's valence_loss=0.9520364999771118, arousal_loss=0.8075006008148193, emotion_loss=1.0400159358978271\n",
      "\n",
      "01_19_23:27:19 Seen so far: 282272 samples\n",
      "\n",
      "01_19_23:27:19 --- 1.8821251392364502 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:21 Training loss at epoch 0 step 8830: 3.163454008102417\n",
      "\n",
      " This round's valence_loss=0.8775508999824524, arousal_loss=0.7534574270248413, emotion_loss=1.4474024772644043\n",
      "\n",
      "01_19_23:27:21 Seen so far: 282592 samples\n",
      "\n",
      "01_19_23:27:21 --- 2.1103789806365967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:23 Training loss at epoch 0 step 8840: 3.0288368225097657\n",
      "\n",
      " This round's valence_loss=0.8953883647918701, arousal_loss=0.69036865234375, emotion_loss=0.9384233355522156\n",
      "\n",
      "01_19_23:27:23 Seen so far: 282912 samples\n",
      "\n",
      "01_19_23:27:23 --- 2.0523438453674316 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:25 Training loss at epoch 0 step 8850: 3.251007390022278\n",
      "\n",
      " This round's valence_loss=1.6692860126495361, arousal_loss=1.5870275497436523, emotion_loss=0.6729028224945068\n",
      "\n",
      "01_19_23:27:25 Seen so far: 283232 samples\n",
      "\n",
      "01_19_23:27:25 --- 2.1256792545318604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:27 Training loss at epoch 0 step 8860: 3.2552063941955565\n",
      "\n",
      " This round's valence_loss=0.99349045753479, arousal_loss=0.872711181640625, emotion_loss=1.148458480834961\n",
      "\n",
      "01_19_23:27:27 Seen so far: 283552 samples\n",
      "\n",
      "01_19_23:27:27 --- 1.889650821685791 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:29 Training loss at epoch 0 step 8870: 3.1712129712104797\n",
      "\n",
      " This round's valence_loss=1.1441011428833008, arousal_loss=0.9829590320587158, emotion_loss=1.0678021907806396\n",
      "\n",
      "01_19_23:27:29 Seen so far: 283872 samples\n",
      "\n",
      "01_19_23:27:29 --- 2.019136905670166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:31 Training loss at epoch 0 step 8880: 2.880114507675171\n",
      "\n",
      " This round's valence_loss=0.7967277765274048, arousal_loss=0.7223944664001465, emotion_loss=1.108075737953186\n",
      "\n",
      "01_19_23:27:31 Seen so far: 284192 samples\n",
      "\n",
      "01_19_23:27:31 --- 2.175079107284546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:33 Training loss at epoch 0 step 8890: 3.173901891708374\n",
      "\n",
      " This round's valence_loss=1.3413524627685547, arousal_loss=1.1871023178100586, emotion_loss=0.9611803293228149\n",
      "\n",
      "01_19_23:27:33 Seen so far: 284512 samples\n",
      "\n",
      "01_19_23:27:33 --- 2.1819608211517334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:35 Training loss at epoch 0 step 8900: 3.043034625053406\n",
      "\n",
      " This round's valence_loss=1.0782378911972046, arousal_loss=0.9854588508605957, emotion_loss=0.7526689767837524\n",
      "\n",
      "01_19_23:27:35 Seen so far: 284832 samples\n",
      "\n",
      "01_19_23:27:35 --- 1.9904570579528809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:37 Training loss at epoch 0 step 8910: 3.056429314613342\n",
      "\n",
      " This round's valence_loss=0.9243482351303101, arousal_loss=0.8153029084205627, emotion_loss=1.2729426622390747\n",
      "\n",
      "01_19_23:27:37 Seen so far: 285152 samples\n",
      "\n",
      "01_19_23:27:37 --- 1.906280517578125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:39 Training loss at epoch 0 step 8920: 3.314388060569763\n",
      "\n",
      " This round's valence_loss=1.1064200401306152, arousal_loss=0.8298497200012207, emotion_loss=0.8161180019378662\n",
      "\n",
      "01_19_23:27:39 Seen so far: 285472 samples\n",
      "\n",
      "01_19_23:27:39 --- 2.1009795665740967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:41 Training loss at epoch 0 step 8930: 3.096673083305359\n",
      "\n",
      " This round's valence_loss=1.0003459453582764, arousal_loss=0.8190449476242065, emotion_loss=1.0387005805969238\n",
      "\n",
      "01_19_23:27:41 Seen so far: 285792 samples\n",
      "\n",
      "01_19_23:27:41 --- 1.9491634368896484 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:43 Training loss at epoch 0 step 8940: 3.1310418605804444\n",
      "\n",
      " This round's valence_loss=0.7706106305122375, arousal_loss=0.5923001766204834, emotion_loss=1.2327461242675781\n",
      "\n",
      "01_19_23:27:43 Seen so far: 286112 samples\n",
      "\n",
      "01_19_23:27:43 --- 1.8568365573883057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:45 Training loss at epoch 0 step 8950: 3.3278733015060427\n",
      "\n",
      " This round's valence_loss=1.2960180044174194, arousal_loss=1.2613940238952637, emotion_loss=1.4100563526153564\n",
      "\n",
      "01_19_23:27:45 Seen so far: 286432 samples\n",
      "\n",
      "01_19_23:27:45 --- 1.8097054958343506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:47 Training loss at epoch 0 step 8960: 2.9586212635040283\n",
      "\n",
      " This round's valence_loss=1.1424806118011475, arousal_loss=1.030588150024414, emotion_loss=1.0733814239501953\n",
      "\n",
      "01_19_23:27:47 Seen so far: 286752 samples\n",
      "\n",
      "01_19_23:27:47 --- 1.914228916168213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:49 Training loss at epoch 0 step 8970: 3.131699573993683\n",
      "\n",
      " This round's valence_loss=0.6107548475265503, arousal_loss=0.4591420292854309, emotion_loss=0.906941294670105\n",
      "\n",
      "01_19_23:27:49 Seen so far: 287072 samples\n",
      "\n",
      "01_19_23:27:49 --- 2.0026063919067383 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:51 Training loss at epoch 0 step 8980: 3.278644299507141\n",
      "\n",
      " This round's valence_loss=1.1875578165054321, arousal_loss=1.0552587509155273, emotion_loss=1.2573964595794678\n",
      "\n",
      "01_19_23:27:51 Seen so far: 287392 samples\n",
      "\n",
      "01_19_23:27:51 --- 1.833667516708374 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:53 Training loss at epoch 0 step 8990: 3.475702142715454\n",
      "\n",
      " This round's valence_loss=1.4643096923828125, arousal_loss=1.3256022930145264, emotion_loss=1.180864930152893\n",
      "\n",
      "01_19_23:27:53 Seen so far: 287712 samples\n",
      "\n",
      "01_19_23:27:53 --- 2.0580875873565674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:55 Training loss at epoch 0 step 9000: 3.360704445838928\n",
      "\n",
      " This round's valence_loss=0.9653144478797913, arousal_loss=0.8503941297531128, emotion_loss=1.1534868478775024\n",
      "\n",
      "01_19_23:27:55 Seen so far: 288032 samples\n",
      "\n",
      "01_19_23:27:55 --- 2.039660930633545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:57 Training loss at epoch 0 step 9010: 3.2228585481643677\n",
      "\n",
      " This round's valence_loss=1.0563843250274658, arousal_loss=0.8246228694915771, emotion_loss=1.1048698425292969\n",
      "\n",
      "01_19_23:27:57 Seen so far: 288352 samples\n",
      "\n",
      "01_19_23:27:57 --- 2.043724775314331 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:27:59 Training loss at epoch 0 step 9020: 3.1437750816345216\n",
      "\n",
      " This round's valence_loss=1.4297751188278198, arousal_loss=1.3317227363586426, emotion_loss=1.1441597938537598\n",
      "\n",
      "01_19_23:27:59 Seen so far: 288672 samples\n",
      "\n",
      "01_19_23:27:59 --- 1.969588279724121 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:01 Training loss at epoch 0 step 9030: 2.8800042390823366\n",
      "\n",
      " This round's valence_loss=1.0126246213912964, arousal_loss=0.8044114112854004, emotion_loss=1.0507032871246338\n",
      "\n",
      "01_19_23:28:01 Seen so far: 288992 samples\n",
      "\n",
      "01_19_23:28:01 --- 1.7828266620635986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:03 Training loss at epoch 0 step 9040: 3.0731997966766356\n",
      "\n",
      " This round's valence_loss=1.3064260482788086, arousal_loss=1.2056515216827393, emotion_loss=1.365959644317627\n",
      "\n",
      "01_19_23:28:03 Seen so far: 289312 samples\n",
      "\n",
      "01_19_23:28:03 --- 1.8644359111785889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:05 Training loss at epoch 0 step 9050: 3.0383983135223387\n",
      "\n",
      " This round's valence_loss=1.090376853942871, arousal_loss=1.010793685913086, emotion_loss=1.0684289932250977\n",
      "\n",
      "01_19_23:28:05 Seen so far: 289632 samples\n",
      "\n",
      "01_19_23:28:05 --- 2.0744640827178955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:07 Training loss at epoch 0 step 9060: 3.2340739250183104\n",
      "\n",
      " This round's valence_loss=0.9617443680763245, arousal_loss=0.8461929559707642, emotion_loss=1.7071683406829834\n",
      "\n",
      "01_19_23:28:07 Seen so far: 289952 samples\n",
      "\n",
      "01_19_23:28:07 --- 2.287402391433716 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:09 Training loss at epoch 0 step 9070: 2.936835026741028\n",
      "\n",
      " This round's valence_loss=0.7381935119628906, arousal_loss=0.5955227613449097, emotion_loss=1.0622832775115967\n",
      "\n",
      "01_19_23:28:09 Seen so far: 290272 samples\n",
      "\n",
      "01_19_23:28:09 --- 2.0812180042266846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:11 Training loss at epoch 0 step 9080: 3.1738603353500365\n",
      "\n",
      " This round's valence_loss=0.9607549905776978, arousal_loss=0.8484322428703308, emotion_loss=1.3143422603607178\n",
      "\n",
      "01_19_23:28:11 Seen so far: 290592 samples\n",
      "\n",
      "01_19_23:28:11 --- 2.089189291000366 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:13 Training loss at epoch 0 step 9090: 3.239667558670044\n",
      "\n",
      " This round's valence_loss=1.0951429605484009, arousal_loss=0.938471794128418, emotion_loss=0.7866020798683167\n",
      "\n",
      "01_19_23:28:13 Seen so far: 290912 samples\n",
      "\n",
      "01_19_23:28:13 --- 1.924156665802002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:15 Training loss at epoch 0 step 9100: 3.203147840499878\n",
      "\n",
      " This round's valence_loss=1.26564621925354, arousal_loss=1.0621767044067383, emotion_loss=1.1381125450134277\n",
      "\n",
      "01_19_23:28:15 Seen so far: 291232 samples\n",
      "\n",
      "01_19_23:28:15 --- 2.0598926544189453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:17 Training loss at epoch 0 step 9110: 3.0096669793128967\n",
      "\n",
      " This round's valence_loss=1.1374776363372803, arousal_loss=0.9718125462532043, emotion_loss=1.009026288986206\n",
      "\n",
      "01_19_23:28:17 Seen so far: 291552 samples\n",
      "\n",
      "01_19_23:28:17 --- 2.190277099609375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:19 Training loss at epoch 0 step 9120: 3.2289573669433596\n",
      "\n",
      " This round's valence_loss=0.9701371192932129, arousal_loss=0.8501574993133545, emotion_loss=0.8613842129707336\n",
      "\n",
      "01_19_23:28:19 Seen so far: 291872 samples\n",
      "\n",
      "01_19_23:28:19 --- 1.9058001041412354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:21 Training loss at epoch 0 step 9130: 3.199862766265869\n",
      "\n",
      " This round's valence_loss=1.0067522525787354, arousal_loss=0.8558894395828247, emotion_loss=0.8552418351173401\n",
      "\n",
      "01_19_23:28:21 Seen so far: 292192 samples\n",
      "\n",
      "01_19_23:28:21 --- 2.1379401683807373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:23 Training loss at epoch 0 step 9140: 3.1156448841094972\n",
      "\n",
      " This round's valence_loss=0.7950230240821838, arousal_loss=0.7227254509925842, emotion_loss=0.9707930088043213\n",
      "\n",
      "01_19_23:28:23 Seen so far: 292512 samples\n",
      "\n",
      "01_19_23:28:23 --- 2.0829689502716064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:25 Training loss at epoch 0 step 9150: 3.353806185722351\n",
      "\n",
      " This round's valence_loss=0.8055319786071777, arousal_loss=0.6060583591461182, emotion_loss=1.3221373558044434\n",
      "\n",
      "01_19_23:28:25 Seen so far: 292832 samples\n",
      "\n",
      "01_19_23:28:25 --- 2.0250802040100098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:27 Training loss at epoch 0 step 9160: 3.3204951524734496\n",
      "\n",
      " This round's valence_loss=1.4280908107757568, arousal_loss=1.3532087802886963, emotion_loss=1.2568057775497437\n",
      "\n",
      "01_19_23:28:27 Seen so far: 293152 samples\n",
      "\n",
      "01_19_23:28:27 --- 2.008371591567993 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:30 Training loss at epoch 0 step 9170: 3.5673126220703124\n",
      "\n",
      " This round's valence_loss=1.179815649986267, arousal_loss=1.1220638751983643, emotion_loss=0.9640021324157715\n",
      "\n",
      "01_19_23:28:30 Seen so far: 293472 samples\n",
      "\n",
      "01_19_23:28:30 --- 2.080002546310425 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:32 Training loss at epoch 0 step 9180: 2.911124014854431\n",
      "\n",
      " This round's valence_loss=0.933462381362915, arousal_loss=0.8429059982299805, emotion_loss=0.8253117799758911\n",
      "\n",
      "01_19_23:28:32 Seen so far: 293792 samples\n",
      "\n",
      "01_19_23:28:32 --- 2.026200532913208 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:33 Training loss at epoch 0 step 9190: 3.000467085838318\n",
      "\n",
      " This round's valence_loss=0.9296934604644775, arousal_loss=0.6774352788925171, emotion_loss=1.041601538658142\n",
      "\n",
      "01_19_23:28:33 Seen so far: 294112 samples\n",
      "\n",
      "01_19_23:28:33 --- 1.7864139080047607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:35 Training loss at epoch 0 step 9200: 3.37593789100647\n",
      "\n",
      " This round's valence_loss=0.9213765859603882, arousal_loss=0.8274699449539185, emotion_loss=1.3176054954528809\n",
      "\n",
      "01_19_23:28:35 Seen so far: 294432 samples\n",
      "\n",
      "01_19_23:28:35 --- 1.9818637371063232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:37 Training loss at epoch 0 step 9210: 2.9438416957855225\n",
      "\n",
      " This round's valence_loss=1.564023494720459, arousal_loss=1.4363763332366943, emotion_loss=1.0305461883544922\n",
      "\n",
      "01_19_23:28:37 Seen so far: 294752 samples\n",
      "\n",
      "01_19_23:28:37 --- 1.9541106224060059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:39 Training loss at epoch 0 step 9220: 3.08774471282959\n",
      "\n",
      " This round's valence_loss=1.1179970502853394, arousal_loss=0.9888888597488403, emotion_loss=1.0068297386169434\n",
      "\n",
      "01_19_23:28:39 Seen so far: 295072 samples\n",
      "\n",
      "01_19_23:28:39 --- 1.9681479930877686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:41 Training loss at epoch 0 step 9230: 2.9981603145599367\n",
      "\n",
      " This round's valence_loss=0.885265588760376, arousal_loss=0.7721284627914429, emotion_loss=1.2486863136291504\n",
      "\n",
      "01_19_23:28:41 Seen so far: 295392 samples\n",
      "\n",
      "01_19_23:28:41 --- 2.1234219074249268 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:43 Training loss at epoch 0 step 9240: 2.798673725128174\n",
      "\n",
      " This round's valence_loss=1.0675430297851562, arousal_loss=0.9665807485580444, emotion_loss=0.7396819591522217\n",
      "\n",
      "01_19_23:28:43 Seen so far: 295712 samples\n",
      "\n",
      "01_19_23:28:43 --- 1.8979923725128174 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:45 Training loss at epoch 0 step 9250: 3.2136063098907472\n",
      "\n",
      " This round's valence_loss=1.4784269332885742, arousal_loss=1.2841873168945312, emotion_loss=0.6900957822799683\n",
      "\n",
      "01_19_23:28:45 Seen so far: 296032 samples\n",
      "\n",
      "01_19_23:28:45 --- 2.1662838459014893 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:47 Training loss at epoch 0 step 9260: 2.687047243118286\n",
      "\n",
      " This round's valence_loss=1.0909876823425293, arousal_loss=0.9786499738693237, emotion_loss=0.992929220199585\n",
      "\n",
      "01_19_23:28:47 Seen so far: 296352 samples\n",
      "\n",
      "01_19_23:28:47 --- 2.0124542713165283 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:49 Training loss at epoch 0 step 9270: 3.3203047037124636\n",
      "\n",
      " This round's valence_loss=0.9446203708648682, arousal_loss=0.8295159339904785, emotion_loss=1.1156673431396484\n",
      "\n",
      "01_19_23:28:49 Seen so far: 296672 samples\n",
      "\n",
      "01_19_23:28:49 --- 1.9012830257415771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:51 Training loss at epoch 0 step 9280: 3.2921595335006715\n",
      "\n",
      " This round's valence_loss=1.1221184730529785, arousal_loss=0.9341844320297241, emotion_loss=0.8443490266799927\n",
      "\n",
      "01_19_23:28:51 Seen so far: 296992 samples\n",
      "\n",
      "01_19_23:28:51 --- 1.9659359455108643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:53 Training loss at epoch 0 step 9290: 2.931601715087891\n",
      "\n",
      " This round's valence_loss=1.206594705581665, arousal_loss=1.1120290756225586, emotion_loss=0.936834990978241\n",
      "\n",
      "01_19_23:28:53 Seen so far: 297312 samples\n",
      "\n",
      "01_19_23:28:53 --- 2.108583688735962 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:55 Training loss at epoch 0 step 9300: 3.2018373727798464\n",
      "\n",
      " This round's valence_loss=1.0411121845245361, arousal_loss=0.9772852063179016, emotion_loss=1.0670477151870728\n",
      "\n",
      "01_19_23:28:55 Seen so far: 297632 samples\n",
      "\n",
      "01_19_23:28:55 --- 2.017354726791382 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:57 Training loss at epoch 0 step 9310: 3.245693874359131\n",
      "\n",
      " This round's valence_loss=0.9887956380844116, arousal_loss=0.8239516615867615, emotion_loss=1.032401442527771\n",
      "\n",
      "01_19_23:28:57 Seen so far: 297952 samples\n",
      "\n",
      "01_19_23:28:57 --- 1.9032938480377197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:28:59 Training loss at epoch 0 step 9320: 3.0071115732192992\n",
      "\n",
      " This round's valence_loss=1.1333413124084473, arousal_loss=0.9766876697540283, emotion_loss=1.1195473670959473\n",
      "\n",
      "01_19_23:28:59 Seen so far: 298272 samples\n",
      "\n",
      "01_19_23:28:59 --- 1.970158338546753 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:01 Training loss at epoch 0 step 9330: 3.131458020210266\n",
      "\n",
      " This round's valence_loss=1.226116418838501, arousal_loss=1.0674868822097778, emotion_loss=0.7354567050933838\n",
      "\n",
      "01_19_23:29:01 Seen so far: 298592 samples\n",
      "\n",
      "01_19_23:29:01 --- 1.7416322231292725 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:03 Training loss at epoch 0 step 9340: 3.3855032920837402\n",
      "\n",
      " This round's valence_loss=1.4096530675888062, arousal_loss=1.3572065830230713, emotion_loss=1.2029879093170166\n",
      "\n",
      "01_19_23:29:03 Seen so far: 298912 samples\n",
      "\n",
      "01_19_23:29:03 --- 2.0677289962768555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:05 Training loss at epoch 0 step 9350: 3.206190514564514\n",
      "\n",
      " This round's valence_loss=1.2021044492721558, arousal_loss=1.0942823886871338, emotion_loss=0.9554116725921631\n",
      "\n",
      "01_19_23:29:05 Seen so far: 299232 samples\n",
      "\n",
      "01_19_23:29:05 --- 2.0142292976379395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:07 Training loss at epoch 0 step 9360: 3.163312840461731\n",
      "\n",
      " This round's valence_loss=1.5623310804367065, arousal_loss=1.4259839057922363, emotion_loss=1.1553940773010254\n",
      "\n",
      "01_19_23:29:07 Seen so far: 299552 samples\n",
      "\n",
      "01_19_23:29:07 --- 2.0422544479370117 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:09 Training loss at epoch 0 step 9370: 2.905432915687561\n",
      "\n",
      " This round's valence_loss=1.1017855405807495, arousal_loss=0.962586522102356, emotion_loss=0.7544131278991699\n",
      "\n",
      "01_19_23:29:09 Seen so far: 299872 samples\n",
      "\n",
      "01_19_23:29:09 --- 1.9707331657409668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:11 Training loss at epoch 0 step 9380: 2.877839374542236\n",
      "\n",
      " This round's valence_loss=1.0841398239135742, arousal_loss=0.9984169602394104, emotion_loss=1.3240807056427002\n",
      "\n",
      "01_19_23:29:11 Seen so far: 300192 samples\n",
      "\n",
      "01_19_23:29:11 --- 2.2977819442749023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:13 Training loss at epoch 0 step 9390: 3.180922245979309\n",
      "\n",
      " This round's valence_loss=0.5545264482498169, arousal_loss=0.33864283561706543, emotion_loss=1.044708013534546\n",
      "\n",
      "01_19_23:29:13 Seen so far: 300512 samples\n",
      "\n",
      "01_19_23:29:13 --- 1.9355459213256836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:15 Training loss at epoch 0 step 9400: 3.0020898580551147\n",
      "\n",
      " This round's valence_loss=0.8039492964744568, arousal_loss=0.5868669748306274, emotion_loss=0.9907643795013428\n",
      "\n",
      "01_19_23:29:15 Seen so far: 300832 samples\n",
      "\n",
      "01_19_23:29:15 --- 2.085905075073242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:17 Training loss at epoch 0 step 9410: 3.1964439392089843\n",
      "\n",
      " This round's valence_loss=1.1600325107574463, arousal_loss=1.1047935485839844, emotion_loss=1.2266792058944702\n",
      "\n",
      "01_19_23:29:17 Seen so far: 301152 samples\n",
      "\n",
      "01_19_23:29:17 --- 1.923814058303833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:19 Training loss at epoch 0 step 9420: 2.9041867733001707\n",
      "\n",
      " This round's valence_loss=0.8999008536338806, arousal_loss=0.710053563117981, emotion_loss=1.285395622253418\n",
      "\n",
      "01_19_23:29:19 Seen so far: 301472 samples\n",
      "\n",
      "01_19_23:29:19 --- 2.0823891162872314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:21 Training loss at epoch 0 step 9430: 2.641562247276306\n",
      "\n",
      " This round's valence_loss=0.8290519714355469, arousal_loss=0.7198539972305298, emotion_loss=1.114603042602539\n",
      "\n",
      "01_19_23:29:21 Seen so far: 301792 samples\n",
      "\n",
      "01_19_23:29:21 --- 1.8425683975219727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:23 Training loss at epoch 0 step 9440: 3.4969557762145995\n",
      "\n",
      " This round's valence_loss=1.5808467864990234, arousal_loss=1.4378752708435059, emotion_loss=1.3615676164627075\n",
      "\n",
      "01_19_23:29:23 Seen so far: 302112 samples\n",
      "\n",
      "01_19_23:29:23 --- 1.919320821762085 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:25 Training loss at epoch 0 step 9450: 2.756038522720337\n",
      "\n",
      " This round's valence_loss=1.009010672569275, arousal_loss=0.8664805293083191, emotion_loss=0.9826581478118896\n",
      "\n",
      "01_19_23:29:25 Seen so far: 302432 samples\n",
      "\n",
      "01_19_23:29:25 --- 1.8303673267364502 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:27 Training loss at epoch 0 step 9460: 3.253902292251587\n",
      "\n",
      " This round's valence_loss=0.9151369333267212, arousal_loss=0.6937363147735596, emotion_loss=1.132502555847168\n",
      "\n",
      "01_19_23:29:27 Seen so far: 302752 samples\n",
      "\n",
      "01_19_23:29:27 --- 1.863201379776001 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:29 Training loss at epoch 0 step 9470: 3.038595199584961\n",
      "\n",
      " This round's valence_loss=1.5836694240570068, arousal_loss=1.4361095428466797, emotion_loss=0.9974043369293213\n",
      "\n",
      "01_19_23:29:29 Seen so far: 303072 samples\n",
      "\n",
      "01_19_23:29:29 --- 1.9751861095428467 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:31 Training loss at epoch 0 step 9480: 3.0185734272003173\n",
      "\n",
      " This round's valence_loss=0.8265007138252258, arousal_loss=0.7387929558753967, emotion_loss=0.943669319152832\n",
      "\n",
      "01_19_23:29:31 Seen so far: 303392 samples\n",
      "\n",
      "01_19_23:29:31 --- 1.9580097198486328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:33 Training loss at epoch 0 step 9490: 3.1946024656295777\n",
      "\n",
      " This round's valence_loss=0.8280811309814453, arousal_loss=0.6999995708465576, emotion_loss=1.0005158185958862\n",
      "\n",
      "01_19_23:29:33 Seen so far: 303712 samples\n",
      "\n",
      "01_19_23:29:33 --- 2.093991994857788 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:35 Training loss at epoch 0 step 9500: 3.096409010887146\n",
      "\n",
      " This round's valence_loss=1.4622623920440674, arousal_loss=1.3730493783950806, emotion_loss=1.1392712593078613\n",
      "\n",
      "01_19_23:29:35 Seen so far: 304032 samples\n",
      "\n",
      "01_19_23:29:35 --- 2.0152602195739746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:37 Training loss at epoch 0 step 9510: 3.254954767227173\n",
      "\n",
      " This round's valence_loss=1.150124430656433, arousal_loss=1.0892493724822998, emotion_loss=1.0835065841674805\n",
      "\n",
      "01_19_23:29:37 Seen so far: 304352 samples\n",
      "\n",
      "01_19_23:29:37 --- 1.9032776355743408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:39 Training loss at epoch 0 step 9520: 3.161567950248718\n",
      "\n",
      " This round's valence_loss=1.2619779109954834, arousal_loss=1.0520998239517212, emotion_loss=0.7327709197998047\n",
      "\n",
      "01_19_23:29:39 Seen so far: 304672 samples\n",
      "\n",
      "01_19_23:29:39 --- 1.9590740203857422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:41 Training loss at epoch 0 step 9530: 3.3746065855026246\n",
      "\n",
      " This round's valence_loss=1.117318034172058, arousal_loss=0.9483202695846558, emotion_loss=1.1107547283172607\n",
      "\n",
      "01_19_23:29:41 Seen so far: 304992 samples\n",
      "\n",
      "01_19_23:29:41 --- 1.7489724159240723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:43 Training loss at epoch 0 step 9540: 3.201766014099121\n",
      "\n",
      " This round's valence_loss=1.0776586532592773, arousal_loss=0.9517072439193726, emotion_loss=1.1402866840362549\n",
      "\n",
      "01_19_23:29:43 Seen so far: 305312 samples\n",
      "\n",
      "01_19_23:29:43 --- 2.085059642791748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:45 Training loss at epoch 0 step 9550: 2.887910842895508\n",
      "\n",
      " This round's valence_loss=1.218721628189087, arousal_loss=1.100288987159729, emotion_loss=1.3040919303894043\n",
      "\n",
      "01_19_23:29:45 Seen so far: 305632 samples\n",
      "\n",
      "01_19_23:29:45 --- 1.915224552154541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:47 Training loss at epoch 0 step 9560: 3.0951194047927855\n",
      "\n",
      " This round's valence_loss=0.44804421067237854, arousal_loss=0.3337130546569824, emotion_loss=1.3113459348678589\n",
      "\n",
      "01_19_23:29:47 Seen so far: 305952 samples\n",
      "\n",
      "01_19_23:29:47 --- 1.9778861999511719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:49 Training loss at epoch 0 step 9570: 3.5306595087051393\n",
      "\n",
      " This round's valence_loss=1.1455774307250977, arousal_loss=0.9408007264137268, emotion_loss=1.4716914892196655\n",
      "\n",
      "01_19_23:29:49 Seen so far: 306272 samples\n",
      "\n",
      "01_19_23:29:49 --- 2.1342408657073975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:51 Training loss at epoch 0 step 9580: 2.9508211851119994\n",
      "\n",
      " This round's valence_loss=0.7386382818222046, arousal_loss=0.5513837933540344, emotion_loss=1.002090573310852\n",
      "\n",
      "01_19_23:29:51 Seen so far: 306592 samples\n",
      "\n",
      "01_19_23:29:51 --- 2.1410818099975586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:53 Training loss at epoch 0 step 9590: 2.899086761474609\n",
      "\n",
      " This round's valence_loss=0.7708308696746826, arousal_loss=0.5705023407936096, emotion_loss=1.059951663017273\n",
      "\n",
      "01_19_23:29:53 Seen so far: 306912 samples\n",
      "\n",
      "01_19_23:29:53 --- 2.4695725440979004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:55 Training loss at epoch 0 step 9600: 3.0056151390075683\n",
      "\n",
      " This round's valence_loss=1.5509111881256104, arousal_loss=1.4512200355529785, emotion_loss=1.0104578733444214\n",
      "\n",
      "01_19_23:29:55 Seen so far: 307232 samples\n",
      "\n",
      "01_19_23:29:55 --- 1.9350290298461914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:57 Training loss at epoch 0 step 9610: 3.1344406604766846\n",
      "\n",
      " This round's valence_loss=1.2304208278656006, arousal_loss=1.1014232635498047, emotion_loss=0.9633022546768188\n",
      "\n",
      "01_19_23:29:57 Seen so far: 307552 samples\n",
      "\n",
      "01_19_23:29:57 --- 2.174834728240967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:29:59 Training loss at epoch 0 step 9620: 3.2586180686950685\n",
      "\n",
      " This round's valence_loss=1.2122249603271484, arousal_loss=1.161602258682251, emotion_loss=1.1383570432662964\n",
      "\n",
      "01_19_23:29:59 Seen so far: 307872 samples\n",
      "\n",
      "01_19_23:29:59 --- 2.063525676727295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:02 Training loss at epoch 0 step 9630: 3.0923035860061647\n",
      "\n",
      " This round's valence_loss=1.6157383918762207, arousal_loss=1.436964750289917, emotion_loss=0.8300241231918335\n",
      "\n",
      "01_19_23:30:02 Seen so far: 308192 samples\n",
      "\n",
      "01_19_23:30:02 --- 2.312613010406494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:04 Training loss at epoch 0 step 9640: 2.7462249994277954\n",
      "\n",
      " This round's valence_loss=0.7251690626144409, arousal_loss=0.6042813062667847, emotion_loss=1.1054657697677612\n",
      "\n",
      "01_19_23:30:04 Seen so far: 308512 samples\n",
      "\n",
      "01_19_23:30:04 --- 1.8307368755340576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:06 Training loss at epoch 0 step 9650: 3.377615785598755\n",
      "\n",
      " This round's valence_loss=1.1944665908813477, arousal_loss=1.0744311809539795, emotion_loss=1.2445895671844482\n",
      "\n",
      "01_19_23:30:06 Seen so far: 308832 samples\n",
      "\n",
      "01_19_23:30:06 --- 2.0235629081726074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:08 Training loss at epoch 0 step 9660: 2.958577060699463\n",
      "\n",
      " This round's valence_loss=0.9602516889572144, arousal_loss=0.7174274921417236, emotion_loss=0.7309963703155518\n",
      "\n",
      "01_19_23:30:08 Seen so far: 309152 samples\n",
      "\n",
      "01_19_23:30:08 --- 1.9449570178985596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:10 Training loss at epoch 0 step 9670: 2.5380754709243774\n",
      "\n",
      " This round's valence_loss=0.738074779510498, arousal_loss=0.6307096481323242, emotion_loss=1.0454181432724\n",
      "\n",
      "01_19_23:30:10 Seen so far: 309472 samples\n",
      "\n",
      "01_19_23:30:10 --- 1.958674669265747 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:12 Training loss at epoch 0 step 9680: 3.0226208925247193\n",
      "\n",
      " This round's valence_loss=0.9517104029655457, arousal_loss=0.8046237230300903, emotion_loss=1.3515805006027222\n",
      "\n",
      "01_19_23:30:12 Seen so far: 309792 samples\n",
      "\n",
      "01_19_23:30:12 --- 2.0336549282073975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:14 Training loss at epoch 0 step 9690: 3.4949369192123414\n",
      "\n",
      " This round's valence_loss=0.7310370206832886, arousal_loss=0.5503572225570679, emotion_loss=1.0799168348312378\n",
      "\n",
      "01_19_23:30:14 Seen so far: 310112 samples\n",
      "\n",
      "01_19_23:30:14 --- 2.1094696521759033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:15 Training loss at epoch 0 step 9700: 3.1610770225524902\n",
      "\n",
      " This round's valence_loss=0.8087849617004395, arousal_loss=0.6022539138793945, emotion_loss=0.9796134233474731\n",
      "\n",
      "01_19_23:30:15 Seen so far: 310432 samples\n",
      "\n",
      "01_19_23:30:15 --- 1.7682945728302002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:17 Training loss at epoch 0 step 9710: 2.7290305376052855\n",
      "\n",
      " This round's valence_loss=1.157893180847168, arousal_loss=0.904926061630249, emotion_loss=0.7349464893341064\n",
      "\n",
      "01_19_23:30:17 Seen so far: 310752 samples\n",
      "\n",
      "01_19_23:30:17 --- 2.0097901821136475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:19 Training loss at epoch 0 step 9720: 3.1613656997680666\n",
      "\n",
      " This round's valence_loss=0.9809862375259399, arousal_loss=0.8748024702072144, emotion_loss=1.5416972637176514\n",
      "\n",
      "01_19_23:30:19 Seen so far: 311072 samples\n",
      "\n",
      "01_19_23:30:19 --- 1.9730174541473389 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:21 Training loss at epoch 0 step 9730: 2.965341305732727\n",
      "\n",
      " This round's valence_loss=0.9251866340637207, arousal_loss=0.7899805307388306, emotion_loss=0.9409928321838379\n",
      "\n",
      "01_19_23:30:21 Seen so far: 311392 samples\n",
      "\n",
      "01_19_23:30:21 --- 1.9460170269012451 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:23 Training loss at epoch 0 step 9740: 3.150681257247925\n",
      "\n",
      " This round's valence_loss=0.8113589286804199, arousal_loss=0.7177855968475342, emotion_loss=1.2613561153411865\n",
      "\n",
      "01_19_23:30:23 Seen so far: 311712 samples\n",
      "\n",
      "01_19_23:30:23 --- 1.984647512435913 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:25 Training loss at epoch 0 step 9750: 3.191778063774109\n",
      "\n",
      " This round's valence_loss=1.1937742233276367, arousal_loss=0.9545900821685791, emotion_loss=0.5995515584945679\n",
      "\n",
      "01_19_23:30:25 Seen so far: 312032 samples\n",
      "\n",
      "01_19_23:30:25 --- 2.0565531253814697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:27 Training loss at epoch 0 step 9760: 3.1717758655548094\n",
      "\n",
      " This round's valence_loss=1.3568185567855835, arousal_loss=1.2549046277999878, emotion_loss=1.2267487049102783\n",
      "\n",
      "01_19_23:30:27 Seen so far: 312352 samples\n",
      "\n",
      "01_19_23:30:27 --- 2.0253233909606934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:29 Training loss at epoch 0 step 9770: 2.7746284008026123\n",
      "\n",
      " This round's valence_loss=0.6444583535194397, arousal_loss=0.4545482099056244, emotion_loss=0.9244644641876221\n",
      "\n",
      "01_19_23:30:29 Seen so far: 312672 samples\n",
      "\n",
      "01_19_23:30:29 --- 1.975816249847412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:32 Training loss at epoch 0 step 9780: 2.9108293414115907\n",
      "\n",
      " This round's valence_loss=0.49718791246414185, arousal_loss=0.3645704388618469, emotion_loss=0.8910489082336426\n",
      "\n",
      "01_19_23:30:32 Seen so far: 312992 samples\n",
      "\n",
      "01_19_23:30:32 --- 2.1135146617889404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:34 Training loss at epoch 0 step 9790: 3.008494329452515\n",
      "\n",
      " This round's valence_loss=1.0085759162902832, arousal_loss=0.835293710231781, emotion_loss=1.1032733917236328\n",
      "\n",
      "01_19_23:30:34 Seen so far: 313312 samples\n",
      "\n",
      "01_19_23:30:34 --- 2.118356466293335 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:36 Training loss at epoch 0 step 9800: 3.319808268547058\n",
      "\n",
      " This round's valence_loss=1.1215870380401611, arousal_loss=0.9664033055305481, emotion_loss=1.106450080871582\n",
      "\n",
      "01_19_23:30:36 Seen so far: 313632 samples\n",
      "\n",
      "01_19_23:30:36 --- 1.9660694599151611 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:38 Training loss at epoch 0 step 9810: 3.0472936391830445\n",
      "\n",
      " This round's valence_loss=1.7012797594070435, arousal_loss=1.571205496788025, emotion_loss=1.1055188179016113\n",
      "\n",
      "01_19_23:30:38 Seen so far: 313952 samples\n",
      "\n",
      "01_19_23:30:38 --- 2.0204381942749023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:40 Training loss at epoch 0 step 9820: 2.989131784439087\n",
      "\n",
      " This round's valence_loss=0.8985147476196289, arousal_loss=0.7965826988220215, emotion_loss=0.9424170255661011\n",
      "\n",
      "01_19_23:30:40 Seen so far: 314272 samples\n",
      "\n",
      "01_19_23:30:40 --- 2.0234897136688232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:42 Training loss at epoch 0 step 9830: 2.8934095978736876\n",
      "\n",
      " This round's valence_loss=1.2014234066009521, arousal_loss=1.109134554862976, emotion_loss=1.0339704751968384\n",
      "\n",
      "01_19_23:30:42 Seen so far: 314592 samples\n",
      "\n",
      "01_19_23:30:42 --- 1.9942424297332764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:44 Training loss at epoch 0 step 9840: 3.1744921445846557\n",
      "\n",
      " This round's valence_loss=1.8593136072158813, arousal_loss=1.8179490566253662, emotion_loss=1.352891445159912\n",
      "\n",
      "01_19_23:30:44 Seen so far: 314912 samples\n",
      "\n",
      "01_19_23:30:44 --- 1.9405920505523682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:46 Training loss at epoch 0 step 9850: 3.080867600440979\n",
      "\n",
      " This round's valence_loss=0.7091012001037598, arousal_loss=0.5986059904098511, emotion_loss=0.975386381149292\n",
      "\n",
      "01_19_23:30:46 Seen so far: 315232 samples\n",
      "\n",
      "01_19_23:30:46 --- 1.9435393810272217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:48 Training loss at epoch 0 step 9860: 3.140492343902588\n",
      "\n",
      " This round's valence_loss=0.8774319291114807, arousal_loss=0.7225804328918457, emotion_loss=1.2564294338226318\n",
      "\n",
      "01_19_23:30:48 Seen so far: 315552 samples\n",
      "\n",
      "01_19_23:30:48 --- 2.1340577602386475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:50 Training loss at epoch 0 step 9870: 3.0768512010574343\n",
      "\n",
      " This round's valence_loss=0.9544200897216797, arousal_loss=0.6773878335952759, emotion_loss=0.9280095100402832\n",
      "\n",
      "01_19_23:30:50 Seen so far: 315872 samples\n",
      "\n",
      "01_19_23:30:50 --- 1.9636712074279785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:51 Training loss at epoch 0 step 9880: 3.0675605297088624\n",
      "\n",
      " This round's valence_loss=0.6626335382461548, arousal_loss=0.6393944621086121, emotion_loss=1.3799304962158203\n",
      "\n",
      "01_19_23:30:51 Seen so far: 316192 samples\n",
      "\n",
      "01_19_23:30:51 --- 1.7435619831085205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:53 Training loss at epoch 0 step 9890: 3.343495750427246\n",
      "\n",
      " This round's valence_loss=0.9338319301605225, arousal_loss=0.8624188899993896, emotion_loss=1.026977300643921\n",
      "\n",
      "01_19_23:30:53 Seen so far: 316512 samples\n",
      "\n",
      "01_19_23:30:53 --- 2.0050699710845947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:56 Training loss at epoch 0 step 9900: 2.8868168354034425\n",
      "\n",
      " This round's valence_loss=0.8602901697158813, arousal_loss=0.7775552272796631, emotion_loss=0.9312136173248291\n",
      "\n",
      "01_19_23:30:56 Seen so far: 316832 samples\n",
      "\n",
      "01_19_23:30:56 --- 2.0837783813476562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:57 Training loss at epoch 0 step 9910: 3.280424118041992\n",
      "\n",
      " This round's valence_loss=1.5803329944610596, arousal_loss=1.4765974283218384, emotion_loss=1.0518608093261719\n",
      "\n",
      "01_19_23:30:57 Seen so far: 317152 samples\n",
      "\n",
      "01_19_23:30:57 --- 1.9721438884735107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:30:59 Training loss at epoch 0 step 9920: 3.251972794532776\n",
      "\n",
      " This round's valence_loss=1.6160322427749634, arousal_loss=1.441007375717163, emotion_loss=1.0271552801132202\n",
      "\n",
      "01_19_23:30:59 Seen so far: 317472 samples\n",
      "\n",
      "01_19_23:30:59 --- 1.8616933822631836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:01 Training loss at epoch 0 step 9930: 3.2402060985565186\n",
      "\n",
      " This round's valence_loss=1.255871295928955, arousal_loss=1.0870040655136108, emotion_loss=0.8161246180534363\n",
      "\n",
      "01_19_23:31:01 Seen so far: 317792 samples\n",
      "\n",
      "01_19_23:31:01 --- 2.027480363845825 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:03 Training loss at epoch 0 step 9940: 3.2617300271987917\n",
      "\n",
      " This round's valence_loss=1.2864959239959717, arousal_loss=1.2125519514083862, emotion_loss=0.9021936058998108\n",
      "\n",
      "01_19_23:31:03 Seen so far: 318112 samples\n",
      "\n",
      "01_19_23:31:03 --- 1.9205598831176758 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:05 Training loss at epoch 0 step 9950: 3.102409291267395\n",
      "\n",
      " This round's valence_loss=1.3378404378890991, arousal_loss=1.1999132633209229, emotion_loss=1.0473649501800537\n",
      "\n",
      "01_19_23:31:05 Seen so far: 318432 samples\n",
      "\n",
      "01_19_23:31:05 --- 2.006885051727295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:08 Training loss at epoch 0 step 9960: 3.4080105304718016\n",
      "\n",
      " This round's valence_loss=1.3237899541854858, arousal_loss=1.1678681373596191, emotion_loss=1.1577167510986328\n",
      "\n",
      "01_19_23:31:08 Seen so far: 318752 samples\n",
      "\n",
      "01_19_23:31:08 --- 2.310106039047241 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:10 Training loss at epoch 0 step 9970: 2.852320909500122\n",
      "\n",
      " This round's valence_loss=0.9962902665138245, arousal_loss=0.8374288082122803, emotion_loss=0.95145183801651\n",
      "\n",
      "01_19_23:31:10 Seen so far: 319072 samples\n",
      "\n",
      "01_19_23:31:10 --- 1.942469596862793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:12 Training loss at epoch 0 step 9980: 3.1062639713287354\n",
      "\n",
      " This round's valence_loss=1.2359973192214966, arousal_loss=1.0902221202850342, emotion_loss=1.2572462558746338\n",
      "\n",
      "01_19_23:31:12 Seen so far: 319392 samples\n",
      "\n",
      "01_19_23:31:12 --- 2.0359947681427 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:14 Training loss at epoch 0 step 9990: 2.992748665809631\n",
      "\n",
      " This round's valence_loss=1.168032169342041, arousal_loss=1.1127471923828125, emotion_loss=1.1069366931915283\n",
      "\n",
      "01_19_23:31:14 Seen so far: 319712 samples\n",
      "\n",
      "01_19_23:31:14 --- 2.0299651622772217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:16 Training loss at epoch 0 step 10000: 3.094889187812805\n",
      "\n",
      " This round's valence_loss=1.1021268367767334, arousal_loss=0.9891846179962158, emotion_loss=1.1693384647369385\n",
      "\n",
      "01_19_23:31:16 Seen so far: 320032 samples\n",
      "\n",
      "01_19_23:31:16 --- 2.1025824546813965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:18 Training loss at epoch 0 step 10010: 3.134396862983704\n",
      "\n",
      " This round's valence_loss=1.81227445602417, arousal_loss=1.6626389026641846, emotion_loss=1.1529297828674316\n",
      "\n",
      "01_19_23:31:18 Seen so far: 320352 samples\n",
      "\n",
      "01_19_23:31:18 --- 2.0284571647644043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:20 Training loss at epoch 0 step 10020: 3.362566685676575\n",
      "\n",
      " This round's valence_loss=0.8513049483299255, arousal_loss=0.7560442090034485, emotion_loss=1.2463324069976807\n",
      "\n",
      "01_19_23:31:20 Seen so far: 320672 samples\n",
      "\n",
      "01_19_23:31:20 --- 1.9826889038085938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:22 Training loss at epoch 0 step 10030: 3.141847252845764\n",
      "\n",
      " This round's valence_loss=1.4522387981414795, arousal_loss=1.3324339389801025, emotion_loss=1.1715402603149414\n",
      "\n",
      "01_19_23:31:22 Seen so far: 320992 samples\n",
      "\n",
      "01_19_23:31:22 --- 2.2070536613464355 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:24 Training loss at epoch 0 step 10040: 2.984074330329895\n",
      "\n",
      " This round's valence_loss=0.7028322815895081, arousal_loss=0.6017333269119263, emotion_loss=0.9837363362312317\n",
      "\n",
      "01_19_23:31:24 Seen so far: 321312 samples\n",
      "\n",
      "01_19_23:31:24 --- 1.9288947582244873 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:26 Training loss at epoch 0 step 10050: 3.161353254318237\n",
      "\n",
      " This round's valence_loss=0.5309883952140808, arousal_loss=0.35159292817115784, emotion_loss=1.4641506671905518\n",
      "\n",
      "01_19_23:31:26 Seen so far: 321632 samples\n",
      "\n",
      "01_19_23:31:26 --- 1.922530174255371 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:28 Training loss at epoch 0 step 10060: 3.307915377616882\n",
      "\n",
      " This round's valence_loss=1.1310644149780273, arousal_loss=0.9681140184402466, emotion_loss=1.276367425918579\n",
      "\n",
      "01_19_23:31:28 Seen so far: 321952 samples\n",
      "\n",
      "01_19_23:31:28 --- 2.000772714614868 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:30 Training loss at epoch 0 step 10070: 3.1252448081970217\n",
      "\n",
      " This round's valence_loss=1.1048083305358887, arousal_loss=0.9593206644058228, emotion_loss=0.8932297229766846\n",
      "\n",
      "01_19_23:31:30 Seen so far: 322272 samples\n",
      "\n",
      "01_19_23:31:30 --- 2.0145390033721924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:32 Training loss at epoch 0 step 10080: 3.1485772371292113\n",
      "\n",
      " This round's valence_loss=1.3077163696289062, arousal_loss=1.1717767715454102, emotion_loss=0.652389645576477\n",
      "\n",
      "01_19_23:31:32 Seen so far: 322592 samples\n",
      "\n",
      "01_19_23:31:32 --- 2.096170663833618 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:34 Training loss at epoch 0 step 10090: 3.0504920721054076\n",
      "\n",
      " This round's valence_loss=1.3245267868041992, arousal_loss=1.082505226135254, emotion_loss=1.155585765838623\n",
      "\n",
      "01_19_23:31:34 Seen so far: 322912 samples\n",
      "\n",
      "01_19_23:31:34 --- 1.9575612545013428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:36 Training loss at epoch 0 step 10100: 3.010255289077759\n",
      "\n",
      " This round's valence_loss=1.0193378925323486, arousal_loss=0.8662371635437012, emotion_loss=1.0518994331359863\n",
      "\n",
      "01_19_23:31:36 Seen so far: 323232 samples\n",
      "\n",
      "01_19_23:31:36 --- 1.9927985668182373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:38 Training loss at epoch 0 step 10110: 2.8750785112380983\n",
      "\n",
      " This round's valence_loss=0.7242754697799683, arousal_loss=0.62655109167099, emotion_loss=1.037783145904541\n",
      "\n",
      "01_19_23:31:38 Seen so far: 323552 samples\n",
      "\n",
      "01_19_23:31:38 --- 2.2731399536132812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:40 Training loss at epoch 0 step 10120: 3.341925287246704\n",
      "\n",
      " This round's valence_loss=1.2017138004302979, arousal_loss=0.9196414947509766, emotion_loss=1.0164170265197754\n",
      "\n",
      "01_19_23:31:40 Seen so far: 323872 samples\n",
      "\n",
      "01_19_23:31:40 --- 2.1207807064056396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:42 Training loss at epoch 0 step 10130: 2.9374106168746947\n",
      "\n",
      " This round's valence_loss=0.9510650038719177, arousal_loss=0.8498643040657043, emotion_loss=0.9438358545303345\n",
      "\n",
      "01_19_23:31:42 Seen so far: 324192 samples\n",
      "\n",
      "01_19_23:31:42 --- 1.9838316440582275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:44 Training loss at epoch 0 step 10140: 3.1311893701553344\n",
      "\n",
      " This round's valence_loss=1.8193747997283936, arousal_loss=1.6600431203842163, emotion_loss=0.8411194682121277\n",
      "\n",
      "01_19_23:31:44 Seen so far: 324512 samples\n",
      "\n",
      "01_19_23:31:44 --- 2.1107804775238037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:46 Training loss at epoch 0 step 10150: 3.2411444425582885\n",
      "\n",
      " This round's valence_loss=1.0054569244384766, arousal_loss=0.8416244983673096, emotion_loss=1.0941598415374756\n",
      "\n",
      "01_19_23:31:46 Seen so far: 324832 samples\n",
      "\n",
      "01_19_23:31:46 --- 2.0908546447753906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:49 Training loss at epoch 0 step 10160: 2.978591871261597\n",
      "\n",
      " This round's valence_loss=0.9404898285865784, arousal_loss=0.8621621131896973, emotion_loss=1.4858061075210571\n",
      "\n",
      "01_19_23:31:49 Seen so far: 325152 samples\n",
      "\n",
      "01_19_23:31:49 --- 2.142336845397949 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:51 Training loss at epoch 0 step 10170: 3.2466991901397706\n",
      "\n",
      " This round's valence_loss=1.3265743255615234, arousal_loss=1.18610680103302, emotion_loss=0.8953306674957275\n",
      "\n",
      "01_19_23:31:51 Seen so far: 325472 samples\n",
      "\n",
      "01_19_23:31:51 --- 2.0057098865509033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:53 Training loss at epoch 0 step 10180: 2.878680610656738\n",
      "\n",
      " This round's valence_loss=1.0341085195541382, arousal_loss=0.9513170123100281, emotion_loss=1.41860032081604\n",
      "\n",
      "01_19_23:31:53 Seen so far: 325792 samples\n",
      "\n",
      "01_19_23:31:53 --- 2.063685894012451 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:55 Training loss at epoch 0 step 10190: 3.0768070220947266\n",
      "\n",
      " This round's valence_loss=1.0759856700897217, arousal_loss=0.9470003843307495, emotion_loss=1.1895298957824707\n",
      "\n",
      "01_19_23:31:55 Seen so far: 326112 samples\n",
      "\n",
      "01_19_23:31:55 --- 1.9086098670959473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:57 Training loss at epoch 0 step 10200: 3.3706033706665037\n",
      "\n",
      " This round's valence_loss=1.1470788717269897, arousal_loss=0.949947714805603, emotion_loss=1.116445779800415\n",
      "\n",
      "01_19_23:31:57 Seen so far: 326432 samples\n",
      "\n",
      "01_19_23:31:57 --- 2.064704418182373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:31:59 Training loss at epoch 0 step 10210: 3.3055814504623413\n",
      "\n",
      " This round's valence_loss=0.9608952403068542, arousal_loss=0.8705208897590637, emotion_loss=1.1976956129074097\n",
      "\n",
      "01_19_23:31:59 Seen so far: 326752 samples\n",
      "\n",
      "01_19_23:31:59 --- 2.3187084197998047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:01 Training loss at epoch 0 step 10220: 2.919931960105896\n",
      "\n",
      " This round's valence_loss=0.831669270992279, arousal_loss=0.6985244154930115, emotion_loss=1.0916526317596436\n",
      "\n",
      "01_19_23:32:01 Seen so far: 327072 samples\n",
      "\n",
      "01_19_23:32:01 --- 2.1155667304992676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:03 Training loss at epoch 0 step 10230: 2.9413447856903074\n",
      "\n",
      " This round's valence_loss=1.0005643367767334, arousal_loss=0.8573212623596191, emotion_loss=1.3178449869155884\n",
      "\n",
      "01_19_23:32:03 Seen so far: 327392 samples\n",
      "\n",
      "01_19_23:32:03 --- 1.797058343887329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:05 Training loss at epoch 0 step 10240: 3.3843966007232664\n",
      "\n",
      " This round's valence_loss=1.354248285293579, arousal_loss=1.1803405284881592, emotion_loss=0.8253690004348755\n",
      "\n",
      "01_19_23:32:05 Seen so far: 327712 samples\n",
      "\n",
      "01_19_23:32:05 --- 1.9076008796691895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:07 Training loss at epoch 0 step 10250: 2.92626953125\n",
      "\n",
      " This round's valence_loss=1.0862871408462524, arousal_loss=1.0014429092407227, emotion_loss=1.1273337602615356\n",
      "\n",
      "01_19_23:32:07 Seen so far: 328032 samples\n",
      "\n",
      "01_19_23:32:07 --- 2.051996946334839 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:09 Training loss at epoch 0 step 10260: 3.4767369985580445\n",
      "\n",
      " This round's valence_loss=1.1558207273483276, arousal_loss=1.0948288440704346, emotion_loss=0.8986594676971436\n",
      "\n",
      "01_19_23:32:09 Seen so far: 328352 samples\n",
      "\n",
      "01_19_23:32:09 --- 2.003342866897583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:11 Training loss at epoch 0 step 10270: 3.028617429733276\n",
      "\n",
      " This round's valence_loss=0.975037693977356, arousal_loss=0.6823442578315735, emotion_loss=0.758277952671051\n",
      "\n",
      "01_19_23:32:11 Seen so far: 328672 samples\n",
      "\n",
      "01_19_23:32:11 --- 1.827042818069458 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:13 Training loss at epoch 0 step 10280: 2.93495352268219\n",
      "\n",
      " This round's valence_loss=1.059561014175415, arousal_loss=0.9444364905357361, emotion_loss=1.0888324975967407\n",
      "\n",
      "01_19_23:32:13 Seen so far: 328992 samples\n",
      "\n",
      "01_19_23:32:13 --- 2.000234365463257 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:15 Training loss at epoch 0 step 10290: 2.9686012983322145\n",
      "\n",
      " This round's valence_loss=0.8418261408805847, arousal_loss=0.7243103384971619, emotion_loss=0.8627969622612\n",
      "\n",
      "01_19_23:32:15 Seen so far: 329312 samples\n",
      "\n",
      "01_19_23:32:15 --- 1.988673448562622 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:17 Training loss at epoch 0 step 10300: 3.0960161685943604\n",
      "\n",
      " This round's valence_loss=1.4504731893539429, arousal_loss=1.3504072427749634, emotion_loss=1.272986888885498\n",
      "\n",
      "01_19_23:32:17 Seen so far: 329632 samples\n",
      "\n",
      "01_19_23:32:17 --- 1.8978612422943115 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:18 Training loss at epoch 0 step 10310: 3.1826149463653564\n",
      "\n",
      " This round's valence_loss=1.100917935371399, arousal_loss=0.954092264175415, emotion_loss=1.2380948066711426\n",
      "\n",
      "01_19_23:32:18 Seen so far: 329952 samples\n",
      "\n",
      "01_19_23:32:18 --- 1.895784854888916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:20 Training loss at epoch 0 step 10320: 3.066367673873901\n",
      "\n",
      " This round's valence_loss=0.6716650128364563, arousal_loss=0.45838743448257446, emotion_loss=1.0053235292434692\n",
      "\n",
      "01_19_23:32:20 Seen so far: 330272 samples\n",
      "\n",
      "01_19_23:32:20 --- 1.9484708309173584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:22 Training loss at epoch 0 step 10330: 2.8911608457565308\n",
      "\n",
      " This round's valence_loss=0.8452886343002319, arousal_loss=0.7217998504638672, emotion_loss=0.9734556078910828\n",
      "\n",
      "01_19_23:32:22 Seen so far: 330592 samples\n",
      "\n",
      "01_19_23:32:22 --- 2.0752949714660645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:24 Training loss at epoch 0 step 10340: 3.102417540550232\n",
      "\n",
      " This round's valence_loss=1.100541114807129, arousal_loss=0.9216277003288269, emotion_loss=0.9439585208892822\n",
      "\n",
      "01_19_23:32:24 Seen so far: 330912 samples\n",
      "\n",
      "01_19_23:32:24 --- 1.88883638381958 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:26 Training loss at epoch 0 step 10350: 3.218319630622864\n",
      "\n",
      " This round's valence_loss=1.2990601062774658, arousal_loss=1.1830145120620728, emotion_loss=1.2642829418182373\n",
      "\n",
      "01_19_23:32:26 Seen so far: 331232 samples\n",
      "\n",
      "01_19_23:32:26 --- 2.0304789543151855 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:28 Training loss at epoch 0 step 10360: 2.9041274785995483\n",
      "\n",
      " This round's valence_loss=0.6658418774604797, arousal_loss=0.5225690007209778, emotion_loss=1.2150341272354126\n",
      "\n",
      "01_19_23:32:28 Seen so far: 331552 samples\n",
      "\n",
      "01_19_23:32:28 --- 1.80454421043396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:30 Training loss at epoch 0 step 10370: 2.3877556562423705\n",
      "\n",
      " This round's valence_loss=0.5196205377578735, arousal_loss=0.3720209002494812, emotion_loss=1.1678706407546997\n",
      "\n",
      "01_19_23:32:30 Seen so far: 331872 samples\n",
      "\n",
      "01_19_23:32:30 --- 2.0355303287506104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:32 Training loss at epoch 0 step 10380: 2.939115619659424\n",
      "\n",
      " This round's valence_loss=1.200695514678955, arousal_loss=1.0909539461135864, emotion_loss=0.6541033983230591\n",
      "\n",
      "01_19_23:32:32 Seen so far: 332192 samples\n",
      "\n",
      "01_19_23:32:32 --- 1.8460800647735596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:34 Training loss at epoch 0 step 10390: 3.06143000125885\n",
      "\n",
      " This round's valence_loss=1.0246824026107788, arousal_loss=0.8128030300140381, emotion_loss=1.287392497062683\n",
      "\n",
      "01_19_23:32:34 Seen so far: 332512 samples\n",
      "\n",
      "01_19_23:32:34 --- 2.1856701374053955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:36 Training loss at epoch 0 step 10400: 3.0088781118392944\n",
      "\n",
      " This round's valence_loss=1.6302342414855957, arousal_loss=1.5833196640014648, emotion_loss=1.1637024879455566\n",
      "\n",
      "01_19_23:32:36 Seen so far: 332832 samples\n",
      "\n",
      "01_19_23:32:36 --- 1.963271141052246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:38 Training loss at epoch 0 step 10410: 2.932128977775574\n",
      "\n",
      " This round's valence_loss=1.5401923656463623, arousal_loss=1.4159352779388428, emotion_loss=0.7464634776115417\n",
      "\n",
      "01_19_23:32:38 Seen so far: 333152 samples\n",
      "\n",
      "01_19_23:32:38 --- 1.8774957656860352 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:40 Training loss at epoch 0 step 10420: 3.131363368034363\n",
      "\n",
      " This round's valence_loss=0.8700724840164185, arousal_loss=0.7638983726501465, emotion_loss=1.2328191995620728\n",
      "\n",
      "01_19_23:32:40 Seen so far: 333472 samples\n",
      "\n",
      "01_19_23:32:40 --- 1.9141902923583984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:42 Training loss at epoch 0 step 10430: 3.2885103702545164\n",
      "\n",
      " This round's valence_loss=1.4241071939468384, arousal_loss=1.3467910289764404, emotion_loss=1.194869041442871\n",
      "\n",
      "01_19_23:32:42 Seen so far: 333792 samples\n",
      "\n",
      "01_19_23:32:42 --- 2.334883689880371 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:44 Training loss at epoch 0 step 10440: 3.210485029220581\n",
      "\n",
      " This round's valence_loss=1.677438735961914, arousal_loss=1.4686216115951538, emotion_loss=1.3023024797439575\n",
      "\n",
      "01_19_23:32:44 Seen so far: 334112 samples\n",
      "\n",
      "01_19_23:32:44 --- 1.915722370147705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:46 Training loss at epoch 0 step 10450: 3.226232409477234\n",
      "\n",
      " This round's valence_loss=0.9015821218490601, arousal_loss=0.7094106674194336, emotion_loss=1.070127010345459\n",
      "\n",
      "01_19_23:32:46 Seen so far: 334432 samples\n",
      "\n",
      "01_19_23:32:46 --- 1.9222924709320068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:48 Training loss at epoch 0 step 10460: 3.243261432647705\n",
      "\n",
      " This round's valence_loss=0.785236120223999, arousal_loss=0.5718117952346802, emotion_loss=0.9172122478485107\n",
      "\n",
      "01_19_23:32:48 Seen so far: 334752 samples\n",
      "\n",
      "01_19_23:32:48 --- 2.3080344200134277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:51 Training loss at epoch 0 step 10470: 3.0852965116500854\n",
      "\n",
      " This round's valence_loss=1.4492738246917725, arousal_loss=1.34187912940979, emotion_loss=1.1354520320892334\n",
      "\n",
      "01_19_23:32:51 Seen so far: 335072 samples\n",
      "\n",
      "01_19_23:32:51 --- 2.067992925643921 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:53 Training loss at epoch 0 step 10480: 3.2629220485687256\n",
      "\n",
      " This round's valence_loss=1.3611905574798584, arousal_loss=1.1857136487960815, emotion_loss=1.17787504196167\n",
      "\n",
      "01_19_23:32:53 Seen so far: 335392 samples\n",
      "\n",
      "01_19_23:32:53 --- 2.0137596130371094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:55 Training loss at epoch 0 step 10490: 3.1063286304473876\n",
      "\n",
      " This round's valence_loss=0.7046478986740112, arousal_loss=0.6005603075027466, emotion_loss=1.2392516136169434\n",
      "\n",
      "01_19_23:32:55 Seen so far: 335712 samples\n",
      "\n",
      "01_19_23:32:55 --- 2.1765925884246826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:57 Training loss at epoch 0 step 10500: 2.9041198015213014\n",
      "\n",
      " This round's valence_loss=0.7540479898452759, arousal_loss=0.6455159187316895, emotion_loss=1.5420058965682983\n",
      "\n",
      "01_19_23:32:57 Seen so far: 336032 samples\n",
      "\n",
      "01_19_23:32:57 --- 2.0283193588256836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:32:59 Training loss at epoch 0 step 10510: 3.5647183895111083\n",
      "\n",
      " This round's valence_loss=0.8173004388809204, arousal_loss=0.6822383403778076, emotion_loss=1.0107814073562622\n",
      "\n",
      "01_19_23:32:59 Seen so far: 336352 samples\n",
      "\n",
      "01_19_23:32:59 --- 2.0886635780334473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:01 Training loss at epoch 0 step 10520: 3.0009026288986207\n",
      "\n",
      " This round's valence_loss=1.2328917980194092, arousal_loss=1.0752100944519043, emotion_loss=1.150776743888855\n",
      "\n",
      "01_19_23:33:01 Seen so far: 336672 samples\n",
      "\n",
      "01_19_23:33:01 --- 1.9505491256713867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:03 Training loss at epoch 0 step 10530: 3.469176411628723\n",
      "\n",
      " This round's valence_loss=1.0760564804077148, arousal_loss=1.0082576274871826, emotion_loss=0.9786866903305054\n",
      "\n",
      "01_19_23:33:03 Seen so far: 336992 samples\n",
      "\n",
      "01_19_23:33:03 --- 2.1474907398223877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:05 Training loss at epoch 0 step 10540: 2.8761484026908875\n",
      "\n",
      " This round's valence_loss=1.114453673362732, arousal_loss=0.9518877267837524, emotion_loss=1.1206114292144775\n",
      "\n",
      "01_19_23:33:05 Seen so far: 337312 samples\n",
      "\n",
      "01_19_23:33:05 --- 1.8057887554168701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:07 Training loss at epoch 0 step 10550: 3.2443044662475584\n",
      "\n",
      " This round's valence_loss=0.8730381727218628, arousal_loss=0.7314074039459229, emotion_loss=0.7634438276290894\n",
      "\n",
      "01_19_23:33:07 Seen so far: 337632 samples\n",
      "\n",
      "01_19_23:33:07 --- 2.1260969638824463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:09 Training loss at epoch 0 step 10560: 3.572060465812683\n",
      "\n",
      " This round's valence_loss=0.9680235385894775, arousal_loss=0.8502612113952637, emotion_loss=1.3616633415222168\n",
      "\n",
      "01_19_23:33:09 Seen so far: 337952 samples\n",
      "\n",
      "01_19_23:33:09 --- 1.830444097518921 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:11 Training loss at epoch 0 step 10570: 3.0293216466903687\n",
      "\n",
      " This round's valence_loss=0.8504486083984375, arousal_loss=0.6232805252075195, emotion_loss=1.5093885660171509\n",
      "\n",
      "01_19_23:33:11 Seen so far: 338272 samples\n",
      "\n",
      "01_19_23:33:11 --- 1.9657771587371826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:13 Training loss at epoch 0 step 10580: 3.293367886543274\n",
      "\n",
      " This round's valence_loss=1.118591547012329, arousal_loss=0.9898873567581177, emotion_loss=0.7839653491973877\n",
      "\n",
      "01_19_23:33:13 Seen so far: 338592 samples\n",
      "\n",
      "01_19_23:33:13 --- 1.8815617561340332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:15 Training loss at epoch 0 step 10590: 3.049771022796631\n",
      "\n",
      " This round's valence_loss=1.464188575744629, arousal_loss=1.3691117763519287, emotion_loss=1.328790307044983\n",
      "\n",
      "01_19_23:33:15 Seen so far: 338912 samples\n",
      "\n",
      "01_19_23:33:15 --- 2.054114580154419 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:16 Training loss at epoch 0 step 10600: 2.8236148357391357\n",
      "\n",
      " This round's valence_loss=0.8589543700218201, arousal_loss=0.6807807683944702, emotion_loss=0.8478072881698608\n",
      "\n",
      "01_19_23:33:16 Seen so far: 339232 samples\n",
      "\n",
      "01_19_23:33:16 --- 1.7956583499908447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:18 Training loss at epoch 0 step 10610: 2.930343174934387\n",
      "\n",
      " This round's valence_loss=0.9945904016494751, arousal_loss=0.789069652557373, emotion_loss=1.0614523887634277\n",
      "\n",
      "01_19_23:33:18 Seen so far: 339552 samples\n",
      "\n",
      "01_19_23:33:18 --- 1.8706023693084717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:20 Training loss at epoch 0 step 10620: 2.964352583885193\n",
      "\n",
      " This round's valence_loss=0.9945093393325806, arousal_loss=0.8505730628967285, emotion_loss=0.5528764128684998\n",
      "\n",
      "01_19_23:33:20 Seen so far: 339872 samples\n",
      "\n",
      "01_19_23:33:20 --- 1.9719221591949463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:22 Training loss at epoch 0 step 10630: 3.2877353191375733\n",
      "\n",
      " This round's valence_loss=1.0015523433685303, arousal_loss=0.909268856048584, emotion_loss=1.3374807834625244\n",
      "\n",
      "01_19_23:33:22 Seen so far: 340192 samples\n",
      "\n",
      "01_19_23:33:22 --- 2.036900520324707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:24 Training loss at epoch 0 step 10640: 3.3161614656448366\n",
      "\n",
      " This round's valence_loss=1.7790229320526123, arousal_loss=1.674075961112976, emotion_loss=0.8767077326774597\n",
      "\n",
      "01_19_23:33:24 Seen so far: 340512 samples\n",
      "\n",
      "01_19_23:33:24 --- 2.209703207015991 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:26 Training loss at epoch 0 step 10650: 2.9990936279296876\n",
      "\n",
      " This round's valence_loss=0.8003629446029663, arousal_loss=0.7384198904037476, emotion_loss=0.969562292098999\n",
      "\n",
      "01_19_23:33:26 Seen so far: 340832 samples\n",
      "\n",
      "01_19_23:33:26 --- 1.828920602798462 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:29 Training loss at epoch 0 step 10660: 3.0396875858306887\n",
      "\n",
      " This round's valence_loss=0.5365562438964844, arousal_loss=0.36660411953926086, emotion_loss=1.0572257041931152\n",
      "\n",
      "01_19_23:33:29 Seen so far: 341152 samples\n",
      "\n",
      "01_19_23:33:29 --- 2.342525005340576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:30 Training loss at epoch 0 step 10670: 2.9468299627304075\n",
      "\n",
      " This round's valence_loss=1.2666211128234863, arousal_loss=1.104166030883789, emotion_loss=0.8962764739990234\n",
      "\n",
      "01_19_23:33:30 Seen so far: 341472 samples\n",
      "\n",
      "01_19_23:33:30 --- 1.821115255355835 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:32 Training loss at epoch 0 step 10680: 3.3891438961029055\n",
      "\n",
      " This round's valence_loss=0.8545656800270081, arousal_loss=0.624294638633728, emotion_loss=1.1027917861938477\n",
      "\n",
      "01_19_23:33:32 Seen so far: 341792 samples\n",
      "\n",
      "01_19_23:33:32 --- 1.9688806533813477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:35 Training loss at epoch 0 step 10690: 3.2322908878326415\n",
      "\n",
      " This round's valence_loss=0.9651832580566406, arousal_loss=0.7399336695671082, emotion_loss=0.760200023651123\n",
      "\n",
      "01_19_23:33:35 Seen so far: 342112 samples\n",
      "\n",
      "01_19_23:33:35 --- 2.072301149368286 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:36 Training loss at epoch 0 step 10700: 3.1603111743927004\n",
      "\n",
      " This round's valence_loss=1.0638426542282104, arousal_loss=0.9769510626792908, emotion_loss=1.1758500337600708\n",
      "\n",
      "01_19_23:33:36 Seen so far: 342432 samples\n",
      "\n",
      "01_19_23:33:36 --- 1.8872272968292236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:38 Training loss at epoch 0 step 10710: 3.181432819366455\n",
      "\n",
      " This round's valence_loss=0.8710613250732422, arousal_loss=0.6908957958221436, emotion_loss=0.9349792003631592\n",
      "\n",
      "01_19_23:33:38 Seen so far: 342752 samples\n",
      "\n",
      "01_19_23:33:38 --- 1.8382248878479004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:40 Training loss at epoch 0 step 10720: 2.954219365119934\n",
      "\n",
      " This round's valence_loss=1.0054473876953125, arousal_loss=0.7971845865249634, emotion_loss=1.0119658708572388\n",
      "\n",
      "01_19_23:33:40 Seen so far: 343072 samples\n",
      "\n",
      "01_19_23:33:40 --- 2.0231473445892334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:42 Training loss at epoch 0 step 10730: 3.0149274110794066\n",
      "\n",
      " This round's valence_loss=1.2454860210418701, arousal_loss=1.0670535564422607, emotion_loss=1.0604093074798584\n",
      "\n",
      "01_19_23:33:42 Seen so far: 343392 samples\n",
      "\n",
      "01_19_23:33:42 --- 2.029564619064331 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:44 Training loss at epoch 0 step 10740: 2.980855369567871\n",
      "\n",
      " This round's valence_loss=1.0649785995483398, arousal_loss=0.9794638752937317, emotion_loss=0.9348005652427673\n",
      "\n",
      "01_19_23:33:44 Seen so far: 343712 samples\n",
      "\n",
      "01_19_23:33:44 --- 1.724303960800171 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:46 Training loss at epoch 0 step 10750: 3.4285683631896973\n",
      "\n",
      " This round's valence_loss=1.0034420490264893, arousal_loss=0.8543604612350464, emotion_loss=0.9648407101631165\n",
      "\n",
      "01_19_23:33:46 Seen so far: 344032 samples\n",
      "\n",
      "01_19_23:33:46 --- 1.8608627319335938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:48 Training loss at epoch 0 step 10760: 3.15954794883728\n",
      "\n",
      " This round's valence_loss=0.996079683303833, arousal_loss=0.850029468536377, emotion_loss=1.1016287803649902\n",
      "\n",
      "01_19_23:33:48 Seen so far: 344352 samples\n",
      "\n",
      "01_19_23:33:48 --- 1.9360806941986084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:50 Training loss at epoch 0 step 10770: 3.2414330005645753\n",
      "\n",
      " This round's valence_loss=1.238053321838379, arousal_loss=1.0973459482192993, emotion_loss=0.9983698129653931\n",
      "\n",
      "01_19_23:33:50 Seen so far: 344672 samples\n",
      "\n",
      "01_19_23:33:50 --- 2.1882011890411377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:52 Training loss at epoch 0 step 10780: 2.937701678276062\n",
      "\n",
      " This round's valence_loss=0.7028177380561829, arousal_loss=0.5106626152992249, emotion_loss=0.7065447568893433\n",
      "\n",
      "01_19_23:33:52 Seen so far: 344992 samples\n",
      "\n",
      "01_19_23:33:52 --- 1.8975002765655518 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:54 Training loss at epoch 0 step 10790: 3.271130013465881\n",
      "\n",
      " This round's valence_loss=0.9320188164710999, arousal_loss=0.8565894961357117, emotion_loss=1.3813503980636597\n",
      "\n",
      "01_19_23:33:54 Seen so far: 345312 samples\n",
      "\n",
      "01_19_23:33:54 --- 2.0160820484161377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:56 Training loss at epoch 0 step 10800: 3.045960712432861\n",
      "\n",
      " This round's valence_loss=1.0036060810089111, arousal_loss=0.827608585357666, emotion_loss=0.8535662293434143\n",
      "\n",
      "01_19_23:33:56 Seen so far: 345632 samples\n",
      "\n",
      "01_19_23:33:56 --- 2.021235942840576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:33:58 Training loss at epoch 0 step 10810: 3.313590097427368\n",
      "\n",
      " This round's valence_loss=0.9451959729194641, arousal_loss=0.7975298762321472, emotion_loss=1.1722428798675537\n",
      "\n",
      "01_19_23:33:58 Seen so far: 345952 samples\n",
      "\n",
      "01_19_23:33:58 --- 1.9908037185668945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:00 Training loss at epoch 0 step 10820: 3.080487775802612\n",
      "\n",
      " This round's valence_loss=1.1437207460403442, arousal_loss=0.9259794354438782, emotion_loss=0.7598586678504944\n",
      "\n",
      "01_19_23:34:00 Seen so far: 346272 samples\n",
      "\n",
      "01_19_23:34:00 --- 1.9744670391082764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:02 Training loss at epoch 0 step 10830: 3.506533455848694\n",
      "\n",
      " This round's valence_loss=1.581301212310791, arousal_loss=1.4461795091629028, emotion_loss=1.2230045795440674\n",
      "\n",
      "01_19_23:34:02 Seen so far: 346592 samples\n",
      "\n",
      "01_19_23:34:02 --- 2.1239402294158936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:04 Training loss at epoch 0 step 10840: 3.314250636100769\n",
      "\n",
      " This round's valence_loss=1.492152452468872, arousal_loss=1.2928969860076904, emotion_loss=0.892153263092041\n",
      "\n",
      "01_19_23:34:04 Seen so far: 346912 samples\n",
      "\n",
      "01_19_23:34:04 --- 2.0113797187805176 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:06 Training loss at epoch 0 step 10850: 3.1957689046859743\n",
      "\n",
      " This round's valence_loss=1.0198380947113037, arousal_loss=0.7934285402297974, emotion_loss=0.6061871647834778\n",
      "\n",
      "01_19_23:34:06 Seen so far: 347232 samples\n",
      "\n",
      "01_19_23:34:06 --- 1.8543460369110107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:08 Training loss at epoch 0 step 10860: 2.8953922986984253\n",
      "\n",
      " This round's valence_loss=0.4815309941768646, arousal_loss=0.40069735050201416, emotion_loss=1.0962390899658203\n",
      "\n",
      "01_19_23:34:08 Seen so far: 347552 samples\n",
      "\n",
      "01_19_23:34:08 --- 2.297337532043457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:10 Training loss at epoch 0 step 10870: 2.914078879356384\n",
      "\n",
      " This round's valence_loss=0.8138003349304199, arousal_loss=0.6740022897720337, emotion_loss=0.9299012422561646\n",
      "\n",
      "01_19_23:34:10 Seen so far: 347872 samples\n",
      "\n",
      "01_19_23:34:10 --- 2.0500407218933105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:12 Training loss at epoch 0 step 10880: 2.9659894943237304\n",
      "\n",
      " This round's valence_loss=1.3270518779754639, arousal_loss=1.2550245523452759, emotion_loss=0.9924604892730713\n",
      "\n",
      "01_19_23:34:12 Seen so far: 348192 samples\n",
      "\n",
      "01_19_23:34:12 --- 1.7451627254486084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:14 Training loss at epoch 0 step 10890: 3.002892756462097\n",
      "\n",
      " This round's valence_loss=0.8655554056167603, arousal_loss=0.6830297112464905, emotion_loss=0.9997080564498901\n",
      "\n",
      "01_19_23:34:14 Seen so far: 348512 samples\n",
      "\n",
      "01_19_23:34:14 --- 1.8972761631011963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:16 Training loss at epoch 0 step 10900: 2.8558776021003722\n",
      "\n",
      " This round's valence_loss=0.5926175713539124, arousal_loss=0.37087780237197876, emotion_loss=0.8444728851318359\n",
      "\n",
      "01_19_23:34:16 Seen so far: 348832 samples\n",
      "\n",
      "01_19_23:34:16 --- 1.9601712226867676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:18 Training loss at epoch 0 step 10910: 3.154281032085419\n",
      "\n",
      " This round's valence_loss=1.2154946327209473, arousal_loss=1.080079436302185, emotion_loss=1.2297614812850952\n",
      "\n",
      "01_19_23:34:18 Seen so far: 349152 samples\n",
      "\n",
      "01_19_23:34:18 --- 2.114067316055298 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:20 Training loss at epoch 0 step 10920: 3.273046064376831\n",
      "\n",
      " This round's valence_loss=1.4279372692108154, arousal_loss=1.4035269021987915, emotion_loss=1.1164803504943848\n",
      "\n",
      "01_19_23:34:20 Seen so far: 349472 samples\n",
      "\n",
      "01_19_23:34:20 --- 1.8731763362884521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:22 Training loss at epoch 0 step 10930: 3.3646023273468018\n",
      "\n",
      " This round's valence_loss=1.054639458656311, arousal_loss=0.8275759816169739, emotion_loss=0.7271141409873962\n",
      "\n",
      "01_19_23:34:22 Seen so far: 349792 samples\n",
      "\n",
      "01_19_23:34:22 --- 2.0454108715057373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:24 Training loss at epoch 0 step 10940: 3.0425243616104125\n",
      "\n",
      " This round's valence_loss=0.6480280160903931, arousal_loss=0.5289522409439087, emotion_loss=1.3336796760559082\n",
      "\n",
      "01_19_23:34:24 Seen so far: 350112 samples\n",
      "\n",
      "01_19_23:34:24 --- 2.332036256790161 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:26 Training loss at epoch 0 step 10950: 2.880897545814514\n",
      "\n",
      " This round's valence_loss=1.2999603748321533, arousal_loss=1.2460830211639404, emotion_loss=1.2823610305786133\n",
      "\n",
      "01_19_23:34:26 Seen so far: 350432 samples\n",
      "\n",
      "01_19_23:34:26 --- 2.0401358604431152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:28 Training loss at epoch 0 step 10960: 3.167516493797302\n",
      "\n",
      " This round's valence_loss=0.6944187879562378, arousal_loss=0.6048378348350525, emotion_loss=1.1313036680221558\n",
      "\n",
      "01_19_23:34:28 Seen so far: 350752 samples\n",
      "\n",
      "01_19_23:34:28 --- 2.0318310260772705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:30 Training loss at epoch 0 step 10970: 2.8070782899856566\n",
      "\n",
      " This round's valence_loss=0.9563313126564026, arousal_loss=0.8003116846084595, emotion_loss=1.201219081878662\n",
      "\n",
      "01_19_23:34:30 Seen so far: 351072 samples\n",
      "\n",
      "01_19_23:34:30 --- 1.830354928970337 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:32 Training loss at epoch 0 step 10980: 3.2426915764808655\n",
      "\n",
      " This round's valence_loss=1.0693175792694092, arousal_loss=0.9755473136901855, emotion_loss=1.279305100440979\n",
      "\n",
      "01_19_23:34:32 Seen so far: 351392 samples\n",
      "\n",
      "01_19_23:34:32 --- 1.978945016860962 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:34 Training loss at epoch 0 step 10990: 3.0759629011154175\n",
      "\n",
      " This round's valence_loss=0.8093608021736145, arousal_loss=0.5553711652755737, emotion_loss=0.8628354072570801\n",
      "\n",
      "01_19_23:34:34 Seen so far: 351712 samples\n",
      "\n",
      "01_19_23:34:34 --- 1.8746750354766846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:36 Training loss at epoch 0 step 11000: 2.8179956793785097\n",
      "\n",
      " This round's valence_loss=0.9775689840316772, arousal_loss=0.9149266481399536, emotion_loss=0.9220789670944214\n",
      "\n",
      "01_19_23:34:36 Seen so far: 352032 samples\n",
      "\n",
      "01_19_23:34:36 --- 2.0183606147766113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:38 Training loss at epoch 0 step 11010: 2.98166880607605\n",
      "\n",
      " This round's valence_loss=1.057438850402832, arousal_loss=0.95108562707901, emotion_loss=0.9911307692527771\n",
      "\n",
      "01_19_23:34:38 Seen so far: 352352 samples\n",
      "\n",
      "01_19_23:34:38 --- 2.1657276153564453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:40 Training loss at epoch 0 step 11020: 2.7851197957992553\n",
      "\n",
      " This round's valence_loss=0.8675135374069214, arousal_loss=0.86137855052948, emotion_loss=1.2709412574768066\n",
      "\n",
      "01_19_23:34:40 Seen so far: 352672 samples\n",
      "\n",
      "01_19_23:34:40 --- 2.0306031703948975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:42 Training loss at epoch 0 step 11030: 2.966833734512329\n",
      "\n",
      " This round's valence_loss=1.2907425165176392, arousal_loss=1.2013825178146362, emotion_loss=0.9595096707344055\n",
      "\n",
      "01_19_23:34:42 Seen so far: 352992 samples\n",
      "\n",
      "01_19_23:34:42 --- 1.8462104797363281 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:44 Training loss at epoch 0 step 11040: 3.0750744104385377\n",
      "\n",
      " This round's valence_loss=1.4804623126983643, arousal_loss=1.3044323921203613, emotion_loss=1.325777292251587\n",
      "\n",
      "01_19_23:34:44 Seen so far: 353312 samples\n",
      "\n",
      "01_19_23:34:44 --- 1.922529697418213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:46 Training loss at epoch 0 step 11050: 3.1096329927444457\n",
      "\n",
      " This round's valence_loss=0.8303576707839966, arousal_loss=0.7894606590270996, emotion_loss=1.2592291831970215\n",
      "\n",
      "01_19_23:34:46 Seen so far: 353632 samples\n",
      "\n",
      "01_19_23:34:46 --- 1.8157942295074463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:48 Training loss at epoch 0 step 11060: 2.887767291069031\n",
      "\n",
      " This round's valence_loss=1.360490083694458, arousal_loss=1.2143495082855225, emotion_loss=0.9602270126342773\n",
      "\n",
      "01_19_23:34:48 Seen so far: 353952 samples\n",
      "\n",
      "01_19_23:34:48 --- 1.905470609664917 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:50 Training loss at epoch 0 step 11070: 2.936761426925659\n",
      "\n",
      " This round's valence_loss=1.2348527908325195, arousal_loss=1.1079694032669067, emotion_loss=1.102895736694336\n",
      "\n",
      "01_19_23:34:50 Seen so far: 354272 samples\n",
      "\n",
      "01_19_23:34:50 --- 1.929394245147705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:52 Training loss at epoch 0 step 11080: 3.091205334663391\n",
      "\n",
      " This round's valence_loss=1.1554641723632812, arousal_loss=1.1428242921829224, emotion_loss=1.2930541038513184\n",
      "\n",
      "01_19_23:34:52 Seen so far: 354592 samples\n",
      "\n",
      "01_19_23:34:52 --- 2.4145572185516357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:54 Training loss at epoch 0 step 11090: 2.933534097671509\n",
      "\n",
      " This round's valence_loss=0.5865979790687561, arousal_loss=0.45869937539100647, emotion_loss=1.2501187324523926\n",
      "\n",
      "01_19_23:34:54 Seen so far: 354912 samples\n",
      "\n",
      "01_19_23:34:54 --- 1.8774867057800293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:56 Training loss at epoch 0 step 11100: 2.8570489645004273\n",
      "\n",
      " This round's valence_loss=1.338832139968872, arousal_loss=1.1425336599349976, emotion_loss=0.812854528427124\n",
      "\n",
      "01_19_23:34:56 Seen so far: 355232 samples\n",
      "\n",
      "01_19_23:34:56 --- 2.2814109325408936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:34:58 Training loss at epoch 0 step 11110: 2.902567672729492\n",
      "\n",
      " This round's valence_loss=1.0361976623535156, arousal_loss=0.8489024043083191, emotion_loss=1.4144208431243896\n",
      "\n",
      "01_19_23:34:58 Seen so far: 355552 samples\n",
      "\n",
      "01_19_23:34:58 --- 1.9783716201782227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:00 Training loss at epoch 0 step 11120: 3.006150794029236\n",
      "\n",
      " This round's valence_loss=0.5585436820983887, arousal_loss=0.5053075551986694, emotion_loss=0.9636373519897461\n",
      "\n",
      "01_19_23:35:00 Seen so far: 355872 samples\n",
      "\n",
      "01_19_23:35:00 --- 2.0352673530578613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:02 Training loss at epoch 0 step 11130: 3.2452861785888674\n",
      "\n",
      " This round's valence_loss=0.9996408224105835, arousal_loss=0.8489269018173218, emotion_loss=1.3552725315093994\n",
      "\n",
      "01_19_23:35:02 Seen so far: 356192 samples\n",
      "\n",
      "01_19_23:35:02 --- 2.160364866256714 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:04 Training loss at epoch 0 step 11140: 3.230927324295044\n",
      "\n",
      " This round's valence_loss=0.7969387769699097, arousal_loss=0.6691591739654541, emotion_loss=0.7961028814315796\n",
      "\n",
      "01_19_23:35:04 Seen so far: 356512 samples\n",
      "\n",
      "01_19_23:35:04 --- 1.8950181007385254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:06 Training loss at epoch 0 step 11150: 2.738381195068359\n",
      "\n",
      " This round's valence_loss=0.9271759986877441, arousal_loss=0.6791284084320068, emotion_loss=0.8153395056724548\n",
      "\n",
      "01_19_23:35:06 Seen so far: 356832 samples\n",
      "\n",
      "01_19_23:35:06 --- 2.0382907390594482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:08 Training loss at epoch 0 step 11160: 3.1287734746932983\n",
      "\n",
      " This round's valence_loss=1.1154435873031616, arousal_loss=0.9401201009750366, emotion_loss=0.8187214136123657\n",
      "\n",
      "01_19_23:35:08 Seen so far: 357152 samples\n",
      "\n",
      "01_19_23:35:08 --- 2.0235660076141357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:10 Training loss at epoch 0 step 11170: 3.2997493386268615\n",
      "\n",
      " This round's valence_loss=1.012145757675171, arousal_loss=0.8558281660079956, emotion_loss=1.2946627140045166\n",
      "\n",
      "01_19_23:35:10 Seen so far: 357472 samples\n",
      "\n",
      "01_19_23:35:10 --- 2.158806324005127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:12 Training loss at epoch 0 step 11180: 3.1693789958953857\n",
      "\n",
      " This round's valence_loss=1.2460945844650269, arousal_loss=1.105088472366333, emotion_loss=1.2679579257965088\n",
      "\n",
      "01_19_23:35:12 Seen so far: 357792 samples\n",
      "\n",
      "01_19_23:35:12 --- 1.8533613681793213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:15 Training loss at epoch 0 step 11190: 3.143157458305359\n",
      "\n",
      " This round's valence_loss=1.1904525756835938, arousal_loss=0.953717827796936, emotion_loss=1.1922743320465088\n",
      "\n",
      "01_19_23:35:15 Seen so far: 358112 samples\n",
      "\n",
      "01_19_23:35:15 --- 2.240405797958374 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:17 Training loss at epoch 0 step 11200: 3.0557881116867067\n",
      "\n",
      " This round's valence_loss=1.1215201616287231, arousal_loss=0.9463792443275452, emotion_loss=1.064115285873413\n",
      "\n",
      "01_19_23:35:17 Seen so far: 358432 samples\n",
      "\n",
      "01_19_23:35:17 --- 1.9794433116912842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:19 Training loss at epoch 0 step 11210: 2.8675007462501525\n",
      "\n",
      " This round's valence_loss=1.332220435142517, arousal_loss=1.2174649238586426, emotion_loss=1.181947112083435\n",
      "\n",
      "01_19_23:35:19 Seen so far: 358752 samples\n",
      "\n",
      "01_19_23:35:19 --- 2.164893865585327 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:21 Training loss at epoch 0 step 11220: 3.344141459465027\n",
      "\n",
      " This round's valence_loss=0.9556730389595032, arousal_loss=0.7043362855911255, emotion_loss=1.0369431972503662\n",
      "\n",
      "01_19_23:35:21 Seen so far: 359072 samples\n",
      "\n",
      "01_19_23:35:21 --- 1.9089992046356201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:23 Training loss at epoch 0 step 11230: 3.2959521532058718\n",
      "\n",
      " This round's valence_loss=1.365910530090332, arousal_loss=1.267336130142212, emotion_loss=1.109559178352356\n",
      "\n",
      "01_19_23:35:23 Seen so far: 359392 samples\n",
      "\n",
      "01_19_23:35:23 --- 1.9083271026611328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:25 Training loss at epoch 0 step 11240: 3.294916772842407\n",
      "\n",
      " This round's valence_loss=0.94419264793396, arousal_loss=0.9236767292022705, emotion_loss=0.9621877670288086\n",
      "\n",
      "01_19_23:35:25 Seen so far: 359712 samples\n",
      "\n",
      "01_19_23:35:25 --- 1.986863136291504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:26 Training loss at epoch 0 step 11250: 2.9980480432510377\n",
      "\n",
      " This round's valence_loss=0.8045400977134705, arousal_loss=0.7564317584037781, emotion_loss=1.0890402793884277\n",
      "\n",
      "01_19_23:35:26 Seen so far: 360032 samples\n",
      "\n",
      "01_19_23:35:26 --- 1.8439733982086182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:28 Training loss at epoch 0 step 11260: 3.4327630281448362\n",
      "\n",
      " This round's valence_loss=1.4555561542510986, arousal_loss=1.3282151222229004, emotion_loss=1.1882877349853516\n",
      "\n",
      "01_19_23:35:28 Seen so far: 360352 samples\n",
      "\n",
      "01_19_23:35:28 --- 1.9377923011779785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:30 Training loss at epoch 0 step 11270: 2.979142093658447\n",
      "\n",
      " This round's valence_loss=0.6835494041442871, arousal_loss=0.6883816123008728, emotion_loss=1.2398474216461182\n",
      "\n",
      "01_19_23:35:30 Seen so far: 360672 samples\n",
      "\n",
      "01_19_23:35:30 --- 1.9294133186340332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:32 Training loss at epoch 0 step 11280: 2.8335460901260374\n",
      "\n",
      " This round's valence_loss=1.5464608669281006, arousal_loss=1.442591905593872, emotion_loss=1.1333374977111816\n",
      "\n",
      "01_19_23:35:32 Seen so far: 360992 samples\n",
      "\n",
      "01_19_23:35:32 --- 1.8876595497131348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:34 Training loss at epoch 0 step 11290: 3.025808024406433\n",
      "\n",
      " This round's valence_loss=0.8274354934692383, arousal_loss=0.7049558162689209, emotion_loss=1.3352715969085693\n",
      "\n",
      "01_19_23:35:34 Seen so far: 361312 samples\n",
      "\n",
      "01_19_23:35:34 --- 1.9491519927978516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:36 Training loss at epoch 0 step 11300: 2.9284043312072754\n",
      "\n",
      " This round's valence_loss=0.6136661767959595, arousal_loss=0.5048409700393677, emotion_loss=1.3377022743225098\n",
      "\n",
      "01_19_23:35:36 Seen so far: 361632 samples\n",
      "\n",
      "01_19_23:35:36 --- 2.128368854522705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:38 Training loss at epoch 0 step 11310: 3.0676111459732054\n",
      "\n",
      " This round's valence_loss=0.8130170106887817, arousal_loss=0.7597478628158569, emotion_loss=0.9630486369132996\n",
      "\n",
      "01_19_23:35:38 Seen so far: 361952 samples\n",
      "\n",
      "01_19_23:35:38 --- 2.2700860500335693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:40 Training loss at epoch 0 step 11320: 3.383734846115112\n",
      "\n",
      " This round's valence_loss=1.2301414012908936, arousal_loss=1.0398547649383545, emotion_loss=0.6748064756393433\n",
      "\n",
      "01_19_23:35:40 Seen so far: 362272 samples\n",
      "\n",
      "01_19_23:35:40 --- 1.8609857559204102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:42 Training loss at epoch 0 step 11330: 3.125963735580444\n",
      "\n",
      " This round's valence_loss=0.9265050292015076, arousal_loss=0.7381296157836914, emotion_loss=0.9299712777137756\n",
      "\n",
      "01_19_23:35:42 Seen so far: 362592 samples\n",
      "\n",
      "01_19_23:35:42 --- 1.9623236656188965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:44 Training loss at epoch 0 step 11340: 2.672952616214752\n",
      "\n",
      " This round's valence_loss=0.7011034488677979, arousal_loss=0.5582911968231201, emotion_loss=1.1638389825820923\n",
      "\n",
      "01_19_23:35:44 Seen so far: 362912 samples\n",
      "\n",
      "01_19_23:35:44 --- 1.9884312152862549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:46 Training loss at epoch 0 step 11350: 3.0176583766937255\n",
      "\n",
      " This round's valence_loss=1.3551794290542603, arousal_loss=1.0485596656799316, emotion_loss=0.9430075883865356\n",
      "\n",
      "01_19_23:35:46 Seen so far: 363232 samples\n",
      "\n",
      "01_19_23:35:46 --- 2.0831923484802246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:48 Training loss at epoch 0 step 11360: 2.563809895515442\n",
      "\n",
      " This round's valence_loss=0.8345999717712402, arousal_loss=0.5349564552307129, emotion_loss=0.7965283989906311\n",
      "\n",
      "01_19_23:35:48 Seen so far: 363552 samples\n",
      "\n",
      "01_19_23:35:48 --- 1.8815929889678955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:50 Training loss at epoch 0 step 11370: 3.3875176668167115\n",
      "\n",
      " This round's valence_loss=1.6934077739715576, arousal_loss=1.6063830852508545, emotion_loss=1.3401626348495483\n",
      "\n",
      "01_19_23:35:50 Seen so far: 363872 samples\n",
      "\n",
      "01_19_23:35:50 --- 1.820991039276123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:52 Training loss at epoch 0 step 11380: 3.1838468313217163\n",
      "\n",
      " This round's valence_loss=1.1424777507781982, arousal_loss=0.9566490054130554, emotion_loss=0.9059520959854126\n",
      "\n",
      "01_19_23:35:52 Seen so far: 364192 samples\n",
      "\n",
      "01_19_23:35:52 --- 2.0779194831848145 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:54 Training loss at epoch 0 step 11390: 3.0233168601989746\n",
      "\n",
      " This round's valence_loss=1.1126848459243774, arousal_loss=0.9855660796165466, emotion_loss=1.0380173921585083\n",
      "\n",
      "01_19_23:35:54 Seen so far: 364512 samples\n",
      "\n",
      "01_19_23:35:54 --- 1.8297984600067139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:56 Training loss at epoch 0 step 11400: 2.9983198642730713\n",
      "\n",
      " This round's valence_loss=1.121496319770813, arousal_loss=0.9422389268875122, emotion_loss=1.0381860733032227\n",
      "\n",
      "01_19_23:35:56 Seen so far: 364832 samples\n",
      "\n",
      "01_19_23:35:56 --- 2.3620409965515137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:35:59 Training loss at epoch 0 step 11410: 3.1588603973388674\n",
      "\n",
      " This round's valence_loss=0.3388741910457611, arousal_loss=0.1586301475763321, emotion_loss=1.3195937871932983\n",
      "\n",
      "01_19_23:35:59 Seen so far: 365152 samples\n",
      "\n",
      "01_19_23:35:59 --- 2.1584627628326416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:00 Training loss at epoch 0 step 11420: 3.3857894420623778\n",
      "\n",
      " This round's valence_loss=1.343719720840454, arousal_loss=1.1799073219299316, emotion_loss=1.1731972694396973\n",
      "\n",
      "01_19_23:36:00 Seen so far: 365472 samples\n",
      "\n",
      "01_19_23:36:00 --- 1.835252285003662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:02 Training loss at epoch 0 step 11430: 3.1472215175628664\n",
      "\n",
      " This round's valence_loss=1.143181324005127, arousal_loss=0.9256842732429504, emotion_loss=1.1863822937011719\n",
      "\n",
      "01_19_23:36:02 Seen so far: 365792 samples\n",
      "\n",
      "01_19_23:36:02 --- 2.1027355194091797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:04 Training loss at epoch 0 step 11440: 2.9400459051132204\n",
      "\n",
      " This round's valence_loss=1.0826032161712646, arousal_loss=0.9307522177696228, emotion_loss=1.1829133033752441\n",
      "\n",
      "01_19_23:36:04 Seen so far: 366112 samples\n",
      "\n",
      "01_19_23:36:04 --- 2.0042293071746826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:06 Training loss at epoch 0 step 11450: 2.9443389415740966\n",
      "\n",
      " This round's valence_loss=1.2906625270843506, arousal_loss=1.180379867553711, emotion_loss=0.9394630789756775\n",
      "\n",
      "01_19_23:36:06 Seen so far: 366432 samples\n",
      "\n",
      "01_19_23:36:06 --- 1.9914278984069824 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:08 Training loss at epoch 0 step 11460: 3.229828381538391\n",
      "\n",
      " This round's valence_loss=1.267126202583313, arousal_loss=1.2011467218399048, emotion_loss=0.6270907521247864\n",
      "\n",
      "01_19_23:36:08 Seen so far: 366752 samples\n",
      "\n",
      "01_19_23:36:08 --- 1.967325210571289 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:10 Training loss at epoch 0 step 11470: 3.0449432134628296\n",
      "\n",
      " This round's valence_loss=1.1724456548690796, arousal_loss=1.1172444820404053, emotion_loss=0.9610923528671265\n",
      "\n",
      "01_19_23:36:10 Seen so far: 367072 samples\n",
      "\n",
      "01_19_23:36:10 --- 1.966651439666748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:13 Training loss at epoch 0 step 11480: 3.114252805709839\n",
      "\n",
      " This round's valence_loss=1.2026522159576416, arousal_loss=1.105882167816162, emotion_loss=1.036323070526123\n",
      "\n",
      "01_19_23:36:13 Seen so far: 367392 samples\n",
      "\n",
      "01_19_23:36:13 --- 2.168154239654541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:15 Training loss at epoch 0 step 11490: 3.6924304723739625\n",
      "\n",
      " This round's valence_loss=1.1883275508880615, arousal_loss=1.1115694046020508, emotion_loss=1.281301736831665\n",
      "\n",
      "01_19_23:36:15 Seen so far: 367712 samples\n",
      "\n",
      "01_19_23:36:15 --- 2.040731906890869 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:17 Training loss at epoch 0 step 11500: 2.9537441730499268\n",
      "\n",
      " This round's valence_loss=0.8581177592277527, arousal_loss=0.7257940769195557, emotion_loss=0.9757216572761536\n",
      "\n",
      "01_19_23:36:17 Seen so far: 368032 samples\n",
      "\n",
      "01_19_23:36:17 --- 2.1410791873931885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:19 Training loss at epoch 0 step 11510: 3.3495104789733885\n",
      "\n",
      " This round's valence_loss=1.6078095436096191, arousal_loss=1.4395904541015625, emotion_loss=1.2901830673217773\n",
      "\n",
      "01_19_23:36:19 Seen so far: 368352 samples\n",
      "\n",
      "01_19_23:36:19 --- 1.9598259925842285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:21 Training loss at epoch 0 step 11520: 3.3356541872024534\n",
      "\n",
      " This round's valence_loss=1.1388823986053467, arousal_loss=0.9313491582870483, emotion_loss=0.9252147078514099\n",
      "\n",
      "01_19_23:36:21 Seen so far: 368672 samples\n",
      "\n",
      "01_19_23:36:21 --- 2.119852304458618 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:23 Training loss at epoch 0 step 11530: 2.9294684171676635\n",
      "\n",
      " This round's valence_loss=1.3017613887786865, arousal_loss=1.202144742012024, emotion_loss=1.007710337638855\n",
      "\n",
      "01_19_23:36:23 Seen so far: 368992 samples\n",
      "\n",
      "01_19_23:36:23 --- 2.3649837970733643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:25 Training loss at epoch 0 step 11540: 2.917331886291504\n",
      "\n",
      " This round's valence_loss=1.2722585201263428, arousal_loss=1.1081504821777344, emotion_loss=1.1097643375396729\n",
      "\n",
      "01_19_23:36:25 Seen so far: 369312 samples\n",
      "\n",
      "01_19_23:36:25 --- 2.1805872917175293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:27 Training loss at epoch 0 step 11550: 2.9589683055877685\n",
      "\n",
      " This round's valence_loss=0.7322028875350952, arousal_loss=0.6714529991149902, emotion_loss=1.0566680431365967\n",
      "\n",
      "01_19_23:36:27 Seen so far: 369632 samples\n",
      "\n",
      "01_19_23:36:27 --- 1.9866969585418701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:29 Training loss at epoch 0 step 11560: 3.22114474773407\n",
      "\n",
      " This round's valence_loss=0.9781774878501892, arousal_loss=0.8340148329734802, emotion_loss=0.9191650152206421\n",
      "\n",
      "01_19_23:36:29 Seen so far: 369952 samples\n",
      "\n",
      "01_19_23:36:29 --- 1.9253051280975342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:31 Training loss at epoch 0 step 11570: 3.210514855384827\n",
      "\n",
      " This round's valence_loss=1.0058740377426147, arousal_loss=0.8753456473350525, emotion_loss=1.2775614261627197\n",
      "\n",
      "01_19_23:36:31 Seen so far: 370272 samples\n",
      "\n",
      "01_19_23:36:31 --- 2.1446051597595215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:33 Training loss at epoch 0 step 11580: 3.0301223754882813\n",
      "\n",
      " This round's valence_loss=1.4991919994354248, arousal_loss=1.324463129043579, emotion_loss=1.1240779161453247\n",
      "\n",
      "01_19_23:36:33 Seen so far: 370592 samples\n",
      "\n",
      "01_19_23:36:33 --- 1.9638383388519287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:35 Training loss at epoch 0 step 11590: 3.1210121154785155\n",
      "\n",
      " This round's valence_loss=0.7468310594558716, arousal_loss=0.625048041343689, emotion_loss=1.0106275081634521\n",
      "\n",
      "01_19_23:36:35 Seen so far: 370912 samples\n",
      "\n",
      "01_19_23:36:35 --- 1.9419581890106201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:38 Training loss at epoch 0 step 11600: 3.0433297634124754\n",
      "\n",
      " This round's valence_loss=1.2006070613861084, arousal_loss=1.1013859510421753, emotion_loss=1.3116437196731567\n",
      "\n",
      "01_19_23:36:38 Seen so far: 371232 samples\n",
      "\n",
      "01_19_23:36:38 --- 2.3498120307922363 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:40 Training loss at epoch 0 step 11610: 2.8679510235786436\n",
      "\n",
      " This round's valence_loss=0.9449164271354675, arousal_loss=0.8005136251449585, emotion_loss=0.7422868609428406\n",
      "\n",
      "01_19_23:36:40 Seen so far: 371552 samples\n",
      "\n",
      "01_19_23:36:40 --- 1.9240260124206543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:42 Training loss at epoch 0 step 11620: 3.149352216720581\n",
      "\n",
      " This round's valence_loss=1.27467679977417, arousal_loss=1.2051283121109009, emotion_loss=0.9234699010848999\n",
      "\n",
      "01_19_23:36:42 Seen so far: 371872 samples\n",
      "\n",
      "01_19_23:36:42 --- 2.2825286388397217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:44 Training loss at epoch 0 step 11630: 3.346531844139099\n",
      "\n",
      " This round's valence_loss=1.4266856908798218, arousal_loss=1.3301048278808594, emotion_loss=1.018027901649475\n",
      "\n",
      "01_19_23:36:44 Seen so far: 372192 samples\n",
      "\n",
      "01_19_23:36:44 --- 1.8705289363861084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:46 Training loss at epoch 0 step 11640: 2.958435297012329\n",
      "\n",
      " This round's valence_loss=1.0892542600631714, arousal_loss=0.9772028923034668, emotion_loss=0.886772871017456\n",
      "\n",
      "01_19_23:36:46 Seen so far: 372512 samples\n",
      "\n",
      "01_19_23:36:46 --- 2.048867702484131 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:48 Training loss at epoch 0 step 11650: 3.19318482875824\n",
      "\n",
      " This round's valence_loss=0.912868082523346, arousal_loss=0.8981672525405884, emotion_loss=1.295231819152832\n",
      "\n",
      "01_19_23:36:48 Seen so far: 372832 samples\n",
      "\n",
      "01_19_23:36:48 --- 1.9805333614349365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:50 Training loss at epoch 0 step 11660: 3.3749725103378294\n",
      "\n",
      " This round's valence_loss=1.8188998699188232, arousal_loss=1.6540594100952148, emotion_loss=0.793837308883667\n",
      "\n",
      "01_19_23:36:50 Seen so far: 373152 samples\n",
      "\n",
      "01_19_23:36:50 --- 1.9858946800231934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:52 Training loss at epoch 0 step 11670: 3.26117844581604\n",
      "\n",
      " This round's valence_loss=1.0352373123168945, arousal_loss=0.8657463788986206, emotion_loss=0.713187575340271\n",
      "\n",
      "01_19_23:36:52 Seen so far: 373472 samples\n",
      "\n",
      "01_19_23:36:52 --- 1.8985133171081543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:54 Training loss at epoch 0 step 11680: 3.0743981122970583\n",
      "\n",
      " This round's valence_loss=1.365211844444275, arousal_loss=1.2036027908325195, emotion_loss=1.0799379348754883\n",
      "\n",
      "01_19_23:36:54 Seen so far: 373792 samples\n",
      "\n",
      "01_19_23:36:54 --- 2.06295108795166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:56 Training loss at epoch 0 step 11690: 3.3714656829833984\n",
      "\n",
      " This round's valence_loss=1.0151300430297852, arousal_loss=0.830600380897522, emotion_loss=0.8754799365997314\n",
      "\n",
      "01_19_23:36:56 Seen so far: 374112 samples\n",
      "\n",
      "01_19_23:36:56 --- 2.024540424346924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:36:58 Training loss at epoch 0 step 11700: 2.9696001768112184\n",
      "\n",
      " This round's valence_loss=0.8000309467315674, arousal_loss=0.6998139023780823, emotion_loss=1.438831090927124\n",
      "\n",
      "01_19_23:36:58 Seen so far: 374432 samples\n",
      "\n",
      "01_19_23:36:58 --- 1.8381705284118652 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:00 Training loss at epoch 0 step 11710: 3.3575963735580445\n",
      "\n",
      " This round's valence_loss=1.2106761932373047, arousal_loss=1.1246249675750732, emotion_loss=1.3641822338104248\n",
      "\n",
      "01_19_23:37:00 Seen so far: 374752 samples\n",
      "\n",
      "01_19_23:37:00 --- 1.961827039718628 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:02 Training loss at epoch 0 step 11720: 3.1843571186065676\n",
      "\n",
      " This round's valence_loss=0.7970575094223022, arousal_loss=0.8041465282440186, emotion_loss=1.5368106365203857\n",
      "\n",
      "01_19_23:37:02 Seen so far: 375072 samples\n",
      "\n",
      "01_19_23:37:02 --- 2.125361919403076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:04 Training loss at epoch 0 step 11730: 2.5921895503997803\n",
      "\n",
      " This round's valence_loss=0.6255711317062378, arousal_loss=0.4565383195877075, emotion_loss=1.143017292022705\n",
      "\n",
      "01_19_23:37:04 Seen so far: 375392 samples\n",
      "\n",
      "01_19_23:37:04 --- 2.246466875076294 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:06 Training loss at epoch 0 step 11740: 3.07839412689209\n",
      "\n",
      " This round's valence_loss=1.2310664653778076, arousal_loss=1.09597909450531, emotion_loss=1.31905996799469\n",
      "\n",
      "01_19_23:37:06 Seen so far: 375712 samples\n",
      "\n",
      "01_19_23:37:06 --- 2.080540657043457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:08 Training loss at epoch 0 step 11750: 3.0943321228027343\n",
      "\n",
      " This round's valence_loss=1.0381028652191162, arousal_loss=0.8365864753723145, emotion_loss=0.6991780400276184\n",
      "\n",
      "01_19_23:37:08 Seen so far: 376032 samples\n",
      "\n",
      "01_19_23:37:08 --- 2.1950254440307617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:10 Training loss at epoch 0 step 11760: 2.787398660182953\n",
      "\n",
      " This round's valence_loss=1.1473510265350342, arousal_loss=0.9465129375457764, emotion_loss=0.4491836428642273\n",
      "\n",
      "01_19_23:37:10 Seen so far: 376352 samples\n",
      "\n",
      "01_19_23:37:10 --- 2.134533405303955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:12 Training loss at epoch 0 step 11770: 3.145512914657593\n",
      "\n",
      " This round's valence_loss=1.0225028991699219, arousal_loss=0.7768783569335938, emotion_loss=0.9625021815299988\n",
      "\n",
      "01_19_23:37:12 Seen so far: 376672 samples\n",
      "\n",
      "01_19_23:37:12 --- 2.048332452774048 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:15 Training loss at epoch 0 step 11780: 2.6720463037490845\n",
      "\n",
      " This round's valence_loss=1.1122968196868896, arousal_loss=0.9512434005737305, emotion_loss=0.9655734896659851\n",
      "\n",
      "01_19_23:37:15 Seen so far: 376992 samples\n",
      "\n",
      "01_19_23:37:15 --- 2.192594528198242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:17 Training loss at epoch 0 step 11790: 3.1735911130905152\n",
      "\n",
      " This round's valence_loss=1.444291353225708, arousal_loss=1.3096258640289307, emotion_loss=1.2680447101593018\n",
      "\n",
      "01_19_23:37:17 Seen so far: 377312 samples\n",
      "\n",
      "01_19_23:37:17 --- 2.103273630142212 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:19 Training loss at epoch 0 step 11800: 2.9487497091293333\n",
      "\n",
      " This round's valence_loss=0.9512039422988892, arousal_loss=0.828544557094574, emotion_loss=1.0356080532073975\n",
      "\n",
      "01_19_23:37:19 Seen so far: 377632 samples\n",
      "\n",
      "01_19_23:37:19 --- 2.035770893096924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:21 Training loss at epoch 0 step 11810: 2.8912401676177977\n",
      "\n",
      " This round's valence_loss=0.7551736831665039, arousal_loss=0.5491584539413452, emotion_loss=0.6250070333480835\n",
      "\n",
      "01_19_23:37:21 Seen so far: 377952 samples\n",
      "\n",
      "01_19_23:37:21 --- 2.1208395957946777 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:23 Training loss at epoch 0 step 11820: 3.1972925424575807\n",
      "\n",
      " This round's valence_loss=1.4521384239196777, arousal_loss=1.3292222023010254, emotion_loss=1.1012555360794067\n",
      "\n",
      "01_19_23:37:23 Seen so far: 378272 samples\n",
      "\n",
      "01_19_23:37:23 --- 1.8600032329559326 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:25 Training loss at epoch 0 step 11830: 2.962329387664795\n",
      "\n",
      " This round's valence_loss=1.424576759338379, arousal_loss=1.3039814233779907, emotion_loss=1.3028230667114258\n",
      "\n",
      "01_19_23:37:25 Seen so far: 378592 samples\n",
      "\n",
      "01_19_23:37:25 --- 2.0430805683135986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:27 Training loss at epoch 0 step 11840: 3.41657817363739\n",
      "\n",
      " This round's valence_loss=0.7990840673446655, arousal_loss=0.7047598361968994, emotion_loss=0.9309878349304199\n",
      "\n",
      "01_19_23:37:27 Seen so far: 378912 samples\n",
      "\n",
      "01_19_23:37:27 --- 2.0398874282836914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:29 Training loss at epoch 0 step 11850: 3.4745214939117433\n",
      "\n",
      " This round's valence_loss=1.2046270370483398, arousal_loss=0.9567395448684692, emotion_loss=1.0862680673599243\n",
      "\n",
      "01_19_23:37:29 Seen so far: 379232 samples\n",
      "\n",
      "01_19_23:37:29 --- 1.872152328491211 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:31 Training loss at epoch 0 step 11860: 3.2144476890563967\n",
      "\n",
      " This round's valence_loss=1.4243297576904297, arousal_loss=1.3091533184051514, emotion_loss=1.1345711946487427\n",
      "\n",
      "01_19_23:37:31 Seen so far: 379552 samples\n",
      "\n",
      "01_19_23:37:31 --- 2.16426944732666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:33 Training loss at epoch 0 step 11870: 2.9144917726516724\n",
      "\n",
      " This round's valence_loss=0.6511812210083008, arousal_loss=0.6241161823272705, emotion_loss=1.0556904077529907\n",
      "\n",
      "01_19_23:37:33 Seen so far: 379872 samples\n",
      "\n",
      "01_19_23:37:33 --- 2.0069172382354736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:35 Training loss at epoch 0 step 11880: 3.0486279726028442\n",
      "\n",
      " This round's valence_loss=1.06480872631073, arousal_loss=0.9958248138427734, emotion_loss=1.359370470046997\n",
      "\n",
      "01_19_23:37:35 Seen so far: 380192 samples\n",
      "\n",
      "01_19_23:37:35 --- 1.9657695293426514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:37 Training loss at epoch 0 step 11890: 3.1847543478012086\n",
      "\n",
      " This round's valence_loss=1.1057860851287842, arousal_loss=1.0215108394622803, emotion_loss=1.0029628276824951\n",
      "\n",
      "01_19_23:37:37 Seen so far: 380512 samples\n",
      "\n",
      "01_19_23:37:37 --- 1.9438273906707764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:39 Training loss at epoch 0 step 11900: 2.919466733932495\n",
      "\n",
      " This round's valence_loss=0.7435808181762695, arousal_loss=0.563724160194397, emotion_loss=0.7369326949119568\n",
      "\n",
      "01_19_23:37:39 Seen so far: 380832 samples\n",
      "\n",
      "01_19_23:37:39 --- 1.8785746097564697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:41 Training loss at epoch 0 step 11910: 3.132890796661377\n",
      "\n",
      " This round's valence_loss=1.5059561729431152, arousal_loss=1.2842167615890503, emotion_loss=0.725517988204956\n",
      "\n",
      "01_19_23:37:41 Seen so far: 381152 samples\n",
      "\n",
      "01_19_23:37:41 --- 2.2166748046875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:43 Training loss at epoch 0 step 11920: 2.955981659889221\n",
      "\n",
      " This round's valence_loss=1.0625040531158447, arousal_loss=0.9860832691192627, emotion_loss=0.7298439741134644\n",
      "\n",
      "01_19_23:37:43 Seen so far: 381472 samples\n",
      "\n",
      "01_19_23:37:43 --- 2.2075765132904053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:45 Training loss at epoch 0 step 11930: 3.16267409324646\n",
      "\n",
      " This round's valence_loss=0.9555848836898804, arousal_loss=0.8574469089508057, emotion_loss=0.916791558265686\n",
      "\n",
      "01_19_23:37:45 Seen so far: 381792 samples\n",
      "\n",
      "01_19_23:37:45 --- 1.8833706378936768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:47 Training loss at epoch 0 step 11940: 3.012276518344879\n",
      "\n",
      " This round's valence_loss=1.5933985710144043, arousal_loss=1.4628374576568604, emotion_loss=1.1305053234100342\n",
      "\n",
      "01_19_23:37:47 Seen so far: 382112 samples\n",
      "\n",
      "01_19_23:37:47 --- 2.0768654346466064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:49 Training loss at epoch 0 step 11950: 3.3846951723098755\n",
      "\n",
      " This round's valence_loss=1.2632522583007812, arousal_loss=1.1689894199371338, emotion_loss=1.2592389583587646\n",
      "\n",
      "01_19_23:37:49 Seen so far: 382432 samples\n",
      "\n",
      "01_19_23:37:49 --- 2.1812710762023926 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:52 Training loss at epoch 0 step 11960: 3.0732887268066404\n",
      "\n",
      " This round's valence_loss=1.283125877380371, arousal_loss=1.0761950016021729, emotion_loss=0.7601301670074463\n",
      "\n",
      "01_19_23:37:52 Seen so far: 382752 samples\n",
      "\n",
      "01_19_23:37:52 --- 2.4493165016174316 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:54 Training loss at epoch 0 step 11970: 3.156938672065735\n",
      "\n",
      " This round's valence_loss=0.5995616912841797, arousal_loss=0.5054817199707031, emotion_loss=1.1656708717346191\n",
      "\n",
      "01_19_23:37:54 Seen so far: 383072 samples\n",
      "\n",
      "01_19_23:37:54 --- 2.155855417251587 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:56 Training loss at epoch 0 step 11980: 2.9507933378219606\n",
      "\n",
      " This round's valence_loss=1.0957551002502441, arousal_loss=0.9619123339653015, emotion_loss=1.3852804899215698\n",
      "\n",
      "01_19_23:37:56 Seen so far: 383392 samples\n",
      "\n",
      "01_19_23:37:56 --- 2.0651681423187256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:37:58 Training loss at epoch 0 step 11990: 3.2029182434082033\n",
      "\n",
      " This round's valence_loss=1.0481853485107422, arousal_loss=0.9405885934829712, emotion_loss=0.8864270448684692\n",
      "\n",
      "01_19_23:37:58 Seen so far: 383712 samples\n",
      "\n",
      "01_19_23:37:58 --- 1.8693599700927734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:00 Training loss at epoch 0 step 12000: 2.8185096263885496\n",
      "\n",
      " This round's valence_loss=1.0486772060394287, arousal_loss=0.8011130094528198, emotion_loss=0.9515695571899414\n",
      "\n",
      "01_19_23:38:00 Seen so far: 384032 samples\n",
      "\n",
      "01_19_23:38:00 --- 1.920978307723999 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:02 Training loss at epoch 0 step 12010: 3.1954713582992555\n",
      "\n",
      " This round's valence_loss=1.1527516841888428, arousal_loss=1.0971307754516602, emotion_loss=0.957574725151062\n",
      "\n",
      "01_19_23:38:02 Seen so far: 384352 samples\n",
      "\n",
      "01_19_23:38:02 --- 1.9772813320159912 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:04 Training loss at epoch 0 step 12020: 3.140079391002655\n",
      "\n",
      " This round's valence_loss=0.899287760257721, arousal_loss=0.7021568417549133, emotion_loss=0.9770082831382751\n",
      "\n",
      "01_19_23:38:04 Seen so far: 384672 samples\n",
      "\n",
      "01_19_23:38:04 --- 1.8903863430023193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:06 Training loss at epoch 0 step 12030: 3.1062132835388185\n",
      "\n",
      " This round's valence_loss=1.1226451396942139, arousal_loss=0.9412282705307007, emotion_loss=0.7604403495788574\n",
      "\n",
      "01_19_23:38:06 Seen so far: 384992 samples\n",
      "\n",
      "01_19_23:38:06 --- 2.1415505409240723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:08 Training loss at epoch 0 step 12040: 2.6552459001541138\n",
      "\n",
      " This round's valence_loss=1.3241016864776611, arousal_loss=1.2712509632110596, emotion_loss=1.3094801902770996\n",
      "\n",
      "01_19_23:38:08 Seen so far: 385312 samples\n",
      "\n",
      "01_19_23:38:08 --- 2.2059667110443115 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:10 Training loss at epoch 0 step 12050: 2.873434901237488\n",
      "\n",
      " This round's valence_loss=0.9214746356010437, arousal_loss=0.7069334983825684, emotion_loss=0.9408721327781677\n",
      "\n",
      "01_19_23:38:10 Seen so far: 385632 samples\n",
      "\n",
      "01_19_23:38:10 --- 2.0193254947662354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:12 Training loss at epoch 0 step 12060: 3.349491000175476\n",
      "\n",
      " This round's valence_loss=1.3338428735733032, arousal_loss=1.2022714614868164, emotion_loss=1.1582235097885132\n",
      "\n",
      "01_19_23:38:12 Seen so far: 385952 samples\n",
      "\n",
      "01_19_23:38:12 --- 1.9613583087921143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:14 Training loss at epoch 0 step 12070: 3.0177826404571535\n",
      "\n",
      " This round's valence_loss=1.0867559909820557, arousal_loss=0.9340941309928894, emotion_loss=0.9390896558761597\n",
      "\n",
      "01_19_23:38:14 Seen so far: 386272 samples\n",
      "\n",
      "01_19_23:38:14 --- 2.186119794845581 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:16 Training loss at epoch 0 step 12080: 3.2856066942214968\n",
      "\n",
      " This round's valence_loss=0.8988392353057861, arousal_loss=0.563113272190094, emotion_loss=1.3844914436340332\n",
      "\n",
      "01_19_23:38:16 Seen so far: 386592 samples\n",
      "\n",
      "01_19_23:38:16 --- 1.9329097270965576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:18 Training loss at epoch 0 step 12090: 3.255330753326416\n",
      "\n",
      " This round's valence_loss=1.4391517639160156, arousal_loss=1.339505672454834, emotion_loss=1.1411728858947754\n",
      "\n",
      "01_19_23:38:18 Seen so far: 386912 samples\n",
      "\n",
      "01_19_23:38:18 --- 1.8072378635406494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:20 Training loss at epoch 0 step 12100: 3.073980188369751\n",
      "\n",
      " This round's valence_loss=0.7740359306335449, arousal_loss=0.5773071050643921, emotion_loss=1.0156476497650146\n",
      "\n",
      "01_19_23:38:20 Seen so far: 387232 samples\n",
      "\n",
      "01_19_23:38:20 --- 1.9259750843048096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:22 Training loss at epoch 0 step 12110: 3.090708613395691\n",
      "\n",
      " This round's valence_loss=1.2746766805648804, arousal_loss=1.048288106918335, emotion_loss=0.9164827466011047\n",
      "\n",
      "01_19_23:38:22 Seen so far: 387552 samples\n",
      "\n",
      "01_19_23:38:22 --- 1.8340303897857666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:24 Training loss at epoch 0 step 12120: 3.1009867906570436\n",
      "\n",
      " This round's valence_loss=1.5334033966064453, arousal_loss=1.4791967868804932, emotion_loss=1.1334255933761597\n",
      "\n",
      "01_19_23:38:24 Seen so far: 387872 samples\n",
      "\n",
      "01_19_23:38:24 --- 2.067505121231079 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:26 Training loss at epoch 0 step 12130: 3.0540292024612428\n",
      "\n",
      " This round's valence_loss=1.1215858459472656, arousal_loss=0.9657143354415894, emotion_loss=1.1263924837112427\n",
      "\n",
      "01_19_23:38:26 Seen so far: 388192 samples\n",
      "\n",
      "01_19_23:38:26 --- 1.9906041622161865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:28 Training loss at epoch 0 step 12140: 2.997360110282898\n",
      "\n",
      " This round's valence_loss=1.075944423675537, arousal_loss=0.9640160799026489, emotion_loss=1.3481383323669434\n",
      "\n",
      "01_19_23:38:28 Seen so far: 388512 samples\n",
      "\n",
      "01_19_23:38:28 --- 2.0393905639648438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:30 Training loss at epoch 0 step 12150: 2.9318639039993286\n",
      "\n",
      " This round's valence_loss=1.5163341760635376, arousal_loss=1.3245439529418945, emotion_loss=0.7516962289810181\n",
      "\n",
      "01_19_23:38:30 Seen so far: 388832 samples\n",
      "\n",
      "01_19_23:38:30 --- 2.139530897140503 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:32 Training loss at epoch 0 step 12160: 3.4131798267364504\n",
      "\n",
      " This round's valence_loss=1.7864454984664917, arousal_loss=1.5481791496276855, emotion_loss=0.9262044429779053\n",
      "\n",
      "01_19_23:38:32 Seen so far: 389152 samples\n",
      "\n",
      "01_19_23:38:32 --- 2.053652763366699 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:34 Training loss at epoch 0 step 12170: 2.9670387744903564\n",
      "\n",
      " This round's valence_loss=0.7657749652862549, arousal_loss=0.5819672346115112, emotion_loss=0.8835449814796448\n",
      "\n",
      "01_19_23:38:34 Seen so far: 389472 samples\n",
      "\n",
      "01_19_23:38:34 --- 1.9314401149749756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:36 Training loss at epoch 0 step 12180: 2.8738285541534423\n",
      "\n",
      " This round's valence_loss=0.9753713607788086, arousal_loss=0.8110411763191223, emotion_loss=0.43082791566848755\n",
      "\n",
      "01_19_23:38:36 Seen so far: 389792 samples\n",
      "\n",
      "01_19_23:38:36 --- 1.8663792610168457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:38 Training loss at epoch 0 step 12190: 3.1835978507995604\n",
      "\n",
      " This round's valence_loss=0.8689931631088257, arousal_loss=0.6893061995506287, emotion_loss=0.823854386806488\n",
      "\n",
      "01_19_23:38:38 Seen so far: 390112 samples\n",
      "\n",
      "01_19_23:38:38 --- 2.490919589996338 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:40 Training loss at epoch 0 step 12200: 3.139843964576721\n",
      "\n",
      " This round's valence_loss=1.1234840154647827, arousal_loss=0.9413368701934814, emotion_loss=1.1583921909332275\n",
      "\n",
      "01_19_23:38:40 Seen so far: 390432 samples\n",
      "\n",
      "01_19_23:38:40 --- 2.0301625728607178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:42 Training loss at epoch 0 step 12210: 2.79827595949173\n",
      "\n",
      " This round's valence_loss=0.7166075110435486, arousal_loss=0.59466952085495, emotion_loss=1.0744178295135498\n",
      "\n",
      "01_19_23:38:42 Seen so far: 390752 samples\n",
      "\n",
      "01_19_23:38:42 --- 2.1024513244628906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:44 Training loss at epoch 0 step 12220: 3.4358834505081175\n",
      "\n",
      " This round's valence_loss=1.0647988319396973, arousal_loss=0.8626229763031006, emotion_loss=0.670040488243103\n",
      "\n",
      "01_19_23:38:44 Seen so far: 391072 samples\n",
      "\n",
      "01_19_23:38:44 --- 1.7518432140350342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:46 Training loss at epoch 0 step 12230: 3.055100679397583\n",
      "\n",
      " This round's valence_loss=0.9471096992492676, arousal_loss=0.7979881763458252, emotion_loss=0.7575505375862122\n",
      "\n",
      "01_19_23:38:46 Seen so far: 391392 samples\n",
      "\n",
      "01_19_23:38:46 --- 1.9946138858795166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:48 Training loss at epoch 0 step 12240: 3.0123995542526245\n",
      "\n",
      " This round's valence_loss=1.2671291828155518, arousal_loss=1.0985219478607178, emotion_loss=0.996981143951416\n",
      "\n",
      "01_19_23:38:48 Seen so far: 391712 samples\n",
      "\n",
      "01_19_23:38:48 --- 1.9816737174987793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:50 Training loss at epoch 0 step 12250: 3.2610138416290284\n",
      "\n",
      " This round's valence_loss=1.503983497619629, arousal_loss=1.2686349153518677, emotion_loss=1.0669234991073608\n",
      "\n",
      "01_19_23:38:50 Seen so far: 392032 samples\n",
      "\n",
      "01_19_23:38:50 --- 1.878781795501709 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:52 Training loss at epoch 0 step 12260: 3.5248820543289185\n",
      "\n",
      " This round's valence_loss=1.4981143474578857, arousal_loss=1.3226535320281982, emotion_loss=1.0425269603729248\n",
      "\n",
      "01_19_23:38:52 Seen so far: 392352 samples\n",
      "\n",
      "01_19_23:38:52 --- 2.0851023197174072 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:54 Training loss at epoch 0 step 12270: 2.814921474456787\n",
      "\n",
      " This round's valence_loss=0.8571512699127197, arousal_loss=0.7218540906906128, emotion_loss=0.9151657819747925\n",
      "\n",
      "01_19_23:38:54 Seen so far: 392672 samples\n",
      "\n",
      "01_19_23:38:54 --- 2.4740114212036133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:57 Training loss at epoch 0 step 12280: 3.0647913455963134\n",
      "\n",
      " This round's valence_loss=0.8895736336708069, arousal_loss=0.6914984583854675, emotion_loss=1.039557695388794\n",
      "\n",
      "01_19_23:38:57 Seen so far: 392992 samples\n",
      "\n",
      "01_19_23:38:57 --- 2.131385564804077 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:38:59 Training loss at epoch 0 step 12290: 3.343546223640442\n",
      "\n",
      " This round's valence_loss=1.0685235261917114, arousal_loss=0.9449888467788696, emotion_loss=0.8605901002883911\n",
      "\n",
      "01_19_23:38:59 Seen so far: 393312 samples\n",
      "\n",
      "01_19_23:38:59 --- 1.9757602214813232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:01 Training loss at epoch 0 step 12300: 2.8673311710357665\n",
      "\n",
      " This round's valence_loss=1.207314372062683, arousal_loss=1.0685786008834839, emotion_loss=1.2671287059783936\n",
      "\n",
      "01_19_23:39:01 Seen so far: 393632 samples\n",
      "\n",
      "01_19_23:39:01 --- 2.006674289703369 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:02 Training loss at epoch 0 step 12310: 2.9976237177848817\n",
      "\n",
      " This round's valence_loss=1.0053224563598633, arousal_loss=0.8328408002853394, emotion_loss=0.9268540143966675\n",
      "\n",
      "01_19_23:39:02 Seen so far: 393952 samples\n",
      "\n",
      "01_19_23:39:02 --- 1.920525312423706 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:04 Training loss at epoch 0 step 12320: 2.8619518518447875\n",
      "\n",
      " This round's valence_loss=0.9072065949440002, arousal_loss=0.7154927253723145, emotion_loss=1.1725313663482666\n",
      "\n",
      "01_19_23:39:04 Seen so far: 394272 samples\n",
      "\n",
      "01_19_23:39:04 --- 1.9639809131622314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:06 Training loss at epoch 0 step 12330: 3.2245852947235107\n",
      "\n",
      " This round's valence_loss=1.5377939939498901, arousal_loss=1.3108925819396973, emotion_loss=1.146439790725708\n",
      "\n",
      "01_19_23:39:06 Seen so far: 394592 samples\n",
      "\n",
      "01_19_23:39:06 --- 2.033750534057617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:08 Training loss at epoch 0 step 12340: 3.2540985107421876\n",
      "\n",
      " This round's valence_loss=0.9687768220901489, arousal_loss=0.8331155776977539, emotion_loss=1.1743462085723877\n",
      "\n",
      "01_19_23:39:08 Seen so far: 394912 samples\n",
      "\n",
      "01_19_23:39:08 --- 1.907459020614624 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:10 Training loss at epoch 0 step 12350: 3.402522420883179\n",
      "\n",
      " This round's valence_loss=1.738692045211792, arousal_loss=1.7324786186218262, emotion_loss=1.3045904636383057\n",
      "\n",
      "01_19_23:39:10 Seen so far: 395232 samples\n",
      "\n",
      "01_19_23:39:10 --- 1.9809699058532715 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:12 Training loss at epoch 0 step 12360: 3.139713191986084\n",
      "\n",
      " This round's valence_loss=0.6684005260467529, arousal_loss=0.46192285418510437, emotion_loss=0.9710645079612732\n",
      "\n",
      "01_19_23:39:12 Seen so far: 395552 samples\n",
      "\n",
      "01_19_23:39:12 --- 2.120265007019043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:15 Training loss at epoch 0 step 12370: 3.000947105884552\n",
      "\n",
      " This round's valence_loss=0.4834028482437134, arousal_loss=0.37781822681427, emotion_loss=0.7814079523086548\n",
      "\n",
      "01_19_23:39:15 Seen so far: 395872 samples\n",
      "\n",
      "01_19_23:39:15 --- 2.2158942222595215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:17 Training loss at epoch 0 step 12380: 3.0909547328948976\n",
      "\n",
      " This round's valence_loss=0.7255172729492188, arousal_loss=0.6070965528488159, emotion_loss=1.1319024562835693\n",
      "\n",
      "01_19_23:39:17 Seen so far: 396192 samples\n",
      "\n",
      "01_19_23:39:17 --- 2.0202672481536865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:19 Training loss at epoch 0 step 12390: 3.059260404109955\n",
      "\n",
      " This round's valence_loss=1.1390190124511719, arousal_loss=0.9690346717834473, emotion_loss=1.1995038986206055\n",
      "\n",
      "01_19_23:39:19 Seen so far: 396512 samples\n",
      "\n",
      "01_19_23:39:19 --- 2.0210556983947754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:21 Training loss at epoch 0 step 12400: 2.9589425802230833\n",
      "\n",
      " This round's valence_loss=1.2321381568908691, arousal_loss=1.0494600534439087, emotion_loss=0.9210584759712219\n",
      "\n",
      "01_19_23:39:21 Seen so far: 396832 samples\n",
      "\n",
      "01_19_23:39:21 --- 2.105820655822754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:23 Training loss at epoch 0 step 12410: 3.1514411211013793\n",
      "\n",
      " This round's valence_loss=1.090948224067688, arousal_loss=0.9637272357940674, emotion_loss=1.2277014255523682\n",
      "\n",
      "01_19_23:39:23 Seen so far: 397152 samples\n",
      "\n",
      "01_19_23:39:23 --- 2.0366344451904297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:25 Training loss at epoch 0 step 12420: 3.0664517641067506\n",
      "\n",
      " This round's valence_loss=0.6621809005737305, arousal_loss=0.48947566747665405, emotion_loss=1.0146924257278442\n",
      "\n",
      "01_19_23:39:25 Seen so far: 397472 samples\n",
      "\n",
      "01_19_23:39:25 --- 1.752328634262085 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:27 Training loss at epoch 0 step 12430: 2.99691846370697\n",
      "\n",
      " This round's valence_loss=1.1231379508972168, arousal_loss=0.9391458034515381, emotion_loss=1.198709487915039\n",
      "\n",
      "01_19_23:39:27 Seen so far: 397792 samples\n",
      "\n",
      "01_19_23:39:27 --- 1.9507725238800049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:29 Training loss at epoch 0 step 12440: 2.7021087288856505\n",
      "\n",
      " This round's valence_loss=1.4321616888046265, arousal_loss=1.3512272834777832, emotion_loss=1.0479838848114014\n",
      "\n",
      "01_19_23:39:29 Seen so far: 398112 samples\n",
      "\n",
      "01_19_23:39:29 --- 1.9940669536590576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:31 Training loss at epoch 0 step 12450: 3.2354348421096804\n",
      "\n",
      " This round's valence_loss=1.35868239402771, arousal_loss=1.2411401271820068, emotion_loss=1.025305986404419\n",
      "\n",
      "01_19_23:39:31 Seen so far: 398432 samples\n",
      "\n",
      "01_19_23:39:31 --- 2.0094330310821533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:33 Training loss at epoch 0 step 12460: 3.0891795635223387\n",
      "\n",
      " This round's valence_loss=0.7994898557662964, arousal_loss=0.7298908829689026, emotion_loss=0.9038937091827393\n",
      "\n",
      "01_19_23:39:33 Seen so far: 398752 samples\n",
      "\n",
      "01_19_23:39:33 --- 2.1606688499450684 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:35 Training loss at epoch 0 step 12470: 3.1437005043029784\n",
      "\n",
      " This round's valence_loss=1.1502509117126465, arousal_loss=0.9318380355834961, emotion_loss=1.1482369899749756\n",
      "\n",
      "01_19_23:39:35 Seen so far: 399072 samples\n",
      "\n",
      "01_19_23:39:35 --- 2.003877878189087 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:37 Training loss at epoch 0 step 12480: 3.300532913208008\n",
      "\n",
      " This round's valence_loss=0.7412562370300293, arousal_loss=0.5886902809143066, emotion_loss=1.2503149509429932\n",
      "\n",
      "01_19_23:39:37 Seen so far: 399392 samples\n",
      "\n",
      "01_19_23:39:37 --- 2.1189754009246826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:39 Training loss at epoch 0 step 12490: 3.5700133085250854\n",
      "\n",
      " This round's valence_loss=1.4964916706085205, arousal_loss=1.2798876762390137, emotion_loss=0.6778514385223389\n",
      "\n",
      "01_19_23:39:39 Seen so far: 399712 samples\n",
      "\n",
      "01_19_23:39:39 --- 1.9680759906768799 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:41 Training loss at epoch 0 step 12500: 3.2714422702789308\n",
      "\n",
      " This round's valence_loss=1.233640193939209, arousal_loss=1.1122857332229614, emotion_loss=1.1844267845153809\n",
      "\n",
      "01_19_23:39:41 Seen so far: 400032 samples\n",
      "\n",
      "01_19_23:39:41 --- 1.9677395820617676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:43 Training loss at epoch 0 step 12510: 3.0414662599563598\n",
      "\n",
      " This round's valence_loss=1.5172059535980225, arousal_loss=1.332892656326294, emotion_loss=1.1308977603912354\n",
      "\n",
      "01_19_23:39:43 Seen so far: 400352 samples\n",
      "\n",
      "01_19_23:39:43 --- 1.9475700855255127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:45 Training loss at epoch 0 step 12520: 2.742767357826233\n",
      "\n",
      " This round's valence_loss=0.8571248054504395, arousal_loss=0.686246395111084, emotion_loss=0.9944769740104675\n",
      "\n",
      "01_19_23:39:45 Seen so far: 400672 samples\n",
      "\n",
      "01_19_23:39:45 --- 2.146538257598877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:47 Training loss at epoch 0 step 12530: 3.1987797737121584\n",
      "\n",
      " This round's valence_loss=0.8974953293800354, arousal_loss=0.8321139812469482, emotion_loss=1.27796471118927\n",
      "\n",
      "01_19_23:39:47 Seen so far: 400992 samples\n",
      "\n",
      "01_19_23:39:47 --- 1.8543531894683838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:49 Training loss at epoch 0 step 12540: 3.113646984100342\n",
      "\n",
      " This round's valence_loss=1.1002066135406494, arousal_loss=0.9241113662719727, emotion_loss=0.9279822111129761\n",
      "\n",
      "01_19_23:39:49 Seen so far: 401312 samples\n",
      "\n",
      "01_19_23:39:49 --- 1.995091199874878 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:51 Training loss at epoch 0 step 12550: 2.9628171920776367\n",
      "\n",
      " This round's valence_loss=1.4414639472961426, arousal_loss=1.4012908935546875, emotion_loss=1.287595510482788\n",
      "\n",
      "01_19_23:39:51 Seen so far: 401632 samples\n",
      "\n",
      "01_19_23:39:51 --- 1.9894554615020752 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:53 Training loss at epoch 0 step 12560: 2.9666561841964723\n",
      "\n",
      " This round's valence_loss=1.552828311920166, arousal_loss=1.444913625717163, emotion_loss=1.1026338338851929\n",
      "\n",
      "01_19_23:39:53 Seen so far: 401952 samples\n",
      "\n",
      "01_19_23:39:53 --- 1.9766511917114258 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:55 Training loss at epoch 0 step 12570: 3.0427128195762636\n",
      "\n",
      " This round's valence_loss=1.0991861820220947, arousal_loss=0.9987401962280273, emotion_loss=1.4004336595535278\n",
      "\n",
      "01_19_23:39:55 Seen so far: 402272 samples\n",
      "\n",
      "01_19_23:39:55 --- 2.0754308700561523 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:57 Training loss at epoch 0 step 12580: 2.9632997632026674\n",
      "\n",
      " This round's valence_loss=0.728906512260437, arousal_loss=0.6254422068595886, emotion_loss=1.1422288417816162\n",
      "\n",
      "01_19_23:39:57 Seen so far: 402592 samples\n",
      "\n",
      "01_19_23:39:57 --- 2.096637487411499 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:39:59 Training loss at epoch 0 step 12590: 3.2869075775146483\n",
      "\n",
      " This round's valence_loss=0.8377697467803955, arousal_loss=0.7431219220161438, emotion_loss=1.2547413110733032\n",
      "\n",
      "01_19_23:39:59 Seen so far: 402912 samples\n",
      "\n",
      "01_19_23:39:59 --- 1.8347275257110596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:01 Training loss at epoch 0 step 12600: 3.2000679969787598\n",
      "\n",
      " This round's valence_loss=0.679735541343689, arousal_loss=0.4347628355026245, emotion_loss=1.0237257480621338\n",
      "\n",
      "01_19_23:40:01 Seen so far: 403232 samples\n",
      "\n",
      "01_19_23:40:01 --- 1.8896527290344238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:02 Training loss at epoch 0 step 12610: 3.162501645088196\n",
      "\n",
      " This round's valence_loss=1.1744134426116943, arousal_loss=1.0807584524154663, emotion_loss=0.9123684167861938\n",
      "\n",
      "01_19_23:40:02 Seen so far: 403552 samples\n",
      "\n",
      "01_19_23:40:02 --- 1.8960654735565186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:04 Training loss at epoch 0 step 12620: 2.9688602447509767\n",
      "\n",
      " This round's valence_loss=1.230964183807373, arousal_loss=1.0786464214324951, emotion_loss=1.2404048442840576\n",
      "\n",
      "01_19_23:40:04 Seen so far: 403872 samples\n",
      "\n",
      "01_19_23:40:04 --- 1.976053237915039 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:07 Training loss at epoch 0 step 12630: 2.955096936225891\n",
      "\n",
      " This round's valence_loss=1.3388819694519043, arousal_loss=1.1819506883621216, emotion_loss=1.0247453451156616\n",
      "\n",
      "01_19_23:40:07 Seen so far: 404192 samples\n",
      "\n",
      "01_19_23:40:07 --- 2.121504068374634 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:09 Training loss at epoch 0 step 12640: 3.0089918851852415\n",
      "\n",
      " This round's valence_loss=1.0722477436065674, arousal_loss=0.9593717455863953, emotion_loss=0.780066192150116\n",
      "\n",
      "01_19_23:40:09 Seen so far: 404512 samples\n",
      "\n",
      "01_19_23:40:09 --- 2.06124210357666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:11 Training loss at epoch 0 step 12650: 3.2734917402267456\n",
      "\n",
      " This round's valence_loss=1.4053289890289307, arousal_loss=1.3357203006744385, emotion_loss=0.8589677810668945\n",
      "\n",
      "01_19_23:40:11 Seen so far: 404832 samples\n",
      "\n",
      "01_19_23:40:11 --- 1.9751055240631104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:13 Training loss at epoch 0 step 12660: 3.125776767730713\n",
      "\n",
      " This round's valence_loss=1.490389108657837, arousal_loss=1.3517709970474243, emotion_loss=0.9091604948043823\n",
      "\n",
      "01_19_23:40:13 Seen so far: 405152 samples\n",
      "\n",
      "01_19_23:40:13 --- 2.1711716651916504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:15 Training loss at epoch 0 step 12670: 3.0361196994781494\n",
      "\n",
      " This round's valence_loss=1.3290596008300781, arousal_loss=1.202085256576538, emotion_loss=0.8337892889976501\n",
      "\n",
      "01_19_23:40:15 Seen so far: 405472 samples\n",
      "\n",
      "01_19_23:40:15 --- 1.9956936836242676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:17 Training loss at epoch 0 step 12680: 3.1400918483734133\n",
      "\n",
      " This round's valence_loss=1.1930180788040161, arousal_loss=1.1178791522979736, emotion_loss=1.2189915180206299\n",
      "\n",
      "01_19_23:40:17 Seen so far: 405792 samples\n",
      "\n",
      "01_19_23:40:17 --- 2.262873411178589 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:19 Training loss at epoch 0 step 12690: 3.254479932785034\n",
      "\n",
      " This round's valence_loss=1.045048713684082, arousal_loss=1.022077202796936, emotion_loss=1.1469342708587646\n",
      "\n",
      "01_19_23:40:19 Seen so far: 406112 samples\n",
      "\n",
      "01_19_23:40:19 --- 2.121561288833618 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:21 Training loss at epoch 0 step 12700: 2.966795468330383\n",
      "\n",
      " This round's valence_loss=1.2250559329986572, arousal_loss=1.0749056339263916, emotion_loss=1.2846728563308716\n",
      "\n",
      "01_19_23:40:21 Seen so far: 406432 samples\n",
      "\n",
      "01_19_23:40:21 --- 2.2392914295196533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:34 Training loss at epoch 1 step 0: 3.1995285511016847\n",
      "\n",
      " This round's valence_loss=1.7539684772491455, arousal_loss=1.6943268775939941, emotion_loss=1.23183274269104\n",
      "\n",
      "01_19_23:40:34 Seen so far: 32 samples\n",
      "\n",
      "01_19_23:40:34 --- 12.741417407989502 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:36 Training loss at epoch 1 step 10: 2.9920207500457763\n",
      "\n",
      " This round's valence_loss=0.7429714202880859, arousal_loss=0.5690258741378784, emotion_loss=0.6724565625190735\n",
      "\n",
      "01_19_23:40:36 Seen so far: 352 samples\n",
      "\n",
      "01_19_23:40:36 --- 2.2955684661865234 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:39 Training loss at epoch 1 step 20: 3.2078161001205445\n",
      "\n",
      " This round's valence_loss=1.1344971656799316, arousal_loss=0.9791478514671326, emotion_loss=0.8903728723526001\n",
      "\n",
      "01_19_23:40:39 Seen so far: 672 samples\n",
      "\n",
      "01_19_23:40:39 --- 2.1842684745788574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:41 Training loss at epoch 1 step 30: 3.204523801803589\n",
      "\n",
      " This round's valence_loss=1.1073825359344482, arousal_loss=0.9587275981903076, emotion_loss=1.198286533355713\n",
      "\n",
      "01_19_23:40:41 Seen so far: 992 samples\n",
      "\n",
      "01_19_23:40:41 --- 2.0537006855010986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:43 Training loss at epoch 1 step 40: 3.2419666290283202\n",
      "\n",
      " This round's valence_loss=0.9624419212341309, arousal_loss=0.851284384727478, emotion_loss=1.1614830493927002\n",
      "\n",
      "01_19_23:40:43 Seen so far: 1312 samples\n",
      "\n",
      "01_19_23:40:43 --- 2.2016656398773193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:45 Training loss at epoch 1 step 50: 2.9256393909454346\n",
      "\n",
      " This round's valence_loss=1.338747501373291, arousal_loss=1.217984914779663, emotion_loss=1.0573489665985107\n",
      "\n",
      "01_19_23:40:45 Seen so far: 1632 samples\n",
      "\n",
      "01_19_23:40:45 --- 2.0292632579803467 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:47 Training loss at epoch 1 step 60: 3.137240171432495\n",
      "\n",
      " This round's valence_loss=0.9459389448165894, arousal_loss=0.8681762218475342, emotion_loss=0.9771028161048889\n",
      "\n",
      "01_19_23:40:47 Seen so far: 1952 samples\n",
      "\n",
      "01_19_23:40:47 --- 2.074483633041382 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:49 Training loss at epoch 1 step 70: 2.754915189743042\n",
      "\n",
      " This round's valence_loss=0.5911442041397095, arousal_loss=0.3467450737953186, emotion_loss=0.8458904027938843\n",
      "\n",
      "01_19_23:40:49 Seen so far: 2272 samples\n",
      "\n",
      "01_19_23:40:49 --- 1.989309549331665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:51 Training loss at epoch 1 step 80: 3.278190779685974\n",
      "\n",
      " This round's valence_loss=1.8005664348602295, arousal_loss=1.7186017036437988, emotion_loss=1.105656385421753\n",
      "\n",
      "01_19_23:40:51 Seen so far: 2592 samples\n",
      "\n",
      "01_19_23:40:51 --- 2.1377763748168945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:53 Training loss at epoch 1 step 90: 2.840607523918152\n",
      "\n",
      " This round's valence_loss=1.3198823928833008, arousal_loss=1.1760468482971191, emotion_loss=0.7005512714385986\n",
      "\n",
      "01_19_23:40:53 Seen so far: 2912 samples\n",
      "\n",
      "01_19_23:40:53 --- 1.8878626823425293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:55 Training loss at epoch 1 step 100: 3.0553346633911134\n",
      "\n",
      " This round's valence_loss=0.5946910381317139, arousal_loss=0.48823100328445435, emotion_loss=1.0731279850006104\n",
      "\n",
      "01_19_23:40:55 Seen so far: 3232 samples\n",
      "\n",
      "01_19_23:40:55 --- 1.9836740493774414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:57 Training loss at epoch 1 step 110: 3.221326303482056\n",
      "\n",
      " This round's valence_loss=1.245382308959961, arousal_loss=1.0914647579193115, emotion_loss=1.1360108852386475\n",
      "\n",
      "01_19_23:40:57 Seen so far: 3552 samples\n",
      "\n",
      "01_19_23:40:57 --- 2.1117641925811768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:40:59 Training loss at epoch 1 step 120: 3.161380910873413\n",
      "\n",
      " This round's valence_loss=1.0683541297912598, arousal_loss=0.9767192602157593, emotion_loss=1.6123216152191162\n",
      "\n",
      "01_19_23:40:59 Seen so far: 3872 samples\n",
      "\n",
      "01_19_23:40:59 --- 2.0986392498016357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:01 Training loss at epoch 1 step 130: 2.97461793422699\n",
      "\n",
      " This round's valence_loss=0.5926175117492676, arousal_loss=0.34391093254089355, emotion_loss=1.1110622882843018\n",
      "\n",
      "01_19_23:41:01 Seen so far: 4192 samples\n",
      "\n",
      "01_19_23:41:01 --- 1.8460726737976074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:03 Training loss at epoch 1 step 140: 3.2018540859222413\n",
      "\n",
      " This round's valence_loss=1.3393096923828125, arousal_loss=1.229905366897583, emotion_loss=1.1716514825820923\n",
      "\n",
      "01_19_23:41:03 Seen so far: 4512 samples\n",
      "\n",
      "01_19_23:41:03 --- 2.1867923736572266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:05 Training loss at epoch 1 step 150: 2.9820645570755007\n",
      "\n",
      " This round's valence_loss=0.8365314602851868, arousal_loss=0.7143419981002808, emotion_loss=0.9513546228408813\n",
      "\n",
      "01_19_23:41:05 Seen so far: 4832 samples\n",
      "\n",
      "01_19_23:41:05 --- 2.0502824783325195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:08 Training loss at epoch 1 step 160: 2.9623456716537477\n",
      "\n",
      " This round's valence_loss=1.015326738357544, arousal_loss=0.9035474061965942, emotion_loss=1.1171715259552002\n",
      "\n",
      "01_19_23:41:08 Seen so far: 5152 samples\n",
      "\n",
      "01_19_23:41:08 --- 2.2519376277923584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:10 Training loss at epoch 1 step 170: 3.2506425619125365\n",
      "\n",
      " This round's valence_loss=1.362637996673584, arousal_loss=1.209604024887085, emotion_loss=1.0153141021728516\n",
      "\n",
      "01_19_23:41:10 Seen so far: 5472 samples\n",
      "\n",
      "01_19_23:41:10 --- 2.1020617485046387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:12 Training loss at epoch 1 step 180: 3.208285903930664\n",
      "\n",
      " This round's valence_loss=1.0766669511795044, arousal_loss=0.9615433812141418, emotion_loss=1.1099145412445068\n",
      "\n",
      "01_19_23:41:12 Seen so far: 5792 samples\n",
      "\n",
      "01_19_23:41:12 --- 1.9004051685333252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:14 Training loss at epoch 1 step 190: 3.08618700504303\n",
      "\n",
      " This round's valence_loss=1.1655902862548828, arousal_loss=0.9568902254104614, emotion_loss=0.7236680388450623\n",
      "\n",
      "01_19_23:41:14 Seen so far: 6112 samples\n",
      "\n",
      "01_19_23:41:14 --- 2.2736361026763916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:16 Training loss at epoch 1 step 200: 2.981174850463867\n",
      "\n",
      " This round's valence_loss=0.9669426679611206, arousal_loss=0.8482996821403503, emotion_loss=1.288745641708374\n",
      "\n",
      "01_19_23:41:16 Seen so far: 6432 samples\n",
      "\n",
      "01_19_23:41:16 --- 1.9111900329589844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:18 Training loss at epoch 1 step 210: 3.116852116584778\n",
      "\n",
      " This round's valence_loss=1.2303826808929443, arousal_loss=1.1033198833465576, emotion_loss=1.0018682479858398\n",
      "\n",
      "01_19_23:41:18 Seen so far: 6752 samples\n",
      "\n",
      "01_19_23:41:18 --- 1.951230525970459 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:20 Training loss at epoch 1 step 220: 2.7508014917373655\n",
      "\n",
      " This round's valence_loss=0.4893447160720825, arousal_loss=0.33275410532951355, emotion_loss=0.7993358373641968\n",
      "\n",
      "01_19_23:41:20 Seen so far: 7072 samples\n",
      "\n",
      "01_19_23:41:20 --- 2.097285032272339 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:22 Training loss at epoch 1 step 230: 2.9628941774368287\n",
      "\n",
      " This round's valence_loss=0.9184497594833374, arousal_loss=0.6808059215545654, emotion_loss=0.6400858759880066\n",
      "\n",
      "01_19_23:41:22 Seen so far: 7392 samples\n",
      "\n",
      "01_19_23:41:22 --- 2.1080574989318848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:24 Training loss at epoch 1 step 240: 3.040732574462891\n",
      "\n",
      " This round's valence_loss=1.1500322818756104, arousal_loss=0.9692507982254028, emotion_loss=1.0118669271469116\n",
      "\n",
      "01_19_23:41:24 Seen so far: 7712 samples\n",
      "\n",
      "01_19_23:41:24 --- 1.862659215927124 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:26 Training loss at epoch 1 step 250: 3.299195981025696\n",
      "\n",
      " This round's valence_loss=1.3241679668426514, arousal_loss=1.2591702938079834, emotion_loss=1.2768397331237793\n",
      "\n",
      "01_19_23:41:26 Seen so far: 8032 samples\n",
      "\n",
      "01_19_23:41:26 --- 1.9906504154205322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:28 Training loss at epoch 1 step 260: 3.048513627052307\n",
      "\n",
      " This round's valence_loss=0.9508994817733765, arousal_loss=0.861596405506134, emotion_loss=1.039669156074524\n",
      "\n",
      "01_19_23:41:28 Seen so far: 8352 samples\n",
      "\n",
      "01_19_23:41:28 --- 2.0471863746643066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:30 Training loss at epoch 1 step 270: 3.1676499605178834\n",
      "\n",
      " This round's valence_loss=1.7648578882217407, arousal_loss=1.6534265279769897, emotion_loss=1.0599573850631714\n",
      "\n",
      "01_19_23:41:30 Seen so far: 8672 samples\n",
      "\n",
      "01_19_23:41:30 --- 1.8317065238952637 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:32 Training loss at epoch 1 step 280: 3.0220881938934325\n",
      "\n",
      " This round's valence_loss=1.0167293548583984, arousal_loss=0.8277156949043274, emotion_loss=0.838472843170166\n",
      "\n",
      "01_19_23:41:32 Seen so far: 8992 samples\n",
      "\n",
      "01_19_23:41:32 --- 1.9146859645843506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:34 Training loss at epoch 1 step 290: 3.075244092941284\n",
      "\n",
      " This round's valence_loss=1.0728867053985596, arousal_loss=1.013096570968628, emotion_loss=1.02884042263031\n",
      "\n",
      "01_19_23:41:34 Seen so far: 9312 samples\n",
      "\n",
      "01_19_23:41:34 --- 2.0855767726898193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:36 Training loss at epoch 1 step 300: 2.939498281478882\n",
      "\n",
      " This round's valence_loss=1.111993670463562, arousal_loss=0.9801472425460815, emotion_loss=0.9024906158447266\n",
      "\n",
      "01_19_23:41:36 Seen so far: 9632 samples\n",
      "\n",
      "01_19_23:41:36 --- 2.158442497253418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:38 Training loss at epoch 1 step 310: 3.05859580039978\n",
      "\n",
      " This round's valence_loss=0.9450440406799316, arousal_loss=0.8165743947029114, emotion_loss=0.7708902359008789\n",
      "\n",
      "01_19_23:41:38 Seen so far: 9952 samples\n",
      "\n",
      "01_19_23:41:38 --- 1.9700274467468262 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:40 Training loss at epoch 1 step 320: 3.1822129607200624\n",
      "\n",
      " This round's valence_loss=0.834143877029419, arousal_loss=0.6941232681274414, emotion_loss=0.9273662567138672\n",
      "\n",
      "01_19_23:41:40 Seen so far: 10272 samples\n",
      "\n",
      "01_19_23:41:40 --- 2.1198008060455322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:42 Training loss at epoch 1 step 330: 2.963801455497742\n",
      "\n",
      " This round's valence_loss=0.9919847846031189, arousal_loss=0.7934260368347168, emotion_loss=1.0474172830581665\n",
      "\n",
      "01_19_23:41:42 Seen so far: 10592 samples\n",
      "\n",
      "01_19_23:41:42 --- 1.9125428199768066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:44 Training loss at epoch 1 step 340: 3.142670154571533\n",
      "\n",
      " This round's valence_loss=1.2597696781158447, arousal_loss=1.065142035484314, emotion_loss=1.0043919086456299\n",
      "\n",
      "01_19_23:41:44 Seen so far: 10912 samples\n",
      "\n",
      "01_19_23:41:44 --- 2.0482027530670166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:46 Training loss at epoch 1 step 350: 2.977797746658325\n",
      "\n",
      " This round's valence_loss=1.3003193140029907, arousal_loss=1.209721565246582, emotion_loss=1.2299470901489258\n",
      "\n",
      "01_19_23:41:46 Seen so far: 11232 samples\n",
      "\n",
      "01_19_23:41:46 --- 1.946192979812622 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:48 Training loss at epoch 1 step 360: 3.4221259355545044\n",
      "\n",
      " This round's valence_loss=1.0920770168304443, arousal_loss=1.0118272304534912, emotion_loss=1.180517554283142\n",
      "\n",
      "01_19_23:41:48 Seen so far: 11552 samples\n",
      "\n",
      "01_19_23:41:48 --- 1.8041791915893555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:50 Training loss at epoch 1 step 370: 3.1944013833999634\n",
      "\n",
      " This round's valence_loss=1.3585052490234375, arousal_loss=1.2288494110107422, emotion_loss=1.011507511138916\n",
      "\n",
      "01_19_23:41:50 Seen so far: 11872 samples\n",
      "\n",
      "01_19_23:41:50 --- 2.215553045272827 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:52 Training loss at epoch 1 step 380: 3.266984462738037\n",
      "\n",
      " This round's valence_loss=1.12654447555542, arousal_loss=0.9340630173683167, emotion_loss=1.1148061752319336\n",
      "\n",
      "01_19_23:41:52 Seen so far: 12192 samples\n",
      "\n",
      "01_19_23:41:52 --- 1.9209461212158203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:54 Training loss at epoch 1 step 390: 3.1539181232452393\n",
      "\n",
      " This round's valence_loss=1.1653964519500732, arousal_loss=0.9798348546028137, emotion_loss=1.150214433670044\n",
      "\n",
      "01_19_23:41:54 Seen so far: 12512 samples\n",
      "\n",
      "01_19_23:41:54 --- 1.834120750427246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:55 Training loss at epoch 1 step 400: 2.8534364461898805\n",
      "\n",
      " This round's valence_loss=1.0046117305755615, arousal_loss=0.8791507482528687, emotion_loss=0.6968556642532349\n",
      "\n",
      "01_19_23:41:55 Seen so far: 12832 samples\n",
      "\n",
      "01_19_23:41:55 --- 1.895744800567627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:41:58 Training loss at epoch 1 step 410: 3.067496991157532\n",
      "\n",
      " This round's valence_loss=1.239945888519287, arousal_loss=1.087191104888916, emotion_loss=1.3740153312683105\n",
      "\n",
      "01_19_23:41:58 Seen so far: 13152 samples\n",
      "\n",
      "01_19_23:41:58 --- 2.0878212451934814 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:00 Training loss at epoch 1 step 420: 3.4469187021255494\n",
      "\n",
      " This round's valence_loss=1.109292984008789, arousal_loss=0.9327164888381958, emotion_loss=0.9471823573112488\n",
      "\n",
      "01_19_23:42:00 Seen so far: 13472 samples\n",
      "\n",
      "01_19_23:42:00 --- 2.188018560409546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:02 Training loss at epoch 1 step 430: 2.841363751888275\n",
      "\n",
      " This round's valence_loss=0.7453904747962952, arousal_loss=0.5786696076393127, emotion_loss=1.5113801956176758\n",
      "\n",
      "01_19_23:42:02 Seen so far: 13792 samples\n",
      "\n",
      "01_19_23:42:02 --- 2.018036365509033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:04 Training loss at epoch 1 step 440: 2.9568602204322816\n",
      "\n",
      " This round's valence_loss=0.4360046088695526, arousal_loss=0.23560699820518494, emotion_loss=0.8052199482917786\n",
      "\n",
      "01_19_23:42:04 Seen so far: 14112 samples\n",
      "\n",
      "01_19_23:42:04 --- 2.0312132835388184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:06 Training loss at epoch 1 step 450: 3.290139138698578\n",
      "\n",
      " This round's valence_loss=1.3742797374725342, arousal_loss=1.2662606239318848, emotion_loss=1.6391780376434326\n",
      "\n",
      "01_19_23:42:06 Seen so far: 14432 samples\n",
      "\n",
      "01_19_23:42:06 --- 1.921889305114746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:08 Training loss at epoch 1 step 460: 3.2911700963974\n",
      "\n",
      " This round's valence_loss=1.0632827281951904, arousal_loss=0.9509073495864868, emotion_loss=0.8471463918685913\n",
      "\n",
      "01_19_23:42:08 Seen so far: 14752 samples\n",
      "\n",
      "01_19_23:42:08 --- 1.913562297821045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:09 Training loss at epoch 1 step 470: 3.3504286766052247\n",
      "\n",
      " This round's valence_loss=1.2098802328109741, arousal_loss=1.071061611175537, emotion_loss=0.9545153975486755\n",
      "\n",
      "01_19_23:42:09 Seen so far: 15072 samples\n",
      "\n",
      "01_19_23:42:09 --- 1.8421087265014648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:11 Training loss at epoch 1 step 480: 3.020678985118866\n",
      "\n",
      " This round's valence_loss=0.8347908854484558, arousal_loss=0.779174268245697, emotion_loss=1.5355480909347534\n",
      "\n",
      "01_19_23:42:11 Seen so far: 15392 samples\n",
      "\n",
      "01_19_23:42:11 --- 1.9895355701446533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:13 Training loss at epoch 1 step 490: 2.8182299613952635\n",
      "\n",
      " This round's valence_loss=1.0060367584228516, arousal_loss=0.8046544790267944, emotion_loss=1.2511115074157715\n",
      "\n",
      "01_19_23:42:13 Seen so far: 15712 samples\n",
      "\n",
      "01_19_23:42:13 --- 1.905195951461792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:16 Training loss at epoch 1 step 500: 3.25866641998291\n",
      "\n",
      " This round's valence_loss=0.7779747247695923, arousal_loss=0.5993068218231201, emotion_loss=1.0235580205917358\n",
      "\n",
      "01_19_23:42:16 Seen so far: 16032 samples\n",
      "\n",
      "01_19_23:42:16 --- 2.2348334789276123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:18 Training loss at epoch 1 step 510: 3.353564977645874\n",
      "\n",
      " This round's valence_loss=1.5050245523452759, arousal_loss=1.338501214981079, emotion_loss=0.9093157052993774\n",
      "\n",
      "01_19_23:42:18 Seen so far: 16352 samples\n",
      "\n",
      "01_19_23:42:18 --- 2.126941204071045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:20 Training loss at epoch 1 step 520: 3.144858956336975\n",
      "\n",
      " This round's valence_loss=1.0155116319656372, arousal_loss=0.8208216428756714, emotion_loss=0.8306117057800293\n",
      "\n",
      "01_19_23:42:20 Seen so far: 16672 samples\n",
      "\n",
      "01_19_23:42:20 --- 2.040724039077759 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:22 Training loss at epoch 1 step 530: 2.9710721373558044\n",
      "\n",
      " This round's valence_loss=0.8505091071128845, arousal_loss=0.7264037132263184, emotion_loss=1.4114131927490234\n",
      "\n",
      "01_19_23:42:22 Seen so far: 16992 samples\n",
      "\n",
      "01_19_23:42:22 --- 1.9696509838104248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:24 Training loss at epoch 1 step 540: 3.303057241439819\n",
      "\n",
      " This round's valence_loss=1.1357241868972778, arousal_loss=0.994163990020752, emotion_loss=1.0143110752105713\n",
      "\n",
      "01_19_23:42:24 Seen so far: 17312 samples\n",
      "\n",
      "01_19_23:42:24 --- 2.06343150138855 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:26 Training loss at epoch 1 step 550: 3.2589851140975954\n",
      "\n",
      " This round's valence_loss=0.7350528240203857, arousal_loss=0.6081945896148682, emotion_loss=1.1985821723937988\n",
      "\n",
      "01_19_23:42:26 Seen so far: 17632 samples\n",
      "\n",
      "01_19_23:42:26 --- 2.247622013092041 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:28 Training loss at epoch 1 step 560: 2.8462416887283326\n",
      "\n",
      " This round's valence_loss=0.9069110155105591, arousal_loss=0.7541540861129761, emotion_loss=0.760471761226654\n",
      "\n",
      "01_19_23:42:28 Seen so far: 17952 samples\n",
      "\n",
      "01_19_23:42:28 --- 2.0058038234710693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:30 Training loss at epoch 1 step 570: 2.801448631286621\n",
      "\n",
      " This round's valence_loss=0.8720821738243103, arousal_loss=0.6867938041687012, emotion_loss=0.9302791357040405\n",
      "\n",
      "01_19_23:42:30 Seen so far: 18272 samples\n",
      "\n",
      "01_19_23:42:30 --- 2.012507677078247 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:32 Training loss at epoch 1 step 580: 2.9861289978027346\n",
      "\n",
      " This round's valence_loss=1.2703051567077637, arousal_loss=1.1271750926971436, emotion_loss=1.108764886856079\n",
      "\n",
      "01_19_23:42:32 Seen so far: 18592 samples\n",
      "\n",
      "01_19_23:42:32 --- 2.067945718765259 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:34 Training loss at epoch 1 step 590: 3.0092637062072756\n",
      "\n",
      " This round's valence_loss=1.220383644104004, arousal_loss=1.0662071704864502, emotion_loss=1.0650835037231445\n",
      "\n",
      "01_19_23:42:34 Seen so far: 18912 samples\n",
      "\n",
      "01_19_23:42:34 --- 2.0780436992645264 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:36 Training loss at epoch 1 step 600: 3.0421590566635133\n",
      "\n",
      " This round's valence_loss=1.171785831451416, arousal_loss=1.0904324054718018, emotion_loss=1.2144746780395508\n",
      "\n",
      "01_19_23:42:36 Seen so far: 19232 samples\n",
      "\n",
      "01_19_23:42:36 --- 1.924482822418213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:38 Training loss at epoch 1 step 610: 3.2547226190567016\n",
      "\n",
      " This round's valence_loss=0.7342383861541748, arousal_loss=0.6363844275474548, emotion_loss=1.1734330654144287\n",
      "\n",
      "01_19_23:42:38 Seen so far: 19552 samples\n",
      "\n",
      "01_19_23:42:38 --- 2.102940559387207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:40 Training loss at epoch 1 step 620: 2.991098976135254\n",
      "\n",
      " This round's valence_loss=1.0027775764465332, arousal_loss=0.9482900500297546, emotion_loss=1.3157777786254883\n",
      "\n",
      "01_19_23:42:40 Seen so far: 19872 samples\n",
      "\n",
      "01_19_23:42:40 --- 2.019016742706299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:42 Training loss at epoch 1 step 630: 3.1342514753341675\n",
      "\n",
      " This round's valence_loss=1.5402460098266602, arousal_loss=1.4522650241851807, emotion_loss=1.1713593006134033\n",
      "\n",
      "01_19_23:42:42 Seen so far: 20192 samples\n",
      "\n",
      "01_19_23:42:42 --- 1.7779319286346436 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:44 Training loss at epoch 1 step 640: 2.9743163704872133\n",
      "\n",
      " This round's valence_loss=0.7066348791122437, arousal_loss=0.4941488802433014, emotion_loss=1.5600662231445312\n",
      "\n",
      "01_19_23:42:44 Seen so far: 20512 samples\n",
      "\n",
      "01_19_23:42:44 --- 1.9167938232421875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:46 Training loss at epoch 1 step 650: 3.253695034980774\n",
      "\n",
      " This round's valence_loss=0.8844656944274902, arousal_loss=0.7300661206245422, emotion_loss=1.2362170219421387\n",
      "\n",
      "01_19_23:42:46 Seen so far: 20832 samples\n",
      "\n",
      "01_19_23:42:46 --- 1.964174509048462 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:48 Training loss at epoch 1 step 660: 3.0162834882736207\n",
      "\n",
      " This round's valence_loss=1.0480525493621826, arousal_loss=0.9556804895401001, emotion_loss=1.0401837825775146\n",
      "\n",
      "01_19_23:42:48 Seen so far: 21152 samples\n",
      "\n",
      "01_19_23:42:48 --- 2.059286594390869 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:50 Training loss at epoch 1 step 670: 3.236161696910858\n",
      "\n",
      " This round's valence_loss=1.1383955478668213, arousal_loss=1.1354906558990479, emotion_loss=1.1422301530838013\n",
      "\n",
      "01_19_23:42:50 Seen so far: 21472 samples\n",
      "\n",
      "01_19_23:42:50 --- 1.9250807762145996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:52 Training loss at epoch 1 step 680: 3.1892637252807616\n",
      "\n",
      " This round's valence_loss=0.8392488956451416, arousal_loss=0.7700172066688538, emotion_loss=1.2521692514419556\n",
      "\n",
      "01_19_23:42:52 Seen so far: 21792 samples\n",
      "\n",
      "01_19_23:42:52 --- 2.137233257293701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:54 Training loss at epoch 1 step 690: 3.27968430519104\n",
      "\n",
      " This round's valence_loss=1.3347363471984863, arousal_loss=1.25882887840271, emotion_loss=0.8729583024978638\n",
      "\n",
      "01_19_23:42:54 Seen so far: 22112 samples\n",
      "\n",
      "01_19_23:42:54 --- 2.145660638809204 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:56 Training loss at epoch 1 step 700: 3.0217310786247253\n",
      "\n",
      " This round's valence_loss=0.6409071683883667, arousal_loss=0.45189327001571655, emotion_loss=1.1092822551727295\n",
      "\n",
      "01_19_23:42:56 Seen so far: 22432 samples\n",
      "\n",
      "01_19_23:42:56 --- 1.8358631134033203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:42:58 Training loss at epoch 1 step 710: 2.774952030181885\n",
      "\n",
      " This round's valence_loss=1.4894566535949707, arousal_loss=1.342071294784546, emotion_loss=1.15093994140625\n",
      "\n",
      "01_19_23:42:58 Seen so far: 22752 samples\n",
      "\n",
      "01_19_23:42:58 --- 1.8926987648010254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:00 Training loss at epoch 1 step 720: 3.167217993736267\n",
      "\n",
      " This round's valence_loss=1.1886482238769531, arousal_loss=1.1811147928237915, emotion_loss=1.040503740310669\n",
      "\n",
      "01_19_23:43:00 Seen so far: 23072 samples\n",
      "\n",
      "01_19_23:43:00 --- 1.884775161743164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:02 Training loss at epoch 1 step 730: 2.982095551490784\n",
      "\n",
      " This round's valence_loss=0.8807951807975769, arousal_loss=0.7622934579849243, emotion_loss=0.8756116628646851\n",
      "\n",
      "01_19_23:43:02 Seen so far: 23392 samples\n",
      "\n",
      "01_19_23:43:02 --- 2.2761521339416504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:04 Training loss at epoch 1 step 740: 3.2032051920890807\n",
      "\n",
      " This round's valence_loss=1.2542264461517334, arousal_loss=1.2291594743728638, emotion_loss=0.8853821754455566\n",
      "\n",
      "01_19_23:43:04 Seen so far: 23712 samples\n",
      "\n",
      "01_19_23:43:04 --- 2.353254795074463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:06 Training loss at epoch 1 step 750: 3.16784462928772\n",
      "\n",
      " This round's valence_loss=1.195420503616333, arousal_loss=1.0856964588165283, emotion_loss=0.8989003300666809\n",
      "\n",
      "01_19_23:43:06 Seen so far: 24032 samples\n",
      "\n",
      "01_19_23:43:06 --- 2.000847101211548 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:08 Training loss at epoch 1 step 760: 3.2146601915359496\n",
      "\n",
      " This round's valence_loss=0.7480185031890869, arousal_loss=0.5930467247962952, emotion_loss=1.2212415933609009\n",
      "\n",
      "01_19_23:43:08 Seen so far: 24352 samples\n",
      "\n",
      "01_19_23:43:08 --- 2.0793519020080566 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:11 Training loss at epoch 1 step 770: 3.3151816606521605\n",
      "\n",
      " This round's valence_loss=0.9771569967269897, arousal_loss=0.8464122414588928, emotion_loss=1.063581943511963\n",
      "\n",
      "01_19_23:43:11 Seen so far: 24672 samples\n",
      "\n",
      "01_19_23:43:11 --- 2.133335590362549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:13 Training loss at epoch 1 step 780: 2.9900498151779176\n",
      "\n",
      " This round's valence_loss=1.1065304279327393, arousal_loss=0.9953926801681519, emotion_loss=0.9423353672027588\n",
      "\n",
      "01_19_23:43:13 Seen so far: 24992 samples\n",
      "\n",
      "01_19_23:43:13 --- 2.0692851543426514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:15 Training loss at epoch 1 step 790: 2.9968432903289797\n",
      "\n",
      " This round's valence_loss=1.1658718585968018, arousal_loss=0.9553091526031494, emotion_loss=0.9836714863777161\n",
      "\n",
      "01_19_23:43:15 Seen so far: 25312 samples\n",
      "\n",
      "01_19_23:43:15 --- 1.9412970542907715 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:17 Training loss at epoch 1 step 800: 3.4986366271972655\n",
      "\n",
      " This round's valence_loss=1.3610789775848389, arousal_loss=1.1549956798553467, emotion_loss=0.9068537354469299\n",
      "\n",
      "01_19_23:43:17 Seen so far: 25632 samples\n",
      "\n",
      "01_19_23:43:17 --- 1.962265968322754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:19 Training loss at epoch 1 step 810: 3.099043345451355\n",
      "\n",
      " This round's valence_loss=1.2318873405456543, arousal_loss=1.1151483058929443, emotion_loss=0.8492342233657837\n",
      "\n",
      "01_19_23:43:19 Seen so far: 25952 samples\n",
      "\n",
      "01_19_23:43:19 --- 1.9627313613891602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:20 Training loss at epoch 1 step 820: 3.04079384803772\n",
      "\n",
      " This round's valence_loss=0.737139105796814, arousal_loss=0.601632833480835, emotion_loss=0.886394202709198\n",
      "\n",
      "01_19_23:43:20 Seen so far: 26272 samples\n",
      "\n",
      "01_19_23:43:20 --- 1.8966073989868164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:23 Training loss at epoch 1 step 830: 3.1961079359054567\n",
      "\n",
      " This round's valence_loss=1.097595453262329, arousal_loss=0.9979888796806335, emotion_loss=1.1556077003479004\n",
      "\n",
      "01_19_23:43:23 Seen so far: 26592 samples\n",
      "\n",
      "01_19_23:43:23 --- 2.105872631072998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:24 Training loss at epoch 1 step 840: 2.8883460640907286\n",
      "\n",
      " This round's valence_loss=1.3109610080718994, arousal_loss=1.2290762662887573, emotion_loss=1.3923354148864746\n",
      "\n",
      "01_19_23:43:24 Seen so far: 26912 samples\n",
      "\n",
      "01_19_23:43:24 --- 1.8656620979309082 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:26 Training loss at epoch 1 step 850: 3.1083899259567263\n",
      "\n",
      " This round's valence_loss=1.1354742050170898, arousal_loss=0.9332590699195862, emotion_loss=1.3941744565963745\n",
      "\n",
      "01_19_23:43:26 Seen so far: 27232 samples\n",
      "\n",
      "01_19_23:43:26 --- 2.029923915863037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:29 Training loss at epoch 1 step 860: 2.932021641731262\n",
      "\n",
      " This round's valence_loss=0.8030532598495483, arousal_loss=0.6266831159591675, emotion_loss=1.139633059501648\n",
      "\n",
      "01_19_23:43:29 Seen so far: 27552 samples\n",
      "\n",
      "01_19_23:43:29 --- 2.0627686977386475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:31 Training loss at epoch 1 step 870: 2.9822219133377077\n",
      "\n",
      " This round's valence_loss=1.316835880279541, arousal_loss=1.2257354259490967, emotion_loss=1.3643290996551514\n",
      "\n",
      "01_19_23:43:31 Seen so far: 27872 samples\n",
      "\n",
      "01_19_23:43:31 --- 2.3294880390167236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:33 Training loss at epoch 1 step 880: 3.3140038013458253\n",
      "\n",
      " This round's valence_loss=1.0331178903579712, arousal_loss=0.837276816368103, emotion_loss=0.8790552616119385\n",
      "\n",
      "01_19_23:43:33 Seen so far: 28192 samples\n",
      "\n",
      "01_19_23:43:33 --- 2.1278505325317383 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:35 Training loss at epoch 1 step 890: 3.4887595653533934\n",
      "\n",
      " This round's valence_loss=0.7502084970474243, arousal_loss=0.6302956938743591, emotion_loss=1.1799864768981934\n",
      "\n",
      "01_19_23:43:35 Seen so far: 28512 samples\n",
      "\n",
      "01_19_23:43:35 --- 1.8848772048950195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:37 Training loss at epoch 1 step 900: 2.898217034339905\n",
      "\n",
      " This round's valence_loss=0.8050507307052612, arousal_loss=0.5599738359451294, emotion_loss=0.9913298487663269\n",
      "\n",
      "01_19_23:43:37 Seen so far: 28832 samples\n",
      "\n",
      "01_19_23:43:37 --- 1.9968557357788086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:39 Training loss at epoch 1 step 910: 3.263612747192383\n",
      "\n",
      " This round's valence_loss=1.6609294414520264, arousal_loss=1.5633280277252197, emotion_loss=1.2098054885864258\n",
      "\n",
      "01_19_23:43:39 Seen so far: 29152 samples\n",
      "\n",
      "01_19_23:43:39 --- 1.9675345420837402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:41 Training loss at epoch 1 step 920: 3.5613016366958616\n",
      "\n",
      " This round's valence_loss=1.235502004623413, arousal_loss=1.0746012926101685, emotion_loss=1.014145851135254\n",
      "\n",
      "01_19_23:43:41 Seen so far: 29472 samples\n",
      "\n",
      "01_19_23:43:41 --- 2.0040903091430664 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:43 Training loss at epoch 1 step 930: 3.046023058891296\n",
      "\n",
      " This round's valence_loss=0.9643332958221436, arousal_loss=0.8640772104263306, emotion_loss=1.0877554416656494\n",
      "\n",
      "01_19_23:43:43 Seen so far: 29792 samples\n",
      "\n",
      "01_19_23:43:43 --- 1.9969878196716309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:45 Training loss at epoch 1 step 940: 3.2516804218292235\n",
      "\n",
      " This round's valence_loss=1.475432276725769, arousal_loss=1.3542349338531494, emotion_loss=0.7615811228752136\n",
      "\n",
      "01_19_23:43:45 Seen so far: 30112 samples\n",
      "\n",
      "01_19_23:43:45 --- 2.2817296981811523 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:47 Training loss at epoch 1 step 950: 3.2495317697525024\n",
      "\n",
      " This round's valence_loss=1.1472423076629639, arousal_loss=0.9347426891326904, emotion_loss=1.0115772485733032\n",
      "\n",
      "01_19_23:43:47 Seen so far: 30432 samples\n",
      "\n",
      "01_19_23:43:47 --- 1.9026477336883545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:49 Training loss at epoch 1 step 960: 2.991399586200714\n",
      "\n",
      " This round's valence_loss=1.3223917484283447, arousal_loss=1.2439171075820923, emotion_loss=1.0240345001220703\n",
      "\n",
      "01_19_23:43:49 Seen so far: 30752 samples\n",
      "\n",
      "01_19_23:43:49 --- 1.9905142784118652 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:51 Training loss at epoch 1 step 970: 3.17611825466156\n",
      "\n",
      " This round's valence_loss=1.2242172956466675, arousal_loss=1.030357003211975, emotion_loss=1.0311346054077148\n",
      "\n",
      "01_19_23:43:51 Seen so far: 31072 samples\n",
      "\n",
      "01_19_23:43:51 --- 2.117201566696167 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:53 Training loss at epoch 1 step 980: 3.045044779777527\n",
      "\n",
      " This round's valence_loss=1.030259609222412, arousal_loss=0.9925245046615601, emotion_loss=1.482979655265808\n",
      "\n",
      "01_19_23:43:53 Seen so far: 31392 samples\n",
      "\n",
      "01_19_23:43:53 --- 1.9709007740020752 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:55 Training loss at epoch 1 step 990: 2.8502433776855467\n",
      "\n",
      " This round's valence_loss=0.49643880128860474, arousal_loss=0.32955285906791687, emotion_loss=1.008491039276123\n",
      "\n",
      "01_19_23:43:55 Seen so far: 31712 samples\n",
      "\n",
      "01_19_23:43:55 --- 2.11303973197937 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:43:57 Training loss at epoch 1 step 1000: 2.853956174850464\n",
      "\n",
      " This round's valence_loss=0.8489371538162231, arousal_loss=0.7031822204589844, emotion_loss=0.6740026473999023\n",
      "\n",
      "01_19_23:43:57 Seen so far: 32032 samples\n",
      "\n",
      "01_19_23:43:57 --- 2.100874185562134 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:00 Training loss at epoch 1 step 1010: 3.057541787624359\n",
      "\n",
      " This round's valence_loss=0.9952670335769653, arousal_loss=0.8164219856262207, emotion_loss=0.7604166269302368\n",
      "\n",
      "01_19_23:44:00 Seen so far: 32352 samples\n",
      "\n",
      "01_19_23:44:00 --- 2.3426332473754883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:02 Training loss at epoch 1 step 1020: 2.9811872959136965\n",
      "\n",
      " This round's valence_loss=1.3947334289550781, arousal_loss=1.1848595142364502, emotion_loss=1.2986714839935303\n",
      "\n",
      "01_19_23:44:02 Seen so far: 32672 samples\n",
      "\n",
      "01_19_23:44:02 --- 1.998070478439331 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:04 Training loss at epoch 1 step 1030: 2.8722634077072144\n",
      "\n",
      " This round's valence_loss=0.4762904942035675, arousal_loss=0.3642015755176544, emotion_loss=1.2681190967559814\n",
      "\n",
      "01_19_23:44:04 Seen so far: 32992 samples\n",
      "\n",
      "01_19_23:44:04 --- 2.195693016052246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:06 Training loss at epoch 1 step 1040: 3.1458706140518187\n",
      "\n",
      " This round's valence_loss=0.8615630269050598, arousal_loss=0.7148599624633789, emotion_loss=0.8620219826698303\n",
      "\n",
      "01_19_23:44:06 Seen so far: 33312 samples\n",
      "\n",
      "01_19_23:44:06 --- 2.0323781967163086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:08 Training loss at epoch 1 step 1050: 3.076715421676636\n",
      "\n",
      " This round's valence_loss=1.406677484512329, arousal_loss=1.3524270057678223, emotion_loss=1.122694492340088\n",
      "\n",
      "01_19_23:44:08 Seen so far: 33632 samples\n",
      "\n",
      "01_19_23:44:08 --- 1.9591894149780273 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:10 Training loss at epoch 1 step 1060: 3.3687668085098266\n",
      "\n",
      " This round's valence_loss=1.2119344472885132, arousal_loss=1.060811996459961, emotion_loss=0.8854806423187256\n",
      "\n",
      "01_19_23:44:10 Seen so far: 33952 samples\n",
      "\n",
      "01_19_23:44:10 --- 2.091503858566284 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:12 Training loss at epoch 1 step 1070: 2.9656603574752807\n",
      "\n",
      " This round's valence_loss=1.5071966648101807, arousal_loss=1.3245203495025635, emotion_loss=1.0868113040924072\n",
      "\n",
      "01_19_23:44:12 Seen so far: 34272 samples\n",
      "\n",
      "01_19_23:44:12 --- 2.2350428104400635 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:14 Training loss at epoch 1 step 1080: 2.9779468059539793\n",
      "\n",
      " This round's valence_loss=1.1387994289398193, arousal_loss=0.7763692140579224, emotion_loss=0.4874063730239868\n",
      "\n",
      "01_19_23:44:14 Seen so far: 34592 samples\n",
      "\n",
      "01_19_23:44:14 --- 2.027977705001831 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:16 Training loss at epoch 1 step 1090: 3.1293179512023928\n",
      "\n",
      " This round's valence_loss=1.1763660907745361, arousal_loss=1.044005036354065, emotion_loss=1.0050783157348633\n",
      "\n",
      "01_19_23:44:16 Seen so far: 34912 samples\n",
      "\n",
      "01_19_23:44:16 --- 1.89284086227417 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:18 Training loss at epoch 1 step 1100: 3.481468176841736\n",
      "\n",
      " This round's valence_loss=0.9360333681106567, arousal_loss=0.7244106531143188, emotion_loss=1.2817282676696777\n",
      "\n",
      "01_19_23:44:18 Seen so far: 35232 samples\n",
      "\n",
      "01_19_23:44:18 --- 2.0613300800323486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:20 Training loss at epoch 1 step 1110: 2.7455811142921447\n",
      "\n",
      " This round's valence_loss=0.8552449941635132, arousal_loss=0.6994173526763916, emotion_loss=0.8447872996330261\n",
      "\n",
      "01_19_23:44:20 Seen so far: 35552 samples\n",
      "\n",
      "01_19_23:44:20 --- 1.9551687240600586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:22 Training loss at epoch 1 step 1120: 3.06207822561264\n",
      "\n",
      " This round's valence_loss=1.4070186614990234, arousal_loss=1.3102848529815674, emotion_loss=1.2452261447906494\n",
      "\n",
      "01_19_23:44:22 Seen so far: 35872 samples\n",
      "\n",
      "01_19_23:44:22 --- 1.9168851375579834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:24 Training loss at epoch 1 step 1130: 3.018365716934204\n",
      "\n",
      " This round's valence_loss=1.0579006671905518, arousal_loss=0.9394292235374451, emotion_loss=1.4545657634735107\n",
      "\n",
      "01_19_23:44:24 Seen so far: 36192 samples\n",
      "\n",
      "01_19_23:44:24 --- 2.4453418254852295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:27 Training loss at epoch 1 step 1140: 3.16294150352478\n",
      "\n",
      " This round's valence_loss=1.2508916854858398, arousal_loss=1.0719114542007446, emotion_loss=0.8421738743782043\n",
      "\n",
      "01_19_23:44:27 Seen so far: 36512 samples\n",
      "\n",
      "01_19_23:44:27 --- 2.0977981090545654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:29 Training loss at epoch 1 step 1150: 2.7203296184539796\n",
      "\n",
      " This round's valence_loss=1.1128456592559814, arousal_loss=0.9754301309585571, emotion_loss=0.9839668869972229\n",
      "\n",
      "01_19_23:44:29 Seen so far: 36832 samples\n",
      "\n",
      "01_19_23:44:29 --- 2.004997968673706 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:31 Training loss at epoch 1 step 1160: 3.02794086933136\n",
      "\n",
      " This round's valence_loss=0.7325603365898132, arousal_loss=0.6193910837173462, emotion_loss=1.1574809551239014\n",
      "\n",
      "01_19_23:44:31 Seen so far: 37152 samples\n",
      "\n",
      "01_19_23:44:31 --- 2.013960123062134 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:33 Training loss at epoch 1 step 1170: 2.9661189317703247\n",
      "\n",
      " This round's valence_loss=1.2271232604980469, arousal_loss=1.10847008228302, emotion_loss=0.8097609281539917\n",
      "\n",
      "01_19_23:44:33 Seen so far: 37472 samples\n",
      "\n",
      "01_19_23:44:33 --- 1.9546363353729248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:34 Training loss at epoch 1 step 1180: 3.029578971862793\n",
      "\n",
      " This round's valence_loss=0.8957022428512573, arousal_loss=0.6780956387519836, emotion_loss=0.8019365072250366\n",
      "\n",
      "01_19_23:44:34 Seen so far: 37792 samples\n",
      "\n",
      "01_19_23:44:34 --- 1.9296112060546875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:36 Training loss at epoch 1 step 1190: 2.954421877861023\n",
      "\n",
      " This round's valence_loss=1.339874505996704, arousal_loss=1.1893043518066406, emotion_loss=0.8177227973937988\n",
      "\n",
      "01_19_23:44:36 Seen so far: 38112 samples\n",
      "\n",
      "01_19_23:44:36 --- 1.8996460437774658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:38 Training loss at epoch 1 step 1200: 2.8690842628479003\n",
      "\n",
      " This round's valence_loss=0.7163516283035278, arousal_loss=0.6701270341873169, emotion_loss=0.8973470330238342\n",
      "\n",
      "01_19_23:44:38 Seen so far: 38432 samples\n",
      "\n",
      "01_19_23:44:38 --- 2.1261565685272217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:41 Training loss at epoch 1 step 1210: 2.932378649711609\n",
      "\n",
      " This round's valence_loss=0.8854055404663086, arousal_loss=0.7265478372573853, emotion_loss=0.8366999626159668\n",
      "\n",
      "01_19_23:44:41 Seen so far: 38752 samples\n",
      "\n",
      "01_19_23:44:41 --- 2.1460509300231934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:43 Training loss at epoch 1 step 1220: 3.0342592716217043\n",
      "\n",
      " This round's valence_loss=0.9880397319793701, arousal_loss=0.8338886499404907, emotion_loss=1.0681941509246826\n",
      "\n",
      "01_19_23:44:43 Seen so far: 39072 samples\n",
      "\n",
      "01_19_23:44:43 --- 1.9374792575836182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:45 Training loss at epoch 1 step 1230: 3.1423895597457885\n",
      "\n",
      " This round's valence_loss=0.8413805961608887, arousal_loss=0.7367721796035767, emotion_loss=0.9666709899902344\n",
      "\n",
      "01_19_23:44:45 Seen so far: 39392 samples\n",
      "\n",
      "01_19_23:44:45 --- 2.0338826179504395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:47 Training loss at epoch 1 step 1240: 3.1330132246017457\n",
      "\n",
      " This round's valence_loss=1.1489136219024658, arousal_loss=0.9762871861457825, emotion_loss=1.2578377723693848\n",
      "\n",
      "01_19_23:44:47 Seen so far: 39712 samples\n",
      "\n",
      "01_19_23:44:47 --- 2.2512173652648926 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:49 Training loss at epoch 1 step 1250: 3.3184824705123903\n",
      "\n",
      " This round's valence_loss=1.4430698156356812, arousal_loss=1.185025930404663, emotion_loss=0.8667194247245789\n",
      "\n",
      "01_19_23:44:49 Seen so far: 40032 samples\n",
      "\n",
      "01_19_23:44:49 --- 2.232103109359741 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:51 Training loss at epoch 1 step 1260: 3.273619508743286\n",
      "\n",
      " This round's valence_loss=1.0570180416107178, arousal_loss=0.9941710233688354, emotion_loss=1.057672381401062\n",
      "\n",
      "01_19_23:44:51 Seen so far: 40352 samples\n",
      "\n",
      "01_19_23:44:51 --- 2.1617934703826904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:53 Training loss at epoch 1 step 1270: 3.1013865947723387\n",
      "\n",
      " This round's valence_loss=0.9050910472869873, arousal_loss=0.6718553304672241, emotion_loss=0.9594178199768066\n",
      "\n",
      "01_19_23:44:53 Seen so far: 40672 samples\n",
      "\n",
      "01_19_23:44:53 --- 1.8928701877593994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:55 Training loss at epoch 1 step 1280: 2.8084290504455565\n",
      "\n",
      " This round's valence_loss=0.7451062202453613, arousal_loss=0.6133602857589722, emotion_loss=1.0575246810913086\n",
      "\n",
      "01_19_23:44:55 Seen so far: 40992 samples\n",
      "\n",
      "01_19_23:44:55 --- 2.025364398956299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:57 Training loss at epoch 1 step 1290: 2.982324647903442\n",
      "\n",
      " This round's valence_loss=0.6194249391555786, arousal_loss=0.5977634787559509, emotion_loss=1.1999766826629639\n",
      "\n",
      "01_19_23:44:57 Seen so far: 41312 samples\n",
      "\n",
      "01_19_23:44:57 --- 2.077002763748169 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:44:59 Training loss at epoch 1 step 1300: 3.2988694429397585\n",
      "\n",
      " This round's valence_loss=1.251122236251831, arousal_loss=1.0670340061187744, emotion_loss=1.1157093048095703\n",
      "\n",
      "01_19_23:44:59 Seen so far: 41632 samples\n",
      "\n",
      "01_19_23:44:59 --- 2.1524314880371094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:01 Training loss at epoch 1 step 1310: 2.970529866218567\n",
      "\n",
      " This round's valence_loss=1.244920253753662, arousal_loss=1.0523673295974731, emotion_loss=0.9758126139640808\n",
      "\n",
      "01_19_23:45:01 Seen so far: 41952 samples\n",
      "\n",
      "01_19_23:45:01 --- 1.8939266204833984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:03 Training loss at epoch 1 step 1320: 3.0576851844787596\n",
      "\n",
      " This round's valence_loss=1.5899534225463867, arousal_loss=1.4306113719940186, emotion_loss=0.8751417398452759\n",
      "\n",
      "01_19_23:45:03 Seen so far: 42272 samples\n",
      "\n",
      "01_19_23:45:03 --- 2.000394821166992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:05 Training loss at epoch 1 step 1330: 3.3737159252166746\n",
      "\n",
      " This round's valence_loss=0.9314166307449341, arousal_loss=0.7119085788726807, emotion_loss=0.7980629205703735\n",
      "\n",
      "01_19_23:45:05 Seen so far: 42592 samples\n",
      "\n",
      "01_19_23:45:05 --- 2.1363115310668945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:08 Training loss at epoch 1 step 1340: 3.2502249479293823\n",
      "\n",
      " This round's valence_loss=1.1648029088974, arousal_loss=1.109959363937378, emotion_loss=1.2163563966751099\n",
      "\n",
      "01_19_23:45:08 Seen so far: 42912 samples\n",
      "\n",
      "01_19_23:45:08 --- 2.1951160430908203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:10 Training loss at epoch 1 step 1350: 3.322334337234497\n",
      "\n",
      " This round's valence_loss=1.0839972496032715, arousal_loss=0.9837781190872192, emotion_loss=1.0434868335723877\n",
      "\n",
      "01_19_23:45:10 Seen so far: 43232 samples\n",
      "\n",
      "01_19_23:45:10 --- 2.074681043624878 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:12 Training loss at epoch 1 step 1360: 3.252177917957306\n",
      "\n",
      " This round's valence_loss=0.8641136884689331, arousal_loss=0.7127276062965393, emotion_loss=1.1690778732299805\n",
      "\n",
      "01_19_23:45:12 Seen so far: 43552 samples\n",
      "\n",
      "01_19_23:45:12 --- 2.0909881591796875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:14 Training loss at epoch 1 step 1370: 2.7357503890991213\n",
      "\n",
      " This round's valence_loss=0.5662753582000732, arousal_loss=0.32924023270606995, emotion_loss=0.8820788264274597\n",
      "\n",
      "01_19_23:45:14 Seen so far: 43872 samples\n",
      "\n",
      "01_19_23:45:14 --- 1.8755943775177002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:16 Training loss at epoch 1 step 1380: 3.0875410079956054\n",
      "\n",
      " This round's valence_loss=1.570770263671875, arousal_loss=1.4500069618225098, emotion_loss=0.9887346029281616\n",
      "\n",
      "01_19_23:45:16 Seen so far: 44192 samples\n",
      "\n",
      "01_19_23:45:16 --- 2.068058967590332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:18 Training loss at epoch 1 step 1390: 3.0620527267456055\n",
      "\n",
      " This round's valence_loss=0.997948169708252, arousal_loss=0.8039196729660034, emotion_loss=0.9624924659729004\n",
      "\n",
      "01_19_23:45:18 Seen so far: 44512 samples\n",
      "\n",
      "01_19_23:45:18 --- 2.205789804458618 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:20 Training loss at epoch 1 step 1400: 3.2088574886322023\n",
      "\n",
      " This round's valence_loss=1.8256711959838867, arousal_loss=1.6598763465881348, emotion_loss=0.8360037207603455\n",
      "\n",
      "01_19_23:45:20 Seen so far: 44832 samples\n",
      "\n",
      "01_19_23:45:20 --- 1.9710049629211426 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:22 Training loss at epoch 1 step 1410: 2.8793105363845823\n",
      "\n",
      " This round's valence_loss=0.9895302653312683, arousal_loss=0.8920568823814392, emotion_loss=0.6895947456359863\n",
      "\n",
      "01_19_23:45:22 Seen so far: 45152 samples\n",
      "\n",
      "01_19_23:45:22 --- 1.90413236618042 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:24 Training loss at epoch 1 step 1420: 2.998717021942139\n",
      "\n",
      " This round's valence_loss=1.5706818103790283, arousal_loss=1.4464359283447266, emotion_loss=1.27734375\n",
      "\n",
      "01_19_23:45:24 Seen so far: 45472 samples\n",
      "\n",
      "01_19_23:45:24 --- 2.14265775680542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:26 Training loss at epoch 1 step 1430: 3.2118692874908445\n",
      "\n",
      " This round's valence_loss=1.3636891841888428, arousal_loss=1.2223358154296875, emotion_loss=1.246145486831665\n",
      "\n",
      "01_19_23:45:26 Seen so far: 45792 samples\n",
      "\n",
      "01_19_23:45:26 --- 2.0751540660858154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:28 Training loss at epoch 1 step 1440: 3.2254281997680665\n",
      "\n",
      " This round's valence_loss=1.2399258613586426, arousal_loss=1.059822916984558, emotion_loss=0.8673888444900513\n",
      "\n",
      "01_19_23:45:28 Seen so far: 46112 samples\n",
      "\n",
      "01_19_23:45:28 --- 2.0662484169006348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:30 Training loss at epoch 1 step 1450: 3.23520975112915\n",
      "\n",
      " This round's valence_loss=1.0649876594543457, arousal_loss=0.9703958034515381, emotion_loss=0.936846137046814\n",
      "\n",
      "01_19_23:45:30 Seen so far: 46432 samples\n",
      "\n",
      "01_19_23:45:30 --- 2.001324415206909 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:32 Training loss at epoch 1 step 1460: 3.352759599685669\n",
      "\n",
      " This round's valence_loss=1.0307854413986206, arousal_loss=0.9545205235481262, emotion_loss=1.0997071266174316\n",
      "\n",
      "01_19_23:45:32 Seen so far: 46752 samples\n",
      "\n",
      "01_19_23:45:32 --- 2.136134147644043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:34 Training loss at epoch 1 step 1470: 2.92064483165741\n",
      "\n",
      " This round's valence_loss=0.7042738199234009, arousal_loss=0.44206446409225464, emotion_loss=0.7643666863441467\n",
      "\n",
      "01_19_23:45:34 Seen so far: 47072 samples\n",
      "\n",
      "01_19_23:45:34 --- 2.059617757797241 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:36 Training loss at epoch 1 step 1480: 3.2019737720489503\n",
      "\n",
      " This round's valence_loss=1.122431993484497, arousal_loss=0.9382257461547852, emotion_loss=0.7943696975708008\n",
      "\n",
      "01_19_23:45:36 Seen so far: 47392 samples\n",
      "\n",
      "01_19_23:45:36 --- 1.9771251678466797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:38 Training loss at epoch 1 step 1490: 3.110575485229492\n",
      "\n",
      " This round's valence_loss=0.5618497133255005, arousal_loss=0.4838443398475647, emotion_loss=1.028043270111084\n",
      "\n",
      "01_19_23:45:38 Seen so far: 47712 samples\n",
      "\n",
      "01_19_23:45:38 --- 1.978013038635254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:40 Training loss at epoch 1 step 1500: 2.8485729336738586\n",
      "\n",
      " This round's valence_loss=1.1931746006011963, arousal_loss=1.0593260526657104, emotion_loss=1.264958143234253\n",
      "\n",
      "01_19_23:45:40 Seen so far: 48032 samples\n",
      "\n",
      "01_19_23:45:40 --- 2.139366388320923 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:42 Training loss at epoch 1 step 1510: 2.9610179901123046\n",
      "\n",
      " This round's valence_loss=1.2145061492919922, arousal_loss=1.0692274570465088, emotion_loss=1.1180734634399414\n",
      "\n",
      "01_19_23:45:42 Seen so far: 48352 samples\n",
      "\n",
      "01_19_23:45:42 --- 1.8686540126800537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:44 Training loss at epoch 1 step 1520: 3.3267179489135743\n",
      "\n",
      " This round's valence_loss=1.337430477142334, arousal_loss=1.1726500988006592, emotion_loss=1.0020875930786133\n",
      "\n",
      "01_19_23:45:44 Seen so far: 48672 samples\n",
      "\n",
      "01_19_23:45:44 --- 1.949223518371582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:46 Training loss at epoch 1 step 1530: 3.158931016921997\n",
      "\n",
      " This round's valence_loss=0.9964186549186707, arousal_loss=0.871796727180481, emotion_loss=1.5146903991699219\n",
      "\n",
      "01_19_23:45:46 Seen so far: 48992 samples\n",
      "\n",
      "01_19_23:45:46 --- 2.276400089263916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:49 Training loss at epoch 1 step 1540: 3.17807400226593\n",
      "\n",
      " This round's valence_loss=1.2183111906051636, arousal_loss=1.1244226694107056, emotion_loss=1.1719799041748047\n",
      "\n",
      "01_19_23:45:49 Seen so far: 49312 samples\n",
      "\n",
      "01_19_23:45:49 --- 2.28277587890625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:51 Training loss at epoch 1 step 1550: 3.0134610652923586\n",
      "\n",
      " This round's valence_loss=1.163137674331665, arousal_loss=1.1156423091888428, emotion_loss=1.0714043378829956\n",
      "\n",
      "01_19_23:45:51 Seen so far: 49632 samples\n",
      "\n",
      "01_19_23:45:51 --- 2.1894078254699707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:53 Training loss at epoch 1 step 1560: 2.96572949886322\n",
      "\n",
      " This round's valence_loss=1.3081858158111572, arousal_loss=1.183928370475769, emotion_loss=1.2512657642364502\n",
      "\n",
      "01_19_23:45:53 Seen so far: 49952 samples\n",
      "\n",
      "01_19_23:45:53 --- 1.9514195919036865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:55 Training loss at epoch 1 step 1570: 3.0966994047164915\n",
      "\n",
      " This round's valence_loss=0.9608893990516663, arousal_loss=0.8876072764396667, emotion_loss=1.3388571739196777\n",
      "\n",
      "01_19_23:45:55 Seen so far: 50272 samples\n",
      "\n",
      "01_19_23:45:55 --- 1.8703653812408447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:57 Training loss at epoch 1 step 1580: 2.957734799385071\n",
      "\n",
      " This round's valence_loss=1.5995783805847168, arousal_loss=1.429283618927002, emotion_loss=1.2866679430007935\n",
      "\n",
      "01_19_23:45:57 Seen so far: 50592 samples\n",
      "\n",
      "01_19_23:45:57 --- 2.246729850769043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:45:59 Training loss at epoch 1 step 1590: 2.86631520986557\n",
      "\n",
      " This round's valence_loss=0.7765405178070068, arousal_loss=0.562316358089447, emotion_loss=0.6236971616744995\n",
      "\n",
      "01_19_23:45:59 Seen so far: 50912 samples\n",
      "\n",
      "01_19_23:45:59 --- 1.7892413139343262 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:01 Training loss at epoch 1 step 1600: 3.066074514389038\n",
      "\n",
      " This round's valence_loss=1.2825045585632324, arousal_loss=1.194847822189331, emotion_loss=1.158322811126709\n",
      "\n",
      "01_19_23:46:01 Seen so far: 51232 samples\n",
      "\n",
      "01_19_23:46:01 --- 2.0296947956085205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:03 Training loss at epoch 1 step 1610: 2.95723717212677\n",
      "\n",
      " This round's valence_loss=1.151491403579712, arousal_loss=0.9229540824890137, emotion_loss=0.9768484830856323\n",
      "\n",
      "01_19_23:46:03 Seen so far: 51552 samples\n",
      "\n",
      "01_19_23:46:03 --- 2.0288825035095215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:05 Training loss at epoch 1 step 1620: 2.899153232574463\n",
      "\n",
      " This round's valence_loss=0.8007560968399048, arousal_loss=0.5517393350601196, emotion_loss=0.7920666933059692\n",
      "\n",
      "01_19_23:46:05 Seen so far: 51872 samples\n",
      "\n",
      "01_19_23:46:05 --- 1.833984136581421 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:07 Training loss at epoch 1 step 1630: 3.2151838541030884\n",
      "\n",
      " This round's valence_loss=0.860364556312561, arousal_loss=0.7090698480606079, emotion_loss=0.6790555715560913\n",
      "\n",
      "01_19_23:46:07 Seen so far: 52192 samples\n",
      "\n",
      "01_19_23:46:07 --- 2.0768814086914062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:09 Training loss at epoch 1 step 1640: 2.9580190181732178\n",
      "\n",
      " This round's valence_loss=0.963113009929657, arousal_loss=0.8678951263427734, emotion_loss=1.2346246242523193\n",
      "\n",
      "01_19_23:46:09 Seen so far: 52512 samples\n",
      "\n",
      "01_19_23:46:09 --- 2.020246982574463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:11 Training loss at epoch 1 step 1650: 2.7815520763397217\n",
      "\n",
      " This round's valence_loss=0.9566158056259155, arousal_loss=0.8800468444824219, emotion_loss=1.1024106740951538\n",
      "\n",
      "01_19_23:46:11 Seen so far: 52832 samples\n",
      "\n",
      "01_19_23:46:11 --- 2.1114304065704346 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:13 Training loss at epoch 1 step 1660: 3.1395914554595947\n",
      "\n",
      " This round's valence_loss=1.3307009935379028, arousal_loss=1.2150665521621704, emotion_loss=1.068356990814209\n",
      "\n",
      "01_19_23:46:13 Seen so far: 53152 samples\n",
      "\n",
      "01_19_23:46:13 --- 1.9879484176635742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:15 Training loss at epoch 1 step 1670: 3.1709333658218384\n",
      "\n",
      " This round's valence_loss=0.9043524265289307, arousal_loss=0.689100980758667, emotion_loss=0.8724280595779419\n",
      "\n",
      "01_19_23:46:15 Seen so far: 53472 samples\n",
      "\n",
      "01_19_23:46:15 --- 1.9791319370269775 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:17 Training loss at epoch 1 step 1680: 2.847419595718384\n",
      "\n",
      " This round's valence_loss=0.8072769641876221, arousal_loss=0.6283348798751831, emotion_loss=0.8182436227798462\n",
      "\n",
      "01_19_23:46:17 Seen so far: 53792 samples\n",
      "\n",
      "01_19_23:46:17 --- 2.240835428237915 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:19 Training loss at epoch 1 step 1690: 2.87089056968689\n",
      "\n",
      " This round's valence_loss=0.6892303228378296, arousal_loss=0.50285804271698, emotion_loss=0.879299521446228\n",
      "\n",
      "01_19_23:46:19 Seen so far: 54112 samples\n",
      "\n",
      "01_19_23:46:19 --- 1.7847521305084229 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:21 Training loss at epoch 1 step 1700: 3.0627962589263915\n",
      "\n",
      " This round's valence_loss=1.090592861175537, arousal_loss=0.9376468658447266, emotion_loss=1.0150351524353027\n",
      "\n",
      "01_19_23:46:21 Seen so far: 54432 samples\n",
      "\n",
      "01_19_23:46:21 --- 2.053978204727173 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:23 Training loss at epoch 1 step 1710: 2.944340181350708\n",
      "\n",
      " This round's valence_loss=0.9169303178787231, arousal_loss=0.7322444915771484, emotion_loss=0.772229790687561\n",
      "\n",
      "01_19_23:46:23 Seen so far: 54752 samples\n",
      "\n",
      "01_19_23:46:23 --- 1.9243254661560059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:25 Training loss at epoch 1 step 1720: 3.5922642946243286\n",
      "\n",
      " This round's valence_loss=1.060449242591858, arousal_loss=0.9586219787597656, emotion_loss=0.9978803396224976\n",
      "\n",
      "01_19_23:46:25 Seen so far: 55072 samples\n",
      "\n",
      "01_19_23:46:25 --- 1.8947713375091553 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:27 Training loss at epoch 1 step 1730: 3.2922664642333985\n",
      "\n",
      " This round's valence_loss=1.36030912399292, arousal_loss=1.1871821880340576, emotion_loss=1.1649727821350098\n",
      "\n",
      "01_19_23:46:27 Seen so far: 55392 samples\n",
      "\n",
      "01_19_23:46:27 --- 1.9158196449279785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:29 Training loss at epoch 1 step 1740: 3.1833109617233277\n",
      "\n",
      " This round's valence_loss=0.9645342826843262, arousal_loss=0.8182509541511536, emotion_loss=0.7913410067558289\n",
      "\n",
      "01_19_23:46:29 Seen so far: 55712 samples\n",
      "\n",
      "01_19_23:46:29 --- 2.1141457557678223 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:31 Training loss at epoch 1 step 1750: 2.9102967500686647\n",
      "\n",
      " This round's valence_loss=1.1185601949691772, arousal_loss=0.9606872797012329, emotion_loss=1.2310059070587158\n",
      "\n",
      "01_19_23:46:31 Seen so far: 56032 samples\n",
      "\n",
      "01_19_23:46:31 --- 1.977949857711792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:33 Training loss at epoch 1 step 1760: 3.0598116159439086\n",
      "\n",
      " This round's valence_loss=0.9107880592346191, arousal_loss=0.8665541410446167, emotion_loss=0.992566704750061\n",
      "\n",
      "01_19_23:46:33 Seen so far: 56352 samples\n",
      "\n",
      "01_19_23:46:33 --- 2.030547618865967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:35 Training loss at epoch 1 step 1770: 2.7197444796562196\n",
      "\n",
      " This round's valence_loss=1.103760004043579, arousal_loss=1.0130670070648193, emotion_loss=1.625737190246582\n",
      "\n",
      "01_19_23:46:35 Seen so far: 56672 samples\n",
      "\n",
      "01_19_23:46:35 --- 2.056574583053589 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:37 Training loss at epoch 1 step 1780: 2.9938133001327514\n",
      "\n",
      " This round's valence_loss=0.9280840158462524, arousal_loss=0.826830267906189, emotion_loss=0.8387306928634644\n",
      "\n",
      "01_19_23:46:37 Seen so far: 56992 samples\n",
      "\n",
      "01_19_23:46:37 --- 1.8996965885162354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:39 Training loss at epoch 1 step 1790: 3.0435088634490968\n",
      "\n",
      " This round's valence_loss=0.9840823411941528, arousal_loss=0.8523181676864624, emotion_loss=0.9632726907730103\n",
      "\n",
      "01_19_23:46:39 Seen so far: 57312 samples\n",
      "\n",
      "01_19_23:46:39 --- 2.094045639038086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:41 Training loss at epoch 1 step 1800: 3.3508877992630004\n",
      "\n",
      " This round's valence_loss=1.0188921689987183, arousal_loss=0.8310674428939819, emotion_loss=0.8668086528778076\n",
      "\n",
      "01_19_23:46:41 Seen so far: 57632 samples\n",
      "\n",
      "01_19_23:46:41 --- 2.0707502365112305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:43 Training loss at epoch 1 step 1810: 3.107925283908844\n",
      "\n",
      " This round's valence_loss=1.252511739730835, arousal_loss=1.1292409896850586, emotion_loss=0.9942384958267212\n",
      "\n",
      "01_19_23:46:43 Seen so far: 57952 samples\n",
      "\n",
      "01_19_23:46:43 --- 2.2067196369171143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:45 Training loss at epoch 1 step 1820: 2.789523410797119\n",
      "\n",
      " This round's valence_loss=0.8503749370574951, arousal_loss=0.7284255027770996, emotion_loss=0.9252195358276367\n",
      "\n",
      "01_19_23:46:45 Seen so far: 58272 samples\n",
      "\n",
      "01_19_23:46:45 --- 1.8928146362304688 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:47 Training loss at epoch 1 step 1830: 3.256370115280151\n",
      "\n",
      " This round's valence_loss=0.79654461145401, arousal_loss=0.7002358436584473, emotion_loss=1.3792225122451782\n",
      "\n",
      "01_19_23:46:47 Seen so far: 58592 samples\n",
      "\n",
      "01_19_23:46:47 --- 2.0676326751708984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:49 Training loss at epoch 1 step 1840: 3.2072377443313598\n",
      "\n",
      " This round's valence_loss=1.1035468578338623, arousal_loss=0.9630222320556641, emotion_loss=0.8702358603477478\n",
      "\n",
      "01_19_23:46:49 Seen so far: 58912 samples\n",
      "\n",
      "01_19_23:46:49 --- 1.9212520122528076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:51 Training loss at epoch 1 step 1850: 3.367418098449707\n",
      "\n",
      " This round's valence_loss=1.230701208114624, arousal_loss=1.1074838638305664, emotion_loss=0.904474139213562\n",
      "\n",
      "01_19_23:46:51 Seen so far: 59232 samples\n",
      "\n",
      "01_19_23:46:51 --- 2.1417698860168457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:53 Training loss at epoch 1 step 1860: 3.007017529010773\n",
      "\n",
      " This round's valence_loss=0.8741722106933594, arousal_loss=0.6958204507827759, emotion_loss=1.0274630784988403\n",
      "\n",
      "01_19_23:46:53 Seen so far: 59552 samples\n",
      "\n",
      "01_19_23:46:53 --- 1.7731282711029053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:55 Training loss at epoch 1 step 1870: 3.023912286758423\n",
      "\n",
      " This round's valence_loss=1.6561849117279053, arousal_loss=1.5888588428497314, emotion_loss=1.1640591621398926\n",
      "\n",
      "01_19_23:46:55 Seen so far: 59872 samples\n",
      "\n",
      "01_19_23:46:55 --- 1.9305555820465088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:57 Training loss at epoch 1 step 1880: 3.0760366678237916\n",
      "\n",
      " This round's valence_loss=1.060443639755249, arousal_loss=0.9956976175308228, emotion_loss=0.9319710731506348\n",
      "\n",
      "01_19_23:46:57 Seen so far: 60192 samples\n",
      "\n",
      "01_19_23:46:57 --- 1.983983039855957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:46:59 Training loss at epoch 1 step 1890: 3.1301852464675903\n",
      "\n",
      " This round's valence_loss=1.339834213256836, arousal_loss=1.223043441772461, emotion_loss=1.1277397871017456\n",
      "\n",
      "01_19_23:46:59 Seen so far: 60512 samples\n",
      "\n",
      "01_19_23:46:59 --- 1.9527246952056885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:01 Training loss at epoch 1 step 1900: 2.997960364818573\n",
      "\n",
      " This round's valence_loss=1.2925529479980469, arousal_loss=1.2086234092712402, emotion_loss=0.925951361656189\n",
      "\n",
      "01_19_23:47:01 Seen so far: 60832 samples\n",
      "\n",
      "01_19_23:47:01 --- 1.725966453552246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:03 Training loss at epoch 1 step 1910: 3.206812596321106\n",
      "\n",
      " This round's valence_loss=0.7960860729217529, arousal_loss=0.5823496580123901, emotion_loss=0.9444997310638428\n",
      "\n",
      "01_19_23:47:03 Seen so far: 61152 samples\n",
      "\n",
      "01_19_23:47:03 --- 2.152125835418701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:05 Training loss at epoch 1 step 1920: 2.940036964416504\n",
      "\n",
      " This round's valence_loss=1.5539205074310303, arousal_loss=1.4737533330917358, emotion_loss=1.4631001949310303\n",
      "\n",
      "01_19_23:47:05 Seen so far: 61472 samples\n",
      "\n",
      "01_19_23:47:05 --- 1.8223865032196045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:07 Training loss at epoch 1 step 1930: 2.9538475036621095\n",
      "\n",
      " This round's valence_loss=0.8793517351150513, arousal_loss=0.7098838090896606, emotion_loss=1.1028668880462646\n",
      "\n",
      "01_19_23:47:07 Seen so far: 61792 samples\n",
      "\n",
      "01_19_23:47:07 --- 2.1794378757476807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:09 Training loss at epoch 1 step 1940: 3.097945284843445\n",
      "\n",
      " This round's valence_loss=1.1753008365631104, arousal_loss=0.9608707427978516, emotion_loss=1.1005041599273682\n",
      "\n",
      "01_19_23:47:09 Seen so far: 62112 samples\n",
      "\n",
      "01_19_23:47:09 --- 1.9444642066955566 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:11 Training loss at epoch 1 step 1950: 3.0863773584365846\n",
      "\n",
      " This round's valence_loss=1.2366251945495605, arousal_loss=1.092948317527771, emotion_loss=1.33024001121521\n",
      "\n",
      "01_19_23:47:11 Seen so far: 62432 samples\n",
      "\n",
      "01_19_23:47:11 --- 2.0177407264709473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:13 Training loss at epoch 1 step 1960: 3.225071740150452\n",
      "\n",
      " This round's valence_loss=0.8217818737030029, arousal_loss=0.6125273704528809, emotion_loss=1.1386499404907227\n",
      "\n",
      "01_19_23:47:13 Seen so far: 62752 samples\n",
      "\n",
      "01_19_23:47:13 --- 1.9576213359832764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:15 Training loss at epoch 1 step 1970: 3.0909398794174194\n",
      "\n",
      " This round's valence_loss=1.1879520416259766, arousal_loss=1.0779495239257812, emotion_loss=0.7501315474510193\n",
      "\n",
      "01_19_23:47:15 Seen so far: 63072 samples\n",
      "\n",
      "01_19_23:47:15 --- 2.0800132751464844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:17 Training loss at epoch 1 step 1980: 2.886389946937561\n",
      "\n",
      " This round's valence_loss=1.066144347190857, arousal_loss=0.9802840948104858, emotion_loss=1.1995636224746704\n",
      "\n",
      "01_19_23:47:17 Seen so far: 63392 samples\n",
      "\n",
      "01_19_23:47:17 --- 1.9283909797668457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:19 Training loss at epoch 1 step 1990: 3.318441128730774\n",
      "\n",
      " This round's valence_loss=1.7048733234405518, arousal_loss=1.557677984237671, emotion_loss=1.1330056190490723\n",
      "\n",
      "01_19_23:47:19 Seen so far: 63712 samples\n",
      "\n",
      "01_19_23:47:19 --- 2.096328020095825 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:21 Training loss at epoch 1 step 2000: 3.3437486410140993\n",
      "\n",
      " This round's valence_loss=1.708282709121704, arousal_loss=1.5404739379882812, emotion_loss=0.90528404712677\n",
      "\n",
      "01_19_23:47:21 Seen so far: 64032 samples\n",
      "\n",
      "01_19_23:47:21 --- 2.0791983604431152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:23 Training loss at epoch 1 step 2010: 3.389942836761475\n",
      "\n",
      " This round's valence_loss=1.405134916305542, arousal_loss=1.3190052509307861, emotion_loss=1.1587507724761963\n",
      "\n",
      "01_19_23:47:23 Seen so far: 64352 samples\n",
      "\n",
      "01_19_23:47:23 --- 1.983928918838501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:25 Training loss at epoch 1 step 2020: 2.8170233964920044\n",
      "\n",
      " This round's valence_loss=1.0876070261001587, arousal_loss=0.9370530843734741, emotion_loss=0.913512110710144\n",
      "\n",
      "01_19_23:47:25 Seen so far: 64672 samples\n",
      "\n",
      "01_19_23:47:25 --- 2.0264036655426025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:27 Training loss at epoch 1 step 2030: 3.0287126541137694\n",
      "\n",
      " This round's valence_loss=0.8241870403289795, arousal_loss=0.6034934520721436, emotion_loss=0.7552088499069214\n",
      "\n",
      "01_19_23:47:27 Seen so far: 64992 samples\n",
      "\n",
      "01_19_23:47:27 --- 2.340555191040039 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:29 Training loss at epoch 1 step 2040: 3.0479876518249513\n",
      "\n",
      " This round's valence_loss=0.8520556688308716, arousal_loss=0.7179850339889526, emotion_loss=0.8763530254364014\n",
      "\n",
      "01_19_23:47:29 Seen so far: 65312 samples\n",
      "\n",
      "01_19_23:47:29 --- 2.0383377075195312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:31 Training loss at epoch 1 step 2050: 2.885285472869873\n",
      "\n",
      " This round's valence_loss=0.9525829553604126, arousal_loss=0.8597463369369507, emotion_loss=0.7099002599716187\n",
      "\n",
      "01_19_23:47:31 Seen so far: 65632 samples\n",
      "\n",
      "01_19_23:47:31 --- 2.1784355640411377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:33 Training loss at epoch 1 step 2060: 2.7776709318161013\n",
      "\n",
      " This round's valence_loss=1.1258783340454102, arousal_loss=0.9182624816894531, emotion_loss=1.2113149166107178\n",
      "\n",
      "01_19_23:47:33 Seen so far: 65952 samples\n",
      "\n",
      "01_19_23:47:33 --- 1.9810082912445068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:35 Training loss at epoch 1 step 2070: 3.3350141286849975\n",
      "\n",
      " This round's valence_loss=1.0651733875274658, arousal_loss=0.9833459258079529, emotion_loss=1.2213340997695923\n",
      "\n",
      "01_19_23:47:35 Seen so far: 66272 samples\n",
      "\n",
      "01_19_23:47:35 --- 1.8708758354187012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:37 Training loss at epoch 1 step 2080: 3.3537545919418337\n",
      "\n",
      " This round's valence_loss=1.312260627746582, arousal_loss=1.067878246307373, emotion_loss=1.1640576124191284\n",
      "\n",
      "01_19_23:47:37 Seen so far: 66592 samples\n",
      "\n",
      "01_19_23:47:37 --- 2.2056219577789307 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:39 Training loss at epoch 1 step 2090: 3.323430132865906\n",
      "\n",
      " This round's valence_loss=1.2790127992630005, arousal_loss=1.053516149520874, emotion_loss=0.9136795997619629\n",
      "\n",
      "01_19_23:47:39 Seen so far: 66912 samples\n",
      "\n",
      "01_19_23:47:39 --- 1.874182939529419 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:41 Training loss at epoch 1 step 2100: 3.1303639888763426\n",
      "\n",
      " This round's valence_loss=0.6388225555419922, arousal_loss=0.5543167591094971, emotion_loss=1.4141666889190674\n",
      "\n",
      "01_19_23:47:41 Seen so far: 67232 samples\n",
      "\n",
      "01_19_23:47:41 --- 1.747459888458252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:43 Training loss at epoch 1 step 2110: 3.1825732707977297\n",
      "\n",
      " This round's valence_loss=1.4583935737609863, arousal_loss=1.3345787525177002, emotion_loss=1.2831376791000366\n",
      "\n",
      "01_19_23:47:43 Seen so far: 67552 samples\n",
      "\n",
      "01_19_23:47:43 --- 1.9968459606170654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:45 Training loss at epoch 1 step 2120: 3.1570656299591064\n",
      "\n",
      " This round's valence_loss=1.7855371236801147, arousal_loss=1.6884366273880005, emotion_loss=1.0670039653778076\n",
      "\n",
      "01_19_23:47:45 Seen so far: 67872 samples\n",
      "\n",
      "01_19_23:47:45 --- 2.0527894496917725 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:47 Training loss at epoch 1 step 2130: 3.5432960987091064\n",
      "\n",
      " This round's valence_loss=0.7074614763259888, arousal_loss=0.6090860366821289, emotion_loss=1.3033158779144287\n",
      "\n",
      "01_19_23:47:47 Seen so far: 68192 samples\n",
      "\n",
      "01_19_23:47:47 --- 2.008216381072998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:49 Training loss at epoch 1 step 2140: 3.62332022190094\n",
      "\n",
      " This round's valence_loss=1.0478723049163818, arousal_loss=0.8372762799263, emotion_loss=1.4952716827392578\n",
      "\n",
      "01_19_23:47:49 Seen so far: 68512 samples\n",
      "\n",
      "01_19_23:47:49 --- 2.132686138153076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:51 Training loss at epoch 1 step 2150: 3.2919820308685304\n",
      "\n",
      " This round's valence_loss=1.4579577445983887, arousal_loss=1.3461799621582031, emotion_loss=1.0705246925354004\n",
      "\n",
      "01_19_23:47:51 Seen so far: 68832 samples\n",
      "\n",
      "01_19_23:47:51 --- 1.9740636348724365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:53 Training loss at epoch 1 step 2160: 3.195124363899231\n",
      "\n",
      " This round's valence_loss=1.3399403095245361, arousal_loss=1.198429822921753, emotion_loss=1.0828721523284912\n",
      "\n",
      "01_19_23:47:53 Seen so far: 69152 samples\n",
      "\n",
      "01_19_23:47:53 --- 1.9895563125610352 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:55 Training loss at epoch 1 step 2170: 2.873174238204956\n",
      "\n",
      " This round's valence_loss=1.0252726078033447, arousal_loss=0.825391411781311, emotion_loss=1.1036665439605713\n",
      "\n",
      "01_19_23:47:55 Seen so far: 69472 samples\n",
      "\n",
      "01_19_23:47:55 --- 1.8426430225372314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:57 Training loss at epoch 1 step 2180: 3.301955986022949\n",
      "\n",
      " This round's valence_loss=1.4223589897155762, arousal_loss=1.3545811176300049, emotion_loss=1.1262640953063965\n",
      "\n",
      "01_19_23:47:57 Seen so far: 69792 samples\n",
      "\n",
      "01_19_23:47:57 --- 2.0466580390930176 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:47:59 Training loss at epoch 1 step 2190: 2.99915269613266\n",
      "\n",
      " This round's valence_loss=0.9979508519172668, arousal_loss=0.8468139171600342, emotion_loss=0.6723495721817017\n",
      "\n",
      "01_19_23:47:59 Seen so far: 70112 samples\n",
      "\n",
      "01_19_23:47:59 --- 1.975531816482544 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:01 Training loss at epoch 1 step 2200: 2.548357880115509\n",
      "\n",
      " This round's valence_loss=1.082348346710205, arousal_loss=0.9264156818389893, emotion_loss=0.845154881477356\n",
      "\n",
      "01_19_23:48:01 Seen so far: 70432 samples\n",
      "\n",
      "01_19_23:48:01 --- 2.1673245429992676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:03 Training loss at epoch 1 step 2210: 3.0223444938659667\n",
      "\n",
      " This round's valence_loss=0.8723759651184082, arousal_loss=0.72776859998703, emotion_loss=0.8334541320800781\n",
      "\n",
      "01_19_23:48:03 Seen so far: 70752 samples\n",
      "\n",
      "01_19_23:48:03 --- 2.1902363300323486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:06 Training loss at epoch 1 step 2220: 3.0226523160934446\n",
      "\n",
      " This round's valence_loss=0.9852513074874878, arousal_loss=0.8811942338943481, emotion_loss=0.8216773271560669\n",
      "\n",
      "01_19_23:48:06 Seen so far: 71072 samples\n",
      "\n",
      "01_19_23:48:06 --- 2.2270750999450684 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:08 Training loss at epoch 1 step 2230: 3.306377410888672\n",
      "\n",
      " This round's valence_loss=1.4605580568313599, arousal_loss=1.3930625915527344, emotion_loss=1.1037676334381104\n",
      "\n",
      "01_19_23:48:08 Seen so far: 71392 samples\n",
      "\n",
      "01_19_23:48:08 --- 2.061192750930786 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:10 Training loss at epoch 1 step 2240: 2.8324344635009764\n",
      "\n",
      " This round's valence_loss=0.575778603553772, arousal_loss=0.3376949727535248, emotion_loss=1.099378228187561\n",
      "\n",
      "01_19_23:48:10 Seen so far: 71712 samples\n",
      "\n",
      "01_19_23:48:10 --- 2.0480141639709473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:12 Training loss at epoch 1 step 2250: 3.287209963798523\n",
      "\n",
      " This round's valence_loss=0.8254150152206421, arousal_loss=0.742280125617981, emotion_loss=1.2631049156188965\n",
      "\n",
      "01_19_23:48:12 Seen so far: 72032 samples\n",
      "\n",
      "01_19_23:48:12 --- 2.1515588760375977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:14 Training loss at epoch 1 step 2260: 2.9013214826583864\n",
      "\n",
      " This round's valence_loss=1.2151515483856201, arousal_loss=1.134164810180664, emotion_loss=1.0940009355545044\n",
      "\n",
      "01_19_23:48:14 Seen so far: 72352 samples\n",
      "\n",
      "01_19_23:48:14 --- 2.0959746837615967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:16 Training loss at epoch 1 step 2270: 3.1614832639694215\n",
      "\n",
      " This round's valence_loss=1.2704577445983887, arousal_loss=1.0717953443527222, emotion_loss=1.1849886178970337\n",
      "\n",
      "01_19_23:48:16 Seen so far: 72672 samples\n",
      "\n",
      "01_19_23:48:16 --- 2.014688730239868 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:18 Training loss at epoch 1 step 2280: 3.0059621810913084\n",
      "\n",
      " This round's valence_loss=1.109771966934204, arousal_loss=0.9573956727981567, emotion_loss=1.0292028188705444\n",
      "\n",
      "01_19_23:48:18 Seen so far: 72992 samples\n",
      "\n",
      "01_19_23:48:18 --- 2.0898845195770264 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:20 Training loss at epoch 1 step 2290: 3.3271222352981566\n",
      "\n",
      " This round's valence_loss=1.217966079711914, arousal_loss=1.1060729026794434, emotion_loss=1.2326991558074951\n",
      "\n",
      "01_19_23:48:20 Seen so far: 73312 samples\n",
      "\n",
      "01_19_23:48:20 --- 1.8296115398406982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:22 Training loss at epoch 1 step 2300: 3.121697115898132\n",
      "\n",
      " This round's valence_loss=0.8381756544113159, arousal_loss=0.6864211559295654, emotion_loss=1.170753002166748\n",
      "\n",
      "01_19_23:48:22 Seen so far: 73632 samples\n",
      "\n",
      "01_19_23:48:22 --- 1.9024639129638672 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:24 Training loss at epoch 1 step 2310: 2.815976083278656\n",
      "\n",
      " This round's valence_loss=1.2231481075286865, arousal_loss=1.1127614974975586, emotion_loss=0.9289572238922119\n",
      "\n",
      "01_19_23:48:24 Seen so far: 73952 samples\n",
      "\n",
      "01_19_23:48:24 --- 1.8982954025268555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:26 Training loss at epoch 1 step 2320: 2.8590338468551635\n",
      "\n",
      " This round's valence_loss=0.8674945831298828, arousal_loss=0.7253209352493286, emotion_loss=1.0097228288650513\n",
      "\n",
      "01_19_23:48:26 Seen so far: 74272 samples\n",
      "\n",
      "01_19_23:48:26 --- 2.136509895324707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:28 Training loss at epoch 1 step 2330: 3.142008662223816\n",
      "\n",
      " This round's valence_loss=0.9978936314582825, arousal_loss=0.8754889965057373, emotion_loss=0.9135382175445557\n",
      "\n",
      "01_19_23:48:28 Seen so far: 74592 samples\n",
      "\n",
      "01_19_23:48:28 --- 2.071211576461792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:30 Training loss at epoch 1 step 2340: 3.1746120691299438\n",
      "\n",
      " This round's valence_loss=1.6290967464447021, arousal_loss=1.5660595893859863, emotion_loss=0.9181280136108398\n",
      "\n",
      "01_19_23:48:30 Seen so far: 74912 samples\n",
      "\n",
      "01_19_23:48:30 --- 2.152056932449341 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:32 Training loss at epoch 1 step 2350: 3.0165998458862306\n",
      "\n",
      " This round's valence_loss=0.9993568658828735, arousal_loss=0.8346724510192871, emotion_loss=0.7363576889038086\n",
      "\n",
      "01_19_23:48:32 Seen so far: 75232 samples\n",
      "\n",
      "01_19_23:48:32 --- 2.0593831539154053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:34 Training loss at epoch 1 step 2360: 3.1533596992492674\n",
      "\n",
      " This round's valence_loss=1.3408223390579224, arousal_loss=1.2045620679855347, emotion_loss=1.313793420791626\n",
      "\n",
      "01_19_23:48:34 Seen so far: 75552 samples\n",
      "\n",
      "01_19_23:48:34 --- 1.9605181217193604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:36 Training loss at epoch 1 step 2370: 2.8263644099235536\n",
      "\n",
      " This round's valence_loss=0.5956448316574097, arousal_loss=0.33087727427482605, emotion_loss=0.8194196224212646\n",
      "\n",
      "01_19_23:48:36 Seen so far: 75872 samples\n",
      "\n",
      "01_19_23:48:36 --- 2.014446496963501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:38 Training loss at epoch 1 step 2380: 2.710425853729248\n",
      "\n",
      " This round's valence_loss=0.9670616984367371, arousal_loss=0.8002451658248901, emotion_loss=0.840353786945343\n",
      "\n",
      "01_19_23:48:38 Seen so far: 76192 samples\n",
      "\n",
      "01_19_23:48:38 --- 1.8907968997955322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:40 Training loss at epoch 1 step 2390: 3.3966810941696166\n",
      "\n",
      " This round's valence_loss=1.0921080112457275, arousal_loss=0.9598791599273682, emotion_loss=0.7621349692344666\n",
      "\n",
      "01_19_23:48:40 Seen so far: 76512 samples\n",
      "\n",
      "01_19_23:48:40 --- 1.8914828300476074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:42 Training loss at epoch 1 step 2400: 2.8453410863876343\n",
      "\n",
      " This round's valence_loss=0.8727248311042786, arousal_loss=0.7575187683105469, emotion_loss=0.739554226398468\n",
      "\n",
      "01_19_23:48:42 Seen so far: 76832 samples\n",
      "\n",
      "01_19_23:48:42 --- 2.0578243732452393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:44 Training loss at epoch 1 step 2410: 3.0258866786956786\n",
      "\n",
      " This round's valence_loss=0.985649824142456, arousal_loss=0.7915010452270508, emotion_loss=0.7145938277244568\n",
      "\n",
      "01_19_23:48:44 Seen so far: 77152 samples\n",
      "\n",
      "01_19_23:48:44 --- 2.0142977237701416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:46 Training loss at epoch 1 step 2420: 3.1688350677490233\n",
      "\n",
      " This round's valence_loss=1.4243426322937012, arousal_loss=1.3213520050048828, emotion_loss=0.8548252582550049\n",
      "\n",
      "01_19_23:48:46 Seen so far: 77472 samples\n",
      "\n",
      "01_19_23:48:46 --- 2.2277727127075195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:48 Training loss at epoch 1 step 2430: 3.312284994125366\n",
      "\n",
      " This round's valence_loss=1.2246677875518799, arousal_loss=1.0990941524505615, emotion_loss=1.0848004817962646\n",
      "\n",
      "01_19_23:48:48 Seen so far: 77792 samples\n",
      "\n",
      "01_19_23:48:48 --- 2.0097880363464355 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:50 Training loss at epoch 1 step 2440: 3.152394425868988\n",
      "\n",
      " This round's valence_loss=0.9267839789390564, arousal_loss=0.8054612874984741, emotion_loss=1.1397361755371094\n",
      "\n",
      "01_19_23:48:50 Seen so far: 78112 samples\n",
      "\n",
      "01_19_23:48:50 --- 1.9158298969268799 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:52 Training loss at epoch 1 step 2450: 3.0919715642929075\n",
      "\n",
      " This round's valence_loss=0.8787206411361694, arousal_loss=0.7534475326538086, emotion_loss=1.216446876525879\n",
      "\n",
      "01_19_23:48:52 Seen so far: 78432 samples\n",
      "\n",
      "01_19_23:48:52 --- 2.021770715713501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:54 Training loss at epoch 1 step 2460: 3.0764989376068117\n",
      "\n",
      " This round's valence_loss=1.1185390949249268, arousal_loss=0.961675763130188, emotion_loss=1.172998070716858\n",
      "\n",
      "01_19_23:48:54 Seen so far: 78752 samples\n",
      "\n",
      "01_19_23:48:54 --- 2.030369281768799 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:56 Training loss at epoch 1 step 2470: 3.1178398370742797\n",
      "\n",
      " This round's valence_loss=0.9851983785629272, arousal_loss=0.8639041781425476, emotion_loss=1.1706656217575073\n",
      "\n",
      "01_19_23:48:56 Seen so far: 79072 samples\n",
      "\n",
      "01_19_23:48:56 --- 2.160193681716919 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:48:58 Training loss at epoch 1 step 2480: 3.005640482902527\n",
      "\n",
      " This round's valence_loss=0.9804391264915466, arousal_loss=0.8465508222579956, emotion_loss=0.9776523113250732\n",
      "\n",
      "01_19_23:48:58 Seen so far: 79392 samples\n",
      "\n",
      "01_19_23:48:58 --- 2.078561544418335 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:00 Training loss at epoch 1 step 2490: 2.4863032341003417\n",
      "\n",
      " This round's valence_loss=0.8789318799972534, arousal_loss=0.7096610069274902, emotion_loss=0.6746286153793335\n",
      "\n",
      "01_19_23:49:00 Seen so far: 79712 samples\n",
      "\n",
      "01_19_23:49:00 --- 2.015986680984497 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:02 Training loss at epoch 1 step 2500: 3.248194766044617\n",
      "\n",
      " This round's valence_loss=1.1594297885894775, arousal_loss=0.9064268469810486, emotion_loss=0.8396452069282532\n",
      "\n",
      "01_19_23:49:02 Seen so far: 80032 samples\n",
      "\n",
      "01_19_23:49:02 --- 1.9116718769073486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:04 Training loss at epoch 1 step 2510: 3.416611647605896\n",
      "\n",
      " This round's valence_loss=1.121093988418579, arousal_loss=0.9602887630462646, emotion_loss=1.0385236740112305\n",
      "\n",
      "01_19_23:49:04 Seen so far: 80352 samples\n",
      "\n",
      "01_19_23:49:04 --- 2.0027031898498535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:06 Training loss at epoch 1 step 2520: 3.2549949407577516\n",
      "\n",
      " This round's valence_loss=1.3249170780181885, arousal_loss=1.2291138172149658, emotion_loss=0.9989772439002991\n",
      "\n",
      "01_19_23:49:06 Seen so far: 80672 samples\n",
      "\n",
      "01_19_23:49:06 --- 2.075918674468994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:08 Training loss at epoch 1 step 2530: 3.1564281821250915\n",
      "\n",
      " This round's valence_loss=1.0183205604553223, arousal_loss=0.8098763227462769, emotion_loss=1.1085894107818604\n",
      "\n",
      "01_19_23:49:08 Seen so far: 80992 samples\n",
      "\n",
      "01_19_23:49:08 --- 2.023510694503784 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:10 Training loss at epoch 1 step 2540: 3.1322744369506834\n",
      "\n",
      " This round's valence_loss=0.9907686710357666, arousal_loss=0.8440788984298706, emotion_loss=0.9968841075897217\n",
      "\n",
      "01_19_23:49:10 Seen so far: 81312 samples\n",
      "\n",
      "01_19_23:49:10 --- 2.002147674560547 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:12 Training loss at epoch 1 step 2550: 3.204047703742981\n",
      "\n",
      " This round's valence_loss=1.4262900352478027, arousal_loss=1.305861473083496, emotion_loss=1.2226338386535645\n",
      "\n",
      "01_19_23:49:12 Seen so far: 81632 samples\n",
      "\n",
      "01_19_23:49:12 --- 1.9629898071289062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:14 Training loss at epoch 1 step 2560: 2.9586233854293824\n",
      "\n",
      " This round's valence_loss=0.9324244260787964, arousal_loss=0.715389609336853, emotion_loss=1.102308988571167\n",
      "\n",
      "01_19_23:49:14 Seen so far: 81952 samples\n",
      "\n",
      "01_19_23:49:14 --- 1.9099674224853516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:16 Training loss at epoch 1 step 2570: 3.098840928077698\n",
      "\n",
      " This round's valence_loss=0.8015464544296265, arousal_loss=0.6312922239303589, emotion_loss=0.9287989139556885\n",
      "\n",
      "01_19_23:49:16 Seen so far: 82272 samples\n",
      "\n",
      "01_19_23:49:16 --- 1.8961188793182373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:18 Training loss at epoch 1 step 2580: 2.7723362922668455\n",
      "\n",
      " This round's valence_loss=1.591928482055664, arousal_loss=1.4397331476211548, emotion_loss=0.8773037791252136\n",
      "\n",
      "01_19_23:49:18 Seen so far: 82592 samples\n",
      "\n",
      "01_19_23:49:18 --- 1.8439123630523682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:20 Training loss at epoch 1 step 2590: 3.0904666662216185\n",
      "\n",
      " This round's valence_loss=0.8997273445129395, arousal_loss=0.6703604459762573, emotion_loss=0.7045853137969971\n",
      "\n",
      "01_19_23:49:20 Seen so far: 82912 samples\n",
      "\n",
      "01_19_23:49:20 --- 1.9293737411499023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:22 Training loss at epoch 1 step 2600: 2.940087687969208\n",
      "\n",
      " This round's valence_loss=0.5268923044204712, arousal_loss=0.33925506472587585, emotion_loss=0.9877252578735352\n",
      "\n",
      "01_19_23:49:22 Seen so far: 83232 samples\n",
      "\n",
      "01_19_23:49:22 --- 2.3419809341430664 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:24 Training loss at epoch 1 step 2610: 2.9814441919326784\n",
      "\n",
      " This round's valence_loss=1.0635838508605957, arousal_loss=0.9394274353981018, emotion_loss=0.9345670938491821\n",
      "\n",
      "01_19_23:49:24 Seen so far: 83552 samples\n",
      "\n",
      "01_19_23:49:24 --- 1.8580772876739502 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:26 Training loss at epoch 1 step 2620: 3.4915401697158814\n",
      "\n",
      " This round's valence_loss=1.4979074001312256, arousal_loss=1.3363251686096191, emotion_loss=1.0434844493865967\n",
      "\n",
      "01_19_23:49:26 Seen so far: 83872 samples\n",
      "\n",
      "01_19_23:49:26 --- 2.003129243850708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:28 Training loss at epoch 1 step 2630: 2.843175768852234\n",
      "\n",
      " This round's valence_loss=1.1252110004425049, arousal_loss=0.999800443649292, emotion_loss=1.1621394157409668\n",
      "\n",
      "01_19_23:49:28 Seen so far: 84192 samples\n",
      "\n",
      "01_19_23:49:28 --- 2.1631031036376953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:31 Training loss at epoch 1 step 2640: 3.1064695596694945\n",
      "\n",
      " This round's valence_loss=1.0521056652069092, arousal_loss=0.8322291374206543, emotion_loss=0.7798866629600525\n",
      "\n",
      "01_19_23:49:31 Seen so far: 84512 samples\n",
      "\n",
      "01_19_23:49:31 --- 2.095551013946533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:33 Training loss at epoch 1 step 2650: 2.9591876745223997\n",
      "\n",
      " This round's valence_loss=0.869102954864502, arousal_loss=0.6824907064437866, emotion_loss=1.033005714416504\n",
      "\n",
      "01_19_23:49:33 Seen so far: 84832 samples\n",
      "\n",
      "01_19_23:49:33 --- 2.1407523155212402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:35 Training loss at epoch 1 step 2660: 3.0745497226715086\n",
      "\n",
      " This round's valence_loss=1.147049903869629, arousal_loss=0.9345942139625549, emotion_loss=0.9170998930931091\n",
      "\n",
      "01_19_23:49:35 Seen so far: 85152 samples\n",
      "\n",
      "01_19_23:49:35 --- 2.28775954246521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:37 Training loss at epoch 1 step 2670: 3.205035352706909\n",
      "\n",
      " This round's valence_loss=1.0071768760681152, arousal_loss=0.6891552805900574, emotion_loss=0.7575881481170654\n",
      "\n",
      "01_19_23:49:37 Seen so far: 85472 samples\n",
      "\n",
      "01_19_23:49:37 --- 2.147963523864746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:39 Training loss at epoch 1 step 2680: 3.1261138677597047\n",
      "\n",
      " This round's valence_loss=1.2271504402160645, arousal_loss=1.051491379737854, emotion_loss=0.7829702496528625\n",
      "\n",
      "01_19_23:49:39 Seen so far: 85792 samples\n",
      "\n",
      "01_19_23:49:39 --- 1.8854405879974365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:41 Training loss at epoch 1 step 2690: 2.949343466758728\n",
      "\n",
      " This round's valence_loss=1.2534074783325195, arousal_loss=1.0465184450149536, emotion_loss=0.7948226928710938\n",
      "\n",
      "01_19_23:49:41 Seen so far: 86112 samples\n",
      "\n",
      "01_19_23:49:41 --- 1.884857177734375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:43 Training loss at epoch 1 step 2700: 3.1806668996810914\n",
      "\n",
      " This round's valence_loss=0.9257117509841919, arousal_loss=0.8283833265304565, emotion_loss=0.9359778761863708\n",
      "\n",
      "01_19_23:49:43 Seen so far: 86432 samples\n",
      "\n",
      "01_19_23:49:43 --- 1.9400155544281006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:45 Training loss at epoch 1 step 2710: 3.4340171098709105\n",
      "\n",
      " This round's valence_loss=1.3499525785446167, arousal_loss=1.2067029476165771, emotion_loss=1.1003625392913818\n",
      "\n",
      "01_19_23:49:45 Seen so far: 86752 samples\n",
      "\n",
      "01_19_23:49:45 --- 1.8792409896850586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:47 Training loss at epoch 1 step 2720: 3.0192641496658323\n",
      "\n",
      " This round's valence_loss=1.4439618587493896, arousal_loss=1.3266345262527466, emotion_loss=0.7340258955955505\n",
      "\n",
      "01_19_23:49:47 Seen so far: 87072 samples\n",
      "\n",
      "01_19_23:49:47 --- 1.9748342037200928 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:49 Training loss at epoch 1 step 2730: 3.169957685470581\n",
      "\n",
      " This round's valence_loss=0.8987767696380615, arousal_loss=0.8413442969322205, emotion_loss=1.3021607398986816\n",
      "\n",
      "01_19_23:49:49 Seen so far: 87392 samples\n",
      "\n",
      "01_19_23:49:49 --- 1.9181783199310303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:51 Training loss at epoch 1 step 2740: 3.1928317308425904\n",
      "\n",
      " This round's valence_loss=1.2881767749786377, arousal_loss=1.1754558086395264, emotion_loss=1.0036495923995972\n",
      "\n",
      "01_19_23:49:51 Seen so far: 87712 samples\n",
      "\n",
      "01_19_23:49:51 --- 2.0789830684661865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:53 Training loss at epoch 1 step 2750: 3.3957958698272703\n",
      "\n",
      " This round's valence_loss=1.3636255264282227, arousal_loss=1.1888689994812012, emotion_loss=0.9973641633987427\n",
      "\n",
      "01_19_23:49:53 Seen so far: 88032 samples\n",
      "\n",
      "01_19_23:49:53 --- 2.099963903427124 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:55 Training loss at epoch 1 step 2760: 2.986468195915222\n",
      "\n",
      " This round's valence_loss=1.164724588394165, arousal_loss=1.074446439743042, emotion_loss=1.0309364795684814\n",
      "\n",
      "01_19_23:49:55 Seen so far: 88352 samples\n",
      "\n",
      "01_19_23:49:55 --- 1.8945095539093018 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:57 Training loss at epoch 1 step 2770: 3.142861843109131\n",
      "\n",
      " This round's valence_loss=0.9693998694419861, arousal_loss=0.8065274953842163, emotion_loss=0.8953381180763245\n",
      "\n",
      "01_19_23:49:57 Seen so far: 88672 samples\n",
      "\n",
      "01_19_23:49:57 --- 1.9731030464172363 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:49:59 Training loss at epoch 1 step 2780: 3.0462520837783815\n",
      "\n",
      " This round's valence_loss=1.3534047603607178, arousal_loss=1.2209067344665527, emotion_loss=1.134620189666748\n",
      "\n",
      "01_19_23:49:59 Seen so far: 88992 samples\n",
      "\n",
      "01_19_23:49:59 --- 2.068046808242798 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:01 Training loss at epoch 1 step 2790: 3.2766896724700927\n",
      "\n",
      " This round's valence_loss=1.1916718482971191, arousal_loss=1.1121063232421875, emotion_loss=1.2221553325653076\n",
      "\n",
      "01_19_23:50:01 Seen so far: 89312 samples\n",
      "\n",
      "01_19_23:50:01 --- 2.1129472255706787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:03 Training loss at epoch 1 step 2800: 3.1330228090286254\n",
      "\n",
      " This round's valence_loss=1.1783866882324219, arousal_loss=1.0862728357315063, emotion_loss=1.065794587135315\n",
      "\n",
      "01_19_23:50:03 Seen so far: 89632 samples\n",
      "\n",
      "01_19_23:50:03 --- 1.9780936241149902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:05 Training loss at epoch 1 step 2810: 2.974901580810547\n",
      "\n",
      " This round's valence_loss=1.265442132949829, arousal_loss=1.0724384784698486, emotion_loss=0.7939268350601196\n",
      "\n",
      "01_19_23:50:05 Seen so far: 89952 samples\n",
      "\n",
      "01_19_23:50:05 --- 2.1417112350463867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:07 Training loss at epoch 1 step 2820: 2.818657410144806\n",
      "\n",
      " This round's valence_loss=0.43862271308898926, arousal_loss=0.36934447288513184, emotion_loss=1.1647111177444458\n",
      "\n",
      "01_19_23:50:07 Seen so far: 90272 samples\n",
      "\n",
      "01_19_23:50:07 --- 2.1795129776000977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:09 Training loss at epoch 1 step 2830: 3.2686217546463014\n",
      "\n",
      " This round's valence_loss=1.6424179077148438, arousal_loss=1.464745044708252, emotion_loss=1.16584312915802\n",
      "\n",
      "01_19_23:50:09 Seen so far: 90592 samples\n",
      "\n",
      "01_19_23:50:09 --- 1.817248821258545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:11 Training loss at epoch 1 step 2840: 2.9003740787506103\n",
      "\n",
      " This round's valence_loss=1.094321846961975, arousal_loss=0.9583117961883545, emotion_loss=0.7483408451080322\n",
      "\n",
      "01_19_23:50:11 Seen so far: 90912 samples\n",
      "\n",
      "01_19_23:50:11 --- 1.9276070594787598 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:13 Training loss at epoch 1 step 2850: 3.1844249725341798\n",
      "\n",
      " This round's valence_loss=0.7962300777435303, arousal_loss=0.5729670524597168, emotion_loss=0.952852189540863\n",
      "\n",
      "01_19_23:50:13 Seen so far: 91232 samples\n",
      "\n",
      "01_19_23:50:13 --- 2.0644524097442627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:15 Training loss at epoch 1 step 2860: 3.183751344680786\n",
      "\n",
      " This round's valence_loss=1.1142148971557617, arousal_loss=1.019054651260376, emotion_loss=1.3127851486206055\n",
      "\n",
      "01_19_23:50:15 Seen so far: 91552 samples\n",
      "\n",
      "01_19_23:50:15 --- 1.840118646621704 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:17 Training loss at epoch 1 step 2870: 3.1638723373413087\n",
      "\n",
      " This round's valence_loss=1.3884291648864746, arousal_loss=1.3401881456375122, emotion_loss=1.2071601152420044\n",
      "\n",
      "01_19_23:50:17 Seen so far: 91872 samples\n",
      "\n",
      "01_19_23:50:17 --- 2.1327126026153564 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:19 Training loss at epoch 1 step 2880: 3.497137522697449\n",
      "\n",
      " This round's valence_loss=1.422268271446228, arousal_loss=1.3492074012756348, emotion_loss=1.1079163551330566\n",
      "\n",
      "01_19_23:50:19 Seen so far: 92192 samples\n",
      "\n",
      "01_19_23:50:19 --- 1.98073148727417 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:21 Training loss at epoch 1 step 2890: 3.081682586669922\n",
      "\n",
      " This round's valence_loss=1.5646765232086182, arousal_loss=1.4881906509399414, emotion_loss=1.2074061632156372\n",
      "\n",
      "01_19_23:50:21 Seen so far: 92512 samples\n",
      "\n",
      "01_19_23:50:21 --- 2.1717522144317627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:23 Training loss at epoch 1 step 2900: 2.9895201683044434\n",
      "\n",
      " This round's valence_loss=1.425841212272644, arousal_loss=1.3201793432235718, emotion_loss=1.070624589920044\n",
      "\n",
      "01_19_23:50:23 Seen so far: 92832 samples\n",
      "\n",
      "01_19_23:50:23 --- 2.1907613277435303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:25 Training loss at epoch 1 step 2910: 3.2136337041854857\n",
      "\n",
      " This round's valence_loss=1.3096108436584473, arousal_loss=1.2343165874481201, emotion_loss=1.0594401359558105\n",
      "\n",
      "01_19_23:50:25 Seen so far: 93152 samples\n",
      "\n",
      "01_19_23:50:25 --- 2.1901636123657227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:28 Training loss at epoch 1 step 2920: 2.9258710861206056\n",
      "\n",
      " This round's valence_loss=1.6655062437057495, arousal_loss=1.5797593593597412, emotion_loss=0.8356785774230957\n",
      "\n",
      "01_19_23:50:28 Seen so far: 93472 samples\n",
      "\n",
      "01_19_23:50:28 --- 2.4188497066497803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:30 Training loss at epoch 1 step 2930: 3.2108730554580687\n",
      "\n",
      " This round's valence_loss=1.1503918170928955, arousal_loss=1.1105213165283203, emotion_loss=1.2148313522338867\n",
      "\n",
      "01_19_23:50:30 Seen so far: 93792 samples\n",
      "\n",
      "01_19_23:50:30 --- 1.9143085479736328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:32 Training loss at epoch 1 step 2940: 2.6605822086334228\n",
      "\n",
      " This round's valence_loss=1.1148579120635986, arousal_loss=0.9627895355224609, emotion_loss=0.8523421287536621\n",
      "\n",
      "01_19_23:50:32 Seen so far: 94112 samples\n",
      "\n",
      "01_19_23:50:32 --- 2.2749714851379395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:34 Training loss at epoch 1 step 2950: 3.2241163730621336\n",
      "\n",
      " This round's valence_loss=1.2444357872009277, arousal_loss=1.0878195762634277, emotion_loss=1.039382815361023\n",
      "\n",
      "01_19_23:50:34 Seen so far: 94432 samples\n",
      "\n",
      "01_19_23:50:34 --- 2.0211541652679443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:36 Training loss at epoch 1 step 2960: 3.3956291675567627\n",
      "\n",
      " This round's valence_loss=1.5151447057724, arousal_loss=1.4782211780548096, emotion_loss=0.9935159683227539\n",
      "\n",
      "01_19_23:50:36 Seen so far: 94752 samples\n",
      "\n",
      "01_19_23:50:36 --- 2.0000827312469482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:38 Training loss at epoch 1 step 2970: 3.3246265649795532\n",
      "\n",
      " This round's valence_loss=1.0274901390075684, arousal_loss=0.8459392786026001, emotion_loss=1.1640605926513672\n",
      "\n",
      "01_19_23:50:38 Seen so far: 95072 samples\n",
      "\n",
      "01_19_23:50:38 --- 1.9975101947784424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:40 Training loss at epoch 1 step 2980: 3.171930193901062\n",
      "\n",
      " This round's valence_loss=1.4575679302215576, arousal_loss=1.316215991973877, emotion_loss=0.9647809863090515\n",
      "\n",
      "01_19_23:50:40 Seen so far: 95392 samples\n",
      "\n",
      "01_19_23:50:40 --- 2.0605835914611816 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:42 Training loss at epoch 1 step 2990: 2.907500076293945\n",
      "\n",
      " This round's valence_loss=1.094568133354187, arousal_loss=0.9630960822105408, emotion_loss=1.1071643829345703\n",
      "\n",
      "01_19_23:50:42 Seen so far: 95712 samples\n",
      "\n",
      "01_19_23:50:42 --- 1.8433711528778076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:44 Training loss at epoch 1 step 3000: 3.037938642501831\n",
      "\n",
      " This round's valence_loss=0.8719125986099243, arousal_loss=0.6792266964912415, emotion_loss=0.9854253530502319\n",
      "\n",
      "01_19_23:50:44 Seen so far: 96032 samples\n",
      "\n",
      "01_19_23:50:44 --- 2.108686685562134 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:46 Training loss at epoch 1 step 3010: 3.073598027229309\n",
      "\n",
      " This round's valence_loss=1.0730385780334473, arousal_loss=0.9766762256622314, emotion_loss=1.0645017623901367\n",
      "\n",
      "01_19_23:50:46 Seen so far: 96352 samples\n",
      "\n",
      "01_19_23:50:46 --- 1.9831562042236328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:48 Training loss at epoch 1 step 3020: 2.8525408625602724\n",
      "\n",
      " This round's valence_loss=1.2253365516662598, arousal_loss=1.0822687149047852, emotion_loss=0.9738385081291199\n",
      "\n",
      "01_19_23:50:48 Seen so far: 96672 samples\n",
      "\n",
      "01_19_23:50:48 --- 2.1673007011413574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:50 Training loss at epoch 1 step 3030: 3.2663805723190307\n",
      "\n",
      " This round's valence_loss=1.459824562072754, arousal_loss=1.3066060543060303, emotion_loss=1.089377760887146\n",
      "\n",
      "01_19_23:50:50 Seen so far: 96992 samples\n",
      "\n",
      "01_19_23:50:50 --- 1.858769178390503 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:52 Training loss at epoch 1 step 3040: 2.943805718421936\n",
      "\n",
      " This round's valence_loss=1.0960664749145508, arousal_loss=0.9618196487426758, emotion_loss=1.2292001247406006\n",
      "\n",
      "01_19_23:50:52 Seen so far: 97312 samples\n",
      "\n",
      "01_19_23:50:52 --- 1.8202369213104248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:54 Training loss at epoch 1 step 3050: 3.1497785329818724\n",
      "\n",
      " This round's valence_loss=1.0357258319854736, arousal_loss=0.8199722766876221, emotion_loss=1.0943996906280518\n",
      "\n",
      "01_19_23:50:54 Seen so far: 97632 samples\n",
      "\n",
      "01_19_23:50:54 --- 1.9684653282165527 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:56 Training loss at epoch 1 step 3060: 2.9739598989486695\n",
      "\n",
      " This round's valence_loss=1.0492192506790161, arousal_loss=0.9618987441062927, emotion_loss=1.116232991218567\n",
      "\n",
      "01_19_23:50:56 Seen so far: 97952 samples\n",
      "\n",
      "01_19_23:50:56 --- 1.9879772663116455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:50:58 Training loss at epoch 1 step 3070: 3.1959338665008543\n",
      "\n",
      " This round's valence_loss=0.8242461681365967, arousal_loss=0.7095069885253906, emotion_loss=0.9565376043319702\n",
      "\n",
      "01_19_23:50:58 Seen so far: 98272 samples\n",
      "\n",
      "01_19_23:50:58 --- 2.036257028579712 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:00 Training loss at epoch 1 step 3080: 3.0900063514709473\n",
      "\n",
      " This round's valence_loss=1.090293049812317, arousal_loss=1.0127935409545898, emotion_loss=0.8800028562545776\n",
      "\n",
      "01_19_23:51:00 Seen so far: 98592 samples\n",
      "\n",
      "01_19_23:51:00 --- 2.0111076831817627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:02 Training loss at epoch 1 step 3090: 3.0759106159210203\n",
      "\n",
      " This round's valence_loss=1.5541505813598633, arousal_loss=1.4631588459014893, emotion_loss=0.8662693500518799\n",
      "\n",
      "01_19_23:51:02 Seen so far: 98912 samples\n",
      "\n",
      "01_19_23:51:02 --- 2.0487029552459717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:04 Training loss at epoch 1 step 3100: 3.033240461349487\n",
      "\n",
      " This round's valence_loss=0.8290892243385315, arousal_loss=0.6966522932052612, emotion_loss=0.9065707921981812\n",
      "\n",
      "01_19_23:51:04 Seen so far: 99232 samples\n",
      "\n",
      "01_19_23:51:04 --- 2.2231802940368652 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:06 Training loss at epoch 1 step 3110: 3.0340951681137085\n",
      "\n",
      " This round's valence_loss=0.9577715396881104, arousal_loss=0.8463289737701416, emotion_loss=0.9832725524902344\n",
      "\n",
      "01_19_23:51:06 Seen so far: 99552 samples\n",
      "\n",
      "01_19_23:51:06 --- 1.9911363124847412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:08 Training loss at epoch 1 step 3120: 3.326836085319519\n",
      "\n",
      " This round's valence_loss=1.483919620513916, arousal_loss=1.280442476272583, emotion_loss=0.7437578439712524\n",
      "\n",
      "01_19_23:51:08 Seen so far: 99872 samples\n",
      "\n",
      "01_19_23:51:08 --- 2.0574262142181396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:10 Training loss at epoch 1 step 3130: 3.2451812982559205\n",
      "\n",
      " This round's valence_loss=1.1305994987487793, arousal_loss=0.9509800672531128, emotion_loss=1.1970914602279663\n",
      "\n",
      "01_19_23:51:10 Seen so far: 100192 samples\n",
      "\n",
      "01_19_23:51:10 --- 1.8278849124908447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:12 Training loss at epoch 1 step 3140: 3.0903831005096434\n",
      "\n",
      " This round's valence_loss=1.099405288696289, arousal_loss=0.9840961694717407, emotion_loss=0.9864184260368347\n",
      "\n",
      "01_19_23:51:12 Seen so far: 100512 samples\n",
      "\n",
      "01_19_23:51:12 --- 1.9445078372955322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:14 Training loss at epoch 1 step 3150: 3.208635997772217\n",
      "\n",
      " This round's valence_loss=1.102808952331543, arousal_loss=0.985954999923706, emotion_loss=1.1960400342941284\n",
      "\n",
      "01_19_23:51:14 Seen so far: 100832 samples\n",
      "\n",
      "01_19_23:51:14 --- 1.8762805461883545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:16 Training loss at epoch 1 step 3160: 2.8328850746154783\n",
      "\n",
      " This round's valence_loss=1.1665565967559814, arousal_loss=0.9736520051956177, emotion_loss=1.2260401248931885\n",
      "\n",
      "01_19_23:51:16 Seen so far: 101152 samples\n",
      "\n",
      "01_19_23:51:16 --- 2.0365307331085205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:18 Training loss at epoch 1 step 3170: 3.186040759086609\n",
      "\n",
      " This round's valence_loss=0.8498975038528442, arousal_loss=0.7065664529800415, emotion_loss=1.3942402601242065\n",
      "\n",
      "01_19_23:51:18 Seen so far: 101472 samples\n",
      "\n",
      "01_19_23:51:18 --- 1.8974940776824951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:20 Training loss at epoch 1 step 3180: 3.0260660648345947\n",
      "\n",
      " This round's valence_loss=0.6647636890411377, arousal_loss=0.44457781314849854, emotion_loss=1.1923727989196777\n",
      "\n",
      "01_19_23:51:20 Seen so far: 101792 samples\n",
      "\n",
      "01_19_23:51:20 --- 1.995436191558838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:22 Training loss at epoch 1 step 3190: 3.0114493131637574\n",
      "\n",
      " This round's valence_loss=0.9631680846214294, arousal_loss=0.8566493391990662, emotion_loss=1.0177115201950073\n",
      "\n",
      "01_19_23:51:22 Seen so far: 102112 samples\n",
      "\n",
      "01_19_23:51:22 --- 1.9884610176086426 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:24 Training loss at epoch 1 step 3200: 3.400555372238159\n",
      "\n",
      " This round's valence_loss=1.4079995155334473, arousal_loss=1.3150923252105713, emotion_loss=1.0309327840805054\n",
      "\n",
      "01_19_23:51:24 Seen so far: 102432 samples\n",
      "\n",
      "01_19_23:51:24 --- 2.019463539123535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:26 Training loss at epoch 1 step 3210: 3.566903328895569\n",
      "\n",
      " This round's valence_loss=1.1980416774749756, arousal_loss=0.9588513374328613, emotion_loss=0.7100462317466736\n",
      "\n",
      "01_19_23:51:26 Seen so far: 102752 samples\n",
      "\n",
      "01_19_23:51:26 --- 1.9632363319396973 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:28 Training loss at epoch 1 step 3220: 3.2771780490875244\n",
      "\n",
      " This round's valence_loss=1.4006627798080444, arousal_loss=1.3223423957824707, emotion_loss=1.3994266986846924\n",
      "\n",
      "01_19_23:51:28 Seen so far: 103072 samples\n",
      "\n",
      "01_19_23:51:28 --- 2.1619155406951904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:30 Training loss at epoch 1 step 3230: 3.106122136116028\n",
      "\n",
      " This round's valence_loss=1.1826659440994263, arousal_loss=0.9209067821502686, emotion_loss=0.8206994533538818\n",
      "\n",
      "01_19_23:51:30 Seen so far: 103392 samples\n",
      "\n",
      "01_19_23:51:30 --- 1.9025158882141113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:32 Training loss at epoch 1 step 3240: 3.2642760038375855\n",
      "\n",
      " This round's valence_loss=1.2003644704818726, arousal_loss=1.0947213172912598, emotion_loss=0.690352737903595\n",
      "\n",
      "01_19_23:51:32 Seen so far: 103712 samples\n",
      "\n",
      "01_19_23:51:32 --- 2.0658979415893555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:34 Training loss at epoch 1 step 3250: 3.0187349796295164\n",
      "\n",
      " This round's valence_loss=0.8636807203292847, arousal_loss=0.6917046308517456, emotion_loss=1.3905682563781738\n",
      "\n",
      "01_19_23:51:34 Seen so far: 104032 samples\n",
      "\n",
      "01_19_23:51:34 --- 2.0250186920166016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:36 Training loss at epoch 1 step 3260: 3.0966094732284546\n",
      "\n",
      " This round's valence_loss=1.2211294174194336, arousal_loss=1.0828304290771484, emotion_loss=0.9717390537261963\n",
      "\n",
      "01_19_23:51:36 Seen so far: 104352 samples\n",
      "\n",
      "01_19_23:51:36 --- 2.2940590381622314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:38 Training loss at epoch 1 step 3270: 3.0616546869277954\n",
      "\n",
      " This round's valence_loss=0.6972094774246216, arousal_loss=0.5959992408752441, emotion_loss=1.0337352752685547\n",
      "\n",
      "01_19_23:51:38 Seen so far: 104672 samples\n",
      "\n",
      "01_19_23:51:38 --- 2.1858952045440674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:41 Training loss at epoch 1 step 3280: 3.062156081199646\n",
      "\n",
      " This round's valence_loss=1.1421101093292236, arousal_loss=0.9487043619155884, emotion_loss=0.9566750526428223\n",
      "\n",
      "01_19_23:51:41 Seen so far: 104992 samples\n",
      "\n",
      "01_19_23:51:41 --- 2.1630167961120605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:43 Training loss at epoch 1 step 3290: 3.105118680000305\n",
      "\n",
      " This round's valence_loss=0.9354057312011719, arousal_loss=0.8839886784553528, emotion_loss=1.3877899646759033\n",
      "\n",
      "01_19_23:51:43 Seen so far: 105312 samples\n",
      "\n",
      "01_19_23:51:43 --- 2.008812665939331 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:45 Training loss at epoch 1 step 3300: 2.836664414405823\n",
      "\n",
      " This round's valence_loss=1.3325097560882568, arousal_loss=1.1620659828186035, emotion_loss=0.9339982271194458\n",
      "\n",
      "01_19_23:51:45 Seen so far: 105632 samples\n",
      "\n",
      "01_19_23:51:45 --- 1.9353232383728027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:46 Training loss at epoch 1 step 3310: 2.9695785522460936\n",
      "\n",
      " This round's valence_loss=1.126206398010254, arousal_loss=0.9944301843643188, emotion_loss=1.2959322929382324\n",
      "\n",
      "01_19_23:51:46 Seen so far: 105952 samples\n",
      "\n",
      "01_19_23:51:46 --- 1.9099855422973633 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:48 Training loss at epoch 1 step 3320: 3.4300599098205566\n",
      "\n",
      " This round's valence_loss=1.344104528427124, arousal_loss=1.1949381828308105, emotion_loss=0.805356502532959\n",
      "\n",
      "01_19_23:51:48 Seen so far: 106272 samples\n",
      "\n",
      "01_19_23:51:48 --- 1.931933879852295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:50 Training loss at epoch 1 step 3330: 2.920377087593079\n",
      "\n",
      " This round's valence_loss=1.0379691123962402, arousal_loss=0.8325473070144653, emotion_loss=0.9201384782791138\n",
      "\n",
      "01_19_23:51:50 Seen so far: 106592 samples\n",
      "\n",
      "01_19_23:51:50 --- 2.0703256130218506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:52 Training loss at epoch 1 step 3340: 3.1516790628433227\n",
      "\n",
      " This round's valence_loss=1.1651394367218018, arousal_loss=0.9653928279876709, emotion_loss=0.6988343000411987\n",
      "\n",
      "01_19_23:51:52 Seen so far: 106912 samples\n",
      "\n",
      "01_19_23:51:52 --- 2.05570125579834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:54 Training loss at epoch 1 step 3350: 3.22450704574585\n",
      "\n",
      " This round's valence_loss=0.9820877313613892, arousal_loss=0.8906062841415405, emotion_loss=1.1665459871292114\n",
      "\n",
      "01_19_23:51:54 Seen so far: 107232 samples\n",
      "\n",
      "01_19_23:51:54 --- 1.8635926246643066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:56 Training loss at epoch 1 step 3360: 3.1129567861557006\n",
      "\n",
      " This round's valence_loss=1.0591928958892822, arousal_loss=0.8606255054473877, emotion_loss=1.2776093482971191\n",
      "\n",
      "01_19_23:51:56 Seen so far: 107552 samples\n",
      "\n",
      "01_19_23:51:56 --- 1.92661714553833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:51:58 Training loss at epoch 1 step 3370: 3.0694438457489013\n",
      "\n",
      " This round's valence_loss=0.9641950130462646, arousal_loss=0.8761018514633179, emotion_loss=0.8599638342857361\n",
      "\n",
      "01_19_23:51:58 Seen so far: 107872 samples\n",
      "\n",
      "01_19_23:51:58 --- 2.1449878215789795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:01 Training loss at epoch 1 step 3380: 2.843657207489014\n",
      "\n",
      " This round's valence_loss=0.9442135095596313, arousal_loss=0.8607498407363892, emotion_loss=1.4117493629455566\n",
      "\n",
      "01_19_23:52:01 Seen so far: 108192 samples\n",
      "\n",
      "01_19_23:52:01 --- 2.1226279735565186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:03 Training loss at epoch 1 step 3390: 3.0227117776870727\n",
      "\n",
      " This round's valence_loss=0.6916018724441528, arousal_loss=0.4680560231208801, emotion_loss=1.1517683267593384\n",
      "\n",
      "01_19_23:52:03 Seen so far: 108512 samples\n",
      "\n",
      "01_19_23:52:03 --- 1.9796664714813232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:04 Training loss at epoch 1 step 3400: 3.1120545625686646\n",
      "\n",
      " This round's valence_loss=1.3676388263702393, arousal_loss=1.2245054244995117, emotion_loss=1.2648760080337524\n",
      "\n",
      "01_19_23:52:04 Seen so far: 108832 samples\n",
      "\n",
      "01_19_23:52:04 --- 1.9779291152954102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:06 Training loss at epoch 1 step 3410: 3.4192177057266235\n",
      "\n",
      " This round's valence_loss=0.8054325580596924, arousal_loss=0.7086058855056763, emotion_loss=1.1060328483581543\n",
      "\n",
      "01_19_23:52:06 Seen so far: 109152 samples\n",
      "\n",
      "01_19_23:52:06 --- 1.9827964305877686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:09 Training loss at epoch 1 step 3420: 3.589551019668579\n",
      "\n",
      " This round's valence_loss=1.6526051759719849, arousal_loss=1.525592565536499, emotion_loss=0.7398263216018677\n",
      "\n",
      "01_19_23:52:09 Seen so far: 109472 samples\n",
      "\n",
      "01_19_23:52:09 --- 2.2979211807250977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:11 Training loss at epoch 1 step 3430: 3.1531543493270875\n",
      "\n",
      " This round's valence_loss=1.5804657936096191, arousal_loss=1.5854136943817139, emotion_loss=0.8272366523742676\n",
      "\n",
      "01_19_23:52:11 Seen so far: 109792 samples\n",
      "\n",
      "01_19_23:52:11 --- 1.9748528003692627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:13 Training loss at epoch 1 step 3440: 3.3871187448501585\n",
      "\n",
      " This round's valence_loss=0.7610560655593872, arousal_loss=0.6521584391593933, emotion_loss=1.2645413875579834\n",
      "\n",
      "01_19_23:52:13 Seen so far: 110112 samples\n",
      "\n",
      "01_19_23:52:13 --- 1.9585545063018799 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:15 Training loss at epoch 1 step 3450: 3.348436951637268\n",
      "\n",
      " This round's valence_loss=1.3707973957061768, arousal_loss=1.3201369047164917, emotion_loss=1.2835153341293335\n",
      "\n",
      "01_19_23:52:15 Seen so far: 110432 samples\n",
      "\n",
      "01_19_23:52:15 --- 1.8946304321289062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:17 Training loss at epoch 1 step 3460: 3.4149930000305178\n",
      "\n",
      " This round's valence_loss=1.2978137731552124, arousal_loss=1.2026333808898926, emotion_loss=1.1236004829406738\n",
      "\n",
      "01_19_23:52:17 Seen so far: 110752 samples\n",
      "\n",
      "01_19_23:52:17 --- 1.9492707252502441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:18 Training loss at epoch 1 step 3470: 3.038903903961182\n",
      "\n",
      " This round's valence_loss=0.6779892444610596, arousal_loss=0.6142188310623169, emotion_loss=1.0462621450424194\n",
      "\n",
      "01_19_23:52:18 Seen so far: 111072 samples\n",
      "\n",
      "01_19_23:52:18 --- 1.9346086978912354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:21 Training loss at epoch 1 step 3480: 3.12165424823761\n",
      "\n",
      " This round's valence_loss=0.9138839244842529, arousal_loss=0.8647005558013916, emotion_loss=1.236647605895996\n",
      "\n",
      "01_19_23:52:21 Seen so far: 111392 samples\n",
      "\n",
      "01_19_23:52:21 --- 2.0671651363372803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:23 Training loss at epoch 1 step 3490: 2.811835289001465\n",
      "\n",
      " This round's valence_loss=0.923335075378418, arousal_loss=0.8523682355880737, emotion_loss=0.9234904050827026\n",
      "\n",
      "01_19_23:52:23 Seen so far: 111712 samples\n",
      "\n",
      "01_19_23:52:23 --- 2.0902535915374756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:25 Training loss at epoch 1 step 3500: 2.7851735591888427\n",
      "\n",
      " This round's valence_loss=1.145956039428711, arousal_loss=0.9932284355163574, emotion_loss=1.0798864364624023\n",
      "\n",
      "01_19_23:52:25 Seen so far: 112032 samples\n",
      "\n",
      "01_19_23:52:25 --- 2.02486515045166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:27 Training loss at epoch 1 step 3510: 2.957332491874695\n",
      "\n",
      " This round's valence_loss=0.7407422661781311, arousal_loss=0.6425954103469849, emotion_loss=1.1659656763076782\n",
      "\n",
      "01_19_23:52:27 Seen so far: 112352 samples\n",
      "\n",
      "01_19_23:52:27 --- 1.9336357116699219 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:29 Training loss at epoch 1 step 3520: 3.5350887775421143\n",
      "\n",
      " This round's valence_loss=1.1037499904632568, arousal_loss=0.9612123966217041, emotion_loss=1.118293285369873\n",
      "\n",
      "01_19_23:52:29 Seen so far: 112672 samples\n",
      "\n",
      "01_19_23:52:29 --- 2.178800344467163 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:31 Training loss at epoch 1 step 3530: 2.853077220916748\n",
      "\n",
      " This round's valence_loss=0.7557443380355835, arousal_loss=0.6326872110366821, emotion_loss=1.207751989364624\n",
      "\n",
      "01_19_23:52:31 Seen so far: 112992 samples\n",
      "\n",
      "01_19_23:52:31 --- 1.9649159908294678 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:33 Training loss at epoch 1 step 3540: 2.7218181014060976\n",
      "\n",
      " This round's valence_loss=0.8855302333831787, arousal_loss=0.669587254524231, emotion_loss=1.078904390335083\n",
      "\n",
      "01_19_23:52:33 Seen so far: 113312 samples\n",
      "\n",
      "01_19_23:52:33 --- 2.1144440174102783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:35 Training loss at epoch 1 step 3550: 2.7451541423797607\n",
      "\n",
      " This round's valence_loss=0.7245835065841675, arousal_loss=0.6028679609298706, emotion_loss=0.9001349210739136\n",
      "\n",
      "01_19_23:52:35 Seen so far: 113632 samples\n",
      "\n",
      "01_19_23:52:35 --- 2.2826688289642334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:37 Training loss at epoch 1 step 3560: 3.5967066287994385\n",
      "\n",
      " This round's valence_loss=1.453498125076294, arousal_loss=1.2957217693328857, emotion_loss=1.0543034076690674\n",
      "\n",
      "01_19_23:52:37 Seen so far: 113952 samples\n",
      "\n",
      "01_19_23:52:37 --- 1.9620251655578613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:39 Training loss at epoch 1 step 3570: 3.115821361541748\n",
      "\n",
      " This round's valence_loss=1.0162646770477295, arousal_loss=0.9357236623764038, emotion_loss=1.0872914791107178\n",
      "\n",
      "01_19_23:52:39 Seen so far: 114272 samples\n",
      "\n",
      "01_19_23:52:39 --- 1.924088716506958 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:41 Training loss at epoch 1 step 3580: 2.8941503047943113\n",
      "\n",
      " This round's valence_loss=0.7699630856513977, arousal_loss=0.5844595432281494, emotion_loss=0.9795239567756653\n",
      "\n",
      "01_19_23:52:41 Seen so far: 114592 samples\n",
      "\n",
      "01_19_23:52:41 --- 2.3191311359405518 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:43 Training loss at epoch 1 step 3590: 3.1556349277496336\n",
      "\n",
      " This round's valence_loss=1.1329119205474854, arousal_loss=1.021936058998108, emotion_loss=1.279015064239502\n",
      "\n",
      "01_19_23:52:43 Seen so far: 114912 samples\n",
      "\n",
      "01_19_23:52:43 --- 1.8007152080535889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:45 Training loss at epoch 1 step 3600: 3.61253023147583\n",
      "\n",
      " This round's valence_loss=1.6913721561431885, arousal_loss=1.556225299835205, emotion_loss=0.9641245603561401\n",
      "\n",
      "01_19_23:52:45 Seen so far: 115232 samples\n",
      "\n",
      "01_19_23:52:45 --- 2.069336175918579 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:47 Training loss at epoch 1 step 3610: 3.109830641746521\n",
      "\n",
      " This round's valence_loss=1.369708776473999, arousal_loss=1.3503737449645996, emotion_loss=1.2491137981414795\n",
      "\n",
      "01_19_23:52:47 Seen so far: 115552 samples\n",
      "\n",
      "01_19_23:52:47 --- 1.8851654529571533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:49 Training loss at epoch 1 step 3620: 3.0553946495056152\n",
      "\n",
      " This round's valence_loss=0.5243399143218994, arousal_loss=0.3655949831008911, emotion_loss=1.170586347579956\n",
      "\n",
      "01_19_23:52:49 Seen so far: 115872 samples\n",
      "\n",
      "01_19_23:52:49 --- 2.0748565196990967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:51 Training loss at epoch 1 step 3630: 3.26948766708374\n",
      "\n",
      " This round's valence_loss=1.0843422412872314, arousal_loss=1.0041894912719727, emotion_loss=1.2850871086120605\n",
      "\n",
      "01_19_23:52:51 Seen so far: 116192 samples\n",
      "\n",
      "01_19_23:52:51 --- 1.850412368774414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:53 Training loss at epoch 1 step 3640: 3.0014354467391966\n",
      "\n",
      " This round's valence_loss=0.6142675280570984, arousal_loss=0.47787797451019287, emotion_loss=0.9732621908187866\n",
      "\n",
      "01_19_23:52:53 Seen so far: 116512 samples\n",
      "\n",
      "01_19_23:52:53 --- 1.8908133506774902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:55 Training loss at epoch 1 step 3650: 3.0364400863647463\n",
      "\n",
      " This round's valence_loss=0.9585946798324585, arousal_loss=0.8373805284500122, emotion_loss=1.5298175811767578\n",
      "\n",
      "01_19_23:52:55 Seen so far: 116832 samples\n",
      "\n",
      "01_19_23:52:55 --- 1.9070138931274414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:57 Training loss at epoch 1 step 3660: 2.9087085485458375\n",
      "\n",
      " This round's valence_loss=0.8506990671157837, arousal_loss=0.6868569850921631, emotion_loss=0.8583856225013733\n",
      "\n",
      "01_19_23:52:57 Seen so far: 117152 samples\n",
      "\n",
      "01_19_23:52:57 --- 2.0993499755859375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:52:59 Training loss at epoch 1 step 3670: 2.897936534881592\n",
      "\n",
      " This round's valence_loss=0.602433443069458, arousal_loss=0.4720384180545807, emotion_loss=1.1435952186584473\n",
      "\n",
      "01_19_23:52:59 Seen so far: 117472 samples\n",
      "\n",
      "01_19_23:52:59 --- 2.014152765274048 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:01 Training loss at epoch 1 step 3680: 3.0538013219833373\n",
      "\n",
      " This round's valence_loss=1.0011142492294312, arousal_loss=0.9249637126922607, emotion_loss=1.0225684642791748\n",
      "\n",
      "01_19_23:53:01 Seen so far: 117792 samples\n",
      "\n",
      "01_19_23:53:01 --- 2.056236743927002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:03 Training loss at epoch 1 step 3690: 3.315070128440857\n",
      "\n",
      " This round's valence_loss=1.552377462387085, arousal_loss=1.4651422500610352, emotion_loss=0.9310318231582642\n",
      "\n",
      "01_19_23:53:03 Seen so far: 118112 samples\n",
      "\n",
      "01_19_23:53:03 --- 1.8571672439575195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:05 Training loss at epoch 1 step 3700: 3.0231045484542847\n",
      "\n",
      " This round's valence_loss=1.2712087631225586, arousal_loss=1.024444818496704, emotion_loss=0.6483708620071411\n",
      "\n",
      "01_19_23:53:05 Seen so far: 118432 samples\n",
      "\n",
      "01_19_23:53:05 --- 2.0277581214904785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:07 Training loss at epoch 1 step 3710: 3.2529780149459837\n",
      "\n",
      " This round's valence_loss=1.1479136943817139, arousal_loss=0.9354547262191772, emotion_loss=0.9583357572555542\n",
      "\n",
      "01_19_23:53:07 Seen so far: 118752 samples\n",
      "\n",
      "01_19_23:53:07 --- 2.102717161178589 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:09 Training loss at epoch 1 step 3720: 3.1481553077697755\n",
      "\n",
      " This round's valence_loss=1.3174854516983032, arousal_loss=1.2403457164764404, emotion_loss=1.0388880968093872\n",
      "\n",
      "01_19_23:53:09 Seen so far: 119072 samples\n",
      "\n",
      "01_19_23:53:09 --- 2.094376802444458 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:11 Training loss at epoch 1 step 3730: 3.053471565246582\n",
      "\n",
      " This round's valence_loss=0.9562945365905762, arousal_loss=0.7185537815093994, emotion_loss=0.8061580061912537\n",
      "\n",
      "01_19_23:53:11 Seen so far: 119392 samples\n",
      "\n",
      "01_19_23:53:11 --- 1.905357837677002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:13 Training loss at epoch 1 step 3740: 3.0461820125579835\n",
      "\n",
      " This round's valence_loss=1.3671722412109375, arousal_loss=1.1499707698822021, emotion_loss=1.2283014059066772\n",
      "\n",
      "01_19_23:53:13 Seen so far: 119712 samples\n",
      "\n",
      "01_19_23:53:13 --- 1.8204500675201416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:15 Training loss at epoch 1 step 3750: 2.958354187011719\n",
      "\n",
      " This round's valence_loss=0.8452872633934021, arousal_loss=0.6045727729797363, emotion_loss=1.1731010675430298\n",
      "\n",
      "01_19_23:53:15 Seen so far: 120032 samples\n",
      "\n",
      "01_19_23:53:15 --- 1.9504077434539795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:17 Training loss at epoch 1 step 3760: 3.3395049571990967\n",
      "\n",
      " This round's valence_loss=1.2119181156158447, arousal_loss=1.0819895267486572, emotion_loss=0.8829001188278198\n",
      "\n",
      "01_19_23:53:17 Seen so far: 120352 samples\n",
      "\n",
      "01_19_23:53:17 --- 2.107606887817383 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:19 Training loss at epoch 1 step 3770: 3.2556304693222047\n",
      "\n",
      " This round's valence_loss=1.1851069927215576, arousal_loss=1.049471378326416, emotion_loss=0.774437665939331\n",
      "\n",
      "01_19_23:53:19 Seen so far: 120672 samples\n",
      "\n",
      "01_19_23:53:19 --- 1.939971923828125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:21 Training loss at epoch 1 step 3780: 3.2629703283309937\n",
      "\n",
      " This round's valence_loss=1.1952065229415894, arousal_loss=1.0691733360290527, emotion_loss=0.9252458214759827\n",
      "\n",
      "01_19_23:53:21 Seen so far: 120992 samples\n",
      "\n",
      "01_19_23:53:21 --- 2.221393585205078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:23 Training loss at epoch 1 step 3790: 2.88510262966156\n",
      "\n",
      " This round's valence_loss=0.8206110000610352, arousal_loss=0.7155110836029053, emotion_loss=1.0671803951263428\n",
      "\n",
      "01_19_23:53:23 Seen so far: 121312 samples\n",
      "\n",
      "01_19_23:53:23 --- 1.967409372329712 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:25 Training loss at epoch 1 step 3800: 3.0300573348999023\n",
      "\n",
      " This round's valence_loss=1.3890379667282104, arousal_loss=1.160989761352539, emotion_loss=0.9308187365531921\n",
      "\n",
      "01_19_23:53:25 Seen so far: 121632 samples\n",
      "\n",
      "01_19_23:53:25 --- 1.9685137271881104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:27 Training loss at epoch 1 step 3810: 3.058782124519348\n",
      "\n",
      " This round's valence_loss=0.6638442277908325, arousal_loss=0.5563898086547852, emotion_loss=1.3267353773117065\n",
      "\n",
      "01_19_23:53:27 Seen so far: 121952 samples\n",
      "\n",
      "01_19_23:53:27 --- 2.061514139175415 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:29 Training loss at epoch 1 step 3820: 3.4138850927352906\n",
      "\n",
      " This round's valence_loss=1.1800878047943115, arousal_loss=1.088170051574707, emotion_loss=0.9747282862663269\n",
      "\n",
      "01_19_23:53:29 Seen so far: 122272 samples\n",
      "\n",
      "01_19_23:53:29 --- 2.173593044281006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:31 Training loss at epoch 1 step 3830: 2.655730700492859\n",
      "\n",
      " This round's valence_loss=1.0929133892059326, arousal_loss=1.0209875106811523, emotion_loss=1.0966875553131104\n",
      "\n",
      "01_19_23:53:31 Seen so far: 122592 samples\n",
      "\n",
      "01_19_23:53:31 --- 2.050095796585083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:33 Training loss at epoch 1 step 3840: 3.0376615166664123\n",
      "\n",
      " This round's valence_loss=0.9255502223968506, arousal_loss=0.8769378662109375, emotion_loss=1.2894572019577026\n",
      "\n",
      "01_19_23:53:33 Seen so far: 122912 samples\n",
      "\n",
      "01_19_23:53:33 --- 1.987769365310669 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:35 Training loss at epoch 1 step 3850: 3.157553458213806\n",
      "\n",
      " This round's valence_loss=1.205709457397461, arousal_loss=1.0995879173278809, emotion_loss=0.9810503721237183\n",
      "\n",
      "01_19_23:53:35 Seen so far: 123232 samples\n",
      "\n",
      "01_19_23:53:35 --- 1.935387134552002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:37 Training loss at epoch 1 step 3860: 3.118647027015686\n",
      "\n",
      " This round's valence_loss=1.112658977508545, arousal_loss=0.9783347845077515, emotion_loss=1.1192739009857178\n",
      "\n",
      "01_19_23:53:37 Seen so far: 123552 samples\n",
      "\n",
      "01_19_23:53:37 --- 1.991279125213623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:39 Training loss at epoch 1 step 3870: 2.778593349456787\n",
      "\n",
      " This round's valence_loss=1.2930469512939453, arousal_loss=1.2764766216278076, emotion_loss=0.9963464736938477\n",
      "\n",
      "01_19_23:53:39 Seen so far: 123872 samples\n",
      "\n",
      "01_19_23:53:39 --- 2.095379590988159 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:41 Training loss at epoch 1 step 3880: 3.385016655921936\n",
      "\n",
      " This round's valence_loss=1.0033745765686035, arousal_loss=0.8176425099372864, emotion_loss=1.0012325048446655\n",
      "\n",
      "01_19_23:53:41 Seen so far: 124192 samples\n",
      "\n",
      "01_19_23:53:41 --- 2.177011728286743 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:43 Training loss at epoch 1 step 3890: 2.9506768941879273\n",
      "\n",
      " This round's valence_loss=1.266160249710083, arousal_loss=1.1042068004608154, emotion_loss=1.3301360607147217\n",
      "\n",
      "01_19_23:53:43 Seen so far: 124512 samples\n",
      "\n",
      "01_19_23:53:43 --- 1.7761082649230957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:45 Training loss at epoch 1 step 3900: 3.0970067739486695\n",
      "\n",
      " This round's valence_loss=1.3331243991851807, arousal_loss=1.211423397064209, emotion_loss=0.8838704824447632\n",
      "\n",
      "01_19_23:53:45 Seen so far: 124832 samples\n",
      "\n",
      "01_19_23:53:45 --- 2.1426994800567627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:47 Training loss at epoch 1 step 3910: 3.19849579334259\n",
      "\n",
      " This round's valence_loss=1.4099242687225342, arousal_loss=1.3282852172851562, emotion_loss=1.171399474143982\n",
      "\n",
      "01_19_23:53:47 Seen so far: 125152 samples\n",
      "\n",
      "01_19_23:53:47 --- 1.8677425384521484 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:49 Training loss at epoch 1 step 3920: 3.280974102020264\n",
      "\n",
      " This round's valence_loss=1.1990196704864502, arousal_loss=1.0882635116577148, emotion_loss=1.01704740524292\n",
      "\n",
      "01_19_23:53:49 Seen so far: 125472 samples\n",
      "\n",
      "01_19_23:53:49 --- 2.034435272216797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:51 Training loss at epoch 1 step 3930: 3.022794234752655\n",
      "\n",
      " This round's valence_loss=1.0978248119354248, arousal_loss=0.9592193365097046, emotion_loss=1.094212532043457\n",
      "\n",
      "01_19_23:53:51 Seen so far: 125792 samples\n",
      "\n",
      "01_19_23:53:51 --- 1.81400728225708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:53 Training loss at epoch 1 step 3940: 3.418688154220581\n",
      "\n",
      " This round's valence_loss=1.3408091068267822, arousal_loss=1.2060198783874512, emotion_loss=1.0046788454055786\n",
      "\n",
      "01_19_23:53:53 Seen so far: 126112 samples\n",
      "\n",
      "01_19_23:53:53 --- 2.1066813468933105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:55 Training loss at epoch 1 step 3950: 2.947717881202698\n",
      "\n",
      " This round's valence_loss=0.9550613164901733, arousal_loss=0.8639576435089111, emotion_loss=1.3502720594406128\n",
      "\n",
      "01_19_23:53:55 Seen so far: 126432 samples\n",
      "\n",
      "01_19_23:53:55 --- 1.980311632156372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:57 Training loss at epoch 1 step 3960: 2.8750164270401\n",
      "\n",
      " This round's valence_loss=0.922167956829071, arousal_loss=0.8742914199829102, emotion_loss=1.362748146057129\n",
      "\n",
      "01_19_23:53:57 Seen so far: 126752 samples\n",
      "\n",
      "01_19_23:53:57 --- 1.9876997470855713 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:53:59 Training loss at epoch 1 step 3970: 3.0713873863220216\n",
      "\n",
      " This round's valence_loss=1.172802448272705, arousal_loss=1.0874836444854736, emotion_loss=1.2345353364944458\n",
      "\n",
      "01_19_23:53:59 Seen so far: 127072 samples\n",
      "\n",
      "01_19_23:53:59 --- 2.0904159545898438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:02 Training loss at epoch 1 step 3980: 3.08784658908844\n",
      "\n",
      " This round's valence_loss=1.3349618911743164, arousal_loss=1.1792852878570557, emotion_loss=1.1582818031311035\n",
      "\n",
      "01_19_23:54:02 Seen so far: 127392 samples\n",
      "\n",
      "01_19_23:54:02 --- 2.2988803386688232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:04 Training loss at epoch 1 step 3990: 3.1574281215667725\n",
      "\n",
      " This round's valence_loss=1.178297996520996, arousal_loss=1.0625789165496826, emotion_loss=1.084694743156433\n",
      "\n",
      "01_19_23:54:04 Seen so far: 127712 samples\n",
      "\n",
      "01_19_23:54:04 --- 2.2191410064697266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:06 Training loss at epoch 1 step 4000: 2.8907568216323853\n",
      "\n",
      " This round's valence_loss=1.5431510210037231, arousal_loss=1.4476406574249268, emotion_loss=0.9382123947143555\n",
      "\n",
      "01_19_23:54:06 Seen so far: 128032 samples\n",
      "\n",
      "01_19_23:54:06 --- 2.4885127544403076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:08 Training loss at epoch 1 step 4010: 3.0587125062942504\n",
      "\n",
      " This round's valence_loss=1.735090970993042, arousal_loss=1.5622637271881104, emotion_loss=0.8444927930831909\n",
      "\n",
      "01_19_23:54:08 Seen so far: 128352 samples\n",
      "\n",
      "01_19_23:54:08 --- 1.9978866577148438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:10 Training loss at epoch 1 step 4020: 3.2328067302703856\n",
      "\n",
      " This round's valence_loss=1.0777404308319092, arousal_loss=0.9651971459388733, emotion_loss=1.2719213962554932\n",
      "\n",
      "01_19_23:54:10 Seen so far: 128672 samples\n",
      "\n",
      "01_19_23:54:10 --- 1.8243138790130615 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:12 Training loss at epoch 1 step 4030: 2.8788059830665587\n",
      "\n",
      " This round's valence_loss=0.508929967880249, arousal_loss=0.3406245708465576, emotion_loss=0.8958929777145386\n",
      "\n",
      "01_19_23:54:12 Seen so far: 128992 samples\n",
      "\n",
      "01_19_23:54:12 --- 2.112773895263672 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:14 Training loss at epoch 1 step 4040: 2.8484774112701414\n",
      "\n",
      " This round's valence_loss=1.0110085010528564, arousal_loss=0.877467930316925, emotion_loss=1.1019989252090454\n",
      "\n",
      "01_19_23:54:14 Seen so far: 129312 samples\n",
      "\n",
      "01_19_23:54:14 --- 1.8838114738464355 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:16 Training loss at epoch 1 step 4050: 2.868003010749817\n",
      "\n",
      " This round's valence_loss=0.9649875164031982, arousal_loss=0.8808819055557251, emotion_loss=0.916404128074646\n",
      "\n",
      "01_19_23:54:16 Seen so far: 129632 samples\n",
      "\n",
      "01_19_23:54:16 --- 1.7688558101654053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:18 Training loss at epoch 1 step 4060: 3.3614327669143678\n",
      "\n",
      " This round's valence_loss=0.9315134286880493, arousal_loss=0.7052654027938843, emotion_loss=0.8394972681999207\n",
      "\n",
      "01_19_23:54:18 Seen so far: 129952 samples\n",
      "\n",
      "01_19_23:54:18 --- 1.9041388034820557 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:19 Training loss at epoch 1 step 4070: 2.8167948961257934\n",
      "\n",
      " This round's valence_loss=0.7928058505058289, arousal_loss=0.572115421295166, emotion_loss=0.8095357418060303\n",
      "\n",
      "01_19_23:54:19 Seen so far: 130272 samples\n",
      "\n",
      "01_19_23:54:19 --- 1.7122118473052979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:21 Training loss at epoch 1 step 4080: 3.1719909429550173\n",
      "\n",
      " This round's valence_loss=1.1495440006256104, arousal_loss=0.9589790105819702, emotion_loss=1.0267620086669922\n",
      "\n",
      "01_19_23:54:21 Seen so far: 130592 samples\n",
      "\n",
      "01_19_23:54:21 --- 1.9558675289154053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:23 Training loss at epoch 1 step 4090: 3.045419692993164\n",
      "\n",
      " This round's valence_loss=0.9586082696914673, arousal_loss=0.8563939332962036, emotion_loss=1.0513896942138672\n",
      "\n",
      "01_19_23:54:23 Seen so far: 130912 samples\n",
      "\n",
      "01_19_23:54:23 --- 1.709937572479248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:25 Training loss at epoch 1 step 4100: 3.100901198387146\n",
      "\n",
      " This round's valence_loss=0.7603346109390259, arousal_loss=0.618539035320282, emotion_loss=1.0271120071411133\n",
      "\n",
      "01_19_23:54:25 Seen so far: 131232 samples\n",
      "\n",
      "01_19_23:54:25 --- 1.7557997703552246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:27 Training loss at epoch 1 step 4110: 3.03958420753479\n",
      "\n",
      " This round's valence_loss=1.3068265914916992, arousal_loss=1.1633775234222412, emotion_loss=0.9388014078140259\n",
      "\n",
      "01_19_23:54:27 Seen so far: 131552 samples\n",
      "\n",
      "01_19_23:54:27 --- 1.965428352355957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:29 Training loss at epoch 1 step 4120: 3.1774816036224367\n",
      "\n",
      " This round's valence_loss=1.2816557884216309, arousal_loss=1.2490720748901367, emotion_loss=1.1067603826522827\n",
      "\n",
      "01_19_23:54:29 Seen so far: 131872 samples\n",
      "\n",
      "01_19_23:54:29 --- 1.6783740520477295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:30 Training loss at epoch 1 step 4130: 2.738802742958069\n",
      "\n",
      " This round's valence_loss=0.887043833732605, arousal_loss=0.7718726396560669, emotion_loss=0.9141730070114136\n",
      "\n",
      "01_19_23:54:30 Seen so far: 132192 samples\n",
      "\n",
      "01_19_23:54:30 --- 1.8449480533599854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:32 Training loss at epoch 1 step 4140: 3.419307732582092\n",
      "\n",
      " This round's valence_loss=1.3100013732910156, arousal_loss=1.2171225547790527, emotion_loss=0.84136962890625\n",
      "\n",
      "01_19_23:54:32 Seen so far: 132512 samples\n",
      "\n",
      "01_19_23:54:32 --- 1.7274906635284424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:34 Training loss at epoch 1 step 4150: 3.3687633275985718\n",
      "\n",
      " This round's valence_loss=1.398810863494873, arousal_loss=1.3525354862213135, emotion_loss=0.7703813314437866\n",
      "\n",
      "01_19_23:54:34 Seen so far: 132832 samples\n",
      "\n",
      "01_19_23:54:34 --- 1.8478035926818848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:36 Training loss at epoch 1 step 4160: 2.983115005493164\n",
      "\n",
      " This round's valence_loss=1.0785013437271118, arousal_loss=1.0072088241577148, emotion_loss=1.3727184534072876\n",
      "\n",
      "01_19_23:54:36 Seen so far: 133152 samples\n",
      "\n",
      "01_19_23:54:36 --- 1.782006025314331 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:38 Training loss at epoch 1 step 4170: 3.1707946062088013\n",
      "\n",
      " This round's valence_loss=1.2100849151611328, arousal_loss=1.0498892068862915, emotion_loss=1.2116369009017944\n",
      "\n",
      "01_19_23:54:38 Seen so far: 133472 samples\n",
      "\n",
      "01_19_23:54:38 --- 1.9471654891967773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:40 Training loss at epoch 1 step 4180: 3.033735692501068\n",
      "\n",
      " This round's valence_loss=1.4231665134429932, arousal_loss=1.3048157691955566, emotion_loss=1.0962737798690796\n",
      "\n",
      "01_19_23:54:40 Seen so far: 133792 samples\n",
      "\n",
      "01_19_23:54:40 --- 1.8894259929656982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:41 Training loss at epoch 1 step 4190: 3.161249589920044\n",
      "\n",
      " This round's valence_loss=0.8724949359893799, arousal_loss=0.7611957788467407, emotion_loss=1.0411988496780396\n",
      "\n",
      "01_19_23:54:41 Seen so far: 134112 samples\n",
      "\n",
      "01_19_23:54:41 --- 1.7566337585449219 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:43 Training loss at epoch 1 step 4200: 3.139929485321045\n",
      "\n",
      " This round's valence_loss=0.9375343322753906, arousal_loss=0.6755967140197754, emotion_loss=0.6581565737724304\n",
      "\n",
      "01_19_23:54:43 Seen so far: 134432 samples\n",
      "\n",
      "01_19_23:54:43 --- 1.6719272136688232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:45 Training loss at epoch 1 step 4210: 2.9481650590896606\n",
      "\n",
      " This round's valence_loss=1.046324372291565, arousal_loss=0.8196381330490112, emotion_loss=0.8508932590484619\n",
      "\n",
      "01_19_23:54:45 Seen so far: 134752 samples\n",
      "\n",
      "01_19_23:54:45 --- 1.6688101291656494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:46 Training loss at epoch 1 step 4220: 3.0341787099838258\n",
      "\n",
      " This round's valence_loss=0.7281713485717773, arousal_loss=0.6329096555709839, emotion_loss=1.1279783248901367\n",
      "\n",
      "01_19_23:54:46 Seen so far: 135072 samples\n",
      "\n",
      "01_19_23:54:46 --- 1.8336868286132812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:48 Training loss at epoch 1 step 4230: 3.317582607269287\n",
      "\n",
      " This round's valence_loss=1.1455979347229004, arousal_loss=0.9456734657287598, emotion_loss=1.433755874633789\n",
      "\n",
      "01_19_23:54:48 Seen so far: 135392 samples\n",
      "\n",
      "01_19_23:54:48 --- 1.661081075668335 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:50 Training loss at epoch 1 step 4240: 3.0342334032058718\n",
      "\n",
      " This round's valence_loss=0.721298098564148, arousal_loss=0.45549750328063965, emotion_loss=1.2144275903701782\n",
      "\n",
      "01_19_23:54:50 Seen so far: 135712 samples\n",
      "\n",
      "01_19_23:54:50 --- 1.7277274131774902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:52 Training loss at epoch 1 step 4250: 3.394330382347107\n",
      "\n",
      " This round's valence_loss=0.8958252668380737, arousal_loss=0.8237787485122681, emotion_loss=1.434894323348999\n",
      "\n",
      "01_19_23:54:52 Seen so far: 136032 samples\n",
      "\n",
      "01_19_23:54:52 --- 1.7283587455749512 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:53 Training loss at epoch 1 step 4260: 3.146650767326355\n",
      "\n",
      " This round's valence_loss=1.444812536239624, arousal_loss=1.2807142734527588, emotion_loss=1.1588417291641235\n",
      "\n",
      "01_19_23:54:53 Seen so far: 136352 samples\n",
      "\n",
      "01_19_23:54:53 --- 1.8071637153625488 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:55 Training loss at epoch 1 step 4270: 3.304235100746155\n",
      "\n",
      " This round's valence_loss=1.0256664752960205, arousal_loss=0.8785089254379272, emotion_loss=1.1965867280960083\n",
      "\n",
      "01_19_23:54:55 Seen so far: 136672 samples\n",
      "\n",
      "01_19_23:54:55 --- 1.7921812534332275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:57 Training loss at epoch 1 step 4280: 3.107485628128052\n",
      "\n",
      " This round's valence_loss=1.3794398307800293, arousal_loss=1.2190454006195068, emotion_loss=0.704464316368103\n",
      "\n",
      "01_19_23:54:57 Seen so far: 136992 samples\n",
      "\n",
      "01_19_23:54:57 --- 1.7673051357269287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:54:59 Training loss at epoch 1 step 4290: 3.4698996782302856\n",
      "\n",
      " This round's valence_loss=1.064096212387085, arousal_loss=0.9743266105651855, emotion_loss=1.36275315284729\n",
      "\n",
      "01_19_23:54:59 Seen so far: 137312 samples\n",
      "\n",
      "01_19_23:54:59 --- 1.7485759258270264 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:00 Training loss at epoch 1 step 4300: 3.21227765083313\n",
      "\n",
      " This round's valence_loss=1.2014071941375732, arousal_loss=1.0806353092193604, emotion_loss=1.0926039218902588\n",
      "\n",
      "01_19_23:55:00 Seen so far: 137632 samples\n",
      "\n",
      "01_19_23:55:00 --- 1.7348215579986572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:02 Training loss at epoch 1 step 4310: 2.9171290397644043\n",
      "\n",
      " This round's valence_loss=1.0083932876586914, arousal_loss=0.8259249925613403, emotion_loss=0.8849459290504456\n",
      "\n",
      "01_19_23:55:02 Seen so far: 137952 samples\n",
      "\n",
      "01_19_23:55:02 --- 1.769319772720337 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:04 Training loss at epoch 1 step 4320: 3.120443952083588\n",
      "\n",
      " This round's valence_loss=1.801651954650879, arousal_loss=1.717490792274475, emotion_loss=0.9045534133911133\n",
      "\n",
      "01_19_23:55:04 Seen so far: 138272 samples\n",
      "\n",
      "01_19_23:55:04 --- 1.7797048091888428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:06 Training loss at epoch 1 step 4330: 3.071740984916687\n",
      "\n",
      " This round's valence_loss=1.0854578018188477, arousal_loss=0.9771479368209839, emotion_loss=1.2821061611175537\n",
      "\n",
      "01_19_23:55:06 Seen so far: 138592 samples\n",
      "\n",
      "01_19_23:55:06 --- 1.798882007598877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:08 Training loss at epoch 1 step 4340: 3.367988181114197\n",
      "\n",
      " This round's valence_loss=1.4670085906982422, arousal_loss=1.2959113121032715, emotion_loss=0.8842160105705261\n",
      "\n",
      "01_19_23:55:08 Seen so far: 138912 samples\n",
      "\n",
      "01_19_23:55:08 --- 1.8684730529785156 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:09 Training loss at epoch 1 step 4350: 3.0893656253814696\n",
      "\n",
      " This round's valence_loss=1.080721139907837, arousal_loss=1.031381607055664, emotion_loss=0.9259534478187561\n",
      "\n",
      "01_19_23:55:09 Seen so far: 139232 samples\n",
      "\n",
      "01_19_23:55:09 --- 1.7703731060028076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:11 Training loss at epoch 1 step 4360: 3.061655592918396\n",
      "\n",
      " This round's valence_loss=1.2130579948425293, arousal_loss=1.0611921548843384, emotion_loss=1.141000509262085\n",
      "\n",
      "01_19_23:55:11 Seen so far: 139552 samples\n",
      "\n",
      "01_19_23:55:11 --- 1.8426620960235596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:13 Training loss at epoch 1 step 4370: 3.050548052787781\n",
      "\n",
      " This round's valence_loss=0.6522828340530396, arousal_loss=0.5234061479568481, emotion_loss=1.2665817737579346\n",
      "\n",
      "01_19_23:55:13 Seen so far: 139872 samples\n",
      "\n",
      "01_19_23:55:13 --- 1.791621208190918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:15 Training loss at epoch 1 step 4380: 3.5346490383148192\n",
      "\n",
      " This round's valence_loss=1.0952439308166504, arousal_loss=0.9122004508972168, emotion_loss=1.4249972105026245\n",
      "\n",
      "01_19_23:55:15 Seen so far: 140192 samples\n",
      "\n",
      "01_19_23:55:15 --- 1.6256508827209473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:17 Training loss at epoch 1 step 4390: 3.35273072719574\n",
      "\n",
      " This round's valence_loss=0.9603170156478882, arousal_loss=0.720367431640625, emotion_loss=1.1999843120574951\n",
      "\n",
      "01_19_23:55:17 Seen so far: 140512 samples\n",
      "\n",
      "01_19_23:55:17 --- 1.8523590564727783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:18 Training loss at epoch 1 step 4400: 2.9844282150268553\n",
      "\n",
      " This round's valence_loss=1.6809790134429932, arousal_loss=1.5415749549865723, emotion_loss=1.1188819408416748\n",
      "\n",
      "01_19_23:55:18 Seen so far: 140832 samples\n",
      "\n",
      "01_19_23:55:18 --- 1.7303986549377441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:20 Training loss at epoch 1 step 4410: 2.9089524269104006\n",
      "\n",
      " This round's valence_loss=0.787787914276123, arousal_loss=0.6116058826446533, emotion_loss=1.3032773733139038\n",
      "\n",
      "01_19_23:55:20 Seen so far: 141152 samples\n",
      "\n",
      "01_19_23:55:20 --- 1.6763076782226562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:22 Training loss at epoch 1 step 4420: 2.9459380388259886\n",
      "\n",
      " This round's valence_loss=1.1769378185272217, arousal_loss=1.0621912479400635, emotion_loss=1.105617642402649\n",
      "\n",
      "01_19_23:55:22 Seen so far: 141472 samples\n",
      "\n",
      "01_19_23:55:22 --- 1.7117037773132324 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:23 Training loss at epoch 1 step 4430: 3.4623609304428102\n",
      "\n",
      " This round's valence_loss=1.3022184371948242, arousal_loss=1.1729092597961426, emotion_loss=1.3211456537246704\n",
      "\n",
      "01_19_23:55:23 Seen so far: 141792 samples\n",
      "\n",
      "01_19_23:55:23 --- 1.6756787300109863 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:25 Training loss at epoch 1 step 4440: 2.9622487783432008\n",
      "\n",
      " This round's valence_loss=1.2286945581436157, arousal_loss=1.0992581844329834, emotion_loss=0.990683376789093\n",
      "\n",
      "01_19_23:55:25 Seen so far: 142112 samples\n",
      "\n",
      "01_19_23:55:25 --- 1.8830037117004395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:27 Training loss at epoch 1 step 4450: 3.1439591884613036\n",
      "\n",
      " This round's valence_loss=0.964840829372406, arousal_loss=0.8060786724090576, emotion_loss=0.8877435922622681\n",
      "\n",
      "01_19_23:55:27 Seen so far: 142432 samples\n",
      "\n",
      "01_19_23:55:27 --- 1.829829454421997 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:29 Training loss at epoch 1 step 4460: 3.3827890753746033\n",
      "\n",
      " This round's valence_loss=1.8022565841674805, arousal_loss=1.6556549072265625, emotion_loss=1.0278633832931519\n",
      "\n",
      "01_19_23:55:29 Seen so far: 142752 samples\n",
      "\n",
      "01_19_23:55:29 --- 1.7177062034606934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:30 Training loss at epoch 1 step 4470: 2.7904972553253176\n",
      "\n",
      " This round's valence_loss=0.873445987701416, arousal_loss=0.7387769222259521, emotion_loss=0.6651020050048828\n",
      "\n",
      "01_19_23:55:30 Seen so far: 143072 samples\n",
      "\n",
      "01_19_23:55:30 --- 1.6204032897949219 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:32 Training loss at epoch 1 step 4480: 2.873060369491577\n",
      "\n",
      " This round's valence_loss=1.2000339031219482, arousal_loss=1.1116611957550049, emotion_loss=0.9616348743438721\n",
      "\n",
      "01_19_23:55:32 Seen so far: 143392 samples\n",
      "\n",
      "01_19_23:55:32 --- 1.6267569065093994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:34 Training loss at epoch 1 step 4490: 3.0871475458145143\n",
      "\n",
      " This round's valence_loss=0.9727523326873779, arousal_loss=0.7949780225753784, emotion_loss=0.6991176009178162\n",
      "\n",
      "01_19_23:55:34 Seen so far: 143712 samples\n",
      "\n",
      "01_19_23:55:34 --- 1.6914992332458496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:35 Training loss at epoch 1 step 4500: 2.7301300287246706\n",
      "\n",
      " This round's valence_loss=1.1289161443710327, arousal_loss=0.9835985898971558, emotion_loss=0.8920494318008423\n",
      "\n",
      "01_19_23:55:35 Seen so far: 144032 samples\n",
      "\n",
      "01_19_23:55:35 --- 1.7235591411590576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:37 Training loss at epoch 1 step 4510: 3.131704592704773\n",
      "\n",
      " This round's valence_loss=1.0190839767456055, arousal_loss=0.8296877145767212, emotion_loss=0.9777780771255493\n",
      "\n",
      "01_19_23:55:37 Seen so far: 144352 samples\n",
      "\n",
      "01_19_23:55:37 --- 1.9927618503570557 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:39 Training loss at epoch 1 step 4520: 3.025695300102234\n",
      "\n",
      " This round's valence_loss=1.1057720184326172, arousal_loss=0.9882063865661621, emotion_loss=0.9587752223014832\n",
      "\n",
      "01_19_23:55:39 Seen so far: 144672 samples\n",
      "\n",
      "01_19_23:55:39 --- 2.011148452758789 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:41 Training loss at epoch 1 step 4530: 2.771688389778137\n",
      "\n",
      " This round's valence_loss=0.8569461107254028, arousal_loss=0.5838440656661987, emotion_loss=0.9928057789802551\n",
      "\n",
      "01_19_23:55:41 Seen so far: 144992 samples\n",
      "\n",
      "01_19_23:55:41 --- 1.791963815689087 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:43 Training loss at epoch 1 step 4540: 3.24832661151886\n",
      "\n",
      " This round's valence_loss=0.753725528717041, arousal_loss=0.5900993347167969, emotion_loss=1.1736537218093872\n",
      "\n",
      "01_19_23:55:43 Seen so far: 145312 samples\n",
      "\n",
      "01_19_23:55:43 --- 1.9500775337219238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:45 Training loss at epoch 1 step 4550: 2.989737558364868\n",
      "\n",
      " This round's valence_loss=1.2925885915756226, arousal_loss=1.0828871726989746, emotion_loss=1.0013813972473145\n",
      "\n",
      "01_19_23:55:45 Seen so far: 145632 samples\n",
      "\n",
      "01_19_23:55:45 --- 1.8731460571289062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:47 Training loss at epoch 1 step 4560: 2.7934931755065917\n",
      "\n",
      " This round's valence_loss=0.6441622972488403, arousal_loss=0.4961443841457367, emotion_loss=0.9989516735076904\n",
      "\n",
      "01_19_23:55:47 Seen so far: 145952 samples\n",
      "\n",
      "01_19_23:55:47 --- 1.6944632530212402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:48 Training loss at epoch 1 step 4570: 2.850869584083557\n",
      "\n",
      " This round's valence_loss=1.1354939937591553, arousal_loss=0.9906479120254517, emotion_loss=1.0769134759902954\n",
      "\n",
      "01_19_23:55:48 Seen so far: 146272 samples\n",
      "\n",
      "01_19_23:55:48 --- 1.7156755924224854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:50 Training loss at epoch 1 step 4580: 2.7868807911872864\n",
      "\n",
      " This round's valence_loss=0.7753570079803467, arousal_loss=0.7403758764266968, emotion_loss=1.2004084587097168\n",
      "\n",
      "01_19_23:55:50 Seen so far: 146592 samples\n",
      "\n",
      "01_19_23:55:50 --- 1.7079839706420898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:52 Training loss at epoch 1 step 4590: 2.9368422746658327\n",
      "\n",
      " This round's valence_loss=1.6386032104492188, arousal_loss=1.4364714622497559, emotion_loss=0.8737121820449829\n",
      "\n",
      "01_19_23:55:52 Seen so far: 146912 samples\n",
      "\n",
      "01_19_23:55:52 --- 1.5432987213134766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:54 Training loss at epoch 1 step 4600: 3.0507025480270387\n",
      "\n",
      " This round's valence_loss=1.0268282890319824, arousal_loss=0.825118899345398, emotion_loss=1.113601803779602\n",
      "\n",
      "01_19_23:55:54 Seen so far: 147232 samples\n",
      "\n",
      "01_19_23:55:54 --- 1.7927720546722412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:55 Training loss at epoch 1 step 4610: 2.825009524822235\n",
      "\n",
      " This round's valence_loss=0.6044666767120361, arousal_loss=0.3216578960418701, emotion_loss=0.8133944272994995\n",
      "\n",
      "01_19_23:55:55 Seen so far: 147552 samples\n",
      "\n",
      "01_19_23:55:55 --- 1.7505238056182861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:57 Training loss at epoch 1 step 4620: 2.8094759345054627\n",
      "\n",
      " This round's valence_loss=0.6287988424301147, arousal_loss=0.428018182516098, emotion_loss=0.8806214332580566\n",
      "\n",
      "01_19_23:55:57 Seen so far: 147872 samples\n",
      "\n",
      "01_19_23:55:57 --- 1.7390110492706299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:55:59 Training loss at epoch 1 step 4630: 3.1963147163391112\n",
      "\n",
      " This round's valence_loss=1.5246169567108154, arousal_loss=1.4193689823150635, emotion_loss=1.0120875835418701\n",
      "\n",
      "01_19_23:55:59 Seen so far: 148192 samples\n",
      "\n",
      "01_19_23:55:59 --- 1.6831583976745605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:01 Training loss at epoch 1 step 4640: 3.1867668628692627\n",
      "\n",
      " This round's valence_loss=1.383810043334961, arousal_loss=1.3615643978118896, emotion_loss=0.903933048248291\n",
      "\n",
      "01_19_23:56:01 Seen so far: 148512 samples\n",
      "\n",
      "01_19_23:56:01 --- 2.0161356925964355 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:03 Training loss at epoch 1 step 4650: 2.8592315316200256\n",
      "\n",
      " This round's valence_loss=1.0885522365570068, arousal_loss=0.9450455904006958, emotion_loss=1.0737563371658325\n",
      "\n",
      "01_19_23:56:03 Seen so far: 148832 samples\n",
      "\n",
      "01_19_23:56:03 --- 1.9581027030944824 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:05 Training loss at epoch 1 step 4660: 3.074480938911438\n",
      "\n",
      " This round's valence_loss=1.3264007568359375, arousal_loss=1.2044117450714111, emotion_loss=1.1587687730789185\n",
      "\n",
      "01_19_23:56:05 Seen so far: 149152 samples\n",
      "\n",
      "01_19_23:56:05 --- 1.9302160739898682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:06 Training loss at epoch 1 step 4670: 3.0431225895881653\n",
      "\n",
      " This round's valence_loss=1.0570478439331055, arousal_loss=0.9845099449157715, emotion_loss=1.2346493005752563\n",
      "\n",
      "01_19_23:56:06 Seen so far: 149472 samples\n",
      "\n",
      "01_19_23:56:06 --- 1.8885798454284668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:08 Training loss at epoch 1 step 4680: 3.3232393741607664\n",
      "\n",
      " This round's valence_loss=0.8534338474273682, arousal_loss=0.7262868881225586, emotion_loss=0.9130663871765137\n",
      "\n",
      "01_19_23:56:08 Seen so far: 149792 samples\n",
      "\n",
      "01_19_23:56:08 --- 1.8398549556732178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:10 Training loss at epoch 1 step 4690: 3.1125921249389648\n",
      "\n",
      " This round's valence_loss=0.7414344549179077, arousal_loss=0.5952026844024658, emotion_loss=1.1080440282821655\n",
      "\n",
      "01_19_23:56:10 Seen so far: 150112 samples\n",
      "\n",
      "01_19_23:56:10 --- 1.7105281352996826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:12 Training loss at epoch 1 step 4700: 2.8364485025405886\n",
      "\n",
      " This round's valence_loss=1.247589349746704, arousal_loss=1.0716898441314697, emotion_loss=0.8894136548042297\n",
      "\n",
      "01_19_23:56:12 Seen so far: 150432 samples\n",
      "\n",
      "01_19_23:56:12 --- 1.7048847675323486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:13 Training loss at epoch 1 step 4710: 3.2951183557510375\n",
      "\n",
      " This round's valence_loss=0.8626827001571655, arousal_loss=0.6685363054275513, emotion_loss=1.001346230506897\n",
      "\n",
      "01_19_23:56:13 Seen so far: 150752 samples\n",
      "\n",
      "01_19_23:56:13 --- 1.7115323543548584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:15 Training loss at epoch 1 step 4720: 3.151765322685242\n",
      "\n",
      " This round's valence_loss=0.8986983299255371, arousal_loss=0.8350108861923218, emotion_loss=1.2146598100662231\n",
      "\n",
      "01_19_23:56:15 Seen so far: 151072 samples\n",
      "\n",
      "01_19_23:56:15 --- 1.8405194282531738 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:17 Training loss at epoch 1 step 4730: 3.059369444847107\n",
      "\n",
      " This round's valence_loss=0.8237433433532715, arousal_loss=0.7535851001739502, emotion_loss=1.5378086566925049\n",
      "\n",
      "01_19_23:56:17 Seen so far: 151392 samples\n",
      "\n",
      "01_19_23:56:17 --- 1.7074971199035645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:19 Training loss at epoch 1 step 4740: 2.945524716377258\n",
      "\n",
      " This round's valence_loss=1.3156917095184326, arousal_loss=1.255426049232483, emotion_loss=0.9025685787200928\n",
      "\n",
      "01_19_23:56:19 Seen so far: 151712 samples\n",
      "\n",
      "01_19_23:56:19 --- 1.6442914009094238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:20 Training loss at epoch 1 step 4750: 3.1935136795043944\n",
      "\n",
      " This round's valence_loss=1.0478925704956055, arousal_loss=1.0093235969543457, emotion_loss=1.105493426322937\n",
      "\n",
      "01_19_23:56:20 Seen so far: 152032 samples\n",
      "\n",
      "01_19_23:56:20 --- 1.710017442703247 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:22 Training loss at epoch 1 step 4760: 3.4736440420150756\n",
      "\n",
      " This round's valence_loss=1.2284679412841797, arousal_loss=1.0774481296539307, emotion_loss=1.1355230808258057\n",
      "\n",
      "01_19_23:56:22 Seen so far: 152352 samples\n",
      "\n",
      "01_19_23:56:22 --- 1.8231208324432373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:24 Training loss at epoch 1 step 4770: 3.1605099201202393\n",
      "\n",
      " This round's valence_loss=1.1197562217712402, arousal_loss=0.9617918729782104, emotion_loss=1.0618996620178223\n",
      "\n",
      "01_19_23:56:24 Seen so far: 152672 samples\n",
      "\n",
      "01_19_23:56:24 --- 1.7032873630523682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:26 Training loss at epoch 1 step 4780: 3.097779130935669\n",
      "\n",
      " This round's valence_loss=0.8253458738327026, arousal_loss=0.6641343832015991, emotion_loss=1.0618566274642944\n",
      "\n",
      "01_19_23:56:26 Seen so far: 152992 samples\n",
      "\n",
      "01_19_23:56:26 --- 1.684812307357788 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:27 Training loss at epoch 1 step 4790: 3.504641962051392\n",
      "\n",
      " This round's valence_loss=1.541895866394043, arousal_loss=1.4511699676513672, emotion_loss=0.9444851875305176\n",
      "\n",
      "01_19_23:56:27 Seen so far: 153312 samples\n",
      "\n",
      "01_19_23:56:27 --- 1.8689744472503662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:29 Training loss at epoch 1 step 4800: 3.002258765697479\n",
      "\n",
      " This round's valence_loss=1.2748100757598877, arousal_loss=1.086031198501587, emotion_loss=0.8687567710876465\n",
      "\n",
      "01_19_23:56:29 Seen so far: 153632 samples\n",
      "\n",
      "01_19_23:56:29 --- 1.7372150421142578 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:31 Training loss at epoch 1 step 4810: 3.204370546340942\n",
      "\n",
      " This round's valence_loss=0.9881595373153687, arousal_loss=0.8712584972381592, emotion_loss=1.1297810077667236\n",
      "\n",
      "01_19_23:56:31 Seen so far: 153952 samples\n",
      "\n",
      "01_19_23:56:31 --- 1.7370517253875732 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:33 Training loss at epoch 1 step 4820: 3.0777642846107485\n",
      "\n",
      " This round's valence_loss=1.0408380031585693, arousal_loss=0.8257502317428589, emotion_loss=1.1305855512619019\n",
      "\n",
      "01_19_23:56:33 Seen so far: 154272 samples\n",
      "\n",
      "01_19_23:56:33 --- 1.7310514450073242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:34 Training loss at epoch 1 step 4830: 3.141407787799835\n",
      "\n",
      " This round's valence_loss=1.467771053314209, arousal_loss=1.3485569953918457, emotion_loss=1.2573041915893555\n",
      "\n",
      "01_19_23:56:34 Seen so far: 154592 samples\n",
      "\n",
      "01_19_23:56:34 --- 1.784264326095581 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:36 Training loss at epoch 1 step 4840: 3.108659338951111\n",
      "\n",
      " This round's valence_loss=1.0166606903076172, arousal_loss=0.8815373182296753, emotion_loss=1.2903430461883545\n",
      "\n",
      "01_19_23:56:36 Seen so far: 154912 samples\n",
      "\n",
      "01_19_23:56:36 --- 1.731921911239624 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:38 Training loss at epoch 1 step 4850: 3.058898687362671\n",
      "\n",
      " This round's valence_loss=1.0652283430099487, arousal_loss=1.0025534629821777, emotion_loss=0.8890430927276611\n",
      "\n",
      "01_19_23:56:38 Seen so far: 155232 samples\n",
      "\n",
      "01_19_23:56:38 --- 1.807518482208252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:40 Training loss at epoch 1 step 4860: 3.0971694946289063\n",
      "\n",
      " This round's valence_loss=0.8888309001922607, arousal_loss=0.6988822221755981, emotion_loss=0.9031344652175903\n",
      "\n",
      "01_19_23:56:40 Seen so far: 155552 samples\n",
      "\n",
      "01_19_23:56:40 --- 1.768484354019165 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:42 Training loss at epoch 1 step 4870: 3.0120043039321898\n",
      "\n",
      " This round's valence_loss=0.9751123189926147, arousal_loss=0.8797342777252197, emotion_loss=1.0576057434082031\n",
      "\n",
      "01_19_23:56:42 Seen so far: 155872 samples\n",
      "\n",
      "01_19_23:56:42 --- 2.0308475494384766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:44 Training loss at epoch 1 step 4880: 2.767621970176697\n",
      "\n",
      " This round's valence_loss=1.0624420642852783, arousal_loss=1.0189588069915771, emotion_loss=1.3070651292800903\n",
      "\n",
      "01_19_23:56:44 Seen so far: 156192 samples\n",
      "\n",
      "01_19_23:56:44 --- 1.9319560527801514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:45 Training loss at epoch 1 step 4890: 2.9289515018463135\n",
      "\n",
      " This round's valence_loss=1.4286285638809204, arousal_loss=1.3424420356750488, emotion_loss=1.3285930156707764\n",
      "\n",
      "01_19_23:56:45 Seen so far: 156512 samples\n",
      "\n",
      "01_19_23:56:45 --- 1.6127328872680664 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:47 Training loss at epoch 1 step 4900: 2.996631956100464\n",
      "\n",
      " This round's valence_loss=0.6666409373283386, arousal_loss=0.5248703956604004, emotion_loss=0.9505490064620972\n",
      "\n",
      "01_19_23:56:47 Seen so far: 156832 samples\n",
      "\n",
      "01_19_23:56:47 --- 1.8547050952911377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:49 Training loss at epoch 1 step 4910: 3.3169816732406616\n",
      "\n",
      " This round's valence_loss=0.6130762696266174, arousal_loss=0.49678850173950195, emotion_loss=0.9299240112304688\n",
      "\n",
      "01_19_23:56:49 Seen so far: 157152 samples\n",
      "\n",
      "01_19_23:56:49 --- 1.7843379974365234 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:51 Training loss at epoch 1 step 4920: 3.184744620323181\n",
      "\n",
      " This round's valence_loss=0.9742006063461304, arousal_loss=0.8739535212516785, emotion_loss=1.2013479471206665\n",
      "\n",
      "01_19_23:56:51 Seen so far: 157472 samples\n",
      "\n",
      "01_19_23:56:51 --- 1.888228416442871 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:53 Training loss at epoch 1 step 4930: 2.7920480489730837\n",
      "\n",
      " This round's valence_loss=0.8719127178192139, arousal_loss=0.7548294067382812, emotion_loss=0.713890790939331\n",
      "\n",
      "01_19_23:56:53 Seen so far: 157792 samples\n",
      "\n",
      "01_19_23:56:53 --- 1.9063019752502441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:54 Training loss at epoch 1 step 4940: 2.9538922548294066\n",
      "\n",
      " This round's valence_loss=1.1059339046478271, arousal_loss=0.9940552711486816, emotion_loss=0.9871467351913452\n",
      "\n",
      "01_19_23:56:54 Seen so far: 158112 samples\n",
      "\n",
      "01_19_23:56:54 --- 1.7201189994812012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:56 Training loss at epoch 1 step 4950: 3.211381030082703\n",
      "\n",
      " This round's valence_loss=1.474544644355774, arousal_loss=1.3511773347854614, emotion_loss=1.350609302520752\n",
      "\n",
      "01_19_23:56:56 Seen so far: 158432 samples\n",
      "\n",
      "01_19_23:56:56 --- 1.8495373725891113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:56:58 Training loss at epoch 1 step 4960: 3.253123140335083\n",
      "\n",
      " This round's valence_loss=1.2039523124694824, arousal_loss=1.117354393005371, emotion_loss=1.0158659219741821\n",
      "\n",
      "01_19_23:56:58 Seen so far: 158752 samples\n",
      "\n",
      "01_19_23:56:58 --- 1.750964879989624 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:00 Training loss at epoch 1 step 4970: 2.677940082550049\n",
      "\n",
      " This round's valence_loss=1.2257039546966553, arousal_loss=1.094196081161499, emotion_loss=0.8829426765441895\n",
      "\n",
      "01_19_23:57:00 Seen so far: 159072 samples\n",
      "\n",
      "01_19_23:57:00 --- 1.8600659370422363 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:02 Training loss at epoch 1 step 4980: 3.245718169212341\n",
      "\n",
      " This round's valence_loss=1.766935110092163, arousal_loss=1.6693432331085205, emotion_loss=1.2783241271972656\n",
      "\n",
      "01_19_23:57:02 Seen so far: 159392 samples\n",
      "\n",
      "01_19_23:57:02 --- 1.8887608051300049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:04 Training loss at epoch 1 step 4990: 2.83806471824646\n",
      "\n",
      " This round's valence_loss=0.7595087289810181, arousal_loss=0.6022423505783081, emotion_loss=1.3446910381317139\n",
      "\n",
      "01_19_23:57:04 Seen so far: 159712 samples\n",
      "\n",
      "01_19_23:57:04 --- 1.7762055397033691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:05 Training loss at epoch 1 step 5000: 2.9723532438278197\n",
      "\n",
      " This round's valence_loss=1.2151904106140137, arousal_loss=1.066694974899292, emotion_loss=0.8541299104690552\n",
      "\n",
      "01_19_23:57:05 Seen so far: 160032 samples\n",
      "\n",
      "01_19_23:57:05 --- 1.7509064674377441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:07 Training loss at epoch 1 step 5010: 3.0244385838508605\n",
      "\n",
      " This round's valence_loss=1.2839891910552979, arousal_loss=1.1996841430664062, emotion_loss=1.1881787776947021\n",
      "\n",
      "01_19_23:57:07 Seen so far: 160352 samples\n",
      "\n",
      "01_19_23:57:07 --- 1.7061192989349365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:09 Training loss at epoch 1 step 5020: 2.99919970035553\n",
      "\n",
      " This round's valence_loss=1.1240187883377075, arousal_loss=0.9777383804321289, emotion_loss=1.0977648496627808\n",
      "\n",
      "01_19_23:57:09 Seen so far: 160672 samples\n",
      "\n",
      "01_19_23:57:09 --- 1.8357875347137451 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:11 Training loss at epoch 1 step 5030: 3.1569464683532713\n",
      "\n",
      " This round's valence_loss=1.2017467021942139, arousal_loss=1.104708194732666, emotion_loss=1.2560005187988281\n",
      "\n",
      "01_19_23:57:11 Seen so far: 160992 samples\n",
      "\n",
      "01_19_23:57:11 --- 1.8479301929473877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:12 Training loss at epoch 1 step 5040: 3.184852194786072\n",
      "\n",
      " This round's valence_loss=1.0658483505249023, arousal_loss=0.8330521583557129, emotion_loss=0.8658921122550964\n",
      "\n",
      "01_19_23:57:12 Seen so far: 161312 samples\n",
      "\n",
      "01_19_23:57:12 --- 1.6641297340393066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:14 Training loss at epoch 1 step 5050: 3.179153060913086\n",
      "\n",
      " This round's valence_loss=1.1941087245941162, arousal_loss=1.0030901432037354, emotion_loss=1.211308479309082\n",
      "\n",
      "01_19_23:57:14 Seen so far: 161632 samples\n",
      "\n",
      "01_19_23:57:14 --- 1.7040808200836182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:16 Training loss at epoch 1 step 5060: 3.006058430671692\n",
      "\n",
      " This round's valence_loss=0.9689487218856812, arousal_loss=0.8366521596908569, emotion_loss=0.7974066734313965\n",
      "\n",
      "01_19_23:57:16 Seen so far: 161952 samples\n",
      "\n",
      "01_19_23:57:16 --- 1.693615436553955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:17 Training loss at epoch 1 step 5070: 3.2984711170196532\n",
      "\n",
      " This round's valence_loss=0.933634877204895, arousal_loss=0.8778775930404663, emotion_loss=1.43081533908844\n",
      "\n",
      "01_19_23:57:17 Seen so far: 162272 samples\n",
      "\n",
      "01_19_23:57:17 --- 1.6840858459472656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:19 Training loss at epoch 1 step 5080: 3.0615808248519896\n",
      "\n",
      " This round's valence_loss=0.7467840909957886, arousal_loss=0.6643074750900269, emotion_loss=1.1551405191421509\n",
      "\n",
      "01_19_23:57:19 Seen so far: 162592 samples\n",
      "\n",
      "01_19_23:57:19 --- 1.6271429061889648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:21 Training loss at epoch 1 step 5090: 2.931270432472229\n",
      "\n",
      " This round's valence_loss=1.1066792011260986, arousal_loss=0.996428370475769, emotion_loss=0.8846306204795837\n",
      "\n",
      "01_19_23:57:21 Seen so far: 162912 samples\n",
      "\n",
      "01_19_23:57:21 --- 1.8711705207824707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:23 Training loss at epoch 1 step 5100: 3.359842801094055\n",
      "\n",
      " This round's valence_loss=1.6403193473815918, arousal_loss=1.5711910724639893, emotion_loss=1.5196219682693481\n",
      "\n",
      "01_19_23:57:23 Seen so far: 163232 samples\n",
      "\n",
      "01_19_23:57:23 --- 1.7771472930908203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:25 Training loss at epoch 1 step 5110: 3.5183337450027468\n",
      "\n",
      " This round's valence_loss=1.9711260795593262, arousal_loss=1.9675254821777344, emotion_loss=1.4074677228927612\n",
      "\n",
      "01_19_23:57:25 Seen so far: 163552 samples\n",
      "\n",
      "01_19_23:57:25 --- 1.861884355545044 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:26 Training loss at epoch 1 step 5120: 2.7736867666244507\n",
      "\n",
      " This round's valence_loss=0.9367260932922363, arousal_loss=0.7334664463996887, emotion_loss=0.8027381896972656\n",
      "\n",
      "01_19_23:57:26 Seen so far: 163872 samples\n",
      "\n",
      "01_19_23:57:26 --- 1.7331688404083252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:28 Training loss at epoch 1 step 5130: 3.4055792331695556\n",
      "\n",
      " This round's valence_loss=1.5499651432037354, arousal_loss=1.3419418334960938, emotion_loss=1.1454256772994995\n",
      "\n",
      "01_19_23:57:28 Seen so far: 164192 samples\n",
      "\n",
      "01_19_23:57:28 --- 1.7405102252960205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:30 Training loss at epoch 1 step 5140: 3.1819419860839844\n",
      "\n",
      " This round's valence_loss=1.2721540927886963, arousal_loss=1.066277265548706, emotion_loss=0.9558157920837402\n",
      "\n",
      "01_19_23:57:30 Seen so far: 164512 samples\n",
      "\n",
      "01_19_23:57:30 --- 1.8321192264556885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:32 Training loss at epoch 1 step 5150: 3.093012309074402\n",
      "\n",
      " This round's valence_loss=1.2011996507644653, arousal_loss=1.101468801498413, emotion_loss=1.1832928657531738\n",
      "\n",
      "01_19_23:57:32 Seen so far: 164832 samples\n",
      "\n",
      "01_19_23:57:32 --- 1.7217166423797607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:33 Training loss at epoch 1 step 5160: 3.291931319236755\n",
      "\n",
      " This round's valence_loss=1.2499216794967651, arousal_loss=1.0860955715179443, emotion_loss=0.9601215124130249\n",
      "\n",
      "01_19_23:57:33 Seen so far: 165152 samples\n",
      "\n",
      "01_19_23:57:33 --- 1.8285131454467773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:35 Training loss at epoch 1 step 5170: 3.2441821575164793\n",
      "\n",
      " This round's valence_loss=1.18501615524292, arousal_loss=1.0564136505126953, emotion_loss=1.074069857597351\n",
      "\n",
      "01_19_23:57:35 Seen so far: 165472 samples\n",
      "\n",
      "01_19_23:57:35 --- 1.9557197093963623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:37 Training loss at epoch 1 step 5180: 3.1324225187301638\n",
      "\n",
      " This round's valence_loss=1.3485232591629028, arousal_loss=1.2078510522842407, emotion_loss=0.9248130321502686\n",
      "\n",
      "01_19_23:57:37 Seen so far: 165792 samples\n",
      "\n",
      "01_19_23:57:37 --- 1.847219705581665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:39 Training loss at epoch 1 step 5190: 3.345238542556763\n",
      "\n",
      " This round's valence_loss=1.2615660429000854, arousal_loss=1.1141853332519531, emotion_loss=1.1210800409317017\n",
      "\n",
      "01_19_23:57:39 Seen so far: 166112 samples\n",
      "\n",
      "01_19_23:57:39 --- 1.7731924057006836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:41 Training loss at epoch 1 step 5200: 2.879615044593811\n",
      "\n",
      " This round's valence_loss=0.9459614753723145, arousal_loss=0.8121267557144165, emotion_loss=1.0354461669921875\n",
      "\n",
      "01_19_23:57:41 Seen so far: 166432 samples\n",
      "\n",
      "01_19_23:57:41 --- 1.6136789321899414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:42 Training loss at epoch 1 step 5210: 3.2545964241027834\n",
      "\n",
      " This round's valence_loss=0.7399955987930298, arousal_loss=0.6087427139282227, emotion_loss=1.1020958423614502\n",
      "\n",
      "01_19_23:57:42 Seen so far: 166752 samples\n",
      "\n",
      "01_19_23:57:42 --- 1.7557804584503174 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:44 Training loss at epoch 1 step 5220: 3.169894075393677\n",
      "\n",
      " This round's valence_loss=0.9888312816619873, arousal_loss=0.8568787574768066, emotion_loss=0.9111655354499817\n",
      "\n",
      "01_19_23:57:44 Seen so far: 167072 samples\n",
      "\n",
      "01_19_23:57:44 --- 1.7105698585510254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:46 Training loss at epoch 1 step 5230: 3.4258508682250977\n",
      "\n",
      " This round's valence_loss=0.6449097394943237, arousal_loss=0.4924313426017761, emotion_loss=0.7443903088569641\n",
      "\n",
      "01_19_23:57:46 Seen so far: 167392 samples\n",
      "\n",
      "01_19_23:57:46 --- 1.6723051071166992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:48 Training loss at epoch 1 step 5240: 3.2188636541366575\n",
      "\n",
      " This round's valence_loss=1.5665886402130127, arousal_loss=1.4731197357177734, emotion_loss=1.21207594871521\n",
      "\n",
      "01_19_23:57:48 Seen so far: 167712 samples\n",
      "\n",
      "01_19_23:57:48 --- 1.7135112285614014 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:50 Training loss at epoch 1 step 5250: 2.972468304634094\n",
      "\n",
      " This round's valence_loss=0.5217859148979187, arousal_loss=0.36429354548454285, emotion_loss=0.9396096467971802\n",
      "\n",
      "01_19_23:57:50 Seen so far: 168032 samples\n",
      "\n",
      "01_19_23:57:50 --- 1.9770498275756836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:51 Training loss at epoch 1 step 5260: 3.0409468054771422\n",
      "\n",
      " This round's valence_loss=1.520989179611206, arousal_loss=1.3334836959838867, emotion_loss=1.1315690279006958\n",
      "\n",
      "01_19_23:57:51 Seen so far: 168352 samples\n",
      "\n",
      "01_19_23:57:51 --- 1.934441328048706 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:53 Training loss at epoch 1 step 5270: 2.970185089111328\n",
      "\n",
      " This round's valence_loss=0.6806814670562744, arousal_loss=0.4646500051021576, emotion_loss=1.0780529975891113\n",
      "\n",
      "01_19_23:57:53 Seen so far: 168672 samples\n",
      "\n",
      "01_19_23:57:53 --- 1.8265554904937744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:55 Training loss at epoch 1 step 5280: 3.086453342437744\n",
      "\n",
      " This round's valence_loss=1.007645845413208, arousal_loss=0.8852095603942871, emotion_loss=1.4190791845321655\n",
      "\n",
      "01_19_23:57:55 Seen so far: 168992 samples\n",
      "\n",
      "01_19_23:57:55 --- 1.9495043754577637 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:57 Training loss at epoch 1 step 5290: 3.1330559253692627\n",
      "\n",
      " This round's valence_loss=1.222475290298462, arousal_loss=1.0651086568832397, emotion_loss=1.025286316871643\n",
      "\n",
      "01_19_23:57:57 Seen so far: 169312 samples\n",
      "\n",
      "01_19_23:57:57 --- 1.7796084880828857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:57:59 Training loss at epoch 1 step 5300: 2.8586691856384276\n",
      "\n",
      " This round's valence_loss=1.337216854095459, arousal_loss=1.2010283470153809, emotion_loss=1.3439429998397827\n",
      "\n",
      "01_19_23:57:59 Seen so far: 169632 samples\n",
      "\n",
      "01_19_23:57:59 --- 1.879042387008667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:01 Training loss at epoch 1 step 5310: 2.8030076026916504\n",
      "\n",
      " This round's valence_loss=0.7989053726196289, arousal_loss=0.7256718873977661, emotion_loss=1.1752361059188843\n",
      "\n",
      "01_19_23:58:01 Seen so far: 169952 samples\n",
      "\n",
      "01_19_23:58:01 --- 1.8057453632354736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:02 Training loss at epoch 1 step 5320: 3.039022707939148\n",
      "\n",
      " This round's valence_loss=0.7589148283004761, arousal_loss=0.5861866474151611, emotion_loss=1.0116850137710571\n",
      "\n",
      "01_19_23:58:02 Seen so far: 170272 samples\n",
      "\n",
      "01_19_23:58:02 --- 1.681966781616211 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:04 Training loss at epoch 1 step 5330: 3.6409204959869386\n",
      "\n",
      " This round's valence_loss=0.8756057024002075, arousal_loss=0.7498701810836792, emotion_loss=1.2013705968856812\n",
      "\n",
      "01_19_23:58:04 Seen so far: 170592 samples\n",
      "\n",
      "01_19_23:58:04 --- 1.6303255558013916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:06 Training loss at epoch 1 step 5340: 3.0458319425582885\n",
      "\n",
      " This round's valence_loss=0.8167895078659058, arousal_loss=0.5549215078353882, emotion_loss=0.8898113369941711\n",
      "\n",
      "01_19_23:58:06 Seen so far: 170912 samples\n",
      "\n",
      "01_19_23:58:06 --- 1.5387790203094482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:07 Training loss at epoch 1 step 5350: 2.7600000143051147\n",
      "\n",
      " This round's valence_loss=0.832050085067749, arousal_loss=0.7220886945724487, emotion_loss=0.8933049440383911\n",
      "\n",
      "01_19_23:58:07 Seen so far: 171232 samples\n",
      "\n",
      "01_19_23:58:07 --- 1.719998836517334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:09 Training loss at epoch 1 step 5360: 3.032062029838562\n",
      "\n",
      " This round's valence_loss=0.8739084005355835, arousal_loss=0.7219936847686768, emotion_loss=0.9845443367958069\n",
      "\n",
      "01_19_23:58:09 Seen so far: 171552 samples\n",
      "\n",
      "01_19_23:58:09 --- 1.8155770301818848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:11 Training loss at epoch 1 step 5370: 2.8353814244270326\n",
      "\n",
      " This round's valence_loss=0.9670926332473755, arousal_loss=0.7964158058166504, emotion_loss=0.8882678747177124\n",
      "\n",
      "01_19_23:58:11 Seen so far: 171872 samples\n",
      "\n",
      "01_19_23:58:11 --- 1.8305621147155762 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:13 Training loss at epoch 1 step 5380: 3.0612706899642945\n",
      "\n",
      " This round's valence_loss=0.7723633050918579, arousal_loss=0.594355583190918, emotion_loss=0.9724952578544617\n",
      "\n",
      "01_19_23:58:13 Seen so far: 172192 samples\n",
      "\n",
      "01_19_23:58:13 --- 1.6417276859283447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:14 Training loss at epoch 1 step 5390: 3.2484317064285277\n",
      "\n",
      " This round's valence_loss=1.7583959102630615, arousal_loss=1.6564658880233765, emotion_loss=1.270103931427002\n",
      "\n",
      "01_19_23:58:14 Seen so far: 172512 samples\n",
      "\n",
      "01_19_23:58:14 --- 1.8105511665344238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:16 Training loss at epoch 1 step 5400: 2.9367876052856445\n",
      "\n",
      " This round's valence_loss=0.8584856986999512, arousal_loss=0.7058035731315613, emotion_loss=1.1106679439544678\n",
      "\n",
      "01_19_23:58:16 Seen so far: 172832 samples\n",
      "\n",
      "01_19_23:58:16 --- 1.8268790245056152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:18 Training loss at epoch 1 step 5410: 3.0407641887664796\n",
      "\n",
      " This round's valence_loss=1.227278470993042, arousal_loss=1.1089885234832764, emotion_loss=1.4032087326049805\n",
      "\n",
      "01_19_23:58:18 Seen so far: 173152 samples\n",
      "\n",
      "01_19_23:58:18 --- 1.7144057750701904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:20 Training loss at epoch 1 step 5420: 2.869676351547241\n",
      "\n",
      " This round's valence_loss=1.6125550270080566, arousal_loss=1.451399564743042, emotion_loss=1.1123305559158325\n",
      "\n",
      "01_19_23:58:20 Seen so far: 173472 samples\n",
      "\n",
      "01_19_23:58:20 --- 1.7391960620880127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:21 Training loss at epoch 1 step 5430: 2.731889510154724\n",
      "\n",
      " This round's valence_loss=1.1146470308303833, arousal_loss=0.9635828733444214, emotion_loss=0.9814469814300537\n",
      "\n",
      "01_19_23:58:21 Seen so far: 173792 samples\n",
      "\n",
      "01_19_23:58:21 --- 1.63230562210083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:23 Training loss at epoch 1 step 5440: 2.7533149480819703\n",
      "\n",
      " This round's valence_loss=1.2333664894104004, arousal_loss=1.0515129566192627, emotion_loss=1.068253755569458\n",
      "\n",
      "01_19_23:58:23 Seen so far: 174112 samples\n",
      "\n",
      "01_19_23:58:23 --- 1.6986231803894043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:25 Training loss at epoch 1 step 5450: 2.9039172291755677\n",
      "\n",
      " This round's valence_loss=0.6219879984855652, arousal_loss=0.5406920909881592, emotion_loss=0.7730995416641235\n",
      "\n",
      "01_19_23:58:25 Seen so far: 174432 samples\n",
      "\n",
      "01_19_23:58:25 --- 1.7966933250427246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:27 Training loss at epoch 1 step 5460: 2.894105315208435\n",
      "\n",
      " This round's valence_loss=0.659989595413208, arousal_loss=0.5267433524131775, emotion_loss=1.3026758432388306\n",
      "\n",
      "01_19_23:58:27 Seen so far: 174752 samples\n",
      "\n",
      "01_19_23:58:27 --- 1.8022232055664062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:29 Training loss at epoch 1 step 5470: 3.207618761062622\n",
      "\n",
      " This round's valence_loss=1.4572019577026367, arousal_loss=1.3040218353271484, emotion_loss=0.8155277967453003\n",
      "\n",
      "01_19_23:58:29 Seen so far: 175072 samples\n",
      "\n",
      "01_19_23:58:29 --- 1.9770116806030273 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:30 Training loss at epoch 1 step 5480: 3.1216508865356447\n",
      "\n",
      " This round's valence_loss=1.342698574066162, arousal_loss=1.2207565307617188, emotion_loss=1.1875405311584473\n",
      "\n",
      "01_19_23:58:30 Seen so far: 175392 samples\n",
      "\n",
      "01_19_23:58:30 --- 1.7423624992370605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:32 Training loss at epoch 1 step 5490: 3.0132233619689943\n",
      "\n",
      " This round's valence_loss=1.2432910203933716, arousal_loss=1.1271324157714844, emotion_loss=1.0064475536346436\n",
      "\n",
      "01_19_23:58:32 Seen so far: 175712 samples\n",
      "\n",
      "01_19_23:58:32 --- 1.8222970962524414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:34 Training loss at epoch 1 step 5500: 3.230141448974609\n",
      "\n",
      " This round's valence_loss=1.2825756072998047, arousal_loss=1.1808068752288818, emotion_loss=0.9881664514541626\n",
      "\n",
      "01_19_23:58:34 Seen so far: 176032 samples\n",
      "\n",
      "01_19_23:58:34 --- 2.040212392807007 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:36 Training loss at epoch 1 step 5510: 2.7423122406005858\n",
      "\n",
      " This round's valence_loss=0.5235641002655029, arousal_loss=0.3374162018299103, emotion_loss=0.7348051071166992\n",
      "\n",
      "01_19_23:58:36 Seen so far: 176352 samples\n",
      "\n",
      "01_19_23:58:36 --- 1.9436798095703125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:38 Training loss at epoch 1 step 5520: 2.879689836502075\n",
      "\n",
      " This round's valence_loss=0.9486747980117798, arousal_loss=0.8399428129196167, emotion_loss=1.0465233325958252\n",
      "\n",
      "01_19_23:58:38 Seen so far: 176672 samples\n",
      "\n",
      "01_19_23:58:38 --- 1.7809975147247314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:40 Training loss at epoch 1 step 5530: 3.045843815803528\n",
      "\n",
      " This round's valence_loss=1.1488301753997803, arousal_loss=0.9481163024902344, emotion_loss=0.8057341575622559\n",
      "\n",
      "01_19_23:58:40 Seen so far: 176992 samples\n",
      "\n",
      "01_19_23:58:40 --- 1.7542839050292969 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:41 Training loss at epoch 1 step 5540: 3.4932475328445434\n",
      "\n",
      " This round's valence_loss=1.2963201999664307, arousal_loss=1.2057628631591797, emotion_loss=1.147737979888916\n",
      "\n",
      "01_19_23:58:41 Seen so far: 177312 samples\n",
      "\n",
      "01_19_23:58:41 --- 1.7436442375183105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:43 Training loss at epoch 1 step 5550: 3.157191276550293\n",
      "\n",
      " This round's valence_loss=1.2216529846191406, arousal_loss=1.0993397235870361, emotion_loss=1.356220006942749\n",
      "\n",
      "01_19_23:58:43 Seen so far: 177632 samples\n",
      "\n",
      "01_19_23:58:43 --- 1.7615752220153809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:45 Training loss at epoch 1 step 5560: 3.049159550666809\n",
      "\n",
      " This round's valence_loss=0.9766519069671631, arousal_loss=0.8530490398406982, emotion_loss=1.089511513710022\n",
      "\n",
      "01_19_23:58:45 Seen so far: 177952 samples\n",
      "\n",
      "01_19_23:58:45 --- 1.8269708156585693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:47 Training loss at epoch 1 step 5570: 3.3057061433792114\n",
      "\n",
      " This round's valence_loss=0.8007476329803467, arousal_loss=0.7797971963882446, emotion_loss=1.1091783046722412\n",
      "\n",
      "01_19_23:58:47 Seen so far: 178272 samples\n",
      "\n",
      "01_19_23:58:47 --- 1.8780686855316162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:49 Training loss at epoch 1 step 5580: 3.38025062084198\n",
      "\n",
      " This round's valence_loss=1.2757539749145508, arousal_loss=1.1189467906951904, emotion_loss=0.6519289016723633\n",
      "\n",
      "01_19_23:58:49 Seen so far: 178592 samples\n",
      "\n",
      "01_19_23:58:49 --- 1.9008097648620605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:51 Training loss at epoch 1 step 5590: 3.273390030860901\n",
      "\n",
      " This round's valence_loss=1.09669828414917, arousal_loss=0.9553486108779907, emotion_loss=0.9506916999816895\n",
      "\n",
      "01_19_23:58:51 Seen so far: 178912 samples\n",
      "\n",
      "01_19_23:58:51 --- 1.7735435962677002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:52 Training loss at epoch 1 step 5600: 2.997929811477661\n",
      "\n",
      " This round's valence_loss=0.7935593128204346, arousal_loss=0.5868625640869141, emotion_loss=0.8730125427246094\n",
      "\n",
      "01_19_23:58:52 Seen so far: 179232 samples\n",
      "\n",
      "01_19_23:58:52 --- 1.6490678787231445 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:54 Training loss at epoch 1 step 5610: 3.291219615936279\n",
      "\n",
      " This round's valence_loss=1.609205961227417, arousal_loss=1.4837310314178467, emotion_loss=1.2199641466140747\n",
      "\n",
      "01_19_23:58:54 Seen so far: 179552 samples\n",
      "\n",
      "01_19_23:58:54 --- 1.8425824642181396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:56 Training loss at epoch 1 step 5620: 3.0254582166671753\n",
      "\n",
      " This round's valence_loss=1.0561320781707764, arousal_loss=0.9906046390533447, emotion_loss=1.2855372428894043\n",
      "\n",
      "01_19_23:58:56 Seen so far: 179872 samples\n",
      "\n",
      "01_19_23:58:56 --- 1.7661025524139404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:58 Training loss at epoch 1 step 5630: 3.4220211267471314\n",
      "\n",
      " This round's valence_loss=1.2032191753387451, arousal_loss=1.08351469039917, emotion_loss=1.1597418785095215\n",
      "\n",
      "01_19_23:58:58 Seen so far: 180192 samples\n",
      "\n",
      "01_19_23:58:58 --- 1.7596986293792725 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:58:59 Training loss at epoch 1 step 5640: 2.872553563117981\n",
      "\n",
      " This round's valence_loss=1.0053095817565918, arousal_loss=0.9640210866928101, emotion_loss=0.8512406349182129\n",
      "\n",
      "01_19_23:58:59 Seen so far: 180512 samples\n",
      "\n",
      "01_19_23:58:59 --- 1.7274670600891113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:01 Training loss at epoch 1 step 5650: 3.264617443084717\n",
      "\n",
      " This round's valence_loss=1.19071364402771, arousal_loss=1.1123952865600586, emotion_loss=1.469966173171997\n",
      "\n",
      "01_19_23:59:01 Seen so far: 180832 samples\n",
      "\n",
      "01_19_23:59:01 --- 1.7176809310913086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:03 Training loss at epoch 1 step 5660: 2.8512295961380003\n",
      "\n",
      " This round's valence_loss=1.027855634689331, arousal_loss=0.8758278489112854, emotion_loss=1.0674011707305908\n",
      "\n",
      "01_19_23:59:03 Seen so far: 181152 samples\n",
      "\n",
      "01_19_23:59:03 --- 1.763246774673462 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:04 Training loss at epoch 1 step 5670: 3.6071870803833006\n",
      "\n",
      " This round's valence_loss=1.3788783550262451, arousal_loss=1.2375578880310059, emotion_loss=0.9389833807945251\n",
      "\n",
      "01_19_23:59:04 Seen so far: 181472 samples\n",
      "\n",
      "01_19_23:59:04 --- 1.6822166442871094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:06 Training loss at epoch 1 step 5680: 2.982111430168152\n",
      "\n",
      " This round's valence_loss=1.456022024154663, arousal_loss=1.3049784898757935, emotion_loss=0.894905686378479\n",
      "\n",
      "01_19_23:59:06 Seen so far: 181792 samples\n",
      "\n",
      "01_19_23:59:06 --- 1.7377099990844727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:08 Training loss at epoch 1 step 5690: 2.858599829673767\n",
      "\n",
      " This round's valence_loss=1.3097054958343506, arousal_loss=1.0215351581573486, emotion_loss=0.8937191367149353\n",
      "\n",
      "01_19_23:59:08 Seen so far: 182112 samples\n",
      "\n",
      "01_19_23:59:08 --- 1.7475519180297852 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:10 Training loss at epoch 1 step 5700: 3.4748568296432496\n",
      "\n",
      " This round's valence_loss=0.7082967758178711, arousal_loss=0.6144225597381592, emotion_loss=1.1158902645111084\n",
      "\n",
      "01_19_23:59:10 Seen so far: 182432 samples\n",
      "\n",
      "01_19_23:59:10 --- 1.7296655178070068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:11 Training loss at epoch 1 step 5710: 2.9864798069000242\n",
      "\n",
      " This round's valence_loss=1.1153416633605957, arousal_loss=0.979783296585083, emotion_loss=0.659072995185852\n",
      "\n",
      "01_19_23:59:11 Seen so far: 182752 samples\n",
      "\n",
      "01_19_23:59:11 --- 1.7580177783966064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:13 Training loss at epoch 1 step 5720: 3.178301382064819\n",
      "\n",
      " This round's valence_loss=1.7768332958221436, arousal_loss=1.7083258628845215, emotion_loss=1.1625401973724365\n",
      "\n",
      "01_19_23:59:13 Seen so far: 183072 samples\n",
      "\n",
      "01_19_23:59:13 --- 1.7096145153045654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:15 Training loss at epoch 1 step 5730: 3.3544650793075563\n",
      "\n",
      " This round's valence_loss=0.9842298030853271, arousal_loss=0.8725839853286743, emotion_loss=0.8203338980674744\n",
      "\n",
      "01_19_23:59:15 Seen so far: 183392 samples\n",
      "\n",
      "01_19_23:59:15 --- 1.8270549774169922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:17 Training loss at epoch 1 step 5740: 3.26356782913208\n",
      "\n",
      " This round's valence_loss=1.1474133729934692, arousal_loss=0.9312155246734619, emotion_loss=0.8650091886520386\n",
      "\n",
      "01_19_23:59:17 Seen so far: 183712 samples\n",
      "\n",
      "01_19_23:59:17 --- 1.737947940826416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:18 Training loss at epoch 1 step 5750: 3.108394956588745\n",
      "\n",
      " This round's valence_loss=1.1965572834014893, arousal_loss=0.8970348834991455, emotion_loss=0.6550995111465454\n",
      "\n",
      "01_19_23:59:18 Seen so far: 184032 samples\n",
      "\n",
      "01_19_23:59:18 --- 1.6792290210723877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:20 Training loss at epoch 1 step 5760: 2.999166655540466\n",
      "\n",
      " This round's valence_loss=1.105388879776001, arousal_loss=0.9319416284561157, emotion_loss=1.1050302982330322\n",
      "\n",
      "01_19_23:59:20 Seen so far: 184352 samples\n",
      "\n",
      "01_19_23:59:20 --- 1.8043110370635986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:22 Training loss at epoch 1 step 5770: 3.2649724006652834\n",
      "\n",
      " This round's valence_loss=1.048506259918213, arousal_loss=1.0348622798919678, emotion_loss=1.4975188970565796\n",
      "\n",
      "01_19_23:59:22 Seen so far: 184672 samples\n",
      "\n",
      "01_19_23:59:22 --- 1.6977314949035645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:24 Training loss at epoch 1 step 5780: 2.7630459308624267\n",
      "\n",
      " This round's valence_loss=0.9776884317398071, arousal_loss=0.8500747680664062, emotion_loss=0.9243978261947632\n",
      "\n",
      "01_19_23:59:24 Seen so far: 184992 samples\n",
      "\n",
      "01_19_23:59:24 --- 1.8406620025634766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:25 Training loss at epoch 1 step 5790: 3.0029304027557373\n",
      "\n",
      " This round's valence_loss=1.4739940166473389, arousal_loss=1.3113267421722412, emotion_loss=0.9408127665519714\n",
      "\n",
      "01_19_23:59:25 Seen so far: 185312 samples\n",
      "\n",
      "01_19_23:59:25 --- 1.7218496799468994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:27 Training loss at epoch 1 step 5800: 2.681216502189636\n",
      "\n",
      " This round's valence_loss=1.0847759246826172, arousal_loss=0.952938437461853, emotion_loss=0.8795973062515259\n",
      "\n",
      "01_19_23:59:27 Seen so far: 185632 samples\n",
      "\n",
      "01_19_23:59:27 --- 1.6943845748901367 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:29 Training loss at epoch 1 step 5810: 3.3355686902999877\n",
      "\n",
      " This round's valence_loss=1.2175002098083496, arousal_loss=1.078474760055542, emotion_loss=1.2188048362731934\n",
      "\n",
      "01_19_23:59:29 Seen so far: 185952 samples\n",
      "\n",
      "01_19_23:59:29 --- 1.9292628765106201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:31 Training loss at epoch 1 step 5820: 3.162242579460144\n",
      "\n",
      " This round's valence_loss=1.4493741989135742, arousal_loss=1.350118637084961, emotion_loss=0.6559532880783081\n",
      "\n",
      "01_19_23:59:31 Seen so far: 186272 samples\n",
      "\n",
      "01_19_23:59:31 --- 1.844339370727539 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:33 Training loss at epoch 1 step 5830: 3.282589054107666\n",
      "\n",
      " This round's valence_loss=1.3670814037322998, arousal_loss=1.1825087070465088, emotion_loss=1.0026859045028687\n",
      "\n",
      "01_19_23:59:33 Seen so far: 186592 samples\n",
      "\n",
      "01_19_23:59:33 --- 1.7686305046081543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:34 Training loss at epoch 1 step 5840: 2.837520480155945\n",
      "\n",
      " This round's valence_loss=0.6140566468238831, arousal_loss=0.5248951315879822, emotion_loss=0.9381906986236572\n",
      "\n",
      "01_19_23:59:34 Seen so far: 186912 samples\n",
      "\n",
      "01_19_23:59:34 --- 1.766460657119751 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:36 Training loss at epoch 1 step 5850: 3.0666967391967774\n",
      "\n",
      " This round's valence_loss=0.5850445032119751, arousal_loss=0.4783669710159302, emotion_loss=1.1934736967086792\n",
      "\n",
      "01_19_23:59:36 Seen so far: 187232 samples\n",
      "\n",
      "01_19_23:59:36 --- 1.7850415706634521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:38 Training loss at epoch 1 step 5860: 3.1406579971313477\n",
      "\n",
      " This round's valence_loss=0.6442478895187378, arousal_loss=0.513023853302002, emotion_loss=1.1470636129379272\n",
      "\n",
      "01_19_23:59:38 Seen so far: 187552 samples\n",
      "\n",
      "01_19_23:59:38 --- 1.6973731517791748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:40 Training loss at epoch 1 step 5870: 3.1313990116119386\n",
      "\n",
      " This round's valence_loss=0.8804006576538086, arousal_loss=0.7352371215820312, emotion_loss=0.7752001285552979\n",
      "\n",
      "01_19_23:59:40 Seen so far: 187872 samples\n",
      "\n",
      "01_19_23:59:40 --- 1.6966936588287354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:41 Training loss at epoch 1 step 5880: 3.0265772342681885\n",
      "\n",
      " This round's valence_loss=0.8714745044708252, arousal_loss=0.7190871238708496, emotion_loss=0.9360759258270264\n",
      "\n",
      "01_19_23:59:41 Seen so far: 188192 samples\n",
      "\n",
      "01_19_23:59:41 --- 1.7656621932983398 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:43 Training loss at epoch 1 step 5890: 3.1200738906860352\n",
      "\n",
      " This round's valence_loss=1.726806879043579, arousal_loss=1.600188970565796, emotion_loss=1.0916144847869873\n",
      "\n",
      "01_19_23:59:43 Seen so far: 188512 samples\n",
      "\n",
      "01_19_23:59:43 --- 1.856525182723999 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:45 Training loss at epoch 1 step 5900: 2.930278491973877\n",
      "\n",
      " This round's valence_loss=0.8799425363540649, arousal_loss=0.7127774357795715, emotion_loss=0.7487097382545471\n",
      "\n",
      "01_19_23:59:45 Seen so far: 188832 samples\n",
      "\n",
      "01_19_23:59:45 --- 1.750819444656372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:47 Training loss at epoch 1 step 5910: 3.052488350868225\n",
      "\n",
      " This round's valence_loss=0.9092665910720825, arousal_loss=0.7611993551254272, emotion_loss=0.8721153736114502\n",
      "\n",
      "01_19_23:59:47 Seen so far: 189152 samples\n",
      "\n",
      "01_19_23:59:47 --- 1.821521520614624 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:49 Training loss at epoch 1 step 5920: 3.1417965412139894\n",
      "\n",
      " This round's valence_loss=1.308439016342163, arousal_loss=1.0822253227233887, emotion_loss=1.0168267488479614\n",
      "\n",
      "01_19_23:59:49 Seen so far: 189472 samples\n",
      "\n",
      "01_19_23:59:49 --- 1.8338828086853027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:50 Training loss at epoch 1 step 5930: 3.1189150333404543\n",
      "\n",
      " This round's valence_loss=1.4235780239105225, arousal_loss=1.3362174034118652, emotion_loss=1.0405585765838623\n",
      "\n",
      "01_19_23:59:50 Seen so far: 189792 samples\n",
      "\n",
      "01_19_23:59:50 --- 1.7121903896331787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:52 Training loss at epoch 1 step 5940: 3.044685196876526\n",
      "\n",
      " This round's valence_loss=0.8490003347396851, arousal_loss=0.7185397148132324, emotion_loss=0.8971655368804932\n",
      "\n",
      "01_19_23:59:52 Seen so far: 190112 samples\n",
      "\n",
      "01_19_23:59:52 --- 1.7078115940093994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:54 Training loss at epoch 1 step 5950: 2.983190393447876\n",
      "\n",
      " This round's valence_loss=0.948677659034729, arousal_loss=0.8653428554534912, emotion_loss=1.378927230834961\n",
      "\n",
      "01_19_23:59:54 Seen so far: 190432 samples\n",
      "\n",
      "01_19_23:59:54 --- 1.8007986545562744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:56 Training loss at epoch 1 step 5960: 3.0113804578781127\n",
      "\n",
      " This round's valence_loss=0.992290735244751, arousal_loss=0.889207124710083, emotion_loss=1.0158592462539673\n",
      "\n",
      "01_19_23:59:56 Seen so far: 190752 samples\n",
      "\n",
      "01_19_23:59:56 --- 1.7951719760894775 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:57 Training loss at epoch 1 step 5970: 3.3147409439086912\n",
      "\n",
      " This round's valence_loss=1.120570421218872, arousal_loss=0.9734575748443604, emotion_loss=1.2857459783554077\n",
      "\n",
      "01_19_23:59:57 Seen so far: 191072 samples\n",
      "\n",
      "01_19_23:59:57 --- 1.8242974281311035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_19_23:59:59 Training loss at epoch 1 step 5980: 3.019921398162842\n",
      "\n",
      " This round's valence_loss=0.7102479934692383, arousal_loss=0.6992009878158569, emotion_loss=1.2104873657226562\n",
      "\n",
      "01_19_23:59:59 Seen so far: 191392 samples\n",
      "\n",
      "01_19_23:59:59 --- 1.831040620803833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:01 Training loss at epoch 1 step 5990: 2.8347575545310972\n",
      "\n",
      " This round's valence_loss=0.5368856191635132, arousal_loss=0.423678994178772, emotion_loss=0.9871723651885986\n",
      "\n",
      "01_20_00:00:01 Seen so far: 191712 samples\n",
      "\n",
      "01_20_00:00:01 --- 1.8308656215667725 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:03 Training loss at epoch 1 step 6000: 3.031354570388794\n",
      "\n",
      " This round's valence_loss=0.9926135540008545, arousal_loss=0.8163489103317261, emotion_loss=0.9434086084365845\n",
      "\n",
      "01_20_00:00:03 Seen so far: 192032 samples\n",
      "\n",
      "01_20_00:00:03 --- 1.8288328647613525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:05 Training loss at epoch 1 step 6010: 3.314575266838074\n",
      "\n",
      " This round's valence_loss=1.4727108478546143, arousal_loss=1.363387107849121, emotion_loss=1.2105082273483276\n",
      "\n",
      "01_20_00:00:05 Seen so far: 192352 samples\n",
      "\n",
      "01_20_00:00:05 --- 1.7348651885986328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:06 Training loss at epoch 1 step 6020: 3.1677822351455687\n",
      "\n",
      " This round's valence_loss=1.2115768194198608, arousal_loss=0.9694957137107849, emotion_loss=0.946932315826416\n",
      "\n",
      "01_20_00:00:06 Seen so far: 192672 samples\n",
      "\n",
      "01_20_00:00:06 --- 1.7242062091827393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:08 Training loss at epoch 1 step 6030: 3.221198892593384\n",
      "\n",
      " This round's valence_loss=1.1600115299224854, arousal_loss=1.1399462223052979, emotion_loss=1.2234444618225098\n",
      "\n",
      "01_20_00:00:08 Seen so far: 192992 samples\n",
      "\n",
      "01_20_00:00:08 --- 1.858618974685669 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:10 Training loss at epoch 1 step 6040: 2.8968645334243774\n",
      "\n",
      " This round's valence_loss=1.495025396347046, arousal_loss=1.3483128547668457, emotion_loss=0.931682825088501\n",
      "\n",
      "01_20_00:00:10 Seen so far: 193312 samples\n",
      "\n",
      "01_20_00:00:10 --- 1.581864356994629 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:12 Training loss at epoch 1 step 6050: 2.842337226867676\n",
      "\n",
      " This round's valence_loss=1.1320509910583496, arousal_loss=0.9545846581459045, emotion_loss=1.0181314945220947\n",
      "\n",
      "01_20_00:00:12 Seen so far: 193632 samples\n",
      "\n",
      "01_20_00:00:12 --- 1.9324769973754883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:14 Training loss at epoch 1 step 6060: 3.4583446979522705\n",
      "\n",
      " This round's valence_loss=1.2235260009765625, arousal_loss=1.0706815719604492, emotion_loss=1.1778596639633179\n",
      "\n",
      "01_20_00:00:14 Seen so far: 193952 samples\n",
      "\n",
      "01_20_00:00:14 --- 1.8190412521362305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:15 Training loss at epoch 1 step 6070: 2.9076467514038087\n",
      "\n",
      " This round's valence_loss=0.6322380304336548, arousal_loss=0.4737684726715088, emotion_loss=0.9718847870826721\n",
      "\n",
      "01_20_00:00:15 Seen so far: 194272 samples\n",
      "\n",
      "01_20_00:00:15 --- 1.7355809211730957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:17 Training loss at epoch 1 step 6080: 3.1673524141311646\n",
      "\n",
      " This round's valence_loss=0.966019868850708, arousal_loss=0.8528448343276978, emotion_loss=1.061715841293335\n",
      "\n",
      "01_20_00:00:17 Seen so far: 194592 samples\n",
      "\n",
      "01_20_00:00:17 --- 1.7387611865997314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:19 Training loss at epoch 1 step 6090: 2.9610649824142454\n",
      "\n",
      " This round's valence_loss=0.7407644987106323, arousal_loss=0.46350735425949097, emotion_loss=0.7201876640319824\n",
      "\n",
      "01_20_00:00:19 Seen so far: 194912 samples\n",
      "\n",
      "01_20_00:00:19 --- 1.7041873931884766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:21 Training loss at epoch 1 step 6100: 2.925355887413025\n",
      "\n",
      " This round's valence_loss=1.9206581115722656, arousal_loss=1.8175909519195557, emotion_loss=0.9825916290283203\n",
      "\n",
      "01_20_00:00:21 Seen so far: 195232 samples\n",
      "\n",
      "01_20_00:00:21 --- 1.788665771484375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:22 Training loss at epoch 1 step 6110: 2.959538722038269\n",
      "\n",
      " This round's valence_loss=1.234424352645874, arousal_loss=1.02619206905365, emotion_loss=0.6432666778564453\n",
      "\n",
      "01_20_00:00:22 Seen so far: 195552 samples\n",
      "\n",
      "01_20_00:00:22 --- 1.8066580295562744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:24 Training loss at epoch 1 step 6120: 3.11205849647522\n",
      "\n",
      " This round's valence_loss=1.3498649597167969, arousal_loss=1.2228237390518188, emotion_loss=0.7873069047927856\n",
      "\n",
      "01_20_00:00:24 Seen so far: 195872 samples\n",
      "\n",
      "01_20_00:00:24 --- 1.7236802577972412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:26 Training loss at epoch 1 step 6130: 2.8755069971084595\n",
      "\n",
      " This round's valence_loss=0.9661973714828491, arousal_loss=0.6724783182144165, emotion_loss=0.8640261888504028\n",
      "\n",
      "01_20_00:00:26 Seen so far: 196192 samples\n",
      "\n",
      "01_20_00:00:26 --- 1.8691291809082031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:28 Training loss at epoch 1 step 6140: 2.8881402254104613\n",
      "\n",
      " This round's valence_loss=1.3747432231903076, arousal_loss=1.223085880279541, emotion_loss=0.7011029720306396\n",
      "\n",
      "01_20_00:00:28 Seen so far: 196512 samples\n",
      "\n",
      "01_20_00:00:28 --- 1.7389976978302002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:30 Training loss at epoch 1 step 6150: 3.0839367866516114\n",
      "\n",
      " This round's valence_loss=0.739578366279602, arousal_loss=0.6376842260360718, emotion_loss=1.231240153312683\n",
      "\n",
      "01_20_00:00:30 Seen so far: 196832 samples\n",
      "\n",
      "01_20_00:00:30 --- 1.8017032146453857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:31 Training loss at epoch 1 step 6160: 2.928323173522949\n",
      "\n",
      " This round's valence_loss=1.3389809131622314, arousal_loss=1.1793575286865234, emotion_loss=1.0258145332336426\n",
      "\n",
      "01_20_00:00:31 Seen so far: 197152 samples\n",
      "\n",
      "01_20_00:00:31 --- 1.810417652130127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:33 Training loss at epoch 1 step 6170: 3.00654673576355\n",
      "\n",
      " This round's valence_loss=0.6856815814971924, arousal_loss=0.5934339761734009, emotion_loss=1.0243287086486816\n",
      "\n",
      "01_20_00:00:33 Seen so far: 197472 samples\n",
      "\n",
      "01_20_00:00:33 --- 1.5894150733947754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:35 Training loss at epoch 1 step 6180: 3.071863889694214\n",
      "\n",
      " This round's valence_loss=1.0880157947540283, arousal_loss=0.9837762117385864, emotion_loss=0.9022859334945679\n",
      "\n",
      "01_20_00:00:35 Seen so far: 197792 samples\n",
      "\n",
      "01_20_00:00:35 --- 1.7323553562164307 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:36 Training loss at epoch 1 step 6190: 2.9986007690429686\n",
      "\n",
      " This round's valence_loss=1.2562175989151, arousal_loss=1.1044950485229492, emotion_loss=0.9659934043884277\n",
      "\n",
      "01_20_00:00:36 Seen so far: 198112 samples\n",
      "\n",
      "01_20_00:00:36 --- 1.823347568511963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:38 Training loss at epoch 1 step 6200: 3.330373764038086\n",
      "\n",
      " This round's valence_loss=0.8829859495162964, arousal_loss=0.7428637742996216, emotion_loss=1.0289193391799927\n",
      "\n",
      "01_20_00:00:38 Seen so far: 198432 samples\n",
      "\n",
      "01_20_00:00:38 --- 1.8769090175628662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:40 Training loss at epoch 1 step 6210: 3.3044639587402345\n",
      "\n",
      " This round's valence_loss=1.4408519268035889, arousal_loss=1.3505288362503052, emotion_loss=1.1799664497375488\n",
      "\n",
      "01_20_00:00:40 Seen so far: 198752 samples\n",
      "\n",
      "01_20_00:00:40 --- 1.8264951705932617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:42 Training loss at epoch 1 step 6220: 3.4742275714874267\n",
      "\n",
      " This round's valence_loss=1.2119166851043701, arousal_loss=1.1059999465942383, emotion_loss=1.3806309700012207\n",
      "\n",
      "01_20_00:00:42 Seen so far: 199072 samples\n",
      "\n",
      "01_20_00:00:42 --- 1.6950349807739258 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:44 Training loss at epoch 1 step 6230: 3.0537142515182496\n",
      "\n",
      " This round's valence_loss=1.2493422031402588, arousal_loss=1.1168181896209717, emotion_loss=1.200779914855957\n",
      "\n",
      "01_20_00:00:44 Seen so far: 199392 samples\n",
      "\n",
      "01_20_00:00:44 --- 1.7247366905212402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:45 Training loss at epoch 1 step 6240: 3.3969820022583006\n",
      "\n",
      " This round's valence_loss=0.7782653570175171, arousal_loss=0.551888108253479, emotion_loss=0.977800726890564\n",
      "\n",
      "01_20_00:00:45 Seen so far: 199712 samples\n",
      "\n",
      "01_20_00:00:45 --- 1.8023250102996826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:47 Training loss at epoch 1 step 6250: 3.243576979637146\n",
      "\n",
      " This round's valence_loss=1.3768117427825928, arousal_loss=1.3134942054748535, emotion_loss=1.3278144598007202\n",
      "\n",
      "01_20_00:00:47 Seen so far: 200032 samples\n",
      "\n",
      "01_20_00:00:47 --- 1.9053122997283936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:49 Training loss at epoch 1 step 6260: 3.051622986793518\n",
      "\n",
      " This round's valence_loss=0.880427360534668, arousal_loss=0.6750094890594482, emotion_loss=0.920857310295105\n",
      "\n",
      "01_20_00:00:49 Seen so far: 200352 samples\n",
      "\n",
      "01_20_00:00:49 --- 1.8494422435760498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:51 Training loss at epoch 1 step 6270: 2.86413391828537\n",
      "\n",
      " This round's valence_loss=0.7456250190734863, arousal_loss=0.5806746482849121, emotion_loss=0.6571711301803589\n",
      "\n",
      "01_20_00:00:51 Seen so far: 200672 samples\n",
      "\n",
      "01_20_00:00:51 --- 1.8204271793365479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:53 Training loss at epoch 1 step 6280: 2.8277992248535155\n",
      "\n",
      " This round's valence_loss=1.1590988636016846, arousal_loss=1.0931167602539062, emotion_loss=1.0877764225006104\n",
      "\n",
      "01_20_00:00:53 Seen so far: 200992 samples\n",
      "\n",
      "01_20_00:00:53 --- 1.852766990661621 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:54 Training loss at epoch 1 step 6290: 2.9109538078308104\n",
      "\n",
      " This round's valence_loss=0.713316798210144, arousal_loss=0.6371884346008301, emotion_loss=1.1278572082519531\n",
      "\n",
      "01_20_00:00:54 Seen so far: 201312 samples\n",
      "\n",
      "01_20_00:00:54 --- 1.6686151027679443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:56 Training loss at epoch 1 step 6300: 3.3393822431564333\n",
      "\n",
      " This round's valence_loss=1.25176203250885, arousal_loss=1.0795403718948364, emotion_loss=0.984773576259613\n",
      "\n",
      "01_20_00:00:56 Seen so far: 201632 samples\n",
      "\n",
      "01_20_00:00:56 --- 1.705157995223999 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:58 Training loss at epoch 1 step 6310: 2.931816649436951\n",
      "\n",
      " This round's valence_loss=0.9850896596908569, arousal_loss=0.8779908418655396, emotion_loss=1.1603024005889893\n",
      "\n",
      "01_20_00:00:58 Seen so far: 201952 samples\n",
      "\n",
      "01_20_00:00:58 --- 1.720677375793457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:00:59 Training loss at epoch 1 step 6320: 3.2275436878204347\n",
      "\n",
      " This round's valence_loss=0.9675894379615784, arousal_loss=0.8159434199333191, emotion_loss=0.9380121231079102\n",
      "\n",
      "01_20_00:00:59 Seen so far: 202272 samples\n",
      "\n",
      "01_20_00:00:59 --- 1.5707166194915771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:01 Training loss at epoch 1 step 6330: 2.8753049612045287\n",
      "\n",
      " This round's valence_loss=1.2474486827850342, arousal_loss=1.063776969909668, emotion_loss=1.037654161453247\n",
      "\n",
      "01_20_00:01:01 Seen so far: 202592 samples\n",
      "\n",
      "01_20_00:01:01 --- 1.7576849460601807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:03 Training loss at epoch 1 step 6340: 3.3175050735473635\n",
      "\n",
      " This round's valence_loss=0.5982393622398376, arousal_loss=0.5338822603225708, emotion_loss=0.8519007563591003\n",
      "\n",
      "01_20_00:01:03 Seen so far: 202912 samples\n",
      "\n",
      "01_20_00:01:03 --- 1.9611942768096924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:05 Training loss at epoch 1 step 6350: 2.77405298948288\n",
      "\n",
      " This round's valence_loss=0.5829372406005859, arousal_loss=0.42835062742233276, emotion_loss=0.7468370199203491\n",
      "\n",
      "01_20_00:01:05 Seen so far: 203232 samples\n",
      "\n",
      "01_20_00:01:05 --- 1.7896702289581299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:07 Training loss at epoch 1 step 6360: 2.9022665858268737\n",
      "\n",
      " This round's valence_loss=0.9765802621841431, arousal_loss=0.8209205865859985, emotion_loss=0.9336742162704468\n",
      "\n",
      "01_20_00:01:07 Seen so far: 203552 samples\n",
      "\n",
      "01_20_00:01:07 --- 1.6525185108184814 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:08 Training loss at epoch 1 step 6370: 3.2222934007644652\n",
      "\n",
      " This round's valence_loss=1.559312105178833, arousal_loss=1.4352909326553345, emotion_loss=0.8283621072769165\n",
      "\n",
      "01_20_00:01:08 Seen so far: 203872 samples\n",
      "\n",
      "01_20_00:01:08 --- 1.7302846908569336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:10 Training loss at epoch 1 step 6380: 3.161384344100952\n",
      "\n",
      " This round's valence_loss=0.9296976327896118, arousal_loss=0.8618361949920654, emotion_loss=1.3748900890350342\n",
      "\n",
      "01_20_00:01:10 Seen so far: 204192 samples\n",
      "\n",
      "01_20_00:01:10 --- 1.8106789588928223 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:12 Training loss at epoch 1 step 6390: 3.1226544618606566\n",
      "\n",
      " This round's valence_loss=1.1281509399414062, arousal_loss=1.012422800064087, emotion_loss=0.9785792231559753\n",
      "\n",
      "01_20_00:01:12 Seen so far: 204512 samples\n",
      "\n",
      "01_20_00:01:12 --- 1.6400492191314697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:14 Training loss at epoch 1 step 6400: 3.37069091796875\n",
      "\n",
      " This round's valence_loss=0.8649893999099731, arousal_loss=0.7107957005500793, emotion_loss=1.3319714069366455\n",
      "\n",
      "01_20_00:01:14 Seen so far: 204832 samples\n",
      "\n",
      "01_20_00:01:14 --- 1.9730026721954346 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:15 Training loss at epoch 1 step 6410: 3.0147838830947875\n",
      "\n",
      " This round's valence_loss=1.4227113723754883, arousal_loss=1.3850326538085938, emotion_loss=0.9514195322990417\n",
      "\n",
      "01_20_00:01:15 Seen so far: 205152 samples\n",
      "\n",
      "01_20_00:01:15 --- 1.6825666427612305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:17 Training loss at epoch 1 step 6420: 3.1594985723495483\n",
      "\n",
      " This round's valence_loss=1.1254606246948242, arousal_loss=1.0295779705047607, emotion_loss=1.0596263408660889\n",
      "\n",
      "01_20_00:01:17 Seen so far: 205472 samples\n",
      "\n",
      "01_20_00:01:17 --- 1.879258394241333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:19 Training loss at epoch 1 step 6430: 2.9505615711212156\n",
      "\n",
      " This round's valence_loss=1.3376855850219727, arousal_loss=1.2022993564605713, emotion_loss=1.1133875846862793\n",
      "\n",
      "01_20_00:01:19 Seen so far: 205792 samples\n",
      "\n",
      "01_20_00:01:19 --- 1.6941967010498047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:21 Training loss at epoch 1 step 6440: 2.8542298555374144\n",
      "\n",
      " This round's valence_loss=1.5004452466964722, arousal_loss=1.4755804538726807, emotion_loss=1.035528540611267\n",
      "\n",
      "01_20_00:01:21 Seen so far: 206112 samples\n",
      "\n",
      "01_20_00:01:21 --- 1.6334121227264404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:22 Training loss at epoch 1 step 6450: 3.2491593599319457\n",
      "\n",
      " This round's valence_loss=1.0550272464752197, arousal_loss=0.9710077047348022, emotion_loss=1.1143381595611572\n",
      "\n",
      "01_20_00:01:22 Seen so far: 206432 samples\n",
      "\n",
      "01_20_00:01:22 --- 1.7364740371704102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:24 Training loss at epoch 1 step 6460: 3.0111990213394164\n",
      "\n",
      " This round's valence_loss=0.8950108289718628, arousal_loss=0.6965152025222778, emotion_loss=0.9635991454124451\n",
      "\n",
      "01_20_00:01:24 Seen so far: 206752 samples\n",
      "\n",
      "01_20_00:01:24 --- 1.6565852165222168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:26 Training loss at epoch 1 step 6470: 3.1655200242996218\n",
      "\n",
      " This round's valence_loss=1.048722267150879, arousal_loss=0.9682028293609619, emotion_loss=0.9824890494346619\n",
      "\n",
      "01_20_00:01:26 Seen so far: 207072 samples\n",
      "\n",
      "01_20_00:01:26 --- 1.7953624725341797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:28 Training loss at epoch 1 step 6480: 3.074350953102112\n",
      "\n",
      " This round's valence_loss=0.8582133054733276, arousal_loss=0.712683916091919, emotion_loss=1.056457757949829\n",
      "\n",
      "01_20_00:01:28 Seen so far: 207392 samples\n",
      "\n",
      "01_20_00:01:28 --- 1.7409090995788574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:30 Training loss at epoch 1 step 6490: 3.02896409034729\n",
      "\n",
      " This round's valence_loss=1.3405499458312988, arousal_loss=1.1763801574707031, emotion_loss=0.9785142540931702\n",
      "\n",
      "01_20_00:01:30 Seen so far: 207712 samples\n",
      "\n",
      "01_20_00:01:30 --- 1.8765292167663574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:31 Training loss at epoch 1 step 6500: 3.21973340511322\n",
      "\n",
      " This round's valence_loss=1.0910043716430664, arousal_loss=1.0018796920776367, emotion_loss=0.8880695104598999\n",
      "\n",
      "01_20_00:01:31 Seen so far: 208032 samples\n",
      "\n",
      "01_20_00:01:31 --- 1.721181869506836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:33 Training loss at epoch 1 step 6510: 2.8555376291275025\n",
      "\n",
      " This round's valence_loss=1.2743055820465088, arousal_loss=1.0853533744812012, emotion_loss=1.0094050168991089\n",
      "\n",
      "01_20_00:01:33 Seen so far: 208352 samples\n",
      "\n",
      "01_20_00:01:33 --- 1.8397579193115234 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:35 Training loss at epoch 1 step 6520: 2.905778431892395\n",
      "\n",
      " This round's valence_loss=0.9179377555847168, arousal_loss=0.7026064395904541, emotion_loss=0.7431706190109253\n",
      "\n",
      "01_20_00:01:35 Seen so far: 208672 samples\n",
      "\n",
      "01_20_00:01:35 --- 1.6953415870666504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:37 Training loss at epoch 1 step 6530: 2.8964715957641602\n",
      "\n",
      " This round's valence_loss=0.8813794851303101, arousal_loss=0.7019906044006348, emotion_loss=0.8922584652900696\n",
      "\n",
      "01_20_00:01:37 Seen so far: 208992 samples\n",
      "\n",
      "01_20_00:01:37 --- 2.016934633255005 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:39 Training loss at epoch 1 step 6540: 2.967044544219971\n",
      "\n",
      " This round's valence_loss=0.8856443166732788, arousal_loss=0.717024564743042, emotion_loss=0.8069632649421692\n",
      "\n",
      "01_20_00:01:39 Seen so far: 209312 samples\n",
      "\n",
      "01_20_00:01:39 --- 1.772991418838501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:40 Training loss at epoch 1 step 6550: 2.9618674993515013\n",
      "\n",
      " This round's valence_loss=0.8937969207763672, arousal_loss=0.6784942150115967, emotion_loss=0.901178777217865\n",
      "\n",
      "01_20_00:01:40 Seen so far: 209632 samples\n",
      "\n",
      "01_20_00:01:40 --- 1.721893310546875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:42 Training loss at epoch 1 step 6560: 2.993452262878418\n",
      "\n",
      " This round's valence_loss=0.9826878905296326, arousal_loss=0.8432880640029907, emotion_loss=1.1909136772155762\n",
      "\n",
      "01_20_00:01:42 Seen so far: 209952 samples\n",
      "\n",
      "01_20_00:01:42 --- 1.794621229171753 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:44 Training loss at epoch 1 step 6570: 2.910588502883911\n",
      "\n",
      " This round's valence_loss=0.994152843952179, arousal_loss=0.8245887756347656, emotion_loss=0.5206426382064819\n",
      "\n",
      "01_20_00:01:44 Seen so far: 210272 samples\n",
      "\n",
      "01_20_00:01:44 --- 1.8236863613128662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:46 Training loss at epoch 1 step 6580: 2.9388041496276855\n",
      "\n",
      " This round's valence_loss=0.9172379970550537, arousal_loss=0.855646014213562, emotion_loss=1.0405839681625366\n",
      "\n",
      "01_20_00:01:46 Seen so far: 210592 samples\n",
      "\n",
      "01_20_00:01:46 --- 1.704665184020996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:47 Training loss at epoch 1 step 6590: 2.594429981708527\n",
      "\n",
      " This round's valence_loss=0.7819298505783081, arousal_loss=0.6052889823913574, emotion_loss=0.9536930918693542\n",
      "\n",
      "01_20_00:01:47 Seen so far: 210912 samples\n",
      "\n",
      "01_20_00:01:47 --- 1.7951180934906006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:49 Training loss at epoch 1 step 6600: 3.0445879340171813\n",
      "\n",
      " This round's valence_loss=0.7993481159210205, arousal_loss=0.7043414115905762, emotion_loss=1.0698003768920898\n",
      "\n",
      "01_20_00:01:49 Seen so far: 211232 samples\n",
      "\n",
      "01_20_00:01:49 --- 1.5546629428863525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:51 Training loss at epoch 1 step 6610: 3.039824104309082\n",
      "\n",
      " This round's valence_loss=1.4617865085601807, arousal_loss=1.3452651500701904, emotion_loss=1.0478754043579102\n",
      "\n",
      "01_20_00:01:51 Seen so far: 211552 samples\n",
      "\n",
      "01_20_00:01:51 --- 1.9158298969268799 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:52 Training loss at epoch 1 step 6620: 2.8909419178962708\n",
      "\n",
      " This round's valence_loss=1.3009743690490723, arousal_loss=1.2167811393737793, emotion_loss=1.1012988090515137\n",
      "\n",
      "01_20_00:01:52 Seen so far: 211872 samples\n",
      "\n",
      "01_20_00:01:52 --- 1.5951876640319824 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:54 Training loss at epoch 1 step 6630: 2.9695979356765747\n",
      "\n",
      " This round's valence_loss=1.3992466926574707, arousal_loss=1.2341923713684082, emotion_loss=1.2748440504074097\n",
      "\n",
      "01_20_00:01:54 Seen so far: 212192 samples\n",
      "\n",
      "01_20_00:01:54 --- 2.039652109146118 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:56 Training loss at epoch 1 step 6640: 3.0985307693481445\n",
      "\n",
      " This round's valence_loss=0.7333581447601318, arousal_loss=0.5659528970718384, emotion_loss=0.9253503084182739\n",
      "\n",
      "01_20_00:01:56 Seen so far: 212512 samples\n",
      "\n",
      "01_20_00:01:56 --- 1.9712817668914795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:01:58 Training loss at epoch 1 step 6650: 3.0274735927581786\n",
      "\n",
      " This round's valence_loss=1.2969386577606201, arousal_loss=1.045356035232544, emotion_loss=1.163001298904419\n",
      "\n",
      "01_20_00:01:58 Seen so far: 212832 samples\n",
      "\n",
      "01_20_00:01:58 --- 1.7731690406799316 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:00 Training loss at epoch 1 step 6660: 3.3517670154571535\n",
      "\n",
      " This round's valence_loss=1.1890318393707275, arousal_loss=1.1507370471954346, emotion_loss=1.34066641330719\n",
      "\n",
      "01_20_00:02:00 Seen so far: 213152 samples\n",
      "\n",
      "01_20_00:02:00 --- 1.7313945293426514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:02 Training loss at epoch 1 step 6670: 3.4152083158493043\n",
      "\n",
      " This round's valence_loss=1.1705517768859863, arousal_loss=1.077683448791504, emotion_loss=0.9886055588722229\n",
      "\n",
      "01_20_00:02:02 Seen so far: 213472 samples\n",
      "\n",
      "01_20_00:02:02 --- 1.6605010032653809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:04 Training loss at epoch 1 step 6680: 3.21601026058197\n",
      "\n",
      " This round's valence_loss=0.6850916147232056, arousal_loss=0.6458861827850342, emotion_loss=1.5738739967346191\n",
      "\n",
      "01_20_00:02:04 Seen so far: 213792 samples\n",
      "\n",
      "01_20_00:02:04 --- 1.96000337600708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:05 Training loss at epoch 1 step 6690: 3.03990581035614\n",
      "\n",
      " This round's valence_loss=1.0212526321411133, arousal_loss=0.8728482723236084, emotion_loss=0.9174258708953857\n",
      "\n",
      "01_20_00:02:05 Seen so far: 214112 samples\n",
      "\n",
      "01_20_00:02:05 --- 1.7000994682312012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:07 Training loss at epoch 1 step 6700: 3.4143947839736937\n",
      "\n",
      " This round's valence_loss=1.0612578392028809, arousal_loss=0.9507625699043274, emotion_loss=1.0302464962005615\n",
      "\n",
      "01_20_00:02:07 Seen so far: 214432 samples\n",
      "\n",
      "01_20_00:02:07 --- 1.6901402473449707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:09 Training loss at epoch 1 step 6710: 3.3671390533447267\n",
      "\n",
      " This round's valence_loss=0.7604032754898071, arousal_loss=0.7912161350250244, emotion_loss=1.0917260646820068\n",
      "\n",
      "01_20_00:02:09 Seen so far: 214752 samples\n",
      "\n",
      "01_20_00:02:09 --- 1.9114408493041992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:11 Training loss at epoch 1 step 6720: 3.278208088874817\n",
      "\n",
      " This round's valence_loss=0.8463186025619507, arousal_loss=0.7203985452651978, emotion_loss=1.1473511457443237\n",
      "\n",
      "01_20_00:02:11 Seen so far: 215072 samples\n",
      "\n",
      "01_20_00:02:11 --- 1.9113831520080566 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:13 Training loss at epoch 1 step 6730: 3.2525898694992064\n",
      "\n",
      " This round's valence_loss=1.42989182472229, arousal_loss=1.3318167924880981, emotion_loss=1.0828173160552979\n",
      "\n",
      "01_20_00:02:13 Seen so far: 215392 samples\n",
      "\n",
      "01_20_00:02:13 --- 1.7449069023132324 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:15 Training loss at epoch 1 step 6740: 2.7439262866973877\n",
      "\n",
      " This round's valence_loss=0.8957458734512329, arousal_loss=0.7187943458557129, emotion_loss=0.8557888865470886\n",
      "\n",
      "01_20_00:02:15 Seen so far: 215712 samples\n",
      "\n",
      "01_20_00:02:15 --- 1.9568116664886475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:16 Training loss at epoch 1 step 6750: 2.9742987632751463\n",
      "\n",
      " This round's valence_loss=0.7864036560058594, arousal_loss=0.5540446639060974, emotion_loss=0.95257169008255\n",
      "\n",
      "01_20_00:02:16 Seen so far: 216032 samples\n",
      "\n",
      "01_20_00:02:16 --- 1.720550537109375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:18 Training loss at epoch 1 step 6760: 3.0916587591171263\n",
      "\n",
      " This round's valence_loss=1.166440486907959, arousal_loss=1.1005699634552002, emotion_loss=1.068578839302063\n",
      "\n",
      "01_20_00:02:18 Seen so far: 216352 samples\n",
      "\n",
      "01_20_00:02:18 --- 1.904634714126587 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:20 Training loss at epoch 1 step 6770: 2.843928265571594\n",
      "\n",
      " This round's valence_loss=1.295790433883667, arousal_loss=1.0878078937530518, emotion_loss=0.7370544672012329\n",
      "\n",
      "01_20_00:02:20 Seen so far: 216672 samples\n",
      "\n",
      "01_20_00:02:20 --- 1.753364086151123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:22 Training loss at epoch 1 step 6780: 3.070997714996338\n",
      "\n",
      " This round's valence_loss=1.1742138862609863, arousal_loss=1.060011863708496, emotion_loss=1.3349988460540771\n",
      "\n",
      "01_20_00:02:22 Seen so far: 216992 samples\n",
      "\n",
      "01_20_00:02:22 --- 1.8450543880462646 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:24 Training loss at epoch 1 step 6790: 3.0821590662002563\n",
      "\n",
      " This round's valence_loss=1.0513916015625, arousal_loss=0.9571473598480225, emotion_loss=1.1504499912261963\n",
      "\n",
      "01_20_00:02:24 Seen so far: 217312 samples\n",
      "\n",
      "01_20_00:02:24 --- 1.7959480285644531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:25 Training loss at epoch 1 step 6800: 3.1545074701309206\n",
      "\n",
      " This round's valence_loss=1.0158162117004395, arousal_loss=0.8208065032958984, emotion_loss=0.9532409310340881\n",
      "\n",
      "01_20_00:02:25 Seen so far: 217632 samples\n",
      "\n",
      "01_20_00:02:25 --- 1.7506320476531982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:27 Training loss at epoch 1 step 6810: 2.927367663383484\n",
      "\n",
      " This round's valence_loss=1.1989219188690186, arousal_loss=1.1255943775177002, emotion_loss=1.515197992324829\n",
      "\n",
      "01_20_00:02:27 Seen so far: 217952 samples\n",
      "\n",
      "01_20_00:02:27 --- 1.687401533126831 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:29 Training loss at epoch 1 step 6820: 3.2060701131820677\n",
      "\n",
      " This round's valence_loss=1.243654727935791, arousal_loss=1.0882370471954346, emotion_loss=1.060168981552124\n",
      "\n",
      "01_20_00:02:29 Seen so far: 218272 samples\n",
      "\n",
      "01_20_00:02:29 --- 1.7123799324035645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:30 Training loss at epoch 1 step 6830: 3.111694097518921\n",
      "\n",
      " This round's valence_loss=0.6758334636688232, arousal_loss=0.5775998830795288, emotion_loss=0.9908909201622009\n",
      "\n",
      "01_20_00:02:30 Seen so far: 218592 samples\n",
      "\n",
      "01_20_00:02:30 --- 1.6602294445037842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:32 Training loss at epoch 1 step 6840: 2.992856740951538\n",
      "\n",
      " This round's valence_loss=0.8251367807388306, arousal_loss=0.7020363211631775, emotion_loss=0.8004287481307983\n",
      "\n",
      "01_20_00:02:32 Seen so far: 218912 samples\n",
      "\n",
      "01_20_00:02:32 --- 1.846513032913208 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:34 Training loss at epoch 1 step 6850: 3.2600627183914184\n",
      "\n",
      " This round's valence_loss=0.6619149446487427, arousal_loss=0.689384937286377, emotion_loss=1.1774084568023682\n",
      "\n",
      "01_20_00:02:34 Seen so far: 219232 samples\n",
      "\n",
      "01_20_00:02:34 --- 1.9178264141082764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:36 Training loss at epoch 1 step 6860: 3.1633087396621704\n",
      "\n",
      " This round's valence_loss=0.8171837329864502, arousal_loss=0.6792155504226685, emotion_loss=0.9978471994400024\n",
      "\n",
      "01_20_00:02:36 Seen so far: 219552 samples\n",
      "\n",
      "01_20_00:02:36 --- 1.8464598655700684 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:38 Training loss at epoch 1 step 6870: 2.8973268985748293\n",
      "\n",
      " This round's valence_loss=0.7497836351394653, arousal_loss=0.5954217910766602, emotion_loss=1.0507209300994873\n",
      "\n",
      "01_20_00:02:38 Seen so far: 219872 samples\n",
      "\n",
      "01_20_00:02:38 --- 1.8044123649597168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:40 Training loss at epoch 1 step 6880: 2.9914395093917845\n",
      "\n",
      " This round's valence_loss=0.8837771415710449, arousal_loss=0.6936969757080078, emotion_loss=0.7274653911590576\n",
      "\n",
      "01_20_00:02:40 Seen so far: 220192 samples\n",
      "\n",
      "01_20_00:02:40 --- 1.806290864944458 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:41 Training loss at epoch 1 step 6890: 3.156636428833008\n",
      "\n",
      " This round's valence_loss=1.4080400466918945, arousal_loss=1.308588981628418, emotion_loss=1.2486207485198975\n",
      "\n",
      "01_20_00:02:41 Seen so far: 220512 samples\n",
      "\n",
      "01_20_00:02:41 --- 1.8749940395355225 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:43 Training loss at epoch 1 step 6900: 3.1612730741500856\n",
      "\n",
      " This round's valence_loss=0.6568642854690552, arousal_loss=0.48393478989601135, emotion_loss=0.8785671591758728\n",
      "\n",
      "01_20_00:02:43 Seen so far: 220832 samples\n",
      "\n",
      "01_20_00:02:43 --- 1.7527923583984375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:45 Training loss at epoch 1 step 6910: 2.855240082740784\n",
      "\n",
      " This round's valence_loss=0.8852081298828125, arousal_loss=0.729554295539856, emotion_loss=0.8921746015548706\n",
      "\n",
      "01_20_00:02:45 Seen so far: 221152 samples\n",
      "\n",
      "01_20_00:02:45 --- 1.873337984085083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:47 Training loss at epoch 1 step 6920: 3.046135425567627\n",
      "\n",
      " This round's valence_loss=1.3952271938323975, arousal_loss=1.2697234153747559, emotion_loss=0.794800341129303\n",
      "\n",
      "01_20_00:02:47 Seen so far: 221472 samples\n",
      "\n",
      "01_20_00:02:47 --- 1.7599279880523682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:49 Training loss at epoch 1 step 6930: 3.0644520044326784\n",
      "\n",
      " This round's valence_loss=0.9583101272583008, arousal_loss=0.8247156143188477, emotion_loss=0.9671923518180847\n",
      "\n",
      "01_20_00:02:49 Seen so far: 221792 samples\n",
      "\n",
      "01_20_00:02:49 --- 1.805673599243164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:50 Training loss at epoch 1 step 6940: 3.13484525680542\n",
      "\n",
      " This round's valence_loss=0.7006446123123169, arousal_loss=0.6547654867172241, emotion_loss=1.3329806327819824\n",
      "\n",
      "01_20_00:02:50 Seen so far: 222112 samples\n",
      "\n",
      "01_20_00:02:50 --- 1.6553857326507568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:52 Training loss at epoch 1 step 6950: 3.265577030181885\n",
      "\n",
      " This round's valence_loss=0.9162274599075317, arousal_loss=0.6912986040115356, emotion_loss=0.9398895502090454\n",
      "\n",
      "01_20_00:02:52 Seen so far: 222432 samples\n",
      "\n",
      "01_20_00:02:52 --- 1.617217779159546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:54 Training loss at epoch 1 step 6960: 3.273714303970337\n",
      "\n",
      " This round's valence_loss=1.200739860534668, arousal_loss=1.111074686050415, emotion_loss=1.4235830307006836\n",
      "\n",
      "01_20_00:02:54 Seen so far: 222752 samples\n",
      "\n",
      "01_20_00:02:54 --- 1.7586190700531006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:55 Training loss at epoch 1 step 6970: 3.1193042516708376\n",
      "\n",
      " This round's valence_loss=0.9556249380111694, arousal_loss=0.8257211446762085, emotion_loss=1.3916569948196411\n",
      "\n",
      "01_20_00:02:55 Seen so far: 223072 samples\n",
      "\n",
      "01_20_00:02:55 --- 1.7992589473724365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:57 Training loss at epoch 1 step 6980: 3.1156264543533325\n",
      "\n",
      " This round's valence_loss=1.263291835784912, arousal_loss=1.0465242862701416, emotion_loss=0.8150250911712646\n",
      "\n",
      "01_20_00:02:57 Seen so far: 223392 samples\n",
      "\n",
      "01_20_00:02:57 --- 1.7726306915283203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:02:59 Training loss at epoch 1 step 6990: 3.1357248783111573\n",
      "\n",
      " This round's valence_loss=1.0755976438522339, arousal_loss=0.9565091133117676, emotion_loss=1.1214592456817627\n",
      "\n",
      "01_20_00:02:59 Seen so far: 223712 samples\n",
      "\n",
      "01_20_00:02:59 --- 1.7284080982208252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:01 Training loss at epoch 1 step 7000: 3.0183982610702516\n",
      "\n",
      " This round's valence_loss=0.7520562410354614, arousal_loss=0.5980110168457031, emotion_loss=0.8716035485267639\n",
      "\n",
      "01_20_00:03:01 Seen so far: 224032 samples\n",
      "\n",
      "01_20_00:03:01 --- 1.8336684703826904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:03 Training loss at epoch 1 step 7010: 3.0106292009353637\n",
      "\n",
      " This round's valence_loss=1.037168025970459, arousal_loss=0.8024908304214478, emotion_loss=0.7823528051376343\n",
      "\n",
      "01_20_00:03:03 Seen so far: 224352 samples\n",
      "\n",
      "01_20_00:03:03 --- 1.8485438823699951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:05 Training loss at epoch 1 step 7020: 2.9974249601364136\n",
      "\n",
      " This round's valence_loss=1.0138249397277832, arousal_loss=0.8983283042907715, emotion_loss=0.990374743938446\n",
      "\n",
      "01_20_00:03:05 Seen so far: 224672 samples\n",
      "\n",
      "01_20_00:03:05 --- 1.8804569244384766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:06 Training loss at epoch 1 step 7030: 2.8897471189498902\n",
      "\n",
      " This round's valence_loss=1.2374486923217773, arousal_loss=1.0674843788146973, emotion_loss=1.0314502716064453\n",
      "\n",
      "01_20_00:03:06 Seen so far: 224992 samples\n",
      "\n",
      "01_20_00:03:06 --- 1.8085498809814453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:08 Training loss at epoch 1 step 7040: 3.1151766777038574\n",
      "\n",
      " This round's valence_loss=0.9568578600883484, arousal_loss=0.7010471224784851, emotion_loss=1.2822881937026978\n",
      "\n",
      "01_20_00:03:08 Seen so far: 225312 samples\n",
      "\n",
      "01_20_00:03:08 --- 1.7579524517059326 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:10 Training loss at epoch 1 step 7050: 2.946924257278442\n",
      "\n",
      " This round's valence_loss=0.9316742420196533, arousal_loss=0.7559927701950073, emotion_loss=1.1498762369155884\n",
      "\n",
      "01_20_00:03:10 Seen so far: 225632 samples\n",
      "\n",
      "01_20_00:03:10 --- 1.8059382438659668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:12 Training loss at epoch 1 step 7060: 2.8123022317886353\n",
      "\n",
      " This round's valence_loss=1.4117071628570557, arousal_loss=1.302429437637329, emotion_loss=1.1957709789276123\n",
      "\n",
      "01_20_00:03:12 Seen so far: 225952 samples\n",
      "\n",
      "01_20_00:03:12 --- 1.9248976707458496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:14 Training loss at epoch 1 step 7070: 2.8466158151626586\n",
      "\n",
      " This round's valence_loss=1.2167034149169922, arousal_loss=1.0845948457717896, emotion_loss=0.5994950532913208\n",
      "\n",
      "01_20_00:03:14 Seen so far: 226272 samples\n",
      "\n",
      "01_20_00:03:14 --- 1.6820662021636963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:15 Training loss at epoch 1 step 7080: 3.053141188621521\n",
      "\n",
      " This round's valence_loss=0.921826958656311, arousal_loss=0.9600149393081665, emotion_loss=1.0108095407485962\n",
      "\n",
      "01_20_00:03:15 Seen so far: 226592 samples\n",
      "\n",
      "01_20_00:03:15 --- 1.6828978061676025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:17 Training loss at epoch 1 step 7090: 3.145338296890259\n",
      "\n",
      " This round's valence_loss=1.8045027256011963, arousal_loss=1.7476847171783447, emotion_loss=1.1982191801071167\n",
      "\n",
      "01_20_00:03:17 Seen so far: 226912 samples\n",
      "\n",
      "01_20_00:03:17 --- 1.815155029296875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:19 Training loss at epoch 1 step 7100: 2.7105934381484986\n",
      "\n",
      " This round's valence_loss=1.0294619798660278, arousal_loss=0.8465646505355835, emotion_loss=1.0694587230682373\n",
      "\n",
      "01_20_00:03:19 Seen so far: 227232 samples\n",
      "\n",
      "01_20_00:03:19 --- 1.690145492553711 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:21 Training loss at epoch 1 step 7110: 3.312308669090271\n",
      "\n",
      " This round's valence_loss=1.0432460308074951, arousal_loss=0.9328905344009399, emotion_loss=1.004310965538025\n",
      "\n",
      "01_20_00:03:21 Seen so far: 227552 samples\n",
      "\n",
      "01_20_00:03:21 --- 1.8458850383758545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:22 Training loss at epoch 1 step 7120: 2.981538200378418\n",
      "\n",
      " This round's valence_loss=0.7412863969802856, arousal_loss=0.5921453237533569, emotion_loss=1.2141335010528564\n",
      "\n",
      "01_20_00:03:22 Seen so far: 227872 samples\n",
      "\n",
      "01_20_00:03:22 --- 1.7928857803344727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:24 Training loss at epoch 1 step 7130: 2.858022356033325\n",
      "\n",
      " This round's valence_loss=1.540284514427185, arousal_loss=1.4493263959884644, emotion_loss=1.0720460414886475\n",
      "\n",
      "01_20_00:03:24 Seen so far: 228192 samples\n",
      "\n",
      "01_20_00:03:24 --- 1.8983218669891357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:26 Training loss at epoch 1 step 7140: 2.946366715431213\n",
      "\n",
      " This round's valence_loss=0.8068565130233765, arousal_loss=0.6094135046005249, emotion_loss=0.7852524518966675\n",
      "\n",
      "01_20_00:03:26 Seen so far: 228512 samples\n",
      "\n",
      "01_20_00:03:26 --- 1.8542859554290771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:28 Training loss at epoch 1 step 7150: 3.443113613128662\n",
      "\n",
      " This round's valence_loss=1.177797555923462, arousal_loss=1.032073736190796, emotion_loss=0.7478314638137817\n",
      "\n",
      "01_20_00:03:28 Seen so far: 228832 samples\n",
      "\n",
      "01_20_00:03:28 --- 1.745074987411499 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:30 Training loss at epoch 1 step 7160: 3.134728455543518\n",
      "\n",
      " This round's valence_loss=1.2764036655426025, arousal_loss=1.2044692039489746, emotion_loss=0.942254364490509\n",
      "\n",
      "01_20_00:03:30 Seen so far: 229152 samples\n",
      "\n",
      "01_20_00:03:30 --- 1.6922791004180908 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:31 Training loss at epoch 1 step 7170: 3.011464166641235\n",
      "\n",
      " This round's valence_loss=0.7508203983306885, arousal_loss=0.6177865266799927, emotion_loss=1.0866063833236694\n",
      "\n",
      "01_20_00:03:31 Seen so far: 229472 samples\n",
      "\n",
      "01_20_00:03:31 --- 1.892280101776123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:33 Training loss at epoch 1 step 7180: 3.6709155082702636\n",
      "\n",
      " This round's valence_loss=1.1974663734436035, arousal_loss=1.1688729524612427, emotion_loss=0.9450538158416748\n",
      "\n",
      "01_20_00:03:33 Seen so far: 229792 samples\n",
      "\n",
      "01_20_00:03:33 --- 1.8298189640045166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:35 Training loss at epoch 1 step 7190: 3.2850590705871583\n",
      "\n",
      " This round's valence_loss=1.1545286178588867, arousal_loss=0.8995183706283569, emotion_loss=0.9703543186187744\n",
      "\n",
      "01_20_00:03:35 Seen so far: 230112 samples\n",
      "\n",
      "01_20_00:03:35 --- 1.8541452884674072 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:37 Training loss at epoch 1 step 7200: 3.2057275772094727\n",
      "\n",
      " This round's valence_loss=1.1968574523925781, arousal_loss=1.0752776861190796, emotion_loss=0.9418445825576782\n",
      "\n",
      "01_20_00:03:37 Seen so far: 230432 samples\n",
      "\n",
      "01_20_00:03:37 --- 1.6882872581481934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:39 Training loss at epoch 1 step 7210: 2.9624372005462645\n",
      "\n",
      " This round's valence_loss=1.2602952718734741, arousal_loss=1.0566517114639282, emotion_loss=1.243699073791504\n",
      "\n",
      "01_20_00:03:39 Seen so far: 230752 samples\n",
      "\n",
      "01_20_00:03:39 --- 1.7104992866516113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:40 Training loss at epoch 1 step 7220: 3.009229230880737\n",
      "\n",
      " This round's valence_loss=1.2572416067123413, arousal_loss=1.0445778369903564, emotion_loss=0.6547656655311584\n",
      "\n",
      "01_20_00:03:40 Seen so far: 231072 samples\n",
      "\n",
      "01_20_00:03:40 --- 1.8844349384307861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:42 Training loss at epoch 1 step 7230: 2.9921204090118407\n",
      "\n",
      " This round's valence_loss=1.257340908050537, arousal_loss=1.2279863357543945, emotion_loss=1.1565768718719482\n",
      "\n",
      "01_20_00:03:42 Seen so far: 231392 samples\n",
      "\n",
      "01_20_00:03:42 --- 1.7079753875732422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:44 Training loss at epoch 1 step 7240: 2.8198264598846436\n",
      "\n",
      " This round's valence_loss=0.6734048128128052, arousal_loss=0.45037195086479187, emotion_loss=0.9522533416748047\n",
      "\n",
      "01_20_00:03:44 Seen so far: 231712 samples\n",
      "\n",
      "01_20_00:03:44 --- 1.8625354766845703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:46 Training loss at epoch 1 step 7250: 2.9639317750930787\n",
      "\n",
      " This round's valence_loss=0.9232109785079956, arousal_loss=0.7326103448867798, emotion_loss=1.3012243509292603\n",
      "\n",
      "01_20_00:03:46 Seen so far: 232032 samples\n",
      "\n",
      "01_20_00:03:46 --- 1.7837538719177246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:47 Training loss at epoch 1 step 7260: 3.2604387044906615\n",
      "\n",
      " This round's valence_loss=0.7148473262786865, arousal_loss=0.6384248733520508, emotion_loss=0.921360433101654\n",
      "\n",
      "01_20_00:03:47 Seen so far: 232352 samples\n",
      "\n",
      "01_20_00:03:47 --- 1.6871585845947266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:49 Training loss at epoch 1 step 7270: 2.9201003193855284\n",
      "\n",
      " This round's valence_loss=0.7118986248970032, arousal_loss=0.6282211542129517, emotion_loss=1.2973068952560425\n",
      "\n",
      "01_20_00:03:49 Seen so far: 232672 samples\n",
      "\n",
      "01_20_00:03:49 --- 1.8655736446380615 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:51 Training loss at epoch 1 step 7280: 3.1351144075393678\n",
      "\n",
      " This round's valence_loss=0.7050670981407166, arousal_loss=0.6146782636642456, emotion_loss=1.210166573524475\n",
      "\n",
      "01_20_00:03:51 Seen so far: 232992 samples\n",
      "\n",
      "01_20_00:03:51 --- 1.7068676948547363 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:53 Training loss at epoch 1 step 7290: 3.064035654067993\n",
      "\n",
      " This round's valence_loss=1.0814646482467651, arousal_loss=1.0249922275543213, emotion_loss=1.2136284112930298\n",
      "\n",
      "01_20_00:03:53 Seen so far: 233312 samples\n",
      "\n",
      "01_20_00:03:53 --- 1.8589470386505127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:55 Training loss at epoch 1 step 7300: 3.120063614845276\n",
      "\n",
      " This round's valence_loss=1.0742689371109009, arousal_loss=0.9801188707351685, emotion_loss=1.066641092300415\n",
      "\n",
      "01_20_00:03:55 Seen so far: 233632 samples\n",
      "\n",
      "01_20_00:03:55 --- 1.8502001762390137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:57 Training loss at epoch 1 step 7310: 3.5652217626571656\n",
      "\n",
      " This round's valence_loss=1.4048575162887573, arousal_loss=1.2287280559539795, emotion_loss=0.900860071182251\n",
      "\n",
      "01_20_00:03:57 Seen so far: 233952 samples\n",
      "\n",
      "01_20_00:03:57 --- 1.8346352577209473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:03:58 Training loss at epoch 1 step 7320: 2.8581271886825563\n",
      "\n",
      " This round's valence_loss=0.9514967203140259, arousal_loss=0.8571920990943909, emotion_loss=1.1675065755844116\n",
      "\n",
      "01_20_00:03:58 Seen so far: 234272 samples\n",
      "\n",
      "01_20_00:03:58 --- 1.8331332206726074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:00 Training loss at epoch 1 step 7330: 3.0191231846809385\n",
      "\n",
      " This round's valence_loss=1.2259132862091064, arousal_loss=1.0770576000213623, emotion_loss=0.8827829360961914\n",
      "\n",
      "01_20_00:04:00 Seen so far: 234592 samples\n",
      "\n",
      "01_20_00:04:00 --- 1.9832913875579834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:02 Training loss at epoch 1 step 7340: 3.1202628135681154\n",
      "\n",
      " This round's valence_loss=1.2966848611831665, arousal_loss=1.0501344203948975, emotion_loss=0.981743574142456\n",
      "\n",
      "01_20_00:04:02 Seen so far: 234912 samples\n",
      "\n",
      "01_20_00:04:02 --- 1.68477201461792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:04 Training loss at epoch 1 step 7350: 3.0741748094558714\n",
      "\n",
      " This round's valence_loss=0.708842396736145, arousal_loss=0.6283010244369507, emotion_loss=1.1642870903015137\n",
      "\n",
      "01_20_00:04:04 Seen so far: 235232 samples\n",
      "\n",
      "01_20_00:04:04 --- 1.844400405883789 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:06 Training loss at epoch 1 step 7360: 2.9811228275299073\n",
      "\n",
      " This round's valence_loss=1.1004542112350464, arousal_loss=0.9457927942276001, emotion_loss=0.804685115814209\n",
      "\n",
      "01_20_00:04:06 Seen so far: 235552 samples\n",
      "\n",
      "01_20_00:04:06 --- 1.7487168312072754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:08 Training loss at epoch 1 step 7370: 3.089821767807007\n",
      "\n",
      " This round's valence_loss=1.0195176601409912, arousal_loss=0.8713016510009766, emotion_loss=1.1554903984069824\n",
      "\n",
      "01_20_00:04:08 Seen so far: 235872 samples\n",
      "\n",
      "01_20_00:04:08 --- 1.88956880569458 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:09 Training loss at epoch 1 step 7380: 2.991880702972412\n",
      "\n",
      " This round's valence_loss=0.6774150133132935, arousal_loss=0.4824361205101013, emotion_loss=1.1304658651351929\n",
      "\n",
      "01_20_00:04:09 Seen so far: 236192 samples\n",
      "\n",
      "01_20_00:04:09 --- 1.7973413467407227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:11 Training loss at epoch 1 step 7390: 3.1969641923904417\n",
      "\n",
      " This round's valence_loss=1.1964097023010254, arousal_loss=1.132033348083496, emotion_loss=1.6598796844482422\n",
      "\n",
      "01_20_00:04:11 Seen so far: 236512 samples\n",
      "\n",
      "01_20_00:04:11 --- 1.793576955795288 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:13 Training loss at epoch 1 step 7400: 2.9645612478256225\n",
      "\n",
      " This round's valence_loss=0.7062100172042847, arousal_loss=0.6119483709335327, emotion_loss=1.0845786333084106\n",
      "\n",
      "01_20_00:04:13 Seen so far: 236832 samples\n",
      "\n",
      "01_20_00:04:13 --- 1.6399757862091064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:15 Training loss at epoch 1 step 7410: 2.987017035484314\n",
      "\n",
      " This round's valence_loss=0.8914926052093506, arousal_loss=0.7259331941604614, emotion_loss=0.7734642624855042\n",
      "\n",
      "01_20_00:04:15 Seen so far: 237152 samples\n",
      "\n",
      "01_20_00:04:15 --- 1.9058825969696045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:17 Training loss at epoch 1 step 7420: 3.23718056678772\n",
      "\n",
      " This round's valence_loss=0.780370831489563, arousal_loss=0.7452532052993774, emotion_loss=0.987911581993103\n",
      "\n",
      "01_20_00:04:17 Seen so far: 237472 samples\n",
      "\n",
      "01_20_00:04:17 --- 1.834533452987671 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:18 Training loss at epoch 1 step 7430: 3.046043503284454\n",
      "\n",
      " This round's valence_loss=0.7706823945045471, arousal_loss=0.5703942775726318, emotion_loss=0.9636139273643494\n",
      "\n",
      "01_20_00:04:18 Seen so far: 237792 samples\n",
      "\n",
      "01_20_00:04:18 --- 1.776658058166504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:20 Training loss at epoch 1 step 7440: 3.3883649349212646\n",
      "\n",
      " This round's valence_loss=1.4916681051254272, arousal_loss=1.4368736743927002, emotion_loss=0.8781842589378357\n",
      "\n",
      "01_20_00:04:20 Seen so far: 238112 samples\n",
      "\n",
      "01_20_00:04:20 --- 1.655585527420044 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:22 Training loss at epoch 1 step 7450: 3.004794549942017\n",
      "\n",
      " This round's valence_loss=0.8257749080657959, arousal_loss=0.7314435243606567, emotion_loss=1.0125105381011963\n",
      "\n",
      "01_20_00:04:22 Seen so far: 238432 samples\n",
      "\n",
      "01_20_00:04:22 --- 1.8907442092895508 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:24 Training loss at epoch 1 step 7460: 2.975537919998169\n",
      "\n",
      " This round's valence_loss=0.7504243850708008, arousal_loss=0.6231483221054077, emotion_loss=1.0543509721755981\n",
      "\n",
      "01_20_00:04:24 Seen so far: 238752 samples\n",
      "\n",
      "01_20_00:04:24 --- 1.832019567489624 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:26 Training loss at epoch 1 step 7470: 3.2319580554962157\n",
      "\n",
      " This round's valence_loss=1.2187995910644531, arousal_loss=1.1396677494049072, emotion_loss=1.4399957656860352\n",
      "\n",
      "01_20_00:04:26 Seen so far: 239072 samples\n",
      "\n",
      "01_20_00:04:26 --- 2.0252528190612793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:27 Training loss at epoch 1 step 7480: 2.8840416431427003\n",
      "\n",
      " This round's valence_loss=1.3623697757720947, arousal_loss=1.3251988887786865, emotion_loss=1.4313242435455322\n",
      "\n",
      "01_20_00:04:27 Seen so far: 239392 samples\n",
      "\n",
      "01_20_00:04:27 --- 1.7110347747802734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:29 Training loss at epoch 1 step 7490: 3.3863879203796388\n",
      "\n",
      " This round's valence_loss=1.2990708351135254, arousal_loss=1.1791369915008545, emotion_loss=0.9314190149307251\n",
      "\n",
      "01_20_00:04:29 Seen so far: 239712 samples\n",
      "\n",
      "01_20_00:04:29 --- 1.7685043811798096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:31 Training loss at epoch 1 step 7500: 3.166165089607239\n",
      "\n",
      " This round's valence_loss=1.300445556640625, arousal_loss=1.2614073753356934, emotion_loss=0.9102315306663513\n",
      "\n",
      "01_20_00:04:31 Seen so far: 240032 samples\n",
      "\n",
      "01_20_00:04:31 --- 1.8267719745635986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:33 Training loss at epoch 1 step 7510: 2.952196955680847\n",
      "\n",
      " This round's valence_loss=1.1645891666412354, arousal_loss=0.9740419387817383, emotion_loss=1.1933608055114746\n",
      "\n",
      "01_20_00:04:33 Seen so far: 240352 samples\n",
      "\n",
      "01_20_00:04:33 --- 1.7996644973754883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:34 Training loss at epoch 1 step 7520: 3.1108617067337034\n",
      "\n",
      " This round's valence_loss=1.1553473472595215, arousal_loss=1.147623062133789, emotion_loss=1.1161613464355469\n",
      "\n",
      "01_20_00:04:34 Seen so far: 240672 samples\n",
      "\n",
      "01_20_00:04:34 --- 1.6427204608917236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:36 Training loss at epoch 1 step 7530: 2.8967774391174315\n",
      "\n",
      " This round's valence_loss=0.9856399297714233, arousal_loss=0.8130334615707397, emotion_loss=0.8066733479499817\n",
      "\n",
      "01_20_00:04:36 Seen so far: 240992 samples\n",
      "\n",
      "01_20_00:04:36 --- 1.760732889175415 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:38 Training loss at epoch 1 step 7540: 3.107183599472046\n",
      "\n",
      " This round's valence_loss=1.5896875858306885, arousal_loss=1.492456078529358, emotion_loss=1.088118076324463\n",
      "\n",
      "01_20_00:04:38 Seen so far: 241312 samples\n",
      "\n",
      "01_20_00:04:38 --- 1.603027105331421 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:39 Training loss at epoch 1 step 7550: 3.0860164403915404\n",
      "\n",
      " This round's valence_loss=1.3069713115692139, arousal_loss=1.2257676124572754, emotion_loss=0.7787483334541321\n",
      "\n",
      "01_20_00:04:39 Seen so far: 241632 samples\n",
      "\n",
      "01_20_00:04:39 --- 1.6949007511138916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:41 Training loss at epoch 1 step 7560: 3.048495960235596\n",
      "\n",
      " This round's valence_loss=1.291374921798706, arousal_loss=1.0565781593322754, emotion_loss=1.0753085613250732\n",
      "\n",
      "01_20_00:04:41 Seen so far: 241952 samples\n",
      "\n",
      "01_20_00:04:41 --- 1.7743542194366455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:43 Training loss at epoch 1 step 7570: 3.168996715545654\n",
      "\n",
      " This round's valence_loss=1.3298664093017578, arousal_loss=1.191969871520996, emotion_loss=0.9824652075767517\n",
      "\n",
      "01_20_00:04:43 Seen so far: 242272 samples\n",
      "\n",
      "01_20_00:04:43 --- 1.5850145816802979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:45 Training loss at epoch 1 step 7580: 3.049587106704712\n",
      "\n",
      " This round's valence_loss=1.1248040199279785, arousal_loss=0.9370169639587402, emotion_loss=0.8295428156852722\n",
      "\n",
      "01_20_00:04:45 Seen so far: 242592 samples\n",
      "\n",
      "01_20_00:04:45 --- 1.7274501323699951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:46 Training loss at epoch 1 step 7590: 3.2395833492279054\n",
      "\n",
      " This round's valence_loss=1.0129311084747314, arousal_loss=0.8639395236968994, emotion_loss=1.0679020881652832\n",
      "\n",
      "01_20_00:04:46 Seen so far: 242912 samples\n",
      "\n",
      "01_20_00:04:46 --- 1.707449197769165 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:48 Training loss at epoch 1 step 7600: 3.0572949767112734\n",
      "\n",
      " This round's valence_loss=1.432054877281189, arousal_loss=1.2990809679031372, emotion_loss=1.040313959121704\n",
      "\n",
      "01_20_00:04:48 Seen so far: 243232 samples\n",
      "\n",
      "01_20_00:04:48 --- 1.6962804794311523 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:50 Training loss at epoch 1 step 7610: 2.9770456314086915\n",
      "\n",
      " This round's valence_loss=1.1618335247039795, arousal_loss=0.976834774017334, emotion_loss=0.7978031635284424\n",
      "\n",
      "01_20_00:04:50 Seen so far: 243552 samples\n",
      "\n",
      "01_20_00:04:50 --- 1.949049949645996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:52 Training loss at epoch 1 step 7620: 3.0613350868225098\n",
      "\n",
      " This round's valence_loss=1.433307409286499, arousal_loss=1.3337116241455078, emotion_loss=1.043572187423706\n",
      "\n",
      "01_20_00:04:52 Seen so far: 243872 samples\n",
      "\n",
      "01_20_00:04:52 --- 1.8162510395050049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:53 Training loss at epoch 1 step 7630: 3.157893204689026\n",
      "\n",
      " This round's valence_loss=0.9693175554275513, arousal_loss=0.8660486936569214, emotion_loss=1.383920669555664\n",
      "\n",
      "01_20_00:04:53 Seen so far: 244192 samples\n",
      "\n",
      "01_20_00:04:53 --- 1.7289228439331055 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:55 Training loss at epoch 1 step 7640: 2.9925666213035584\n",
      "\n",
      " This round's valence_loss=1.1013227701187134, arousal_loss=0.9576493501663208, emotion_loss=0.8485040664672852\n",
      "\n",
      "01_20_00:04:55 Seen so far: 244512 samples\n",
      "\n",
      "01_20_00:04:55 --- 1.67710542678833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:57 Training loss at epoch 1 step 7650: 3.5117599725723267\n",
      "\n",
      " This round's valence_loss=1.3197288513183594, arousal_loss=1.2092504501342773, emotion_loss=1.158840298652649\n",
      "\n",
      "01_20_00:04:57 Seen so far: 244832 samples\n",
      "\n",
      "01_20_00:04:57 --- 1.7695786952972412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:04:59 Training loss at epoch 1 step 7660: 2.795914328098297\n",
      "\n",
      " This round's valence_loss=0.9181474447250366, arousal_loss=0.8165900707244873, emotion_loss=1.1845980882644653\n",
      "\n",
      "01_20_00:04:59 Seen so far: 245152 samples\n",
      "\n",
      "01_20_00:04:59 --- 1.7668533325195312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:00 Training loss at epoch 1 step 7670: 2.861360764503479\n",
      "\n",
      " This round's valence_loss=1.1268928050994873, arousal_loss=1.0439364910125732, emotion_loss=0.9666604399681091\n",
      "\n",
      "01_20_00:05:00 Seen so far: 245472 samples\n",
      "\n",
      "01_20_00:05:00 --- 1.750563621520996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:02 Training loss at epoch 1 step 7680: 3.070330834388733\n",
      "\n",
      " This round's valence_loss=1.091538667678833, arousal_loss=0.9254462122917175, emotion_loss=0.9660115242004395\n",
      "\n",
      "01_20_00:05:02 Seen so far: 245792 samples\n",
      "\n",
      "01_20_00:05:02 --- 1.788466215133667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:04 Training loss at epoch 1 step 7690: 3.090184187889099\n",
      "\n",
      " This round's valence_loss=1.3478806018829346, arousal_loss=1.2028048038482666, emotion_loss=1.1645557880401611\n",
      "\n",
      "01_20_00:05:04 Seen so far: 246112 samples\n",
      "\n",
      "01_20_00:05:04 --- 1.7463853359222412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:06 Training loss at epoch 1 step 7700: 3.4279284954071043\n",
      "\n",
      " This round's valence_loss=0.9165599346160889, arousal_loss=0.6802049875259399, emotion_loss=0.8013043999671936\n",
      "\n",
      "01_20_00:05:06 Seen so far: 246432 samples\n",
      "\n",
      "01_20_00:05:06 --- 1.7158288955688477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:08 Training loss at epoch 1 step 7710: 3.398253393173218\n",
      "\n",
      " This round's valence_loss=1.6238081455230713, arousal_loss=1.4571328163146973, emotion_loss=1.1099435091018677\n",
      "\n",
      "01_20_00:05:08 Seen so far: 246752 samples\n",
      "\n",
      "01_20_00:05:08 --- 1.829552412033081 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:09 Training loss at epoch 1 step 7720: 2.8728732109069823\n",
      "\n",
      " This round's valence_loss=1.2562847137451172, arousal_loss=1.1125108003616333, emotion_loss=1.115977168083191\n",
      "\n",
      "01_20_00:05:09 Seen so far: 247072 samples\n",
      "\n",
      "01_20_00:05:09 --- 1.717930793762207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:11 Training loss at epoch 1 step 7730: 3.0700773000717163\n",
      "\n",
      " This round's valence_loss=1.2846763134002686, arousal_loss=1.0868314504623413, emotion_loss=0.9798257946968079\n",
      "\n",
      "01_20_00:05:11 Seen so far: 247392 samples\n",
      "\n",
      "01_20_00:05:11 --- 1.705247402191162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:13 Training loss at epoch 1 step 7740: 2.895774579048157\n",
      "\n",
      " This round's valence_loss=1.2115569114685059, arousal_loss=1.0637061595916748, emotion_loss=0.8666764497756958\n",
      "\n",
      "01_20_00:05:13 Seen so far: 247712 samples\n",
      "\n",
      "01_20_00:05:13 --- 1.7516822814941406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:15 Training loss at epoch 1 step 7750: 3.1236684322357178\n",
      "\n",
      " This round's valence_loss=0.8711527585983276, arousal_loss=0.7372246980667114, emotion_loss=1.0529671907424927\n",
      "\n",
      "01_20_00:05:15 Seen so far: 248032 samples\n",
      "\n",
      "01_20_00:05:15 --- 1.8175909519195557 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:16 Training loss at epoch 1 step 7760: 3.16627516746521\n",
      "\n",
      " This round's valence_loss=0.806860625743866, arousal_loss=0.8161567449569702, emotion_loss=0.9331320524215698\n",
      "\n",
      "01_20_00:05:16 Seen so far: 248352 samples\n",
      "\n",
      "01_20_00:05:16 --- 1.6866958141326904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:18 Training loss at epoch 1 step 7770: 3.2156506776809692\n",
      "\n",
      " This round's valence_loss=0.8341027498245239, arousal_loss=0.727186918258667, emotion_loss=0.9504640102386475\n",
      "\n",
      "01_20_00:05:18 Seen so far: 248672 samples\n",
      "\n",
      "01_20_00:05:18 --- 1.884450912475586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:20 Training loss at epoch 1 step 7780: 3.087123155593872\n",
      "\n",
      " This round's valence_loss=1.354130506515503, arousal_loss=1.221069574356079, emotion_loss=1.0403753519058228\n",
      "\n",
      "01_20_00:05:20 Seen so far: 248992 samples\n",
      "\n",
      "01_20_00:05:20 --- 1.9558517932891846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:22 Training loss at epoch 1 step 7790: 3.024393367767334\n",
      "\n",
      " This round's valence_loss=0.951858639717102, arousal_loss=0.821256160736084, emotion_loss=1.1617636680603027\n",
      "\n",
      "01_20_00:05:22 Seen so far: 249312 samples\n",
      "\n",
      "01_20_00:05:22 --- 1.827578067779541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:24 Training loss at epoch 1 step 7800: 3.3558293104171755\n",
      "\n",
      " This round's valence_loss=1.4707310199737549, arousal_loss=1.359365701675415, emotion_loss=1.2878392934799194\n",
      "\n",
      "01_20_00:05:24 Seen so far: 249632 samples\n",
      "\n",
      "01_20_00:05:24 --- 2.1635982990264893 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:26 Training loss at epoch 1 step 7810: 2.962032675743103\n",
      "\n",
      " This round's valence_loss=1.1146929264068604, arousal_loss=0.9821147918701172, emotion_loss=0.9686720371246338\n",
      "\n",
      "01_20_00:05:26 Seen so far: 249952 samples\n",
      "\n",
      "01_20_00:05:26 --- 1.7727067470550537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:28 Training loss at epoch 1 step 7820: 3.019856262207031\n",
      "\n",
      " This round's valence_loss=0.9235565066337585, arousal_loss=0.8628890514373779, emotion_loss=1.0387918949127197\n",
      "\n",
      "01_20_00:05:28 Seen so far: 250272 samples\n",
      "\n",
      "01_20_00:05:28 --- 1.7842833995819092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:29 Training loss at epoch 1 step 7830: 2.8566990375518797\n",
      "\n",
      " This round's valence_loss=0.5100951194763184, arousal_loss=0.4408077597618103, emotion_loss=1.1520359516143799\n",
      "\n",
      "01_20_00:05:29 Seen so far: 250592 samples\n",
      "\n",
      "01_20_00:05:29 --- 1.9000396728515625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:32 Training loss at epoch 1 step 7840: 3.156721496582031\n",
      "\n",
      " This round's valence_loss=1.1518466472625732, arousal_loss=0.9846546649932861, emotion_loss=0.9720420837402344\n",
      "\n",
      "01_20_00:05:32 Seen so far: 250912 samples\n",
      "\n",
      "01_20_00:05:32 --- 2.0713250637054443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:34 Training loss at epoch 1 step 7850: 3.1960986614227296\n",
      "\n",
      " This round's valence_loss=1.1191517114639282, arousal_loss=0.9380838871002197, emotion_loss=1.0891352891921997\n",
      "\n",
      "01_20_00:05:34 Seen so far: 251232 samples\n",
      "\n",
      "01_20_00:05:34 --- 2.0303878784179688 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:36 Training loss at epoch 1 step 7860: 2.7618149518966675\n",
      "\n",
      " This round's valence_loss=0.8852992653846741, arousal_loss=0.6709186434745789, emotion_loss=0.9857348203659058\n",
      "\n",
      "01_20_00:05:36 Seen so far: 251552 samples\n",
      "\n",
      "01_20_00:05:36 --- 2.0744762420654297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:38 Training loss at epoch 1 step 7870: 2.743322658538818\n",
      "\n",
      " This round's valence_loss=0.8108630180358887, arousal_loss=0.7598692178726196, emotion_loss=1.0016891956329346\n",
      "\n",
      "01_20_00:05:38 Seen so far: 251872 samples\n",
      "\n",
      "01_20_00:05:38 --- 2.0345218181610107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:40 Training loss at epoch 1 step 7880: 3.0609087228775023\n",
      "\n",
      " This round's valence_loss=1.1034353971481323, arousal_loss=1.0137981176376343, emotion_loss=1.1011855602264404\n",
      "\n",
      "01_20_00:05:40 Seen so far: 252192 samples\n",
      "\n",
      "01_20_00:05:40 --- 1.8013455867767334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:41 Training loss at epoch 1 step 7890: 3.0793238162994383\n",
      "\n",
      " This round's valence_loss=1.46891188621521, arousal_loss=1.313690185546875, emotion_loss=0.8140543699264526\n",
      "\n",
      "01_20_00:05:41 Seen so far: 252512 samples\n",
      "\n",
      "01_20_00:05:41 --- 1.8543245792388916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:43 Training loss at epoch 1 step 7900: 2.9899487495422363\n",
      "\n",
      " This round's valence_loss=0.9799818396568298, arousal_loss=0.840224027633667, emotion_loss=0.9169158935546875\n",
      "\n",
      "01_20_00:05:43 Seen so far: 252832 samples\n",
      "\n",
      "01_20_00:05:43 --- 1.833261489868164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:45 Training loss at epoch 1 step 7910: 3.1552989006042482\n",
      "\n",
      " This round's valence_loss=1.0758545398712158, arousal_loss=0.9540555477142334, emotion_loss=1.2938501834869385\n",
      "\n",
      "01_20_00:05:45 Seen so far: 253152 samples\n",
      "\n",
      "01_20_00:05:45 --- 1.7461974620819092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:47 Training loss at epoch 1 step 7920: 3.1981871843338014\n",
      "\n",
      " This round's valence_loss=0.9468239545822144, arousal_loss=0.8614479303359985, emotion_loss=1.132485270500183\n",
      "\n",
      "01_20_00:05:47 Seen so far: 253472 samples\n",
      "\n",
      "01_20_00:05:47 --- 1.7577674388885498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:49 Training loss at epoch 1 step 7930: 3.102166485786438\n",
      "\n",
      " This round's valence_loss=1.1037583351135254, arousal_loss=0.9277288913726807, emotion_loss=0.9953374266624451\n",
      "\n",
      "01_20_00:05:49 Seen so far: 253792 samples\n",
      "\n",
      "01_20_00:05:49 --- 1.9449851512908936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:51 Training loss at epoch 1 step 7940: 3.008397173881531\n",
      "\n",
      " This round's valence_loss=0.8052330017089844, arousal_loss=0.7639654874801636, emotion_loss=1.1788674592971802\n",
      "\n",
      "01_20_00:05:51 Seen so far: 254112 samples\n",
      "\n",
      "01_20_00:05:51 --- 1.9848518371582031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:52 Training loss at epoch 1 step 7950: 2.9721572518348696\n",
      "\n",
      " This round's valence_loss=0.4171004891395569, arousal_loss=0.25666043162345886, emotion_loss=1.1780670881271362\n",
      "\n",
      "01_20_00:05:52 Seen so far: 254432 samples\n",
      "\n",
      "01_20_00:05:52 --- 1.7665598392486572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:54 Training loss at epoch 1 step 7960: 2.9268130540847777\n",
      "\n",
      " This round's valence_loss=1.0923689603805542, arousal_loss=0.9734265208244324, emotion_loss=1.0600905418395996\n",
      "\n",
      "01_20_00:05:54 Seen so far: 254752 samples\n",
      "\n",
      "01_20_00:05:54 --- 1.7564735412597656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:56 Training loss at epoch 1 step 7970: 2.983994197845459\n",
      "\n",
      " This round's valence_loss=0.8944031000137329, arousal_loss=0.772312343120575, emotion_loss=0.9231606721878052\n",
      "\n",
      "01_20_00:05:56 Seen so far: 255072 samples\n",
      "\n",
      "01_20_00:05:56 --- 1.775618314743042 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:05:58 Training loss at epoch 1 step 7980: 3.3455819725990295\n",
      "\n",
      " This round's valence_loss=1.5360729694366455, arousal_loss=1.4464843273162842, emotion_loss=1.2971482276916504\n",
      "\n",
      "01_20_00:05:58 Seen so far: 255392 samples\n",
      "\n",
      "01_20_00:05:58 --- 1.8746860027313232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:00 Training loss at epoch 1 step 7990: 2.8969305515289308\n",
      "\n",
      " This round's valence_loss=0.7309157848358154, arousal_loss=0.585237979888916, emotion_loss=1.2499642372131348\n",
      "\n",
      "01_20_00:06:00 Seen so far: 255712 samples\n",
      "\n",
      "01_20_00:06:00 --- 1.82755446434021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:01 Training loss at epoch 1 step 8000: 3.0565062046051024\n",
      "\n",
      " This round's valence_loss=0.8028558492660522, arousal_loss=0.7315492630004883, emotion_loss=1.1423977613449097\n",
      "\n",
      "01_20_00:06:01 Seen so far: 256032 samples\n",
      "\n",
      "01_20_00:06:01 --- 1.7581346035003662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:03 Training loss at epoch 1 step 8010: 3.013299345970154\n",
      "\n",
      " This round's valence_loss=0.89714515209198, arousal_loss=0.7518734931945801, emotion_loss=0.9391341209411621\n",
      "\n",
      "01_20_00:06:03 Seen so far: 256352 samples\n",
      "\n",
      "01_20_00:06:03 --- 1.8444626331329346 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:05 Training loss at epoch 1 step 8020: 3.13370566368103\n",
      "\n",
      " This round's valence_loss=1.1395201683044434, arousal_loss=0.9701555967330933, emotion_loss=0.9937483072280884\n",
      "\n",
      "01_20_00:06:05 Seen so far: 256672 samples\n",
      "\n",
      "01_20_00:06:05 --- 1.8577263355255127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:07 Training loss at epoch 1 step 8030: 3.1396857500076294\n",
      "\n",
      " This round's valence_loss=1.319716215133667, arousal_loss=1.239654541015625, emotion_loss=1.1523655652999878\n",
      "\n",
      "01_20_00:06:07 Seen so far: 256992 samples\n",
      "\n",
      "01_20_00:06:07 --- 1.6306145191192627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:08 Training loss at epoch 1 step 8040: 2.7732359528541566\n",
      "\n",
      " This round's valence_loss=1.060942530632019, arousal_loss=0.9624598026275635, emotion_loss=1.3491517305374146\n",
      "\n",
      "01_20_00:06:08 Seen so far: 257312 samples\n",
      "\n",
      "01_20_00:06:08 --- 1.7733268737792969 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:10 Training loss at epoch 1 step 8050: 3.294050407409668\n",
      "\n",
      " This round's valence_loss=1.3302242755889893, arousal_loss=1.2165250778198242, emotion_loss=1.0495030879974365\n",
      "\n",
      "01_20_00:06:10 Seen so far: 257632 samples\n",
      "\n",
      "01_20_00:06:10 --- 1.9146342277526855 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:12 Training loss at epoch 1 step 8060: 3.111997365951538\n",
      "\n",
      " This round's valence_loss=1.0853681564331055, arousal_loss=0.9788594245910645, emotion_loss=0.8495296239852905\n",
      "\n",
      "01_20_00:06:12 Seen so far: 257952 samples\n",
      "\n",
      "01_20_00:06:12 --- 1.819871187210083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:14 Training loss at epoch 1 step 8070: 2.846151924133301\n",
      "\n",
      " This round's valence_loss=1.0629467964172363, arousal_loss=0.9459556341171265, emotion_loss=1.0670961141586304\n",
      "\n",
      "01_20_00:06:14 Seen so far: 258272 samples\n",
      "\n",
      "01_20_00:06:14 --- 1.7332603931427002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:16 Training loss at epoch 1 step 8080: 3.088913083076477\n",
      "\n",
      " This round's valence_loss=1.5927753448486328, arousal_loss=1.439213514328003, emotion_loss=1.0660080909729004\n",
      "\n",
      "01_20_00:06:16 Seen so far: 258592 samples\n",
      "\n",
      "01_20_00:06:16 --- 1.5967001914978027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:17 Training loss at epoch 1 step 8090: 3.3108089447021483\n",
      "\n",
      " This round's valence_loss=0.9551789164543152, arousal_loss=0.8364262580871582, emotion_loss=1.2706329822540283\n",
      "\n",
      "01_20_00:06:17 Seen so far: 258912 samples\n",
      "\n",
      "01_20_00:06:17 --- 1.8674840927124023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:19 Training loss at epoch 1 step 8100: 2.860319197177887\n",
      "\n",
      " This round's valence_loss=1.347468376159668, arousal_loss=1.1998822689056396, emotion_loss=0.9079327583312988\n",
      "\n",
      "01_20_00:06:19 Seen so far: 259232 samples\n",
      "\n",
      "01_20_00:06:19 --- 1.7650113105773926 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:21 Training loss at epoch 1 step 8110: 3.0009133338928224\n",
      "\n",
      " This round's valence_loss=0.9935972690582275, arousal_loss=0.8794955015182495, emotion_loss=1.1970701217651367\n",
      "\n",
      "01_20_00:06:21 Seen so far: 259552 samples\n",
      "\n",
      "01_20_00:06:21 --- 1.8631539344787598 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:23 Training loss at epoch 1 step 8120: 3.092103624343872\n",
      "\n",
      " This round's valence_loss=1.2787306308746338, arousal_loss=1.1892459392547607, emotion_loss=0.877472996711731\n",
      "\n",
      "01_20_00:06:23 Seen so far: 259872 samples\n",
      "\n",
      "01_20_00:06:23 --- 1.7614850997924805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:25 Training loss at epoch 1 step 8130: 3.0822025775909423\n",
      "\n",
      " This round's valence_loss=0.642135500907898, arousal_loss=0.4175703525543213, emotion_loss=0.9478302001953125\n",
      "\n",
      "01_20_00:06:25 Seen so far: 260192 samples\n",
      "\n",
      "01_20_00:06:25 --- 1.8624365329742432 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:26 Training loss at epoch 1 step 8140: 3.083400845527649\n",
      "\n",
      " This round's valence_loss=0.7035629749298096, arousal_loss=0.4043509364128113, emotion_loss=0.6870231628417969\n",
      "\n",
      "01_20_00:06:26 Seen so far: 260512 samples\n",
      "\n",
      "01_20_00:06:26 --- 1.7047598361968994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:28 Training loss at epoch 1 step 8150: 2.9202256917953493\n",
      "\n",
      " This round's valence_loss=1.4882290363311768, arousal_loss=1.3129007816314697, emotion_loss=0.9670660495758057\n",
      "\n",
      "01_20_00:06:28 Seen so far: 260832 samples\n",
      "\n",
      "01_20_00:06:28 --- 1.9231822490692139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:30 Training loss at epoch 1 step 8160: 3.199728584289551\n",
      "\n",
      " This round's valence_loss=1.2067525386810303, arousal_loss=1.1030677556991577, emotion_loss=1.1645164489746094\n",
      "\n",
      "01_20_00:06:30 Seen so far: 261152 samples\n",
      "\n",
      "01_20_00:06:30 --- 1.8208215236663818 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:32 Training loss at epoch 1 step 8170: 3.065548849105835\n",
      "\n",
      " This round's valence_loss=1.2529256343841553, arousal_loss=1.2185931205749512, emotion_loss=1.1984224319458008\n",
      "\n",
      "01_20_00:06:32 Seen so far: 261472 samples\n",
      "\n",
      "01_20_00:06:32 --- 1.8540594577789307 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:34 Training loss at epoch 1 step 8180: 3.0759143352508547\n",
      "\n",
      " This round's valence_loss=1.250781536102295, arousal_loss=1.1017712354660034, emotion_loss=1.0429878234863281\n",
      "\n",
      "01_20_00:06:34 Seen so far: 261792 samples\n",
      "\n",
      "01_20_00:06:34 --- 1.8760056495666504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:36 Training loss at epoch 1 step 8190: 3.243719720840454\n",
      "\n",
      " This round's valence_loss=1.2239885330200195, arousal_loss=1.067274570465088, emotion_loss=1.0460338592529297\n",
      "\n",
      "01_20_00:06:36 Seen so far: 262112 samples\n",
      "\n",
      "01_20_00:06:36 --- 1.9348955154418945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:38 Training loss at epoch 1 step 8200: 3.0244807958602906\n",
      "\n",
      " This round's valence_loss=1.0930352210998535, arousal_loss=0.9920421838760376, emotion_loss=1.311079978942871\n",
      "\n",
      "01_20_00:06:38 Seen so far: 262432 samples\n",
      "\n",
      "01_20_00:06:38 --- 2.065248727798462 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:40 Training loss at epoch 1 step 8210: 3.2351362466812135\n",
      "\n",
      " This round's valence_loss=1.2033876180648804, arousal_loss=0.9766350984573364, emotion_loss=0.6550458669662476\n",
      "\n",
      "01_20_00:06:40 Seen so far: 262752 samples\n",
      "\n",
      "01_20_00:06:40 --- 1.9870562553405762 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:42 Training loss at epoch 1 step 8220: 2.639157438278198\n",
      "\n",
      " This round's valence_loss=1.298403263092041, arousal_loss=1.0805854797363281, emotion_loss=1.0312473773956299\n",
      "\n",
      "01_20_00:06:42 Seen so far: 263072 samples\n",
      "\n",
      "01_20_00:06:42 --- 1.878352403640747 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:44 Training loss at epoch 1 step 8230: 2.777219605445862\n",
      "\n",
      " This round's valence_loss=1.1181950569152832, arousal_loss=0.981413722038269, emotion_loss=1.013864517211914\n",
      "\n",
      "01_20_00:06:44 Seen so far: 263392 samples\n",
      "\n",
      "01_20_00:06:44 --- 1.935013771057129 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:45 Training loss at epoch 1 step 8240: 3.0942391395568847\n",
      "\n",
      " This round's valence_loss=0.7722699642181396, arousal_loss=0.6062576770782471, emotion_loss=0.9016377925872803\n",
      "\n",
      "01_20_00:06:45 Seen so far: 263712 samples\n",
      "\n",
      "01_20_00:06:45 --- 1.794236183166504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:47 Training loss at epoch 1 step 8250: 3.011241340637207\n",
      "\n",
      " This round's valence_loss=1.0306564569473267, arousal_loss=0.8099292516708374, emotion_loss=0.7444514632225037\n",
      "\n",
      "01_20_00:06:47 Seen so far: 264032 samples\n",
      "\n",
      "01_20_00:06:47 --- 1.9143602848052979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:49 Training loss at epoch 1 step 8260: 3.358027791976929\n",
      "\n",
      " This round's valence_loss=1.1098790168762207, arousal_loss=0.9493973255157471, emotion_loss=1.01704740524292\n",
      "\n",
      "01_20_00:06:49 Seen so far: 264352 samples\n",
      "\n",
      "01_20_00:06:49 --- 1.8580677509307861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:51 Training loss at epoch 1 step 8270: 2.971841645240784\n",
      "\n",
      " This round's valence_loss=1.3157472610473633, arousal_loss=1.0835984945297241, emotion_loss=0.9349567890167236\n",
      "\n",
      "01_20_00:06:51 Seen so far: 264672 samples\n",
      "\n",
      "01_20_00:06:51 --- 1.916654109954834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:53 Training loss at epoch 1 step 8280: 3.2593217372894285\n",
      "\n",
      " This round's valence_loss=0.7223281860351562, arousal_loss=0.5858423709869385, emotion_loss=0.992944061756134\n",
      "\n",
      "01_20_00:06:53 Seen so far: 264992 samples\n",
      "\n",
      "01_20_00:06:53 --- 1.9119000434875488 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:55 Training loss at epoch 1 step 8290: 2.9096652030944825\n",
      "\n",
      " This round's valence_loss=1.0088913440704346, arousal_loss=0.8537013530731201, emotion_loss=1.096137285232544\n",
      "\n",
      "01_20_00:06:55 Seen so far: 265312 samples\n",
      "\n",
      "01_20_00:06:55 --- 1.6868090629577637 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:57 Training loss at epoch 1 step 8300: 2.89448082447052\n",
      "\n",
      " This round's valence_loss=1.4331567287445068, arousal_loss=1.3362982273101807, emotion_loss=1.2565085887908936\n",
      "\n",
      "01_20_00:06:57 Seen so far: 265632 samples\n",
      "\n",
      "01_20_00:06:57 --- 1.8456120491027832 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:06:58 Training loss at epoch 1 step 8310: 3.0875100612640383\n",
      "\n",
      " This round's valence_loss=0.9474447965621948, arousal_loss=0.7341198921203613, emotion_loss=1.0395991802215576\n",
      "\n",
      "01_20_00:06:58 Seen so far: 265952 samples\n",
      "\n",
      "01_20_00:06:58 --- 1.7821378707885742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:00 Training loss at epoch 1 step 8320: 3.012514615058899\n",
      "\n",
      " This round's valence_loss=0.8176774978637695, arousal_loss=0.7303242683410645, emotion_loss=1.2753424644470215\n",
      "\n",
      "01_20_00:07:00 Seen so far: 266272 samples\n",
      "\n",
      "01_20_00:07:00 --- 1.6806342601776123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:02 Training loss at epoch 1 step 8330: 2.9732340574264526\n",
      "\n",
      " This round's valence_loss=1.432773232460022, arousal_loss=1.3269429206848145, emotion_loss=1.1032699346542358\n",
      "\n",
      "01_20_00:07:02 Seen so far: 266592 samples\n",
      "\n",
      "01_20_00:07:02 --- 1.8907475471496582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:04 Training loss at epoch 1 step 8340: 3.051571488380432\n",
      "\n",
      " This round's valence_loss=0.8373074531555176, arousal_loss=0.7081660628318787, emotion_loss=1.0306702852249146\n",
      "\n",
      "01_20_00:07:04 Seen so far: 266912 samples\n",
      "\n",
      "01_20_00:07:04 --- 1.7595860958099365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:05 Training loss at epoch 1 step 8350: 2.8933754920959474\n",
      "\n",
      " This round's valence_loss=0.5447055101394653, arousal_loss=0.37759286165237427, emotion_loss=0.997626543045044\n",
      "\n",
      "01_20_00:07:05 Seen so far: 267232 samples\n",
      "\n",
      "01_20_00:07:05 --- 1.6660845279693604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:07 Training loss at epoch 1 step 8360: 2.7355862140655516\n",
      "\n",
      " This round's valence_loss=0.5404964685440063, arousal_loss=0.31805986166000366, emotion_loss=0.9192577004432678\n",
      "\n",
      "01_20_00:07:07 Seen so far: 267552 samples\n",
      "\n",
      "01_20_00:07:07 --- 1.7655656337738037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:09 Training loss at epoch 1 step 8370: 3.268718886375427\n",
      "\n",
      " This round's valence_loss=0.7951618432998657, arousal_loss=0.5884410738945007, emotion_loss=0.9788834452629089\n",
      "\n",
      "01_20_00:07:09 Seen so far: 267872 samples\n",
      "\n",
      "01_20_00:07:09 --- 1.8238191604614258 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:10 Training loss at epoch 1 step 8380: 3.3606369495391846\n",
      "\n",
      " This round's valence_loss=1.2269880771636963, arousal_loss=1.0919053554534912, emotion_loss=0.8894044160842896\n",
      "\n",
      "01_20_00:07:10 Seen so far: 268192 samples\n",
      "\n",
      "01_20_00:07:10 --- 1.5301411151885986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:12 Training loss at epoch 1 step 8390: 3.0648136854171755\n",
      "\n",
      " This round's valence_loss=1.1266257762908936, arousal_loss=0.988695502281189, emotion_loss=0.8198745250701904\n",
      "\n",
      "01_20_00:07:12 Seen so far: 268512 samples\n",
      "\n",
      "01_20_00:07:12 --- 1.7056994438171387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:14 Training loss at epoch 1 step 8400: 3.241852807998657\n",
      "\n",
      " This round's valence_loss=1.041118860244751, arousal_loss=0.8129489421844482, emotion_loss=0.8587641716003418\n",
      "\n",
      "01_20_00:07:14 Seen so far: 268832 samples\n",
      "\n",
      "01_20_00:07:14 --- 1.7195887565612793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:16 Training loss at epoch 1 step 8410: 2.8638906955718992\n",
      "\n",
      " This round's valence_loss=0.7224509119987488, arousal_loss=0.493667870759964, emotion_loss=0.9706909656524658\n",
      "\n",
      "01_20_00:07:16 Seen so far: 269152 samples\n",
      "\n",
      "01_20_00:07:16 --- 1.5895144939422607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:17 Training loss at epoch 1 step 8420: 3.3176018476486204\n",
      "\n",
      " This round's valence_loss=1.4617071151733398, arousal_loss=1.3152539730072021, emotion_loss=1.0936295986175537\n",
      "\n",
      "01_20_00:07:17 Seen so far: 269472 samples\n",
      "\n",
      "01_20_00:07:17 --- 1.6174829006195068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:19 Training loss at epoch 1 step 8430: 3.1257320165634157\n",
      "\n",
      " This round's valence_loss=1.3132975101470947, arousal_loss=1.044647455215454, emotion_loss=1.0839871168136597\n",
      "\n",
      "01_20_00:07:19 Seen so far: 269792 samples\n",
      "\n",
      "01_20_00:07:19 --- 1.646214485168457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:21 Training loss at epoch 1 step 8440: 3.1406580448150634\n",
      "\n",
      " This round's valence_loss=1.1317682266235352, arousal_loss=0.9621914625167847, emotion_loss=0.7084527015686035\n",
      "\n",
      "01_20_00:07:21 Seen so far: 270112 samples\n",
      "\n",
      "01_20_00:07:21 --- 1.8879542350769043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:22 Training loss at epoch 1 step 8450: 3.18946316242218\n",
      "\n",
      " This round's valence_loss=0.6946687698364258, arousal_loss=0.5622851848602295, emotion_loss=1.260770320892334\n",
      "\n",
      "01_20_00:07:22 Seen so far: 270432 samples\n",
      "\n",
      "01_20_00:07:22 --- 1.679072380065918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:24 Training loss at epoch 1 step 8460: 2.948475694656372\n",
      "\n",
      " This round's valence_loss=0.8187927007675171, arousal_loss=0.7288744449615479, emotion_loss=1.465885877609253\n",
      "\n",
      "01_20_00:07:24 Seen so far: 270752 samples\n",
      "\n",
      "01_20_00:07:24 --- 1.8161394596099854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:26 Training loss at epoch 1 step 8470: 3.2388435125350954\n",
      "\n",
      " This round's valence_loss=0.8766018748283386, arousal_loss=0.7089509963989258, emotion_loss=1.0204601287841797\n",
      "\n",
      "01_20_00:07:26 Seen so far: 271072 samples\n",
      "\n",
      "01_20_00:07:26 --- 1.7902655601501465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:28 Training loss at epoch 1 step 8480: 3.026552987098694\n",
      "\n",
      " This round's valence_loss=1.0798144340515137, arousal_loss=1.0024359226226807, emotion_loss=1.0213055610656738\n",
      "\n",
      "01_20_00:07:28 Seen so far: 271392 samples\n",
      "\n",
      "01_20_00:07:28 --- 1.7693867683410645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:29 Training loss at epoch 1 step 8490: 2.679764378070831\n",
      "\n",
      " This round's valence_loss=0.8080307245254517, arousal_loss=0.7317053079605103, emotion_loss=1.2921137809753418\n",
      "\n",
      "01_20_00:07:29 Seen so far: 271712 samples\n",
      "\n",
      "01_20_00:07:29 --- 1.699479341506958 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:31 Training loss at epoch 1 step 8500: 3.1403512954711914\n",
      "\n",
      " This round's valence_loss=1.3247101306915283, arousal_loss=1.1854628324508667, emotion_loss=0.8679463267326355\n",
      "\n",
      "01_20_00:07:31 Seen so far: 272032 samples\n",
      "\n",
      "01_20_00:07:31 --- 1.9439234733581543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:33 Training loss at epoch 1 step 8510: 2.7570780754089355\n",
      "\n",
      " This round's valence_loss=0.5902724266052246, arousal_loss=0.5111837387084961, emotion_loss=1.1128801107406616\n",
      "\n",
      "01_20_00:07:33 Seen so far: 272352 samples\n",
      "\n",
      "01_20_00:07:33 --- 1.7309460639953613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:35 Training loss at epoch 1 step 8520: 3.1808362722396852\n",
      "\n",
      " This round's valence_loss=0.8661385774612427, arousal_loss=0.6936193108558655, emotion_loss=1.114500880241394\n",
      "\n",
      "01_20_00:07:35 Seen so far: 272672 samples\n",
      "\n",
      "01_20_00:07:35 --- 1.6925013065338135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:37 Training loss at epoch 1 step 8530: 2.914175736904144\n",
      "\n",
      " This round's valence_loss=1.3120067119598389, arousal_loss=1.193597435951233, emotion_loss=0.8921929001808167\n",
      "\n",
      "01_20_00:07:37 Seen so far: 272992 samples\n",
      "\n",
      "01_20_00:07:37 --- 1.7290103435516357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:38 Training loss at epoch 1 step 8540: 3.059818911552429\n",
      "\n",
      " This round's valence_loss=0.9534251689910889, arousal_loss=0.8339856863021851, emotion_loss=1.059626579284668\n",
      "\n",
      "01_20_00:07:38 Seen so far: 273312 samples\n",
      "\n",
      "01_20_00:07:38 --- 1.8313946723937988 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:40 Training loss at epoch 1 step 8550: 2.96421902179718\n",
      "\n",
      " This round's valence_loss=1.3458200693130493, arousal_loss=1.2008991241455078, emotion_loss=0.8774620294570923\n",
      "\n",
      "01_20_00:07:40 Seen so far: 273632 samples\n",
      "\n",
      "01_20_00:07:40 --- 1.7593839168548584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:42 Training loss at epoch 1 step 8560: 3.2112919092178345\n",
      "\n",
      " This round's valence_loss=1.2973945140838623, arousal_loss=1.1814870834350586, emotion_loss=0.5151708126068115\n",
      "\n",
      "01_20_00:07:42 Seen so far: 273952 samples\n",
      "\n",
      "01_20_00:07:42 --- 1.7374162673950195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:44 Training loss at epoch 1 step 8570: 2.8236722350120544\n",
      "\n",
      " This round's valence_loss=0.8969415426254272, arousal_loss=0.7333678007125854, emotion_loss=0.8071094751358032\n",
      "\n",
      "01_20_00:07:44 Seen so far: 274272 samples\n",
      "\n",
      "01_20_00:07:44 --- 1.787498950958252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:45 Training loss at epoch 1 step 8580: 3.137350296974182\n",
      "\n",
      " This round's valence_loss=0.862151563167572, arousal_loss=0.7450975179672241, emotion_loss=1.3517452478408813\n",
      "\n",
      "01_20_00:07:45 Seen so far: 274592 samples\n",
      "\n",
      "01_20_00:07:45 --- 1.6688008308410645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:47 Training loss at epoch 1 step 8590: 2.7200996398925783\n",
      "\n",
      " This round's valence_loss=1.4226421117782593, arousal_loss=1.327641487121582, emotion_loss=0.7391700744628906\n",
      "\n",
      "01_20_00:07:47 Seen so far: 274912 samples\n",
      "\n",
      "01_20_00:07:47 --- 1.646106481552124 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:49 Training loss at epoch 1 step 8600: 3.0293524503707885\n",
      "\n",
      " This round's valence_loss=0.8994699716567993, arousal_loss=0.7484009861946106, emotion_loss=1.0161216259002686\n",
      "\n",
      "01_20_00:07:49 Seen so far: 275232 samples\n",
      "\n",
      "01_20_00:07:49 --- 1.8158364295959473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:50 Training loss at epoch 1 step 8610: 3.0903508186340334\n",
      "\n",
      " This round's valence_loss=0.8957829475402832, arousal_loss=0.6890525817871094, emotion_loss=0.6771285533905029\n",
      "\n",
      "01_20_00:07:50 Seen so far: 275552 samples\n",
      "\n",
      "01_20_00:07:50 --- 1.734499454498291 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:52 Training loss at epoch 1 step 8620: 3.2069637298583986\n",
      "\n",
      " This round's valence_loss=0.9372107982635498, arousal_loss=0.8920648097991943, emotion_loss=0.9711569547653198\n",
      "\n",
      "01_20_00:07:52 Seen so far: 275872 samples\n",
      "\n",
      "01_20_00:07:52 --- 1.8926236629486084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:54 Training loss at epoch 1 step 8630: 3.0871954679489138\n",
      "\n",
      " This round's valence_loss=1.581159234046936, arousal_loss=1.5251588821411133, emotion_loss=1.0130314826965332\n",
      "\n",
      "01_20_00:07:54 Seen so far: 276192 samples\n",
      "\n",
      "01_20_00:07:54 --- 1.6669483184814453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:56 Training loss at epoch 1 step 8640: 2.9662917017936707\n",
      "\n",
      " This round's valence_loss=0.9616515636444092, arousal_loss=0.8748652935028076, emotion_loss=0.9996145963668823\n",
      "\n",
      "01_20_00:07:56 Seen so far: 276512 samples\n",
      "\n",
      "01_20_00:07:56 --- 1.8901031017303467 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:07:58 Training loss at epoch 1 step 8650: 2.750836265087128\n",
      "\n",
      " This round's valence_loss=0.6157615780830383, arousal_loss=0.4771254062652588, emotion_loss=0.8294099569320679\n",
      "\n",
      "01_20_00:07:58 Seen so far: 276832 samples\n",
      "\n",
      "01_20_00:07:58 --- 2.0122315883636475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:00 Training loss at epoch 1 step 8660: 3.0944732427597046\n",
      "\n",
      " This round's valence_loss=1.122862458229065, arousal_loss=0.9473966956138611, emotion_loss=1.4497990608215332\n",
      "\n",
      "01_20_00:08:00 Seen so far: 277152 samples\n",
      "\n",
      "01_20_00:08:00 --- 1.808086633682251 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:02 Training loss at epoch 1 step 8670: 2.9016507506370544\n",
      "\n",
      " This round's valence_loss=0.7445172667503357, arousal_loss=0.6206380724906921, emotion_loss=1.2137441635131836\n",
      "\n",
      "01_20_00:08:02 Seen so far: 277472 samples\n",
      "\n",
      "01_20_00:08:02 --- 1.8288979530334473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:04 Training loss at epoch 1 step 8680: 2.9078229665756226\n",
      "\n",
      " This round's valence_loss=1.0701950788497925, arousal_loss=1.0083478689193726, emotion_loss=1.0724873542785645\n",
      "\n",
      "01_20_00:08:04 Seen so far: 277792 samples\n",
      "\n",
      "01_20_00:08:04 --- 2.085491418838501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:05 Training loss at epoch 1 step 8690: 2.800063681602478\n",
      "\n",
      " This round's valence_loss=0.9167212247848511, arousal_loss=0.7335503101348877, emotion_loss=0.8589192628860474\n",
      "\n",
      "01_20_00:08:05 Seen so far: 278112 samples\n",
      "\n",
      "01_20_00:08:05 --- 1.686445951461792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:07 Training loss at epoch 1 step 8700: 3.1852216005325316\n",
      "\n",
      " This round's valence_loss=1.3078136444091797, arousal_loss=1.2068499326705933, emotion_loss=1.2042427062988281\n",
      "\n",
      "01_20_00:08:07 Seen so far: 278432 samples\n",
      "\n",
      "01_20_00:08:07 --- 1.7195978164672852 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:09 Training loss at epoch 1 step 8710: 3.2074178218841554\n",
      "\n",
      " This round's valence_loss=1.097091794013977, arousal_loss=1.0439836978912354, emotion_loss=1.084465742111206\n",
      "\n",
      "01_20_00:08:09 Seen so far: 278752 samples\n",
      "\n",
      "01_20_00:08:09 --- 1.69270920753479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:11 Training loss at epoch 1 step 8720: 2.9569824934005737\n",
      "\n",
      " This round's valence_loss=1.7409814596176147, arousal_loss=1.5397909879684448, emotion_loss=1.3632850646972656\n",
      "\n",
      "01_20_00:08:11 Seen so far: 279072 samples\n",
      "\n",
      "01_20_00:08:11 --- 1.8642747402191162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:12 Training loss at epoch 1 step 8730: 2.937960314750671\n",
      "\n",
      " This round's valence_loss=0.9559799432754517, arousal_loss=0.715635359287262, emotion_loss=0.8475285768508911\n",
      "\n",
      "01_20_00:08:12 Seen so far: 279392 samples\n",
      "\n",
      "01_20_00:08:12 --- 1.806462049484253 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:14 Training loss at epoch 1 step 8740: 3.1493079662323\n",
      "\n",
      " This round's valence_loss=1.070176124572754, arousal_loss=1.002441644668579, emotion_loss=1.028098464012146\n",
      "\n",
      "01_20_00:08:14 Seen so far: 279712 samples\n",
      "\n",
      "01_20_00:08:14 --- 1.7306253910064697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:16 Training loss at epoch 1 step 8750: 3.1326196432113647\n",
      "\n",
      " This round's valence_loss=0.9520534873008728, arousal_loss=0.8418768644332886, emotion_loss=1.1857309341430664\n",
      "\n",
      "01_20_00:08:16 Seen so far: 280032 samples\n",
      "\n",
      "01_20_00:08:16 --- 1.941343069076538 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:18 Training loss at epoch 1 step 8760: 2.941028356552124\n",
      "\n",
      " This round's valence_loss=1.1408140659332275, arousal_loss=1.1004705429077148, emotion_loss=1.000866413116455\n",
      "\n",
      "01_20_00:08:18 Seen so far: 280352 samples\n",
      "\n",
      "01_20_00:08:18 --- 1.7531507015228271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:20 Training loss at epoch 1 step 8770: 3.187670612335205\n",
      "\n",
      " This round's valence_loss=0.8150310516357422, arousal_loss=0.8208296298980713, emotion_loss=0.9965941905975342\n",
      "\n",
      "01_20_00:08:20 Seen so far: 280672 samples\n",
      "\n",
      "01_20_00:08:20 --- 1.7034919261932373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:21 Training loss at epoch 1 step 8780: 2.8772013187408447\n",
      "\n",
      " This round's valence_loss=0.846077561378479, arousal_loss=0.7046449184417725, emotion_loss=1.3858642578125\n",
      "\n",
      "01_20_00:08:21 Seen so far: 280992 samples\n",
      "\n",
      "01_20_00:08:21 --- 1.600806474685669 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:23 Training loss at epoch 1 step 8790: 3.064582419395447\n",
      "\n",
      " This round's valence_loss=1.3255935907363892, arousal_loss=1.2284932136535645, emotion_loss=1.0154833793640137\n",
      "\n",
      "01_20_00:08:23 Seen so far: 281312 samples\n",
      "\n",
      "01_20_00:08:23 --- 1.6243813037872314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:24 Training loss at epoch 1 step 8800: 3.1739545822143556\n",
      "\n",
      " This round's valence_loss=1.0871713161468506, arousal_loss=1.0162851810455322, emotion_loss=0.8488681316375732\n",
      "\n",
      "01_20_00:08:24 Seen so far: 281632 samples\n",
      "\n",
      "01_20_00:08:24 --- 1.6852545738220215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:26 Training loss at epoch 1 step 8810: 2.926002287864685\n",
      "\n",
      " This round's valence_loss=1.3359242677688599, arousal_loss=1.2054182291030884, emotion_loss=0.7992277145385742\n",
      "\n",
      "01_20_00:08:26 Seen so far: 281952 samples\n",
      "\n",
      "01_20_00:08:26 --- 1.620774507522583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:28 Training loss at epoch 1 step 8820: 3.0506022691726686\n",
      "\n",
      " This round's valence_loss=0.9520324468612671, arousal_loss=0.8074977397918701, emotion_loss=1.011038064956665\n",
      "\n",
      "01_20_00:08:28 Seen so far: 282272 samples\n",
      "\n",
      "01_20_00:08:28 --- 1.7006142139434814 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:30 Training loss at epoch 1 step 8830: 3.0995957612991334\n",
      "\n",
      " This round's valence_loss=0.8775502443313599, arousal_loss=0.7534563541412354, emotion_loss=1.36757230758667\n",
      "\n",
      "01_20_00:08:30 Seen so far: 282592 samples\n",
      "\n",
      "01_20_00:08:30 --- 1.9345333576202393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:32 Training loss at epoch 1 step 8840: 2.952265405654907\n",
      "\n",
      " This round's valence_loss=0.8953883051872253, arousal_loss=0.6903681755065918, emotion_loss=0.9033355712890625\n",
      "\n",
      "01_20_00:08:32 Seen so far: 282912 samples\n",
      "\n",
      "01_20_00:08:32 --- 1.8677101135253906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:34 Training loss at epoch 1 step 8850: 3.174054574966431\n",
      "\n",
      " This round's valence_loss=1.669283390045166, arousal_loss=1.5870258808135986, emotion_loss=0.573464572429657\n",
      "\n",
      "01_20_00:08:34 Seen so far: 283232 samples\n",
      "\n",
      "01_20_00:08:34 --- 1.9104666709899902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:35 Training loss at epoch 1 step 8860: 3.1867967367172243\n",
      "\n",
      " This round's valence_loss=0.9934896230697632, arousal_loss=0.8727107048034668, emotion_loss=1.087693452835083\n",
      "\n",
      "01_20_00:08:35 Seen so far: 283552 samples\n",
      "\n",
      "01_20_00:08:35 --- 1.7324962615966797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:37 Training loss at epoch 1 step 8870: 3.1077443838119505\n",
      "\n",
      " This round's valence_loss=1.1441006660461426, arousal_loss=0.9829584956169128, emotion_loss=1.0604009628295898\n",
      "\n",
      "01_20_00:08:37 Seen so far: 283872 samples\n",
      "\n",
      "01_20_00:08:37 --- 1.749467372894287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:39 Training loss at epoch 1 step 8880: 2.791958737373352\n",
      "\n",
      " This round's valence_loss=0.7967276573181152, arousal_loss=0.7223944067955017, emotion_loss=0.9369849562644958\n",
      "\n",
      "01_20_00:08:39 Seen so far: 284192 samples\n",
      "\n",
      "01_20_00:08:39 --- 1.9081480503082275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:41 Training loss at epoch 1 step 8890: 3.103117847442627\n",
      "\n",
      " This round's valence_loss=1.3413505554199219, arousal_loss=1.1871006488800049, emotion_loss=0.9031946659088135\n",
      "\n",
      "01_20_00:08:41 Seen so far: 284512 samples\n",
      "\n",
      "01_20_00:08:41 --- 1.8702654838562012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:43 Training loss at epoch 1 step 8900: 2.9998621940612793\n",
      "\n",
      " This round's valence_loss=1.0782358646392822, arousal_loss=0.985456645488739, emotion_loss=0.7689796090126038\n",
      "\n",
      "01_20_00:08:43 Seen so far: 284832 samples\n",
      "\n",
      "01_20_00:08:43 --- 1.756108045578003 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:44 Training loss at epoch 1 step 8910: 3.0089963912963866\n",
      "\n",
      " This round's valence_loss=0.9243451356887817, arousal_loss=0.8152997493743896, emotion_loss=1.2804274559020996\n",
      "\n",
      "01_20_00:08:44 Seen so far: 285152 samples\n",
      "\n",
      "01_20_00:08:44 --- 1.6899921894073486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:46 Training loss at epoch 1 step 8920: 3.2226032495498655\n",
      "\n",
      " This round's valence_loss=1.1064198017120361, arousal_loss=0.829849362373352, emotion_loss=0.7323411703109741\n",
      "\n",
      "01_20_00:08:46 Seen so far: 285472 samples\n",
      "\n",
      "01_20_00:08:46 --- 1.8078100681304932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:48 Training loss at epoch 1 step 8930: 3.045274591445923\n",
      "\n",
      " This round's valence_loss=1.0003435611724854, arousal_loss=0.8190421462059021, emotion_loss=1.058685302734375\n",
      "\n",
      "01_20_00:08:48 Seen so far: 285792 samples\n",
      "\n",
      "01_20_00:08:48 --- 1.7066919803619385 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:49 Training loss at epoch 1 step 8940: 3.0747602701187136\n",
      "\n",
      " This round's valence_loss=0.7706105709075928, arousal_loss=0.5923001170158386, emotion_loss=1.1407990455627441\n",
      "\n",
      "01_20_00:08:49 Seen so far: 286112 samples\n",
      "\n",
      "01_20_00:08:49 --- 1.6347978115081787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:51 Training loss at epoch 1 step 8950: 3.2591020822525025\n",
      "\n",
      " This round's valence_loss=1.2960171699523926, arousal_loss=1.261393427848816, emotion_loss=1.3446643352508545\n",
      "\n",
      "01_20_00:08:51 Seen so far: 286432 samples\n",
      "\n",
      "01_20_00:08:51 --- 1.6535065174102783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:53 Training loss at epoch 1 step 8960: 2.9187423944473267\n",
      "\n",
      " This round's valence_loss=1.1424779891967773, arousal_loss=1.0305860042572021, emotion_loss=1.081109642982483\n",
      "\n",
      "01_20_00:08:53 Seen so far: 286752 samples\n",
      "\n",
      "01_20_00:08:53 --- 1.7509443759918213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:55 Training loss at epoch 1 step 8970: 3.0832614660263062\n",
      "\n",
      " This round's valence_loss=0.6107548475265503, arousal_loss=0.4591418504714966, emotion_loss=0.9204255938529968\n",
      "\n",
      "01_20_00:08:55 Seen so far: 287072 samples\n",
      "\n",
      "01_20_00:08:55 --- 1.796022653579712 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:56 Training loss at epoch 1 step 8980: 3.1927452802658083\n",
      "\n",
      " This round's valence_loss=1.1875526905059814, arousal_loss=1.0552504062652588, emotion_loss=1.1814297437667847\n",
      "\n",
      "01_20_00:08:56 Seen so far: 287392 samples\n",
      "\n",
      "01_20_00:08:56 --- 1.5887961387634277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:08:58 Training loss at epoch 1 step 8990: 3.4052876472473144\n",
      "\n",
      " This round's valence_loss=1.464308500289917, arousal_loss=1.3256006240844727, emotion_loss=1.1345833539962769\n",
      "\n",
      "01_20_00:08:58 Seen so far: 287712 samples\n",
      "\n",
      "01_20_00:08:58 --- 1.7851669788360596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:00 Training loss at epoch 1 step 9000: 3.3009337186813354\n",
      "\n",
      " This round's valence_loss=0.9653123021125793, arousal_loss=0.8503928184509277, emotion_loss=1.0418767929077148\n",
      "\n",
      "01_20_00:09:00 Seen so far: 288032 samples\n",
      "\n",
      "01_20_00:09:00 --- 1.7774438858032227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:01 Training loss at epoch 1 step 9010: 3.1525099515914916\n",
      "\n",
      " This round's valence_loss=1.056382179260254, arousal_loss=0.8246210217475891, emotion_loss=0.98374342918396\n",
      "\n",
      "01_20_00:09:01 Seen so far: 288352 samples\n",
      "\n",
      "01_20_00:09:01 --- 1.745082139968872 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:03 Training loss at epoch 1 step 9020: 3.072004294395447\n",
      "\n",
      " This round's valence_loss=1.4297709465026855, arousal_loss=1.3317196369171143, emotion_loss=1.0739495754241943\n",
      "\n",
      "01_20_00:09:03 Seen so far: 288672 samples\n",
      "\n",
      "01_20_00:09:03 --- 1.800396203994751 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:05 Training loss at epoch 1 step 9030: 2.7900312423706053\n",
      "\n",
      " This round's valence_loss=1.0126233100891113, arousal_loss=0.8044067025184631, emotion_loss=0.8900308609008789\n",
      "\n",
      "01_20_00:09:05 Seen so far: 288992 samples\n",
      "\n",
      "01_20_00:09:05 --- 1.6358187198638916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:07 Training loss at epoch 1 step 9040: 2.9676774621009825\n",
      "\n",
      " This round's valence_loss=1.306424617767334, arousal_loss=1.2056500911712646, emotion_loss=1.2493412494659424\n",
      "\n",
      "01_20_00:09:07 Seen so far: 289312 samples\n",
      "\n",
      "01_20_00:09:07 --- 1.6763520240783691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:08 Training loss at epoch 1 step 9050: 2.9834208488464355\n",
      "\n",
      " This round's valence_loss=1.090376615524292, arousal_loss=1.0107934474945068, emotion_loss=0.9045274257659912\n",
      "\n",
      "01_20_00:09:08 Seen so far: 289632 samples\n",
      "\n",
      "01_20_00:09:08 --- 1.880162239074707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:11 Training loss at epoch 1 step 9060: 3.1591107130050657\n",
      "\n",
      " This round's valence_loss=0.9617416262626648, arousal_loss=0.8461908102035522, emotion_loss=1.5826880931854248\n",
      "\n",
      "01_20_00:09:11 Seen so far: 289952 samples\n",
      "\n",
      "01_20_00:09:11 --- 2.0512378215789795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:12 Training loss at epoch 1 step 9070: 2.8725834131240844\n",
      "\n",
      " This round's valence_loss=0.738193154335022, arousal_loss=0.5955222249031067, emotion_loss=1.1155929565429688\n",
      "\n",
      "01_20_00:09:12 Seen so far: 290272 samples\n",
      "\n",
      "01_20_00:09:12 --- 1.7943804264068604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:14 Training loss at epoch 1 step 9080: 3.1322423934936525\n",
      "\n",
      " This round's valence_loss=0.9607542753219604, arousal_loss=0.8484318256378174, emotion_loss=1.2571325302124023\n",
      "\n",
      "01_20_00:09:14 Seen so far: 290592 samples\n",
      "\n",
      "01_20_00:09:14 --- 1.8802151679992676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:16 Training loss at epoch 1 step 9090: 3.155655765533447\n",
      "\n",
      " This round's valence_loss=1.0951428413391113, arousal_loss=0.9384716749191284, emotion_loss=0.7362266182899475\n",
      "\n",
      "01_20_00:09:16 Seen so far: 290912 samples\n",
      "\n",
      "01_20_00:09:16 --- 1.7312498092651367 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:18 Training loss at epoch 1 step 9100: 3.181135725975037\n",
      "\n",
      " This round's valence_loss=1.2656452655792236, arousal_loss=1.062175989151001, emotion_loss=1.163441777229309\n",
      "\n",
      "01_20_00:09:18 Seen so far: 291232 samples\n",
      "\n",
      "01_20_00:09:18 --- 1.8547706604003906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:20 Training loss at epoch 1 step 9110: 2.9434717655181886\n",
      "\n",
      " This round's valence_loss=1.1374763250350952, arousal_loss=0.9718109965324402, emotion_loss=0.9083160161972046\n",
      "\n",
      "01_20_00:09:20 Seen so far: 291552 samples\n",
      "\n",
      "01_20_00:09:20 --- 1.9375956058502197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:21 Training loss at epoch 1 step 9120: 3.130452108383179\n",
      "\n",
      " This round's valence_loss=0.9701366424560547, arousal_loss=0.8501571416854858, emotion_loss=0.7551282644271851\n",
      "\n",
      "01_20_00:09:21 Seen so far: 291872 samples\n",
      "\n",
      "01_20_00:09:21 --- 1.6946372985839844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:23 Training loss at epoch 1 step 9130: 3.1388535022735597\n",
      "\n",
      " This round's valence_loss=1.0067522525787354, arousal_loss=0.8558893203735352, emotion_loss=0.6588460206985474\n",
      "\n",
      "01_20_00:09:23 Seen so far: 292192 samples\n",
      "\n",
      "01_20_00:09:23 --- 1.8999428749084473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:25 Training loss at epoch 1 step 9140: 3.057055449485779\n",
      "\n",
      " This round's valence_loss=0.7950229644775391, arousal_loss=0.7227253913879395, emotion_loss=0.950147807598114\n",
      "\n",
      "01_20_00:09:25 Seen so far: 292512 samples\n",
      "\n",
      "01_20_00:09:25 --- 1.8792970180511475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:27 Training loss at epoch 1 step 9150: 3.2507450342178346\n",
      "\n",
      " This round's valence_loss=0.8055319786071777, arousal_loss=0.6060583591461182, emotion_loss=1.2838212251663208\n",
      "\n",
      "01_20_00:09:27 Seen so far: 292832 samples\n",
      "\n",
      "01_20_00:09:27 --- 1.7580456733703613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:29 Training loss at epoch 1 step 9160: 3.2645106315612793\n",
      "\n",
      " This round's valence_loss=1.4280871152877808, arousal_loss=1.3532044887542725, emotion_loss=1.2684483528137207\n",
      "\n",
      "01_20_00:09:29 Seen so far: 293152 samples\n",
      "\n",
      "01_20_00:09:29 --- 1.8238868713378906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:31 Training loss at epoch 1 step 9170: 3.5475483417510985\n",
      "\n",
      " This round's valence_loss=1.1798095703125, arousal_loss=1.1220605373382568, emotion_loss=0.9855332374572754\n",
      "\n",
      "01_20_00:09:31 Seen so far: 293472 samples\n",
      "\n",
      "01_20_00:09:31 --- 1.7481160163879395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:32 Training loss at epoch 1 step 9180: 2.8406962633132933\n",
      "\n",
      " This round's valence_loss=0.9334577322006226, arousal_loss=0.8429014682769775, emotion_loss=0.809731125831604\n",
      "\n",
      "01_20_00:09:32 Seen so far: 293792 samples\n",
      "\n",
      "01_20_00:09:32 --- 1.7222862243652344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:34 Training loss at epoch 1 step 9190: 2.9157439470291138\n",
      "\n",
      " This round's valence_loss=0.9296934604644775, arousal_loss=0.6774351596832275, emotion_loss=1.014904260635376\n",
      "\n",
      "01_20_00:09:34 Seen so far: 294112 samples\n",
      "\n",
      "01_20_00:09:34 --- 1.6489536762237549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:36 Training loss at epoch 1 step 9200: 3.274077224731445\n",
      "\n",
      " This round's valence_loss=0.921363353729248, arousal_loss=0.827445924282074, emotion_loss=1.2054412364959717\n",
      "\n",
      "01_20_00:09:36 Seen so far: 294432 samples\n",
      "\n",
      "01_20_00:09:36 --- 1.7282805442810059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:37 Training loss at epoch 1 step 9210: 2.846181333065033\n",
      "\n",
      " This round's valence_loss=1.5640194416046143, arousal_loss=1.436372995376587, emotion_loss=0.8358988165855408\n",
      "\n",
      "01_20_00:09:37 Seen so far: 294752 samples\n",
      "\n",
      "01_20_00:09:37 --- 1.7349238395690918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:39 Training loss at epoch 1 step 9220: 3.035178518295288\n",
      "\n",
      " This round's valence_loss=1.117996096611023, arousal_loss=0.9888878464698792, emotion_loss=0.9276918172836304\n",
      "\n",
      "01_20_00:09:39 Seen so far: 295072 samples\n",
      "\n",
      "01_20_00:09:39 --- 1.7269840240478516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:41 Training loss at epoch 1 step 9230: 2.944036364555359\n",
      "\n",
      " This round's valence_loss=0.885265052318573, arousal_loss=0.7721281051635742, emotion_loss=1.150888204574585\n",
      "\n",
      "01_20_00:09:41 Seen so far: 295392 samples\n",
      "\n",
      "01_20_00:09:41 --- 1.8911850452423096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:43 Training loss at epoch 1 step 9240: 2.7394039630889893\n",
      "\n",
      " This round's valence_loss=1.0675427913665771, arousal_loss=0.9665805101394653, emotion_loss=0.7144336104393005\n",
      "\n",
      "01_20_00:09:43 Seen so far: 295712 samples\n",
      "\n",
      "01_20_00:09:43 --- 1.6486003398895264 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:45 Training loss at epoch 1 step 9250: 3.148026394844055\n",
      "\n",
      " This round's valence_loss=1.4784266948699951, arousal_loss=1.2841869592666626, emotion_loss=0.6744505167007446\n",
      "\n",
      "01_20_00:09:45 Seen so far: 296032 samples\n",
      "\n",
      "01_20_00:09:45 --- 1.8723201751708984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:46 Training loss at epoch 1 step 9260: 2.618871259689331\n",
      "\n",
      " This round's valence_loss=1.090987205505371, arousal_loss=0.9786494970321655, emotion_loss=0.8377628326416016\n",
      "\n",
      "01_20_00:09:46 Seen so far: 296352 samples\n",
      "\n",
      "01_20_00:09:46 --- 1.7791590690612793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:48 Training loss at epoch 1 step 9270: 3.2475545167922975\n",
      "\n",
      " This round's valence_loss=0.9446163177490234, arousal_loss=0.8295037746429443, emotion_loss=0.9904618263244629\n",
      "\n",
      "01_20_00:09:48 Seen so far: 296672 samples\n",
      "\n",
      "01_20_00:09:48 --- 1.6896765232086182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:50 Training loss at epoch 1 step 9280: 3.2265822172164915\n",
      "\n",
      " This round's valence_loss=1.1221182346343994, arousal_loss=0.934184193611145, emotion_loss=0.7783586978912354\n",
      "\n",
      "01_20_00:09:50 Seen so far: 296992 samples\n",
      "\n",
      "01_20_00:09:50 --- 1.7620604038238525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:52 Training loss at epoch 1 step 9290: 2.881349062919617\n",
      "\n",
      " This round's valence_loss=1.2065937519073486, arousal_loss=1.1120281219482422, emotion_loss=0.8729742765426636\n",
      "\n",
      "01_20_00:09:52 Seen so far: 297312 samples\n",
      "\n",
      "01_20_00:09:52 --- 1.8400392532348633 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:53 Training loss at epoch 1 step 9300: 3.143623399734497\n",
      "\n",
      " This round's valence_loss=1.0411087274551392, arousal_loss=0.9772834777832031, emotion_loss=1.120436191558838\n",
      "\n",
      "01_20_00:09:53 Seen so far: 297632 samples\n",
      "\n",
      "01_20_00:09:53 --- 1.7633798122406006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:55 Training loss at epoch 1 step 9310: 3.150716686248779\n",
      "\n",
      " This round's valence_loss=0.9887949228286743, arousal_loss=0.823951005935669, emotion_loss=0.9216281771659851\n",
      "\n",
      "01_20_00:09:55 Seen so far: 297952 samples\n",
      "\n",
      "01_20_00:09:55 --- 1.751384973526001 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:57 Training loss at epoch 1 step 9320: 2.9156840443611145\n",
      "\n",
      " This round's valence_loss=1.133340835571289, arousal_loss=0.9766873717308044, emotion_loss=1.011818289756775\n",
      "\n",
      "01_20_00:09:57 Seen so far: 298272 samples\n",
      "\n",
      "01_20_00:09:57 --- 1.7487812042236328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:09:58 Training loss at epoch 1 step 9330: 3.0757373332977296\n",
      "\n",
      " This round's valence_loss=1.2261162996292114, arousal_loss=1.0674867630004883, emotion_loss=0.6801269054412842\n",
      "\n",
      "01_20_00:09:58 Seen so far: 298592 samples\n",
      "\n",
      "01_20_00:09:58 --- 1.5847325325012207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:00 Training loss at epoch 1 step 9340: 3.284576678276062\n",
      "\n",
      " This round's valence_loss=1.409651756286621, arousal_loss=1.3572039604187012, emotion_loss=1.0907070636749268\n",
      "\n",
      "01_20_00:10:00 Seen so far: 298912 samples\n",
      "\n",
      "01_20_00:10:00 --- 1.9202966690063477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:02 Training loss at epoch 1 step 9350: 3.143834638595581\n",
      "\n",
      " This round's valence_loss=1.2021015882492065, arousal_loss=1.0942808389663696, emotion_loss=0.9621688723564148\n",
      "\n",
      "01_20_00:10:02 Seen so far: 299232 samples\n",
      "\n",
      "01_20_00:10:02 --- 1.7962212562561035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:04 Training loss at epoch 1 step 9360: 3.089300584793091\n",
      "\n",
      " This round's valence_loss=1.562330722808838, arousal_loss=1.4259834289550781, emotion_loss=1.0850971937179565\n",
      "\n",
      "01_20_00:10:04 Seen so far: 299552 samples\n",
      "\n",
      "01_20_00:10:04 --- 1.7759339809417725 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:06 Training loss at epoch 1 step 9370: 2.8159610748291017\n",
      "\n",
      " This round's valence_loss=1.1017844676971436, arousal_loss=0.962584376335144, emotion_loss=0.7266591787338257\n",
      "\n",
      "01_20_00:10:06 Seen so far: 299872 samples\n",
      "\n",
      "01_20_00:10:06 --- 1.726844310760498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:08 Training loss at epoch 1 step 9380: 2.771481513977051\n",
      "\n",
      " This round's valence_loss=1.0841368436813354, arousal_loss=0.9984143972396851, emotion_loss=1.2365107536315918\n",
      "\n",
      "01_20_00:10:08 Seen so far: 300192 samples\n",
      "\n",
      "01_20_00:10:08 --- 2.025336742401123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:09 Training loss at epoch 1 step 9390: 3.1145743131637573\n",
      "\n",
      " This round's valence_loss=0.5545274019241333, arousal_loss=0.338641881942749, emotion_loss=0.996679961681366\n",
      "\n",
      "01_20_00:10:09 Seen so far: 300512 samples\n",
      "\n",
      "01_20_00:10:09 --- 1.6420512199401855 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:11 Training loss at epoch 1 step 9400: 2.953941893577576\n",
      "\n",
      " This round's valence_loss=0.8039489984512329, arousal_loss=0.5868657827377319, emotion_loss=0.8868038058280945\n",
      "\n",
      "01_20_00:10:11 Seen so far: 300832 samples\n",
      "\n",
      "01_20_00:10:11 --- 1.7764475345611572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:13 Training loss at epoch 1 step 9410: 3.13724365234375\n",
      "\n",
      " This round's valence_loss=1.160032033920288, arousal_loss=1.1047931909561157, emotion_loss=1.1514670848846436\n",
      "\n",
      "01_20_00:10:13 Seen so far: 301152 samples\n",
      "\n",
      "01_20_00:10:13 --- 1.720179557800293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:15 Training loss at epoch 1 step 9420: 2.8497842669487\n",
      "\n",
      " This round's valence_loss=0.8999003767967224, arousal_loss=0.7100527286529541, emotion_loss=1.19955575466156\n",
      "\n",
      "01_20_00:10:15 Seen so far: 301472 samples\n",
      "\n",
      "01_20_00:10:15 --- 1.840698003768921 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:16 Training loss at epoch 1 step 9430: 2.595050024986267\n",
      "\n",
      " This round's valence_loss=0.8290518522262573, arousal_loss=0.7198536396026611, emotion_loss=1.1994166374206543\n",
      "\n",
      "01_20_00:10:16 Seen so far: 301792 samples\n",
      "\n",
      "01_20_00:10:16 --- 1.6310052871704102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:18 Training loss at epoch 1 step 9440: 3.460481810569763\n",
      "\n",
      " This round's valence_loss=1.5808441638946533, arousal_loss=1.437873363494873, emotion_loss=1.2795696258544922\n",
      "\n",
      "01_20_00:10:18 Seen so far: 302112 samples\n",
      "\n",
      "01_20_00:10:18 --- 1.705587387084961 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:20 Training loss at epoch 1 step 9450: 2.7030258059501646\n",
      "\n",
      " This round's valence_loss=1.0090105533599854, arousal_loss=0.8664803504943848, emotion_loss=0.9728606939315796\n",
      "\n",
      "01_20_00:10:20 Seen so far: 302432 samples\n",
      "\n",
      "01_20_00:10:20 --- 1.6748833656311035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:21 Training loss at epoch 1 step 9460: 3.174803447723389\n",
      "\n",
      " This round's valence_loss=0.9151368141174316, arousal_loss=0.6937360763549805, emotion_loss=1.0148993730545044\n",
      "\n",
      "01_20_00:10:21 Seen so far: 302752 samples\n",
      "\n",
      "01_20_00:10:21 --- 1.6896443367004395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:23 Training loss at epoch 1 step 9470: 2.9479872941970826\n",
      "\n",
      " This round's valence_loss=1.5836677551269531, arousal_loss=1.4361083507537842, emotion_loss=0.9159296751022339\n",
      "\n",
      "01_20_00:10:23 Seen so far: 303072 samples\n",
      "\n",
      "01_20_00:10:23 --- 1.7351150512695312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:25 Training loss at epoch 1 step 9480: 2.944875192642212\n",
      "\n",
      " This round's valence_loss=0.8264999389648438, arousal_loss=0.7387921810150146, emotion_loss=0.924028754234314\n",
      "\n",
      "01_20_00:10:25 Seen so far: 303392 samples\n",
      "\n",
      "01_20_00:10:25 --- 1.7094652652740479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:27 Training loss at epoch 1 step 9490: 3.110673952102661\n",
      "\n",
      " This round's valence_loss=0.8280808925628662, arousal_loss=0.6999992728233337, emotion_loss=0.8532790541648865\n",
      "\n",
      "01_20_00:10:27 Seen so far: 303712 samples\n",
      "\n",
      "01_20_00:10:27 --- 1.846001148223877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:28 Training loss at epoch 1 step 9500: 3.044171404838562\n",
      "\n",
      " This round's valence_loss=1.4622610807418823, arousal_loss=1.373048186302185, emotion_loss=1.0409632921218872\n",
      "\n",
      "01_20_00:10:28 Seen so far: 304032 samples\n",
      "\n",
      "01_20_00:10:28 --- 1.7800297737121582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:30 Training loss at epoch 1 step 9510: 3.1876537561416627\n",
      "\n",
      " This round's valence_loss=1.1501237154006958, arousal_loss=1.0892488956451416, emotion_loss=0.9019832611083984\n",
      "\n",
      "01_20_00:10:30 Seen so far: 304352 samples\n",
      "\n",
      "01_20_00:10:30 --- 1.660498857498169 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:32 Training loss at epoch 1 step 9520: 3.0468522548675536\n",
      "\n",
      " This round's valence_loss=1.2619764804840088, arousal_loss=1.0520977973937988, emotion_loss=0.6951689720153809\n",
      "\n",
      "01_20_00:10:32 Seen so far: 304672 samples\n",
      "\n",
      "01_20_00:10:32 --- 1.7237908840179443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:33 Training loss at epoch 1 step 9530: 3.2957051038742065\n",
      "\n",
      " This round's valence_loss=1.1173174381256104, arousal_loss=0.9483197927474976, emotion_loss=1.0911731719970703\n",
      "\n",
      "01_20_00:10:33 Seen so far: 304992 samples\n",
      "\n",
      "01_20_00:10:33 --- 1.5598101615905762 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:35 Training loss at epoch 1 step 9540: 3.1331206798553466\n",
      "\n",
      " This round's valence_loss=1.0776581764221191, arousal_loss=0.9517067074775696, emotion_loss=1.1989152431488037\n",
      "\n",
      "01_20_00:10:35 Seen so far: 305312 samples\n",
      "\n",
      "01_20_00:10:35 --- 1.8060302734375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:37 Training loss at epoch 1 step 9550: 2.8231457352638243\n",
      "\n",
      " This round's valence_loss=1.218719720840454, arousal_loss=1.100287675857544, emotion_loss=1.2293879985809326\n",
      "\n",
      "01_20_00:10:37 Seen so far: 305632 samples\n",
      "\n",
      "01_20_00:10:37 --- 1.727640151977539 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:39 Training loss at epoch 1 step 9560: 3.0506109952926637\n",
      "\n",
      " This round's valence_loss=0.44804441928863525, arousal_loss=0.3337128460407257, emotion_loss=1.2040821313858032\n",
      "\n",
      "01_20_00:10:39 Seen so far: 305952 samples\n",
      "\n",
      "01_20_00:10:39 --- 1.6958975791931152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:40 Training loss at epoch 1 step 9570: 3.447535490989685\n",
      "\n",
      " This round's valence_loss=1.1455705165863037, arousal_loss=0.9407922625541687, emotion_loss=1.3862154483795166\n",
      "\n",
      "01_20_00:10:40 Seen so far: 306272 samples\n",
      "\n",
      "01_20_00:10:40 --- 1.864980936050415 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:42 Training loss at epoch 1 step 9580: 2.899717116355896\n",
      "\n",
      " This round's valence_loss=0.7386380434036255, arousal_loss=0.5513829588890076, emotion_loss=1.0077316761016846\n",
      "\n",
      "01_20_00:10:42 Seen so far: 306592 samples\n",
      "\n",
      "01_20_00:10:42 --- 1.8366637229919434 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:44 Training loss at epoch 1 step 9590: 2.840844678878784\n",
      "\n",
      " This round's valence_loss=0.7708278894424438, arousal_loss=0.5705001354217529, emotion_loss=1.0326582193374634\n",
      "\n",
      "01_20_00:10:44 Seen so far: 306912 samples\n",
      "\n",
      "01_20_00:10:44 --- 2.097503185272217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:46 Training loss at epoch 1 step 9600: 2.970615863800049\n",
      "\n",
      " This round's valence_loss=1.5509088039398193, arousal_loss=1.4512174129486084, emotion_loss=1.0305559635162354\n",
      "\n",
      "01_20_00:10:46 Seen so far: 307232 samples\n",
      "\n",
      "01_20_00:10:46 --- 1.6620428562164307 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:48 Training loss at epoch 1 step 9610: 3.062745749950409\n",
      "\n",
      " This round's valence_loss=1.2304208278656006, arousal_loss=1.1014232635498047, emotion_loss=0.8991090059280396\n",
      "\n",
      "01_20_00:10:48 Seen so far: 307552 samples\n",
      "\n",
      "01_20_00:10:48 --- 1.8636627197265625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:50 Training loss at epoch 1 step 9620: 3.180148482322693\n",
      "\n",
      " This round's valence_loss=1.2122246026992798, arousal_loss=1.1616020202636719, emotion_loss=1.0439064502716064\n",
      "\n",
      "01_20_00:10:50 Seen so far: 307872 samples\n",
      "\n",
      "01_20_00:10:50 --- 1.8378701210021973 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:52 Training loss at epoch 1 step 9630: 3.032906937599182\n",
      "\n",
      " This round's valence_loss=1.6157382726669312, arousal_loss=1.436964511871338, emotion_loss=0.6777156591415405\n",
      "\n",
      "01_20_00:10:52 Seen so far: 308192 samples\n",
      "\n",
      "01_20_00:10:52 --- 2.0618951320648193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:54 Training loss at epoch 1 step 9640: 2.6777151226997375\n",
      "\n",
      " This round's valence_loss=0.7251689434051514, arousal_loss=0.6042811870574951, emotion_loss=1.1094915866851807\n",
      "\n",
      "01_20_00:10:54 Seen so far: 308512 samples\n",
      "\n",
      "01_20_00:10:54 --- 1.708787202835083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:55 Training loss at epoch 1 step 9650: 3.3395236492156983\n",
      "\n",
      " This round's valence_loss=1.1944644451141357, arousal_loss=1.0744290351867676, emotion_loss=1.295501947402954\n",
      "\n",
      "01_20_00:10:55 Seen so far: 308832 samples\n",
      "\n",
      "01_20_00:10:55 --- 1.8178954124450684 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:57 Training loss at epoch 1 step 9660: 2.9114407777786253\n",
      "\n",
      " This round's valence_loss=0.9602516889572144, arousal_loss=0.7174274921417236, emotion_loss=0.7193116545677185\n",
      "\n",
      "01_20_00:10:57 Seen so far: 309152 samples\n",
      "\n",
      "01_20_00:10:57 --- 1.717052698135376 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:10:59 Training loss at epoch 1 step 9670: 2.518138813972473\n",
      "\n",
      " This round's valence_loss=0.7380746603012085, arousal_loss=0.6307094693183899, emotion_loss=1.0260860919952393\n",
      "\n",
      "01_20_00:10:59 Seen so far: 309472 samples\n",
      "\n",
      "01_20_00:10:59 --- 1.7508471012115479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:01 Training loss at epoch 1 step 9680: 2.9343419790267946\n",
      "\n",
      " This round's valence_loss=0.951697051525116, arousal_loss=0.8046078681945801, emotion_loss=1.2060883045196533\n",
      "\n",
      "01_20_00:11:01 Seen so far: 309792 samples\n",
      "\n",
      "01_20_00:11:01 --- 1.7638521194458008 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:02 Training loss at epoch 1 step 9690: 3.4383059978485107\n",
      "\n",
      " This round's valence_loss=0.7310367822647095, arousal_loss=0.5503569841384888, emotion_loss=1.0228177309036255\n",
      "\n",
      "01_20_00:11:02 Seen so far: 310112 samples\n",
      "\n",
      "01_20_00:11:02 --- 1.8337514400482178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:04 Training loss at epoch 1 step 9700: 3.10838987827301\n",
      "\n",
      " This round's valence_loss=0.8087913393974304, arousal_loss=0.6022382974624634, emotion_loss=0.9127495288848877\n",
      "\n",
      "01_20_00:11:04 Seen so far: 310432 samples\n",
      "\n",
      "01_20_00:11:04 --- 1.6024975776672363 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:06 Training loss at epoch 1 step 9710: 2.6375244855880737\n",
      "\n",
      " This round's valence_loss=1.1578927040100098, arousal_loss=0.9049252271652222, emotion_loss=0.7212986946105957\n",
      "\n",
      "01_20_00:11:06 Seen so far: 310752 samples\n",
      "\n",
      "01_20_00:11:06 --- 1.793567419052124 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:08 Training loss at epoch 1 step 9720: 3.073789429664612\n",
      "\n",
      " This round's valence_loss=0.9809859395027161, arousal_loss=0.8748023509979248, emotion_loss=1.444356083869934\n",
      "\n",
      "01_20_00:11:08 Seen so far: 311072 samples\n",
      "\n",
      "01_20_00:11:08 --- 1.701920986175537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:09 Training loss at epoch 1 step 9730: 2.8787272453308104\n",
      "\n",
      " This round's valence_loss=0.9251857995986938, arousal_loss=0.7899794578552246, emotion_loss=0.845307469367981\n",
      "\n",
      "01_20_00:11:09 Seen so far: 311392 samples\n",
      "\n",
      "01_20_00:11:09 --- 1.7354087829589844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:11 Training loss at epoch 1 step 9740: 3.087602424621582\n",
      "\n",
      " This round's valence_loss=0.8113584518432617, arousal_loss=0.7177850008010864, emotion_loss=1.1853320598602295\n",
      "\n",
      "01_20_00:11:11 Seen so far: 311712 samples\n",
      "\n",
      "01_20_00:11:11 --- 1.7328062057495117 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:13 Training loss at epoch 1 step 9750: 3.1679923057556154\n",
      "\n",
      " This round's valence_loss=1.1937737464904785, arousal_loss=0.9545893669128418, emotion_loss=0.5575929880142212\n",
      "\n",
      "01_20_00:11:13 Seen so far: 312032 samples\n",
      "\n",
      "01_20_00:11:13 --- 1.8627588748931885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:15 Training loss at epoch 1 step 9760: 3.1202279329299927\n",
      "\n",
      " This round's valence_loss=1.3568165302276611, arousal_loss=1.2549030780792236, emotion_loss=1.0952544212341309\n",
      "\n",
      "01_20_00:11:15 Seen so far: 312352 samples\n",
      "\n",
      "01_20_00:11:15 --- 1.8141200542449951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:16 Training loss at epoch 1 step 9770: 2.738276243209839\n",
      "\n",
      " This round's valence_loss=0.6444586515426636, arousal_loss=0.4545478820800781, emotion_loss=0.9349993467330933\n",
      "\n",
      "01_20_00:11:16 Seen so far: 312672 samples\n",
      "\n",
      "01_20_00:11:16 --- 1.781111478805542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:18 Training loss at epoch 1 step 9780: 2.844248342514038\n",
      "\n",
      " This round's valence_loss=0.4971882104873657, arousal_loss=0.3645707070827484, emotion_loss=0.8358648419380188\n",
      "\n",
      "01_20_00:11:18 Seen so far: 312992 samples\n",
      "\n",
      "01_20_00:11:18 --- 1.8164687156677246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:20 Training loss at epoch 1 step 9790: 2.931027626991272\n",
      "\n",
      " This round's valence_loss=1.0085757970809937, arousal_loss=0.8352935314178467, emotion_loss=1.0601177215576172\n",
      "\n",
      "01_20_00:11:20 Seen so far: 313312 samples\n",
      "\n",
      "01_20_00:11:20 --- 1.8928685188293457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:22 Training loss at epoch 1 step 9800: 3.249176263809204\n",
      "\n",
      " This round's valence_loss=1.1215863227844238, arousal_loss=0.9664026498794556, emotion_loss=0.998775064945221\n",
      "\n",
      "01_20_00:11:22 Seen so far: 313632 samples\n",
      "\n",
      "01_20_00:11:22 --- 1.7862019538879395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:24 Training loss at epoch 1 step 9810: 2.972275412082672\n",
      "\n",
      " This round's valence_loss=1.7012766599655151, arousal_loss=1.571202278137207, emotion_loss=1.0570133924484253\n",
      "\n",
      "01_20_00:11:24 Seen so far: 313952 samples\n",
      "\n",
      "01_20_00:11:24 --- 1.8095598220825195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:26 Training loss at epoch 1 step 9820: 2.934471344947815\n",
      "\n",
      " This round's valence_loss=0.8985142707824707, arousal_loss=0.7965821027755737, emotion_loss=0.907177209854126\n",
      "\n",
      "01_20_00:11:26 Seen so far: 314272 samples\n",
      "\n",
      "01_20_00:11:26 --- 1.7968213558197021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:27 Training loss at epoch 1 step 9830: 2.8161882400512694\n",
      "\n",
      " This round's valence_loss=1.201422929763794, arousal_loss=1.1091341972351074, emotion_loss=0.9064153432846069\n",
      "\n",
      "01_20_00:11:27 Seen so far: 314592 samples\n",
      "\n",
      "01_20_00:11:27 --- 1.8172712326049805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:29 Training loss at epoch 1 step 9840: 3.0813092947006226\n",
      "\n",
      " This round's valence_loss=1.8593107461929321, arousal_loss=1.817947268486023, emotion_loss=1.270261526107788\n",
      "\n",
      "01_20_00:11:29 Seen so far: 314912 samples\n",
      "\n",
      "01_20_00:11:29 --- 1.675398826599121 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:31 Training loss at epoch 1 step 9850: 3.029686951637268\n",
      "\n",
      " This round's valence_loss=0.7091008424758911, arousal_loss=0.598605751991272, emotion_loss=0.9591797590255737\n",
      "\n",
      "01_20_00:11:31 Seen so far: 315232 samples\n",
      "\n",
      "01_20_00:11:31 --- 1.737067699432373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:33 Training loss at epoch 1 step 9860: 3.0544787645339966\n",
      "\n",
      " This round's valence_loss=0.8774311542510986, arousal_loss=0.7225797772407532, emotion_loss=1.1070743799209595\n",
      "\n",
      "01_20_00:11:33 Seen so far: 315552 samples\n",
      "\n",
      "01_20_00:11:33 --- 1.8485238552093506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:34 Training loss at epoch 1 step 9870: 3.0040404081344603\n",
      "\n",
      " This round's valence_loss=0.9544201493263245, arousal_loss=0.6773872375488281, emotion_loss=0.7881102561950684\n",
      "\n",
      "01_20_00:11:34 Seen so far: 315872 samples\n",
      "\n",
      "01_20_00:11:34 --- 1.801788091659546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:36 Training loss at epoch 1 step 9880: 2.9818966388702393\n",
      "\n",
      " This round's valence_loss=0.6626308560371399, arousal_loss=0.6393932104110718, emotion_loss=1.2573106288909912\n",
      "\n",
      "01_20_00:11:36 Seen so far: 316192 samples\n",
      "\n",
      "01_20_00:11:36 --- 1.5287230014801025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:38 Training loss at epoch 1 step 9890: 3.256190061569214\n",
      "\n",
      " This round's valence_loss=0.9338278770446777, arousal_loss=0.8624157905578613, emotion_loss=0.8624919056892395\n",
      "\n",
      "01_20_00:11:38 Seen so far: 316512 samples\n",
      "\n",
      "01_20_00:11:38 --- 1.77268648147583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:40 Training loss at epoch 1 step 9900: 2.8110501050949095\n",
      "\n",
      " This round's valence_loss=0.8602901697158813, arousal_loss=0.7775551676750183, emotion_loss=0.938658595085144\n",
      "\n",
      "01_20_00:11:40 Seen so far: 316832 samples\n",
      "\n",
      "01_20_00:11:40 --- 1.9190292358398438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:41 Training loss at epoch 1 step 9910: 3.191752529144287\n",
      "\n",
      " This round's valence_loss=1.5803325176239014, arousal_loss=1.4765970706939697, emotion_loss=0.9623302817344666\n",
      "\n",
      "01_20_00:11:41 Seen so far: 317152 samples\n",
      "\n",
      "01_20_00:11:41 --- 1.7575275897979736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:43 Training loss at epoch 1 step 9920: 3.179836320877075\n",
      "\n",
      " This round's valence_loss=1.6160321235656738, arousal_loss=1.441007375717163, emotion_loss=0.8746013641357422\n",
      "\n",
      "01_20_00:11:43 Seen so far: 317472 samples\n",
      "\n",
      "01_20_00:11:43 --- 1.6503491401672363 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:45 Training loss at epoch 1 step 9930: 3.1704214811325073\n",
      "\n",
      " This round's valence_loss=1.2558705806732178, arousal_loss=1.0870033502578735, emotion_loss=0.7519063353538513\n",
      "\n",
      "01_20_00:11:45 Seen so far: 317792 samples\n",
      "\n",
      "01_20_00:11:45 --- 1.727247953414917 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:47 Training loss at epoch 1 step 9940: 3.179113531112671\n",
      "\n",
      " This round's valence_loss=1.2864952087402344, arousal_loss=1.2125508785247803, emotion_loss=0.7878648042678833\n",
      "\n",
      "01_20_00:11:47 Seen so far: 318112 samples\n",
      "\n",
      "01_20_00:11:47 --- 1.7706503868103027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:48 Training loss at epoch 1 step 9950: 2.9952730894088746\n",
      "\n",
      " This round's valence_loss=1.337838888168335, arousal_loss=1.199912190437317, emotion_loss=0.935215950012207\n",
      "\n",
      "01_20_00:11:48 Seen so far: 318432 samples\n",
      "\n",
      "01_20_00:11:48 --- 1.8115761280059814 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:50 Training loss at epoch 1 step 9960: 3.3675313591957092\n",
      "\n",
      " This round's valence_loss=1.323789119720459, arousal_loss=1.1678671836853027, emotion_loss=1.1647720336914062\n",
      "\n",
      "01_20_00:11:50 Seen so far: 318752 samples\n",
      "\n",
      "01_20_00:11:50 --- 2.002479076385498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:52 Training loss at epoch 1 step 9970: 2.789450764656067\n",
      "\n",
      " This round's valence_loss=0.9962896108627319, arousal_loss=0.8374276161193848, emotion_loss=0.9174939393997192\n",
      "\n",
      "01_20_00:11:52 Seen so far: 319072 samples\n",
      "\n",
      "01_20_00:11:52 --- 1.6855590343475342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:54 Training loss at epoch 1 step 9980: 3.05459246635437\n",
      "\n",
      " This round's valence_loss=1.2359967231750488, arousal_loss=1.090221643447876, emotion_loss=1.231266975402832\n",
      "\n",
      "01_20_00:11:54 Seen so far: 319392 samples\n",
      "\n",
      "01_20_00:11:54 --- 1.831308364868164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:56 Training loss at epoch 1 step 9990: 2.9453046917915344\n",
      "\n",
      " This round's valence_loss=1.1680312156677246, arousal_loss=1.112746238708496, emotion_loss=1.0202072858810425\n",
      "\n",
      "01_20_00:11:56 Seen so far: 319712 samples\n",
      "\n",
      "01_20_00:11:56 --- 1.7371997833251953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:57 Training loss at epoch 1 step 10000: 3.0542570829391478\n",
      "\n",
      " This round's valence_loss=1.1021263599395752, arousal_loss=0.9891842007637024, emotion_loss=1.173461675643921\n",
      "\n",
      "01_20_00:11:57 Seen so far: 320032 samples\n",
      "\n",
      "01_20_00:11:57 --- 1.846296787261963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:11:59 Training loss at epoch 1 step 10010: 3.0668944835662844\n",
      "\n",
      " This round's valence_loss=1.812272310256958, arousal_loss=1.662636399269104, emotion_loss=1.1451714038848877\n",
      "\n",
      "01_20_00:11:59 Seen so far: 320352 samples\n",
      "\n",
      "01_20_00:11:59 --- 1.7907390594482422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:01 Training loss at epoch 1 step 10020: 3.2508151531219482\n",
      "\n",
      " This round's valence_loss=0.8513047695159912, arousal_loss=0.7560440301895142, emotion_loss=1.1221537590026855\n",
      "\n",
      "01_20_00:12:01 Seen so far: 320672 samples\n",
      "\n",
      "01_20_00:12:01 --- 1.7850353717803955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:03 Training loss at epoch 1 step 10030: 3.0653422832489015\n",
      "\n",
      " This round's valence_loss=1.4522342681884766, arousal_loss=1.3324286937713623, emotion_loss=1.0636746883392334\n",
      "\n",
      "01_20_00:12:03 Seen so far: 320992 samples\n",
      "\n",
      "01_20_00:12:03 --- 1.9681415557861328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:05 Training loss at epoch 1 step 10040: 2.918541169166565\n",
      "\n",
      " This round's valence_loss=0.7028321623802185, arousal_loss=0.6017329692840576, emotion_loss=0.9467226266860962\n",
      "\n",
      "01_20_00:12:05 Seen so far: 321312 samples\n",
      "\n",
      "01_20_00:12:05 --- 1.7878673076629639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:07 Training loss at epoch 1 step 10050: 3.0675969243049623\n",
      "\n",
      " This round's valence_loss=0.530988335609436, arousal_loss=0.35159289836883545, emotion_loss=1.5017627477645874\n",
      "\n",
      "01_20_00:12:07 Seen so far: 321632 samples\n",
      "\n",
      "01_20_00:12:07 --- 1.7024290561676025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:08 Training loss at epoch 1 step 10060: 3.2565117359161375\n",
      "\n",
      " This round's valence_loss=1.1310644149780273, arousal_loss=0.9681140184402466, emotion_loss=1.1061499118804932\n",
      "\n",
      "01_20_00:12:08 Seen so far: 321952 samples\n",
      "\n",
      "01_20_00:12:08 --- 1.7242555618286133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:10 Training loss at epoch 1 step 10070: 3.061304140090942\n",
      "\n",
      " This round's valence_loss=1.1048082113265991, arousal_loss=0.959320604801178, emotion_loss=0.8763775825500488\n",
      "\n",
      "01_20_00:12:10 Seen so far: 322272 samples\n",
      "\n",
      "01_20_00:12:10 --- 1.846083402633667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:12 Training loss at epoch 1 step 10080: 3.118313026428223\n",
      "\n",
      " This round's valence_loss=1.3077163696289062, arousal_loss=1.1717767715454102, emotion_loss=0.6097714304924011\n",
      "\n",
      "01_20_00:12:12 Seen so far: 322592 samples\n",
      "\n",
      "01_20_00:12:12 --- 1.798144817352295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:14 Training loss at epoch 1 step 10090: 2.978263735771179\n",
      "\n",
      " This round's valence_loss=1.3245257139205933, arousal_loss=1.0825040340423584, emotion_loss=1.14958918094635\n",
      "\n",
      "01_20_00:12:14 Seen so far: 322912 samples\n",
      "\n",
      "01_20_00:12:14 --- 1.7167649269104004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:15 Training loss at epoch 1 step 10100: 2.9475662231445314\n",
      "\n",
      " This round's valence_loss=1.0193376541137695, arousal_loss=0.8662370443344116, emotion_loss=1.0173091888427734\n",
      "\n",
      "01_20_00:12:15 Seen so far: 323232 samples\n",
      "\n",
      "01_20_00:12:15 --- 1.78770112991333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:17 Training loss at epoch 1 step 10110: 2.784480881690979\n",
      "\n",
      " This round's valence_loss=0.7242754101753235, arousal_loss=0.6265510320663452, emotion_loss=0.9495365619659424\n",
      "\n",
      "01_20_00:12:17 Seen so far: 323552 samples\n",
      "\n",
      "01_20_00:12:17 --- 1.9454305171966553 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:19 Training loss at epoch 1 step 10120: 3.266080927848816\n",
      "\n",
      " This round's valence_loss=1.2017138004302979, arousal_loss=0.9196413159370422, emotion_loss=0.9974251389503479\n",
      "\n",
      "01_20_00:12:19 Seen so far: 323872 samples\n",
      "\n",
      "01_20_00:12:19 --- 1.8465027809143066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:21 Training loss at epoch 1 step 10130: 2.911397409439087\n",
      "\n",
      " This round's valence_loss=0.951064944267273, arousal_loss=0.8498642444610596, emotion_loss=0.9527517557144165\n",
      "\n",
      "01_20_00:12:21 Seen so far: 324192 samples\n",
      "\n",
      "01_20_00:12:21 --- 1.7558908462524414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:23 Training loss at epoch 1 step 10140: 3.0556674718856813\n",
      "\n",
      " This round's valence_loss=1.8193740844726562, arousal_loss=1.660042643547058, emotion_loss=0.7674329280853271\n",
      "\n",
      "01_20_00:12:23 Seen so far: 324512 samples\n",
      "\n",
      "01_20_00:12:23 --- 1.8860228061676025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:25 Training loss at epoch 1 step 10150: 3.164183521270752\n",
      "\n",
      " This round's valence_loss=1.0054559707641602, arousal_loss=0.8416234254837036, emotion_loss=0.9578864574432373\n",
      "\n",
      "01_20_00:12:25 Seen so far: 324832 samples\n",
      "\n",
      "01_20_00:12:25 --- 1.8852617740631104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:27 Training loss at epoch 1 step 10160: 2.915446376800537\n",
      "\n",
      " This round's valence_loss=0.9404890537261963, arousal_loss=0.8621615171432495, emotion_loss=1.4015876054763794\n",
      "\n",
      "01_20_00:12:27 Seen so far: 325152 samples\n",
      "\n",
      "01_20_00:12:27 --- 1.8310556411743164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:28 Training loss at epoch 1 step 10170: 3.1983785152435305\n",
      "\n",
      " This round's valence_loss=1.3265738487243652, arousal_loss=1.1861063241958618, emotion_loss=0.8438297510147095\n",
      "\n",
      "01_20_00:12:28 Seen so far: 325472 samples\n",
      "\n",
      "01_20_00:12:28 --- 1.8423678874969482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:30 Training loss at epoch 1 step 10180: 2.8093111515045166\n",
      "\n",
      " This round's valence_loss=1.0341081619262695, arousal_loss=0.9513165950775146, emotion_loss=1.399795651435852\n",
      "\n",
      "01_20_00:12:30 Seen so far: 325792 samples\n",
      "\n",
      "01_20_00:12:30 --- 1.8066637516021729 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:32 Training loss at epoch 1 step 10190: 2.9481009244918823\n",
      "\n",
      " This round's valence_loss=1.0759849548339844, arousal_loss=0.9469993114471436, emotion_loss=1.1813933849334717\n",
      "\n",
      "01_20_00:12:32 Seen so far: 326112 samples\n",
      "\n",
      "01_20_00:12:32 --- 1.690596342086792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:34 Training loss at epoch 1 step 10200: 3.2864271640777587\n",
      "\n",
      " This round's valence_loss=1.1470787525177002, arousal_loss=0.9499474167823792, emotion_loss=1.0021487474441528\n",
      "\n",
      "01_20_00:12:34 Seen so far: 326432 samples\n",
      "\n",
      "01_20_00:12:34 --- 1.9965064525604248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:36 Training loss at epoch 1 step 10210: 3.2244046092033387\n",
      "\n",
      " This round's valence_loss=0.9608950614929199, arousal_loss=0.8705207705497742, emotion_loss=1.0794912576675415\n",
      "\n",
      "01_20_00:12:36 Seen so far: 326752 samples\n",
      "\n",
      "01_20_00:12:36 --- 2.0054523944854736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:38 Training loss at epoch 1 step 10220: 2.85684974193573\n",
      "\n",
      " This round's valence_loss=0.8316690921783447, arousal_loss=0.6985241174697876, emotion_loss=1.0577069520950317\n",
      "\n",
      "01_20_00:12:38 Seen so far: 327072 samples\n",
      "\n",
      "01_20_00:12:38 --- 1.8632004261016846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:39 Training loss at epoch 1 step 10230: 2.8786092042922973\n",
      "\n",
      " This round's valence_loss=1.0005638599395752, arousal_loss=0.8573207259178162, emotion_loss=1.3672198057174683\n",
      "\n",
      "01_20_00:12:39 Seen so far: 327392 samples\n",
      "\n",
      "01_20_00:12:39 --- 1.6357903480529785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:41 Training loss at epoch 1 step 10240: 3.3053009510040283\n",
      "\n",
      " This round's valence_loss=1.3542479276657104, arousal_loss=1.180340051651001, emotion_loss=0.8190068006515503\n",
      "\n",
      "01_20_00:12:41 Seen so far: 327712 samples\n",
      "\n",
      "01_20_00:12:41 --- 1.676095724105835 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:43 Training loss at epoch 1 step 10250: 2.8325721859931945\n",
      "\n",
      " This round's valence_loss=1.0862836837768555, arousal_loss=1.0014419555664062, emotion_loss=1.1113765239715576\n",
      "\n",
      "01_20_00:12:43 Seen so far: 328032 samples\n",
      "\n",
      "01_20_00:12:43 --- 1.7917814254760742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:45 Training loss at epoch 1 step 10260: 3.380996751785278\n",
      "\n",
      " This round's valence_loss=1.1558200120925903, arousal_loss=1.0948283672332764, emotion_loss=0.8467304706573486\n",
      "\n",
      "01_20_00:12:45 Seen so far: 328352 samples\n",
      "\n",
      "01_20_00:12:45 --- 1.7350938320159912 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:46 Training loss at epoch 1 step 10270: 2.9449912309646606\n",
      "\n",
      " This round's valence_loss=0.9750373959541321, arousal_loss=0.6823438405990601, emotion_loss=0.6347790956497192\n",
      "\n",
      "01_20_00:12:46 Seen so far: 328672 samples\n",
      "\n",
      "01_20_00:12:46 --- 1.636000633239746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:48 Training loss at epoch 1 step 10280: 2.877303862571716\n",
      "\n",
      " This round's valence_loss=1.0595608949661255, arousal_loss=0.9444363713264465, emotion_loss=1.092688798904419\n",
      "\n",
      "01_20_00:12:48 Seen so far: 328992 samples\n",
      "\n",
      "01_20_00:12:48 --- 1.6520473957061768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:50 Training loss at epoch 1 step 10290: 2.856053328514099\n",
      "\n",
      " This round's valence_loss=0.8418257832527161, arousal_loss=0.724310040473938, emotion_loss=0.7510796785354614\n",
      "\n",
      "01_20_00:12:50 Seen so far: 329312 samples\n",
      "\n",
      "01_20_00:12:50 --- 1.8138935565948486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:51 Training loss at epoch 1 step 10300: 3.0385090351104735\n",
      "\n",
      " This round's valence_loss=1.4504722356796265, arousal_loss=1.350406527519226, emotion_loss=1.224744439125061\n",
      "\n",
      "01_20_00:12:51 Seen so far: 329632 samples\n",
      "\n",
      "01_20_00:12:51 --- 1.697221040725708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:53 Training loss at epoch 1 step 10310: 3.1071707963943482\n",
      "\n",
      " This round's valence_loss=1.1009160280227661, arousal_loss=0.9540895223617554, emotion_loss=1.115026593208313\n",
      "\n",
      "01_20_00:12:53 Seen so far: 329952 samples\n",
      "\n",
      "01_20_00:12:53 --- 1.6324481964111328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:55 Training loss at epoch 1 step 10320: 2.9879806518554686\n",
      "\n",
      " This round's valence_loss=0.6716649532318115, arousal_loss=0.4583849310874939, emotion_loss=0.9943565726280212\n",
      "\n",
      "01_20_00:12:55 Seen so far: 330272 samples\n",
      "\n",
      "01_20_00:12:55 --- 1.7248106002807617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:57 Training loss at epoch 1 step 10330: 2.8267260789871216\n",
      "\n",
      " This round's valence_loss=0.8452883958816528, arousal_loss=0.7217996120452881, emotion_loss=0.955955445766449\n",
      "\n",
      "01_20_00:12:57 Seen so far: 330592 samples\n",
      "\n",
      "01_20_00:12:57 --- 1.8755393028259277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:12:58 Training loss at epoch 1 step 10340: 3.023155760765076\n",
      "\n",
      " This round's valence_loss=1.1005408763885498, arousal_loss=0.9216271638870239, emotion_loss=0.9600808620452881\n",
      "\n",
      "01_20_00:12:58 Seen so far: 330912 samples\n",
      "\n",
      "01_20_00:12:58 --- 1.704744577407837 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:00 Training loss at epoch 1 step 10350: 3.1534549474716185\n",
      "\n",
      " This round's valence_loss=1.2990590333938599, arousal_loss=1.1830137968063354, emotion_loss=1.2248127460479736\n",
      "\n",
      "01_20_00:13:00 Seen so far: 331232 samples\n",
      "\n",
      "01_20_00:13:00 --- 1.8372375965118408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:02 Training loss at epoch 1 step 10360: 2.8215121030807495\n",
      "\n",
      " This round's valence_loss=0.6658414006233215, arousal_loss=0.522568941116333, emotion_loss=1.0898606777191162\n",
      "\n",
      "01_20_00:13:02 Seen so far: 331552 samples\n",
      "\n",
      "01_20_00:13:02 --- 1.6343934535980225 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:04 Training loss at epoch 1 step 10370: 2.3387510418891906\n",
      "\n",
      " This round's valence_loss=0.5196207761764526, arousal_loss=0.3720209002494812, emotion_loss=1.2664580345153809\n",
      "\n",
      "01_20_00:13:04 Seen so far: 331872 samples\n",
      "\n",
      "01_20_00:13:04 --- 1.7848262786865234 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:05 Training loss at epoch 1 step 10380: 2.8646620988845823\n",
      "\n",
      " This round's valence_loss=1.2006934881210327, arousal_loss=1.090952754020691, emotion_loss=0.6488048434257507\n",
      "\n",
      "01_20_00:13:05 Seen so far: 332192 samples\n",
      "\n",
      "01_20_00:13:05 --- 1.6496224403381348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:07 Training loss at epoch 1 step 10390: 2.9960095405578615\n",
      "\n",
      " This round's valence_loss=1.0246806144714355, arousal_loss=0.8128019571304321, emotion_loss=1.2442843914031982\n",
      "\n",
      "01_20_00:13:07 Seen so far: 332512 samples\n",
      "\n",
      "01_20_00:13:07 --- 1.9952309131622314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:09 Training loss at epoch 1 step 10400: 2.9358932733535767\n",
      "\n",
      " This round's valence_loss=1.6302330493927002, arousal_loss=1.5833189487457275, emotion_loss=1.0715141296386719\n",
      "\n",
      "01_20_00:13:09 Seen so far: 332832 samples\n",
      "\n",
      "01_20_00:13:09 --- 1.714906930923462 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:11 Training loss at epoch 1 step 10410: 2.851725673675537\n",
      "\n",
      " This round's valence_loss=1.5401887893676758, arousal_loss=1.4159328937530518, emotion_loss=0.6889079809188843\n",
      "\n",
      "01_20_00:13:11 Seen so far: 333152 samples\n",
      "\n",
      "01_20_00:13:11 --- 1.7554049491882324 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:12 Training loss at epoch 1 step 10420: 3.048484778404236\n",
      "\n",
      " This round's valence_loss=0.8700719475746155, arousal_loss=0.7638977766036987, emotion_loss=1.1176505088806152\n",
      "\n",
      "01_20_00:13:12 Seen so far: 333472 samples\n",
      "\n",
      "01_20_00:13:12 --- 1.6362228393554688 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:14 Training loss at epoch 1 step 10430: 3.2369800567626954\n",
      "\n",
      " This round's valence_loss=1.4240961074829102, arousal_loss=1.3467820882797241, emotion_loss=1.1361627578735352\n",
      "\n",
      "01_20_00:13:14 Seen so far: 333792 samples\n",
      "\n",
      "01_20_00:13:14 --- 2.0284597873687744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:16 Training loss at epoch 1 step 10440: 3.121537375450134\n",
      "\n",
      " This round's valence_loss=1.6774351596832275, arousal_loss=1.4686188697814941, emotion_loss=1.2173606157302856\n",
      "\n",
      "01_20_00:13:16 Seen so far: 334112 samples\n",
      "\n",
      "01_20_00:13:16 --- 1.7014679908752441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:18 Training loss at epoch 1 step 10450: 3.145933175086975\n",
      "\n",
      " This round's valence_loss=0.9015816450119019, arousal_loss=0.7094101309776306, emotion_loss=0.998297929763794\n",
      "\n",
      "01_20_00:13:18 Seen so far: 334432 samples\n",
      "\n",
      "01_20_00:13:18 --- 1.6800646781921387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:20 Training loss at epoch 1 step 10460: 3.177463936805725\n",
      "\n",
      " This round's valence_loss=0.7852360606193542, arousal_loss=0.5718114972114563, emotion_loss=0.8990612030029297\n",
      "\n",
      "01_20_00:13:20 Seen so far: 334752 samples\n",
      "\n",
      "01_20_00:13:20 --- 1.949535608291626 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:21 Training loss at epoch 1 step 10470: 3.0422412276268007\n",
      "\n",
      " This round's valence_loss=1.4492712020874023, arousal_loss=1.341876745223999, emotion_loss=1.0396461486816406\n",
      "\n",
      "01_20_00:13:21 Seen so far: 335072 samples\n",
      "\n",
      "01_20_00:13:21 --- 1.7626028060913086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:23 Training loss at epoch 1 step 10480: 3.2318209171295167\n",
      "\n",
      " This round's valence_loss=1.3611903190612793, arousal_loss=1.185713291168213, emotion_loss=1.0355455875396729\n",
      "\n",
      "01_20_00:13:23 Seen so far: 335392 samples\n",
      "\n",
      "01_20_00:13:23 --- 1.7649235725402832 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:25 Training loss at epoch 1 step 10490: 3.03920578956604\n",
      "\n",
      " This round's valence_loss=0.7046473622322083, arousal_loss=0.600560188293457, emotion_loss=1.161536693572998\n",
      "\n",
      "01_20_00:13:25 Seen so far: 335712 samples\n",
      "\n",
      "01_20_00:13:25 --- 1.8988995552062988 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:27 Training loss at epoch 1 step 10500: 2.8774627923965452\n",
      "\n",
      " This round's valence_loss=0.7540479302406311, arousal_loss=0.6455159187316895, emotion_loss=1.5756385326385498\n",
      "\n",
      "01_20_00:13:27 Seen so far: 336032 samples\n",
      "\n",
      "01_20_00:13:27 --- 1.760138750076294 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:29 Training loss at epoch 1 step 10510: 3.5092976808547975\n",
      "\n",
      " This round's valence_loss=0.8172996044158936, arousal_loss=0.6822368502616882, emotion_loss=1.0297267436981201\n",
      "\n",
      "01_20_00:13:29 Seen so far: 336352 samples\n",
      "\n",
      "01_20_00:13:29 --- 1.8458750247955322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:30 Training loss at epoch 1 step 10520: 2.945305061340332\n",
      "\n",
      " This round's valence_loss=1.2328884601593018, arousal_loss=1.0752081871032715, emotion_loss=1.045243501663208\n",
      "\n",
      "01_20_00:13:30 Seen so far: 336672 samples\n",
      "\n",
      "01_20_00:13:30 --- 1.6422779560089111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:32 Training loss at epoch 1 step 10530: 3.3993398904800416\n",
      "\n",
      " This round's valence_loss=1.0760366916656494, arousal_loss=1.0082347393035889, emotion_loss=0.9431378841400146\n",
      "\n",
      "01_20_00:13:32 Seen so far: 336992 samples\n",
      "\n",
      "01_20_00:13:32 --- 1.9191019535064697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:34 Training loss at epoch 1 step 10540: 2.8485952377319337\n",
      "\n",
      " This round's valence_loss=1.1144530773162842, arousal_loss=0.9518873691558838, emotion_loss=1.2048778533935547\n",
      "\n",
      "01_20_00:13:34 Seen so far: 337312 samples\n",
      "\n",
      "01_20_00:13:34 --- 1.6262249946594238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:36 Training loss at epoch 1 step 10550: 3.1613502502441406\n",
      "\n",
      " This round's valence_loss=0.8730380535125732, arousal_loss=0.7314073443412781, emotion_loss=0.709334135055542\n",
      "\n",
      "01_20_00:13:36 Seen so far: 337632 samples\n",
      "\n",
      "01_20_00:13:36 --- 1.8270082473754883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:37 Training loss at epoch 1 step 10560: 3.535227918624878\n",
      "\n",
      " This round's valence_loss=0.9680230617523193, arousal_loss=0.8502609133720398, emotion_loss=1.232428789138794\n",
      "\n",
      "01_20_00:13:37 Seen so far: 337952 samples\n",
      "\n",
      "01_20_00:13:37 --- 1.6674673557281494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:39 Training loss at epoch 1 step 10570: 2.943852174282074\n",
      "\n",
      " This round's valence_loss=0.8504490852355957, arousal_loss=0.6232789754867554, emotion_loss=1.5104559659957886\n",
      "\n",
      "01_20_00:13:39 Seen so far: 338272 samples\n",
      "\n",
      "01_20_00:13:39 --- 1.6429510116577148 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:41 Training loss at epoch 1 step 10580: 3.229986619949341\n",
      "\n",
      " This round's valence_loss=1.1185901165008545, arousal_loss=0.9898862838745117, emotion_loss=0.7081015110015869\n",
      "\n",
      "01_20_00:13:41 Seen so far: 338592 samples\n",
      "\n",
      "01_20_00:13:41 --- 1.656390905380249 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:42 Training loss at epoch 1 step 10590: 2.994326114654541\n",
      "\n",
      " This round's valence_loss=1.4641872644424438, arousal_loss=1.369110107421875, emotion_loss=1.3381552696228027\n",
      "\n",
      "01_20_00:13:42 Seen so far: 338912 samples\n",
      "\n",
      "01_20_00:13:42 --- 1.7927367687225342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:44 Training loss at epoch 1 step 10600: 2.7547239661216736\n",
      "\n",
      " This round's valence_loss=0.8589540719985962, arousal_loss=0.6807800531387329, emotion_loss=0.8007243871688843\n",
      "\n",
      "01_20_00:13:44 Seen so far: 339232 samples\n",
      "\n",
      "01_20_00:13:44 --- 1.6270461082458496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:46 Training loss at epoch 1 step 10610: 2.8789002180099486\n",
      "\n",
      " This round's valence_loss=0.9945900440216064, arousal_loss=0.7890689373016357, emotion_loss=0.9951363801956177\n",
      "\n",
      "01_20_00:13:46 Seen so far: 339552 samples\n",
      "\n",
      "01_20_00:13:46 --- 1.64931058883667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:47 Training loss at epoch 1 step 10620: 2.9025280237197877\n",
      "\n",
      " This round's valence_loss=0.9945093393325806, arousal_loss=0.8505730628967285, emotion_loss=0.5682998895645142\n",
      "\n",
      "01_20_00:13:47 Seen so far: 339872 samples\n",
      "\n",
      "01_20_00:13:47 --- 1.6983675956726074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:49 Training loss at epoch 1 step 10630: 3.209577035903931\n",
      "\n",
      " This round's valence_loss=1.0015519857406616, arousal_loss=0.9092687368392944, emotion_loss=1.3139052391052246\n",
      "\n",
      "01_20_00:13:49 Seen so far: 340192 samples\n",
      "\n",
      "01_20_00:13:49 --- 1.7843787670135498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:51 Training loss at epoch 1 step 10640: 3.2722790241241455\n",
      "\n",
      " This round's valence_loss=1.7790218591690063, arousal_loss=1.674074649810791, emotion_loss=0.8198477029800415\n",
      "\n",
      "01_20_00:13:51 Seen so far: 340512 samples\n",
      "\n",
      "01_20_00:13:51 --- 1.9167423248291016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:53 Training loss at epoch 1 step 10650: 2.9096800327301025\n",
      "\n",
      " This round's valence_loss=0.8003628849983215, arousal_loss=0.738419771194458, emotion_loss=0.8450707197189331\n",
      "\n",
      "01_20_00:13:53 Seen so far: 340832 samples\n",
      "\n",
      "01_20_00:13:53 --- 1.716355800628662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:55 Training loss at epoch 1 step 10660: 2.96273250579834\n",
      "\n",
      " This round's valence_loss=0.5365562438964844, arousal_loss=0.3666040301322937, emotion_loss=1.0064551830291748\n",
      "\n",
      "01_20_00:13:55 Seen so far: 341152 samples\n",
      "\n",
      "01_20_00:13:55 --- 2.0552892684936523 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:57 Training loss at epoch 1 step 10670: 2.8563143491744993\n",
      "\n",
      " This round's valence_loss=1.2666202783584595, arousal_loss=1.1041650772094727, emotion_loss=0.7142404913902283\n",
      "\n",
      "01_20_00:13:57 Seen so far: 341472 samples\n",
      "\n",
      "01_20_00:13:57 --- 1.6520538330078125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:13:58 Training loss at epoch 1 step 10680: 3.3488635301589964\n",
      "\n",
      " This round's valence_loss=0.8545664548873901, arousal_loss=0.6242938041687012, emotion_loss=1.00872802734375\n",
      "\n",
      "01_20_00:13:58 Seen so far: 341792 samples\n",
      "\n",
      "01_20_00:13:58 --- 1.7473342418670654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:00 Training loss at epoch 1 step 10690: 3.175890851020813\n",
      "\n",
      " This round's valence_loss=0.9651832580566406, arousal_loss=0.7399336099624634, emotion_loss=0.7420998811721802\n",
      "\n",
      "01_20_00:14:00 Seen so far: 342112 samples\n",
      "\n",
      "01_20_00:14:00 --- 1.8465807437896729 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:02 Training loss at epoch 1 step 10700: 3.1003628730773927\n",
      "\n",
      " This round's valence_loss=1.0638420581817627, arousal_loss=0.9769504070281982, emotion_loss=1.094904899597168\n",
      "\n",
      "01_20_00:14:02 Seen so far: 342432 samples\n",
      "\n",
      "01_20_00:14:02 --- 1.7057936191558838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:04 Training loss at epoch 1 step 10710: 3.119942283630371\n",
      "\n",
      " This round's valence_loss=0.8710612654685974, arousal_loss=0.690895676612854, emotion_loss=0.9799137115478516\n",
      "\n",
      "01_20_00:14:04 Seen so far: 342752 samples\n",
      "\n",
      "01_20_00:14:04 --- 1.6832783222198486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:05 Training loss at epoch 1 step 10720: 2.923599123954773\n",
      "\n",
      " This round's valence_loss=1.0054471492767334, arousal_loss=0.7971839308738708, emotion_loss=0.958051860332489\n",
      "\n",
      "01_20_00:14:05 Seen so far: 343072 samples\n",
      "\n",
      "01_20_00:14:05 --- 1.8259479999542236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:07 Training loss at epoch 1 step 10730: 2.938017022609711\n",
      "\n",
      " This round's valence_loss=1.2454856634140015, arousal_loss=1.0670533180236816, emotion_loss=0.9573554992675781\n",
      "\n",
      "01_20_00:14:07 Seen so far: 343392 samples\n",
      "\n",
      "01_20_00:14:07 --- 1.8132340908050537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:09 Training loss at epoch 1 step 10740: 2.9088119983673097\n",
      "\n",
      " This round's valence_loss=1.0649782419204712, arousal_loss=0.9794633984565735, emotion_loss=0.7652320861816406\n",
      "\n",
      "01_20_00:14:09 Seen so far: 343712 samples\n",
      "\n",
      "01_20_00:14:09 --- 1.5157170295715332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:10 Training loss at epoch 1 step 10750: 3.332959508895874\n",
      "\n",
      " This round's valence_loss=1.0034414529800415, arousal_loss=0.8543592691421509, emotion_loss=0.7968156933784485\n",
      "\n",
      "01_20_00:14:10 Seen so far: 344032 samples\n",
      "\n",
      "01_20_00:14:10 --- 1.6719980239868164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:12 Training loss at epoch 1 step 10760: 3.087717425823212\n",
      "\n",
      " This round's valence_loss=0.9960795640945435, arousal_loss=0.8500293493270874, emotion_loss=0.9989372491836548\n",
      "\n",
      "01_20_00:14:12 Seen so far: 344352 samples\n",
      "\n",
      "01_20_00:14:12 --- 1.738267421722412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:14 Training loss at epoch 1 step 10770: 3.1256957411766053\n",
      "\n",
      " This round's valence_loss=1.2380530834197998, arousal_loss=1.0973457098007202, emotion_loss=0.913884162902832\n",
      "\n",
      "01_20_00:14:14 Seen so far: 344672 samples\n",
      "\n",
      "01_20_00:14:14 --- 1.876833438873291 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:16 Training loss at epoch 1 step 10780: 2.8792927384376528\n",
      "\n",
      " This round's valence_loss=0.7028176784515381, arousal_loss=0.5106625556945801, emotion_loss=0.6187444925308228\n",
      "\n",
      "01_20_00:14:16 Seen so far: 344992 samples\n",
      "\n",
      "01_20_00:14:16 --- 1.7229528427124023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:17 Training loss at epoch 1 step 10790: 3.2144420862197878\n",
      "\n",
      " This round's valence_loss=0.9320181608200073, arousal_loss=0.85658860206604, emotion_loss=1.283586025238037\n",
      "\n",
      "01_20_00:14:17 Seen so far: 345312 samples\n",
      "\n",
      "01_20_00:14:17 --- 1.744246006011963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:19 Training loss at epoch 1 step 10800: 2.9699684619903564\n",
      "\n",
      " This round's valence_loss=1.003605842590332, arousal_loss=0.827608048915863, emotion_loss=0.8275030255317688\n",
      "\n",
      "01_20_00:14:19 Seen so far: 345632 samples\n",
      "\n",
      "01_20_00:14:19 --- 1.863562822341919 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:21 Training loss at epoch 1 step 10810: 3.2536491632461546\n",
      "\n",
      " This round's valence_loss=0.9451953172683716, arousal_loss=0.7975289821624756, emotion_loss=0.9930402636528015\n",
      "\n",
      "01_20_00:14:21 Seen so far: 345952 samples\n",
      "\n",
      "01_20_00:14:21 --- 1.7459471225738525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:23 Training loss at epoch 1 step 10820: 3.0021745204925536\n",
      "\n",
      " This round's valence_loss=1.1437199115753174, arousal_loss=0.9259782433509827, emotion_loss=0.6179338693618774\n",
      "\n",
      "01_20_00:14:23 Seen so far: 346272 samples\n",
      "\n",
      "01_20_00:14:23 --- 1.7243249416351318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:25 Training loss at epoch 1 step 10830: 3.4573366403579713\n",
      "\n",
      " This round's valence_loss=1.5812993049621582, arousal_loss=1.4461772441864014, emotion_loss=1.1292245388031006\n",
      "\n",
      "01_20_00:14:25 Seen so far: 346592 samples\n",
      "\n",
      "01_20_00:14:25 --- 1.8981666564941406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:27 Training loss at epoch 1 step 10840: 3.2713374853134156\n",
      "\n",
      " This round's valence_loss=1.492152214050293, arousal_loss=1.2928967475891113, emotion_loss=0.8542882800102234\n",
      "\n",
      "01_20_00:14:27 Seen so far: 346912 samples\n",
      "\n",
      "01_20_00:14:27 --- 1.795607566833496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:28 Training loss at epoch 1 step 10850: 3.1468846797943115\n",
      "\n",
      " This round's valence_loss=1.0198379755020142, arousal_loss=0.7934284210205078, emotion_loss=0.5757240056991577\n",
      "\n",
      "01_20_00:14:28 Seen so far: 347232 samples\n",
      "\n",
      "01_20_00:14:28 --- 1.6617250442504883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:30 Training loss at epoch 1 step 10860: 2.793631935119629\n",
      "\n",
      " This round's valence_loss=0.4815309941768646, arousal_loss=0.40069735050201416, emotion_loss=1.0274853706359863\n",
      "\n",
      "01_20_00:14:30 Seen so far: 347552 samples\n",
      "\n",
      "01_20_00:14:30 --- 1.9675607681274414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:32 Training loss at epoch 1 step 10870: 2.8932920694351196\n",
      "\n",
      " This round's valence_loss=0.8138002157211304, arousal_loss=0.6740021705627441, emotion_loss=0.9408697485923767\n",
      "\n",
      "01_20_00:14:32 Seen so far: 347872 samples\n",
      "\n",
      "01_20_00:14:32 --- 1.7803003787994385 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:33 Training loss at epoch 1 step 10880: 2.9023795127868652\n",
      "\n",
      " This round's valence_loss=1.3270514011383057, arousal_loss=1.2550239562988281, emotion_loss=0.877305269241333\n",
      "\n",
      "01_20_00:14:33 Seen so far: 348192 samples\n",
      "\n",
      "01_20_00:14:33 --- 1.5648226737976074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:35 Training loss at epoch 1 step 10890: 2.9282339096069334\n",
      "\n",
      " This round's valence_loss=0.8655552864074707, arousal_loss=0.6830295324325562, emotion_loss=0.8798264265060425\n",
      "\n",
      "01_20_00:14:35 Seen so far: 348512 samples\n",
      "\n",
      "01_20_00:14:35 --- 1.706644058227539 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:37 Training loss at epoch 1 step 10900: 2.7976662158966064\n",
      "\n",
      " This round's valence_loss=0.5926178097724915, arousal_loss=0.3708777129650116, emotion_loss=0.7969072461128235\n",
      "\n",
      "01_20_00:14:37 Seen so far: 348832 samples\n",
      "\n",
      "01_20_00:14:37 --- 1.8126857280731201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:39 Training loss at epoch 1 step 10910: 3.0870506525039674\n",
      "\n",
      " This round's valence_loss=1.21549391746521, arousal_loss=1.080077886581421, emotion_loss=1.1161580085754395\n",
      "\n",
      "01_20_00:14:39 Seen so far: 349152 samples\n",
      "\n",
      "01_20_00:14:39 --- 1.917271375656128 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:41 Training loss at epoch 1 step 10920: 3.2238893032073976\n",
      "\n",
      " This round's valence_loss=1.4279356002807617, arousal_loss=1.4035253524780273, emotion_loss=0.9596959352493286\n",
      "\n",
      "01_20_00:14:41 Seen so far: 349472 samples\n",
      "\n",
      "01_20_00:14:41 --- 1.7082724571228027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:42 Training loss at epoch 1 step 10930: 3.2466371774673464\n",
      "\n",
      " This round's valence_loss=1.0546391010284424, arousal_loss=0.8275748491287231, emotion_loss=0.6593588590621948\n",
      "\n",
      "01_20_00:14:42 Seen so far: 349792 samples\n",
      "\n",
      "01_20_00:14:42 --- 1.754772424697876 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:44 Training loss at epoch 1 step 10940: 2.981268215179443\n",
      "\n",
      " This round's valence_loss=0.6480280160903931, arousal_loss=0.5289521813392639, emotion_loss=1.3194847106933594\n",
      "\n",
      "01_20_00:14:44 Seen so far: 350112 samples\n",
      "\n",
      "01_20_00:14:44 --- 2.0484344959259033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:46 Training loss at epoch 1 step 10950: 2.800682878494263\n",
      "\n",
      " This round's valence_loss=1.2999603748321533, arousal_loss=1.2460830211639404, emotion_loss=1.1816585063934326\n",
      "\n",
      "01_20_00:14:46 Seen so far: 350432 samples\n",
      "\n",
      "01_20_00:14:46 --- 1.753119707107544 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:48 Training loss at epoch 1 step 10960: 3.0964847564697267\n",
      "\n",
      " This round's valence_loss=0.6944185495376587, arousal_loss=0.6048375368118286, emotion_loss=1.0536236763000488\n",
      "\n",
      "01_20_00:14:48 Seen so far: 350752 samples\n",
      "\n",
      "01_20_00:14:48 --- 1.784188985824585 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:50 Training loss at epoch 1 step 10970: 2.7776331901550293\n",
      "\n",
      " This round's valence_loss=0.9563312530517578, arousal_loss=0.8003115653991699, emotion_loss=1.176706314086914\n",
      "\n",
      "01_20_00:14:50 Seen so far: 351072 samples\n",
      "\n",
      "01_20_00:14:50 --- 1.594646692276001 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:51 Training loss at epoch 1 step 10980: 3.1739118814468386\n",
      "\n",
      " This round's valence_loss=1.0693172216415405, arousal_loss=0.9755470752716064, emotion_loss=1.178179144859314\n",
      "\n",
      "01_20_00:14:51 Seen so far: 351392 samples\n",
      "\n",
      "01_20_00:14:51 --- 1.78334641456604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:53 Training loss at epoch 1 step 10990: 3.010215950012207\n",
      "\n",
      " This round's valence_loss=0.8093613386154175, arousal_loss=0.5553700923919678, emotion_loss=0.8555399775505066\n",
      "\n",
      "01_20_00:14:53 Seen so far: 351712 samples\n",
      "\n",
      "01_20_00:14:53 --- 1.6385307312011719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:55 Training loss at epoch 1 step 11000: 2.7762033104896546\n",
      "\n",
      " This round's valence_loss=0.9775689244270325, arousal_loss=0.9149265289306641, emotion_loss=0.9441830515861511\n",
      "\n",
      "01_20_00:14:55 Seen so far: 352032 samples\n",
      "\n",
      "01_20_00:14:55 --- 1.8397114276885986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:57 Training loss at epoch 1 step 11010: 2.910984253883362\n",
      "\n",
      " This round's valence_loss=1.057438611984253, arousal_loss=0.9510852694511414, emotion_loss=0.8983418941497803\n",
      "\n",
      "01_20_00:14:57 Seen so far: 352352 samples\n",
      "\n",
      "01_20_00:14:57 --- 1.8869075775146484 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:14:59 Training loss at epoch 1 step 11020: 2.6907067775726317\n",
      "\n",
      " This round's valence_loss=0.8675134181976318, arousal_loss=0.8613783717155457, emotion_loss=1.191447138786316\n",
      "\n",
      "01_20_00:14:59 Seen so far: 352672 samples\n",
      "\n",
      "01_20_00:14:59 --- 1.8001611232757568 seconds for iter 10 step, each step have 32, so the model train with 320 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_20_00:15:00 Training loss at epoch 1 step 11030: 2.8898075580596925\n",
      "\n",
      " This round's valence_loss=1.2907423973083496, arousal_loss=1.2013823986053467, emotion_loss=0.8960061073303223\n",
      "\n",
      "01_20_00:15:00 Seen so far: 352992 samples\n",
      "\n",
      "01_20_00:15:00 --- 1.6858429908752441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:02 Training loss at epoch 1 step 11040: 2.9999551296234133\n",
      "\n",
      " This round's valence_loss=1.4804620742797852, arousal_loss=1.3044317960739136, emotion_loss=1.1495305299758911\n",
      "\n",
      "01_20_00:15:02 Seen so far: 353312 samples\n",
      "\n",
      "01_20_00:15:02 --- 1.6860473155975342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:04 Training loss at epoch 1 step 11050: 3.0508933782577516\n",
      "\n",
      " This round's valence_loss=0.8303574919700623, arousal_loss=0.7894605994224548, emotion_loss=1.2020509243011475\n",
      "\n",
      "01_20_00:15:04 Seen so far: 353632 samples\n",
      "\n",
      "01_20_00:15:04 --- 1.6905286312103271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:05 Training loss at epoch 1 step 11060: 2.822137725353241\n",
      "\n",
      " This round's valence_loss=1.3604897260665894, arousal_loss=1.2143492698669434, emotion_loss=0.888445258140564\n",
      "\n",
      "01_20_00:15:05 Seen so far: 353952 samples\n",
      "\n",
      "01_20_00:15:05 --- 1.7543933391571045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:07 Training loss at epoch 1 step 11070: 2.856258201599121\n",
      "\n",
      " This round's valence_loss=1.2348525524139404, arousal_loss=1.1079691648483276, emotion_loss=0.9873957633972168\n",
      "\n",
      "01_20_00:15:07 Seen so far: 354272 samples\n",
      "\n",
      "01_20_00:15:07 --- 1.8148045539855957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:09 Training loss at epoch 1 step 11080: 3.016137146949768\n",
      "\n",
      " This round's valence_loss=1.1554639339447021, arousal_loss=1.1428241729736328, emotion_loss=1.2399885654449463\n",
      "\n",
      "01_20_00:15:09 Seen so far: 354592 samples\n",
      "\n",
      "01_20_00:15:09 --- 2.0147416591644287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:11 Training loss at epoch 1 step 11090: 2.886178708076477\n",
      "\n",
      " This round's valence_loss=0.5865978598594666, arousal_loss=0.45869922637939453, emotion_loss=1.1619462966918945\n",
      "\n",
      "01_20_00:15:11 Seen so far: 354912 samples\n",
      "\n",
      "01_20_00:15:11 --- 1.5615613460540771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:13 Training loss at epoch 1 step 11100: 2.7888704776763915\n",
      "\n",
      " This round's valence_loss=1.3388320207595825, arousal_loss=1.1425334215164185, emotion_loss=0.8116111159324646\n",
      "\n",
      "01_20_00:15:13 Seen so far: 355232 samples\n",
      "\n",
      "01_20_00:15:13 --- 1.9926114082336426 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:14 Training loss at epoch 1 step 11110: 2.8265767812728884\n",
      "\n",
      " This round's valence_loss=1.0361976623535156, arousal_loss=0.8489023447036743, emotion_loss=1.420648217201233\n",
      "\n",
      "01_20_00:15:14 Seen so far: 355552 samples\n",
      "\n",
      "01_20_00:15:14 --- 1.6975204944610596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:16 Training loss at epoch 1 step 11120: 2.9241066932678224\n",
      "\n",
      " This round's valence_loss=0.5585426688194275, arousal_loss=0.5053060054779053, emotion_loss=0.8861451148986816\n",
      "\n",
      "01_20_00:15:16 Seen so far: 355872 samples\n",
      "\n",
      "01_20_00:15:16 --- 1.7286059856414795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:18 Training loss at epoch 1 step 11130: 3.1754737377166746\n",
      "\n",
      " This round's valence_loss=0.9996404647827148, arousal_loss=0.8489264845848083, emotion_loss=1.2788782119750977\n",
      "\n",
      "01_20_00:15:18 Seen so far: 356192 samples\n",
      "\n",
      "01_20_00:15:18 --- 1.9494495391845703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:20 Training loss at epoch 1 step 11140: 3.1907438039779663\n",
      "\n",
      " This round's valence_loss=0.7969387769699097, arousal_loss=0.6691591739654541, emotion_loss=0.6791172623634338\n",
      "\n",
      "01_20_00:15:20 Seen so far: 356512 samples\n",
      "\n",
      "01_20_00:15:20 --- 1.6995935440063477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:22 Training loss at epoch 1 step 11150: 2.6608951807022097\n",
      "\n",
      " This round's valence_loss=0.9271759986877441, arousal_loss=0.6791282892227173, emotion_loss=0.7252188920974731\n",
      "\n",
      "01_20_00:15:22 Seen so far: 356832 samples\n",
      "\n",
      "01_20_00:15:22 --- 1.7896819114685059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:23 Training loss at epoch 1 step 11160: 3.07926025390625\n",
      "\n",
      " This round's valence_loss=1.1154417991638184, arousal_loss=0.940116286277771, emotion_loss=0.8444546461105347\n",
      "\n",
      "01_20_00:15:23 Seen so far: 357152 samples\n",
      "\n",
      "01_20_00:15:23 --- 1.7166287899017334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:25 Training loss at epoch 1 step 11170: 3.2088547348976135\n",
      "\n",
      " This round's valence_loss=1.0121443271636963, arousal_loss=0.855826735496521, emotion_loss=1.1660265922546387\n",
      "\n",
      "01_20_00:15:25 Seen so far: 357472 samples\n",
      "\n",
      "01_20_00:15:25 --- 1.8900461196899414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:27 Training loss at epoch 1 step 11180: 3.110620403289795\n",
      "\n",
      " This round's valence_loss=1.2460923194885254, arousal_loss=1.1050870418548584, emotion_loss=1.3225078582763672\n",
      "\n",
      "01_20_00:15:27 Seen so far: 357792 samples\n",
      "\n",
      "01_20_00:15:27 --- 1.624804973602295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:29 Training loss at epoch 1 step 11190: 3.115913510322571\n",
      "\n",
      " This round's valence_loss=1.1904515027999878, arousal_loss=0.9537171721458435, emotion_loss=1.0708258152008057\n",
      "\n",
      "01_20_00:15:29 Seen so far: 358112 samples\n",
      "\n",
      "01_20_00:15:29 --- 1.953129768371582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:31 Training loss at epoch 1 step 11200: 2.9860257387161253\n",
      "\n",
      " This round's valence_loss=1.1215198040008545, arousal_loss=0.9463787078857422, emotion_loss=1.0664567947387695\n",
      "\n",
      "01_20_00:15:31 Seen so far: 358432 samples\n",
      "\n",
      "01_20_00:15:31 --- 1.7513618469238281 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:32 Training loss at epoch 1 step 11210: 2.8122740626335143\n",
      "\n",
      " This round's valence_loss=1.332220196723938, arousal_loss=1.2174646854400635, emotion_loss=1.1254853010177612\n",
      "\n",
      "01_20_00:15:32 Seen so far: 358752 samples\n",
      "\n",
      "01_20_00:15:32 --- 1.9175546169281006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:34 Training loss at epoch 1 step 11220: 3.271749210357666\n",
      "\n",
      " This round's valence_loss=0.9556717872619629, arousal_loss=0.7043343782424927, emotion_loss=1.0161573886871338\n",
      "\n",
      "01_20_00:15:34 Seen so far: 359072 samples\n",
      "\n",
      "01_20_00:15:34 --- 1.667959451675415 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:36 Training loss at epoch 1 step 11230: 3.235923719406128\n",
      "\n",
      " This round's valence_loss=1.3659095764160156, arousal_loss=1.2673351764678955, emotion_loss=1.0828006267547607\n",
      "\n",
      "01_20_00:15:36 Seen so far: 359392 samples\n",
      "\n",
      "01_20_00:15:36 --- 1.6881933212280273 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:38 Training loss at epoch 1 step 11240: 3.2124478340148928\n",
      "\n",
      " This round's valence_loss=0.9441922307014465, arousal_loss=0.923676609992981, emotion_loss=0.9125590324401855\n",
      "\n",
      "01_20_00:15:38 Seen so far: 359712 samples\n",
      "\n",
      "01_20_00:15:38 --- 1.8072748184204102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:39 Training loss at epoch 1 step 11250: 2.9249502420425415\n",
      "\n",
      " This round's valence_loss=0.8045399188995361, arousal_loss=0.756431519985199, emotion_loss=1.0659854412078857\n",
      "\n",
      "01_20_00:15:39 Seen so far: 360032 samples\n",
      "\n",
      "01_20_00:15:39 --- 1.6490609645843506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:41 Training loss at epoch 1 step 11260: 3.3674118280410767\n",
      "\n",
      " This round's valence_loss=1.4555549621582031, arousal_loss=1.3282139301300049, emotion_loss=1.1319997310638428\n",
      "\n",
      "01_20_00:15:41 Seen so far: 360352 samples\n",
      "\n",
      "01_20_00:15:41 --- 1.746070146560669 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:43 Training loss at epoch 1 step 11270: 2.9129504203796386\n",
      "\n",
      " This round's valence_loss=0.683547854423523, arousal_loss=0.6883805990219116, emotion_loss=1.2404004335403442\n",
      "\n",
      "01_20_00:15:43 Seen so far: 360672 samples\n",
      "\n",
      "01_20_00:15:43 --- 1.74104905128479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:44 Training loss at epoch 1 step 11280: 2.7571218729019167\n",
      "\n",
      " This round's valence_loss=1.546460747718811, arousal_loss=1.442591667175293, emotion_loss=1.0751891136169434\n",
      "\n",
      "01_20_00:15:44 Seen so far: 360992 samples\n",
      "\n",
      "01_20_00:15:44 --- 1.6870882511138916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:46 Training loss at epoch 1 step 11290: 2.9665908813476562\n",
      "\n",
      " This round's valence_loss=0.8274353742599487, arousal_loss=0.7049557566642761, emotion_loss=1.2092909812927246\n",
      "\n",
      "01_20_00:15:46 Seen so far: 361312 samples\n",
      "\n",
      "01_20_00:15:46 --- 1.7290399074554443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:48 Training loss at epoch 1 step 11300: 2.858465313911438\n",
      "\n",
      " This round's valence_loss=0.6136665344238281, arousal_loss=0.504839301109314, emotion_loss=1.1516849994659424\n",
      "\n",
      "01_20_00:15:48 Seen so far: 361632 samples\n",
      "\n",
      "01_20_00:15:48 --- 1.8535995483398438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:50 Training loss at epoch 1 step 11310: 3.0211251974105835\n",
      "\n",
      " This round's valence_loss=0.8130170106887817, arousal_loss=0.7597478032112122, emotion_loss=0.8609195947647095\n",
      "\n",
      "01_20_00:15:50 Seen so far: 361952 samples\n",
      "\n",
      "01_20_00:15:50 --- 1.9327890872955322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:52 Training loss at epoch 1 step 11320: 3.301645112037659\n",
      "\n",
      " This round's valence_loss=1.2301409244537354, arousal_loss=1.0398544073104858, emotion_loss=0.6773950457572937\n",
      "\n",
      "01_20_00:15:52 Seen so far: 362272 samples\n",
      "\n",
      "01_20_00:15:52 --- 1.676969051361084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:53 Training loss at epoch 1 step 11330: 3.044002413749695\n",
      "\n",
      " This round's valence_loss=0.9265048503875732, arousal_loss=0.7381287813186646, emotion_loss=0.9839020371437073\n",
      "\n",
      "01_20_00:15:53 Seen so far: 362592 samples\n",
      "\n",
      "01_20_00:15:53 --- 1.7157068252563477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:55 Training loss at epoch 1 step 11340: 2.6218841910362243\n",
      "\n",
      " This round's valence_loss=0.7011013031005859, arousal_loss=0.558288037776947, emotion_loss=1.2141597270965576\n",
      "\n",
      "01_20_00:15:55 Seen so far: 362912 samples\n",
      "\n",
      "01_20_00:15:55 --- 1.7496178150177002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:57 Training loss at epoch 1 step 11350: 2.9356134653091432\n",
      "\n",
      " This round's valence_loss=1.3551793098449707, arousal_loss=1.0485594272613525, emotion_loss=0.9538282752037048\n",
      "\n",
      "01_20_00:15:57 Seen so far: 363232 samples\n",
      "\n",
      "01_20_00:15:57 --- 1.7906982898712158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:15:59 Training loss at epoch 1 step 11360: 2.492848789691925\n",
      "\n",
      " This round's valence_loss=0.8345999717712402, arousal_loss=0.5349562764167786, emotion_loss=0.6979415416717529\n",
      "\n",
      "01_20_00:15:59 Seen so far: 363552 samples\n",
      "\n",
      "01_20_00:15:59 --- 1.66416335105896 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:00 Training loss at epoch 1 step 11370: 3.346288466453552\n",
      "\n",
      " This round's valence_loss=1.693404197692871, arousal_loss=1.6063807010650635, emotion_loss=1.334303379058838\n",
      "\n",
      "01_20_00:16:00 Seen so far: 363872 samples\n",
      "\n",
      "01_20_00:16:00 --- 1.7088348865509033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:02 Training loss at epoch 1 step 11380: 3.1152167558670043\n",
      "\n",
      " This round's valence_loss=1.14247727394104, arousal_loss=0.9566484689712524, emotion_loss=0.7754368782043457\n",
      "\n",
      "01_20_00:16:02 Seen so far: 364192 samples\n",
      "\n",
      "01_20_00:16:02 --- 1.8013770580291748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:04 Training loss at epoch 1 step 11390: 2.9753475427627563\n",
      "\n",
      " This round's valence_loss=1.112684726715088, arousal_loss=0.9855660200119019, emotion_loss=0.9933372139930725\n",
      "\n",
      "01_20_00:16:04 Seen so far: 364512 samples\n",
      "\n",
      "01_20_00:16:04 --- 1.694751262664795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:06 Training loss at epoch 1 step 11400: 2.9369463205337523\n",
      "\n",
      " This round's valence_loss=1.1214962005615234, arousal_loss=0.9422388076782227, emotion_loss=1.0361298322677612\n",
      "\n",
      "01_20_00:16:06 Seen so far: 364832 samples\n",
      "\n",
      "01_20_00:16:06 --- 2.0351943969726562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:08 Training loss at epoch 1 step 11410: 3.1104068636894224\n",
      "\n",
      " This round's valence_loss=0.3388742208480835, arousal_loss=0.1586306095123291, emotion_loss=1.222520351409912\n",
      "\n",
      "01_20_00:16:08 Seen so far: 365152 samples\n",
      "\n",
      "01_20_00:16:08 --- 1.8456368446350098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:09 Training loss at epoch 1 step 11420: 3.313912606239319\n",
      "\n",
      " This round's valence_loss=1.3437179327011108, arousal_loss=1.1799060106277466, emotion_loss=1.1578110456466675\n",
      "\n",
      "01_20_00:16:09 Seen so far: 365472 samples\n",
      "\n",
      "01_20_00:16:09 --- 1.6550040245056152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:11 Training loss at epoch 1 step 11430: 3.1008654117584227\n",
      "\n",
      " This round's valence_loss=1.1431810855865479, arousal_loss=0.9256840944290161, emotion_loss=1.1392672061920166\n",
      "\n",
      "01_20_00:16:11 Seen so far: 365792 samples\n",
      "\n",
      "01_20_00:16:11 --- 1.9214661121368408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:13 Training loss at epoch 1 step 11440: 2.8677138090133667\n",
      "\n",
      " This round's valence_loss=1.0826029777526855, arousal_loss=0.9307519793510437, emotion_loss=1.115473747253418\n",
      "\n",
      "01_20_00:16:13 Seen so far: 366112 samples\n",
      "\n",
      "01_20_00:16:13 --- 1.7951326370239258 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:15 Training loss at epoch 1 step 11450: 2.8310922622680663\n",
      "\n",
      " This round's valence_loss=1.2906620502471924, arousal_loss=1.1803793907165527, emotion_loss=0.8879623413085938\n",
      "\n",
      "01_20_00:16:15 Seen so far: 366432 samples\n",
      "\n",
      "01_20_00:16:15 --- 1.8195571899414062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:17 Training loss at epoch 1 step 11460: 3.1581419706344604\n",
      "\n",
      " This round's valence_loss=1.2671260833740234, arousal_loss=1.2011466026306152, emotion_loss=0.5701282024383545\n",
      "\n",
      "01_20_00:16:17 Seen so far: 366752 samples\n",
      "\n",
      "01_20_00:16:17 --- 1.7605690956115723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:18 Training loss at epoch 1 step 11470: 2.9760427474975586\n",
      "\n",
      " This round's valence_loss=1.1724448204040527, arousal_loss=1.117243766784668, emotion_loss=0.908997654914856\n",
      "\n",
      "01_20_00:16:18 Seen so far: 367072 samples\n",
      "\n",
      "01_20_00:16:18 --- 1.7491836547851562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:20 Training loss at epoch 1 step 11480: 3.0552775621414185\n",
      "\n",
      " This round's valence_loss=1.2026519775390625, arousal_loss=1.105882167816162, emotion_loss=0.9711086750030518\n",
      "\n",
      "01_20_00:16:20 Seen so far: 367392 samples\n",
      "\n",
      "01_20_00:16:20 --- 1.8135449886322021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:22 Training loss at epoch 1 step 11490: 3.6086802244186402\n",
      "\n",
      " This round's valence_loss=1.188326358795166, arousal_loss=1.111568808555603, emotion_loss=1.182701826095581\n",
      "\n",
      "01_20_00:16:22 Seen so far: 367712 samples\n",
      "\n",
      "01_20_00:16:22 --- 1.7663311958312988 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:24 Training loss at epoch 1 step 11500: 2.887320113182068\n",
      "\n",
      " This round's valence_loss=0.8581173419952393, arousal_loss=0.725793719291687, emotion_loss=0.942631721496582\n",
      "\n",
      "01_20_00:16:24 Seen so far: 368032 samples\n",
      "\n",
      "01_20_00:16:24 --- 1.8524115085601807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:25 Training loss at epoch 1 step 11510: 3.238519477844238\n",
      "\n",
      " This round's valence_loss=1.6078081130981445, arousal_loss=1.439589023590088, emotion_loss=1.1574523448944092\n",
      "\n",
      "01_20_00:16:25 Seen so far: 368352 samples\n",
      "\n",
      "01_20_00:16:25 --- 1.7212848663330078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:27 Training loss at epoch 1 step 11520: 3.25867702960968\n",
      "\n",
      " This round's valence_loss=1.1388823986053467, arousal_loss=0.9313490390777588, emotion_loss=0.9215982556343079\n",
      "\n",
      "01_20_00:16:27 Seen so far: 368672 samples\n",
      "\n",
      "01_20_00:16:27 --- 1.8904409408569336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:29 Training loss at epoch 1 step 11530: 2.862235164642334\n",
      "\n",
      " This round's valence_loss=1.3017587661743164, arousal_loss=1.202141284942627, emotion_loss=0.9127852320671082\n",
      "\n",
      "01_20_00:16:29 Seen so far: 368992 samples\n",
      "\n",
      "01_20_00:16:29 --- 2.0578742027282715 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:31 Training loss at epoch 1 step 11540: 2.880194568634033\n",
      "\n",
      " This round's valence_loss=1.2722580432891846, arousal_loss=1.1081502437591553, emotion_loss=1.0811941623687744\n",
      "\n",
      "01_20_00:16:31 Seen so far: 369312 samples\n",
      "\n",
      "01_20_00:16:31 --- 1.8990087509155273 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:33 Training loss at epoch 1 step 11550: 2.892776441574097\n",
      "\n",
      " This round's valence_loss=0.7322028875350952, arousal_loss=0.6714528799057007, emotion_loss=1.0370131731033325\n",
      "\n",
      "01_20_00:16:33 Seen so far: 369632 samples\n",
      "\n",
      "01_20_00:16:33 --- 1.7639760971069336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:35 Training loss at epoch 1 step 11560: 3.157888317108154\n",
      "\n",
      " This round's valence_loss=0.9781773686408997, arousal_loss=0.8340147137641907, emotion_loss=0.8678256273269653\n",
      "\n",
      "01_20_00:16:35 Seen so far: 369952 samples\n",
      "\n",
      "01_20_00:16:35 --- 1.7270889282226562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:37 Training loss at epoch 1 step 11570: 3.1493923664093018\n",
      "\n",
      " This round's valence_loss=1.0058739185333252, arousal_loss=0.8753455877304077, emotion_loss=1.1685731410980225\n",
      "\n",
      "01_20_00:16:37 Seen so far: 370272 samples\n",
      "\n",
      "01_20_00:16:37 --- 1.9569592475891113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:38 Training loss at epoch 1 step 11580: 2.961765193939209\n",
      "\n",
      " This round's valence_loss=1.4991912841796875, arousal_loss=1.324462652206421, emotion_loss=1.0204682350158691\n",
      "\n",
      "01_20_00:16:38 Seen so far: 370592 samples\n",
      "\n",
      "01_20_00:16:38 --- 1.7006616592407227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:40 Training loss at epoch 1 step 11590: 3.016354489326477\n",
      "\n",
      " This round's valence_loss=0.746830940246582, arousal_loss=0.6250479817390442, emotion_loss=0.9202661514282227\n",
      "\n",
      "01_20_00:16:40 Seen so far: 370912 samples\n",
      "\n",
      "01_20_00:16:40 --- 1.7406554222106934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:42 Training loss at epoch 1 step 11600: 2.9780023813247682\n",
      "\n",
      " This round's valence_loss=1.2006065845489502, arousal_loss=1.1013858318328857, emotion_loss=1.1656596660614014\n",
      "\n",
      "01_20_00:16:42 Seen so far: 371232 samples\n",
      "\n",
      "01_20_00:16:42 --- 1.9822444915771484 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:44 Training loss at epoch 1 step 11610: 2.8176354646682737\n",
      "\n",
      " This round's valence_loss=0.9449163675308228, arousal_loss=0.8005135655403137, emotion_loss=0.7359861135482788\n",
      "\n",
      "01_20_00:16:44 Seen so far: 371552 samples\n",
      "\n",
      "01_20_00:16:44 --- 1.733959674835205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:46 Training loss at epoch 1 step 11620: 3.1288965940475464\n",
      "\n",
      " This round's valence_loss=1.2746765613555908, arousal_loss=1.2051280736923218, emotion_loss=0.9276385307312012\n",
      "\n",
      "01_20_00:16:46 Seen so far: 371872 samples\n",
      "\n",
      "01_20_00:16:46 --- 1.927159070968628 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:48 Training loss at epoch 1 step 11630: 3.291121172904968\n",
      "\n",
      " This round's valence_loss=1.4266853332519531, arousal_loss=1.3301044702529907, emotion_loss=1.0460758209228516\n",
      "\n",
      "01_20_00:16:48 Seen so far: 372192 samples\n",
      "\n",
      "01_20_00:16:48 --- 1.679276704788208 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:49 Training loss at epoch 1 step 11640: 2.929467558860779\n",
      "\n",
      " This round's valence_loss=1.0892491340637207, arousal_loss=0.9771944284439087, emotion_loss=0.8623519539833069\n",
      "\n",
      "01_20_00:16:49 Seen so far: 372512 samples\n",
      "\n",
      "01_20_00:16:49 --- 1.8061435222625732 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:51 Training loss at epoch 1 step 11650: 3.1376106262207033\n",
      "\n",
      " This round's valence_loss=0.912866473197937, arousal_loss=0.8981657028198242, emotion_loss=1.2160543203353882\n",
      "\n",
      "01_20_00:16:51 Seen so far: 372832 samples\n",
      "\n",
      "01_20_00:16:51 --- 1.724799633026123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:53 Training loss at epoch 1 step 11660: 3.314805746078491\n",
      "\n",
      " This round's valence_loss=1.8188955783843994, arousal_loss=1.6540558338165283, emotion_loss=0.790729284286499\n",
      "\n",
      "01_20_00:16:53 Seen so far: 373152 samples\n",
      "\n",
      "01_20_00:16:53 --- 1.73409104347229 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:55 Training loss at epoch 1 step 11670: 3.214754414558411\n",
      "\n",
      " This round's valence_loss=1.035236120223999, arousal_loss=0.8657447099685669, emotion_loss=0.738341212272644\n",
      "\n",
      "01_20_00:16:55 Seen so far: 373472 samples\n",
      "\n",
      "01_20_00:16:55 --- 1.6966729164123535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:56 Training loss at epoch 1 step 11680: 3.0011865139007567\n",
      "\n",
      " This round's valence_loss=1.3652093410491943, arousal_loss=1.203598976135254, emotion_loss=1.0180697441101074\n",
      "\n",
      "01_20_00:16:56 Seen so far: 373792 samples\n",
      "\n",
      "01_20_00:16:56 --- 1.865497350692749 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:16:58 Training loss at epoch 1 step 11690: 3.313183379173279\n",
      "\n",
      " This round's valence_loss=1.015129566192627, arousal_loss=0.8305995464324951, emotion_loss=0.8477598428726196\n",
      "\n",
      "01_20_00:16:58 Seen so far: 374112 samples\n",
      "\n",
      "01_20_00:16:58 --- 1.820704698562622 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:00 Training loss at epoch 1 step 11700: 2.8800666093826295\n",
      "\n",
      " This round's valence_loss=0.8000304698944092, arousal_loss=0.6998136043548584, emotion_loss=1.3779692649841309\n",
      "\n",
      "01_20_00:17:00 Seen so far: 374432 samples\n",
      "\n",
      "01_20_00:17:00 --- 1.6831576824188232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:02 Training loss at epoch 1 step 11710: 3.312930369377136\n",
      "\n",
      " This round's valence_loss=1.2106761932373047, arousal_loss=1.1246249675750732, emotion_loss=1.3251703977584839\n",
      "\n",
      "01_20_00:17:02 Seen so far: 374752 samples\n",
      "\n",
      "01_20_00:17:02 --- 1.6908717155456543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:03 Training loss at epoch 1 step 11720: 3.124470829963684\n",
      "\n",
      " This round's valence_loss=0.7970572710037231, arousal_loss=0.804146409034729, emotion_loss=1.4936829805374146\n",
      "\n",
      "01_20_00:17:03 Seen so far: 375072 samples\n",
      "\n",
      "01_20_00:17:03 --- 1.8949968814849854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:05 Training loss at epoch 1 step 11730: 2.507623565196991\n",
      "\n",
      " This round's valence_loss=0.6255711317062378, arousal_loss=0.45653823018074036, emotion_loss=1.0291767120361328\n",
      "\n",
      "01_20_00:17:05 Seen so far: 375392 samples\n",
      "\n",
      "01_20_00:17:05 --- 1.9419212341308594 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:07 Training loss at epoch 1 step 11740: 3.0277214527130125\n",
      "\n",
      " This round's valence_loss=1.2310662269592285, arousal_loss=1.0959789752960205, emotion_loss=1.2502528429031372\n",
      "\n",
      "01_20_00:17:07 Seen so far: 375712 samples\n",
      "\n",
      "01_20_00:17:07 --- 1.805558204650879 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:09 Training loss at epoch 1 step 11750: 3.07872359752655\n",
      "\n",
      " This round's valence_loss=1.0381028652191162, arousal_loss=0.8365864753723145, emotion_loss=0.6666103601455688\n",
      "\n",
      "01_20_00:17:09 Seen so far: 376032 samples\n",
      "\n",
      "01_20_00:17:09 --- 1.9533627033233643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:11 Training loss at epoch 1 step 11760: 2.765474057197571\n",
      "\n",
      " This round's valence_loss=1.1473511457443237, arousal_loss=0.9465128779411316, emotion_loss=0.42431509494781494\n",
      "\n",
      "01_20_00:17:11 Seen so far: 376352 samples\n",
      "\n",
      "01_20_00:17:11 --- 1.974703073501587 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:13 Training loss at epoch 1 step 11770: 3.054917597770691\n",
      "\n",
      " This round's valence_loss=1.0225021839141846, arousal_loss=0.776877760887146, emotion_loss=0.8730815649032593\n",
      "\n",
      "01_20_00:17:13 Seen so far: 376672 samples\n",
      "\n",
      "01_20_00:17:13 --- 1.7858130931854248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:15 Training loss at epoch 1 step 11780: 2.594842553138733\n",
      "\n",
      " This round's valence_loss=1.1122963428497314, arousal_loss=0.9512429237365723, emotion_loss=0.9446926712989807\n",
      "\n",
      "01_20_00:17:15 Seen so far: 376992 samples\n",
      "\n",
      "01_20_00:17:15 --- 1.9047579765319824 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:17 Training loss at epoch 1 step 11790: 3.1028576374053953\n",
      "\n",
      " This round's valence_loss=1.4442845582962036, arousal_loss=1.309619665145874, emotion_loss=1.239859938621521\n",
      "\n",
      "01_20_00:17:17 Seen so far: 377312 samples\n",
      "\n",
      "01_20_00:17:17 --- 1.8450429439544678 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:18 Training loss at epoch 1 step 11800: 2.8853580713272096\n",
      "\n",
      " This round's valence_loss=0.9512032270431519, arousal_loss=0.828544020652771, emotion_loss=0.9650331735610962\n",
      "\n",
      "01_20_00:17:18 Seen so far: 377632 samples\n",
      "\n",
      "01_20_00:17:18 --- 1.757218837738037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:20 Training loss at epoch 1 step 11810: 2.828017795085907\n",
      "\n",
      " This round's valence_loss=0.7551736831665039, arousal_loss=0.5491578578948975, emotion_loss=0.5913885831832886\n",
      "\n",
      "01_20_00:17:20 Seen so far: 377952 samples\n",
      "\n",
      "01_20_00:17:20 --- 1.8857982158660889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:22 Training loss at epoch 1 step 11820: 3.1311922311782836\n",
      "\n",
      " This round's valence_loss=1.452136754989624, arousal_loss=1.3292205333709717, emotion_loss=1.0602458715438843\n",
      "\n",
      "01_20_00:17:22 Seen so far: 378272 samples\n",
      "\n",
      "01_20_00:17:22 --- 1.6591122150421143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:24 Training loss at epoch 1 step 11830: 2.9170347690582275\n",
      "\n",
      " This round's valence_loss=1.4245765209197998, arousal_loss=1.3039813041687012, emotion_loss=1.2228636741638184\n",
      "\n",
      "01_20_00:17:24 Seen so far: 378592 samples\n",
      "\n",
      "01_20_00:17:24 --- 1.7716255187988281 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:26 Training loss at epoch 1 step 11840: 3.3069737434387205\n",
      "\n",
      " This round's valence_loss=0.799083948135376, arousal_loss=0.7047597169876099, emotion_loss=0.7711914777755737\n",
      "\n",
      "01_20_00:17:26 Seen so far: 378912 samples\n",
      "\n",
      "01_20_00:17:26 --- 1.8077335357666016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:27 Training loss at epoch 1 step 11850: 3.4028024673461914\n",
      "\n",
      " This round's valence_loss=1.2046270370483398, arousal_loss=0.9567395448684692, emotion_loss=0.9211623072624207\n",
      "\n",
      "01_20_00:17:27 Seen so far: 379232 samples\n",
      "\n",
      "01_20_00:17:27 --- 1.6295018196105957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:29 Training loss at epoch 1 step 11860: 3.1439226388931276\n",
      "\n",
      " This round's valence_loss=1.4243278503417969, arousal_loss=1.3091516494750977, emotion_loss=1.030202865600586\n",
      "\n",
      "01_20_00:17:29 Seen so far: 379552 samples\n",
      "\n",
      "01_20_00:17:29 --- 1.8866181373596191 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:31 Training loss at epoch 1 step 11870: 2.844424819946289\n",
      "\n",
      " This round's valence_loss=0.6511809229850769, arousal_loss=0.6241160035133362, emotion_loss=0.994522213935852\n",
      "\n",
      "01_20_00:17:31 Seen so far: 379872 samples\n",
      "\n",
      "01_20_00:17:31 --- 1.6951868534088135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:33 Training loss at epoch 1 step 11880: 2.9606965303421022\n",
      "\n",
      " This round's valence_loss=1.064807415008545, arousal_loss=0.9958236217498779, emotion_loss=1.2706880569458008\n",
      "\n",
      "01_20_00:17:33 Seen so far: 380192 samples\n",
      "\n",
      "01_20_00:17:33 --- 1.7769718170166016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:34 Training loss at epoch 1 step 11890: 3.147019290924072\n",
      "\n",
      " This round's valence_loss=1.1057846546173096, arousal_loss=1.0215096473693848, emotion_loss=0.8857851028442383\n",
      "\n",
      "01_20_00:17:34 Seen so far: 380512 samples\n",
      "\n",
      "01_20_00:17:34 --- 1.6924290657043457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:36 Training loss at epoch 1 step 11900: 2.849150371551514\n",
      "\n",
      " This round's valence_loss=0.7435808181762695, arousal_loss=0.563724160194397, emotion_loss=0.7173660397529602\n",
      "\n",
      "01_20_00:17:36 Seen so far: 380832 samples\n",
      "\n",
      "01_20_00:17:36 --- 1.7132670879364014 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:38 Training loss at epoch 1 step 11910: 3.062936806678772\n",
      "\n",
      " This round's valence_loss=1.5059560537338257, arousal_loss=1.2842166423797607, emotion_loss=0.6771910786628723\n",
      "\n",
      "01_20_00:17:38 Seen so far: 381152 samples\n",
      "\n",
      "01_20_00:17:38 --- 1.9521784782409668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:40 Training loss at epoch 1 step 11920: 2.9126051902770995\n",
      "\n",
      " This round's valence_loss=1.0625038146972656, arousal_loss=0.9860831499099731, emotion_loss=0.6648108959197998\n",
      "\n",
      "01_20_00:17:40 Seen so far: 381472 samples\n",
      "\n",
      "01_20_00:17:40 --- 1.9847652912139893 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:42 Training loss at epoch 1 step 11930: 3.1093398094177247\n",
      "\n",
      " This round's valence_loss=0.955584704875946, arousal_loss=0.8574466109275818, emotion_loss=0.8852754831314087\n",
      "\n",
      "01_20_00:17:42 Seen so far: 381792 samples\n",
      "\n",
      "01_20_00:17:42 --- 1.7535181045532227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:43 Training loss at epoch 1 step 11940: 2.940273404121399\n",
      "\n",
      " This round's valence_loss=1.5933985710144043, arousal_loss=1.4628374576568604, emotion_loss=1.0047881603240967\n",
      "\n",
      "01_20_00:17:43 Seen so far: 382112 samples\n",
      "\n",
      "01_20_00:17:43 --- 1.789137840270996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:45 Training loss at epoch 1 step 11950: 3.3018541812896727\n",
      "\n",
      " This round's valence_loss=1.2632519006729126, arousal_loss=1.1689891815185547, emotion_loss=1.1145210266113281\n",
      "\n",
      "01_20_00:17:45 Seen so far: 382432 samples\n",
      "\n",
      "01_20_00:17:45 --- 1.7747645378112793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:47 Training loss at epoch 1 step 11960: 3.0241554260253904\n",
      "\n",
      " This round's valence_loss=1.283125877380371, arousal_loss=1.0761948823928833, emotion_loss=0.6863240003585815\n",
      "\n",
      "01_20_00:17:47 Seen so far: 382752 samples\n",
      "\n",
      "01_20_00:17:47 --- 2.161534309387207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:49 Training loss at epoch 1 step 11970: 3.096065545082092\n",
      "\n",
      " This round's valence_loss=0.5995616912841797, arousal_loss=0.5054816603660583, emotion_loss=1.0347338914871216\n",
      "\n",
      "01_20_00:17:49 Seen so far: 383072 samples\n",
      "\n",
      "01_20_00:17:49 --- 1.810697078704834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:51 Training loss at epoch 1 step 11980: 2.8592483758926392\n",
      "\n",
      " This round's valence_loss=1.095754861831665, arousal_loss=0.9619119167327881, emotion_loss=1.2083361148834229\n",
      "\n",
      "01_20_00:17:51 Seen so far: 383392 samples\n",
      "\n",
      "01_20_00:17:51 --- 1.8771977424621582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:53 Training loss at epoch 1 step 11990: 3.137489914894104\n",
      "\n",
      " This round's valence_loss=1.0481853485107422, arousal_loss=0.9405885338783264, emotion_loss=0.8512978553771973\n",
      "\n",
      "01_20_00:17:53 Seen so far: 383712 samples\n",
      "\n",
      "01_20_00:17:53 --- 1.6612434387207031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:54 Training loss at epoch 1 step 12000: 2.7657732725143434\n",
      "\n",
      " This round's valence_loss=1.0486770868301392, arousal_loss=0.8011130094528198, emotion_loss=0.8485300540924072\n",
      "\n",
      "01_20_00:17:54 Seen so far: 384032 samples\n",
      "\n",
      "01_20_00:17:54 --- 1.7667419910430908 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:56 Training loss at epoch 1 step 12010: 3.12798068523407\n",
      "\n",
      " This round's valence_loss=1.152750015258789, arousal_loss=1.0971299409866333, emotion_loss=0.9559677839279175\n",
      "\n",
      "01_20_00:17:56 Seen so far: 384352 samples\n",
      "\n",
      "01_20_00:17:56 --- 1.7571141719818115 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:17:58 Training loss at epoch 1 step 12020: 3.0768479108810425\n",
      "\n",
      " This round's valence_loss=0.8992877006530762, arousal_loss=0.7021563053131104, emotion_loss=0.9078699946403503\n",
      "\n",
      "01_20_00:17:58 Seen so far: 384672 samples\n",
      "\n",
      "01_20_00:17:58 --- 1.7421526908874512 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:00 Training loss at epoch 1 step 12030: 3.0596550941467284\n",
      "\n",
      " This round's valence_loss=1.1226451396942139, arousal_loss=0.9412280917167664, emotion_loss=0.6801693439483643\n",
      "\n",
      "01_20_00:18:00 Seen so far: 384992 samples\n",
      "\n",
      "01_20_00:18:00 --- 1.9581420421600342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:02 Training loss at epoch 1 step 12040: 2.5868896007537843\n",
      "\n",
      " This round's valence_loss=1.3241016864776611, arousal_loss=1.2712509632110596, emotion_loss=1.2521144151687622\n",
      "\n",
      "01_20_00:18:02 Seen so far: 385312 samples\n",
      "\n",
      "01_20_00:18:02 --- 1.8566319942474365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:04 Training loss at epoch 1 step 12050: 2.8204174518585203\n",
      "\n",
      " This round's valence_loss=0.9214745759963989, arousal_loss=0.7069333791732788, emotion_loss=0.9656325578689575\n",
      "\n",
      "01_20_00:18:04 Seen so far: 385632 samples\n",
      "\n",
      "01_20_00:18:04 --- 1.7835299968719482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:05 Training loss at epoch 1 step 12060: 3.3035796880722046\n",
      "\n",
      " This round's valence_loss=1.3338398933410645, arousal_loss=1.2022666931152344, emotion_loss=1.2229385375976562\n",
      "\n",
      "01_20_00:18:05 Seen so far: 385952 samples\n",
      "\n",
      "01_20_00:18:05 --- 1.7130517959594727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:07 Training loss at epoch 1 step 12070: 2.959522819519043\n",
      "\n",
      " This round's valence_loss=1.0867559909820557, arousal_loss=0.9340940713882446, emotion_loss=0.8796439170837402\n",
      "\n",
      "01_20_00:18:07 Seen so far: 386272 samples\n",
      "\n",
      "01_20_00:18:07 --- 1.8435821533203125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:09 Training loss at epoch 1 step 12080: 3.214301252365112\n",
      "\n",
      " This round's valence_loss=0.8988394141197205, arousal_loss=0.5631074905395508, emotion_loss=1.3072091341018677\n",
      "\n",
      "01_20_00:18:09 Seen so far: 386592 samples\n",
      "\n",
      "01_20_00:18:09 --- 1.7370505332946777 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:11 Training loss at epoch 1 step 12090: 3.178901958465576\n",
      "\n",
      " This round's valence_loss=1.4391493797302246, arousal_loss=1.3395037651062012, emotion_loss=1.1600440740585327\n",
      "\n",
      "01_20_00:18:11 Seen so far: 386912 samples\n",
      "\n",
      "01_20_00:18:11 --- 1.6213421821594238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:12 Training loss at epoch 1 step 12100: 2.9840507030487062\n",
      "\n",
      " This round's valence_loss=0.7740360498428345, arousal_loss=0.577306866645813, emotion_loss=0.9553423523902893\n",
      "\n",
      "01_20_00:18:12 Seen so far: 387232 samples\n",
      "\n",
      "01_20_00:18:12 --- 1.742096185684204 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:14 Training loss at epoch 1 step 12110: 3.017875146865845\n",
      "\n",
      " This round's valence_loss=1.2746765613555908, arousal_loss=1.0482878684997559, emotion_loss=0.8613429665565491\n",
      "\n",
      "01_20_00:18:14 Seen so far: 387552 samples\n",
      "\n",
      "01_20_00:18:14 --- 1.6459746360778809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:16 Training loss at epoch 1 step 12120: 3.02093026638031\n",
      "\n",
      " This round's valence_loss=1.533402681350708, arousal_loss=1.479196310043335, emotion_loss=1.0239863395690918\n",
      "\n",
      "01_20_00:18:16 Seen so far: 387872 samples\n",
      "\n",
      "01_20_00:18:16 --- 1.7399156093597412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:17 Training loss at epoch 1 step 12130: 2.991308259963989\n",
      "\n",
      " This round's valence_loss=1.121585726737976, arousal_loss=0.9657142162322998, emotion_loss=1.1293327808380127\n",
      "\n",
      "01_20_00:18:17 Seen so far: 388192 samples\n",
      "\n",
      "01_20_00:18:17 --- 1.8141734600067139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:19 Training loss at epoch 1 step 12140: 2.941859793663025\n",
      "\n",
      " This round's valence_loss=1.075944185256958, arousal_loss=0.9640159606933594, emotion_loss=1.2483887672424316\n",
      "\n",
      "01_20_00:18:19 Seen so far: 388512 samples\n",
      "\n",
      "01_20_00:18:19 --- 1.783186674118042 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:21 Training loss at epoch 1 step 12150: 2.8572441220283507\n",
      "\n",
      " This round's valence_loss=1.516334056854248, arousal_loss=1.3245437145233154, emotion_loss=0.7358508110046387\n",
      "\n",
      "01_20_00:18:21 Seen so far: 388832 samples\n",
      "\n",
      "01_20_00:18:21 --- 1.9134521484375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:23 Training loss at epoch 1 step 12160: 3.3704966068267823\n",
      "\n",
      " This round's valence_loss=1.7864453792572021, arousal_loss=1.548179030418396, emotion_loss=0.8409960269927979\n",
      "\n",
      "01_20_00:18:23 Seen so far: 389152 samples\n",
      "\n",
      "01_20_00:18:23 --- 1.853830337524414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:25 Training loss at epoch 1 step 12170: 2.926809000968933\n",
      "\n",
      " This round's valence_loss=0.7657749652862549, arousal_loss=0.5819672346115112, emotion_loss=0.9111863374710083\n",
      "\n",
      "01_20_00:18:25 Seen so far: 389472 samples\n",
      "\n",
      "01_20_00:18:25 --- 1.7463111877441406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:26 Training loss at epoch 1 step 12180: 2.8204824924468994\n",
      "\n",
      " This round's valence_loss=0.9753713607788086, arousal_loss=0.8110411167144775, emotion_loss=0.43251705169677734\n",
      "\n",
      "01_20_00:18:26 Seen so far: 389792 samples\n",
      "\n",
      "01_20_00:18:26 --- 1.6340034008026123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:29 Training loss at epoch 1 step 12190: 3.0911502599716187\n",
      "\n",
      " This round's valence_loss=0.8689931035041809, arousal_loss=0.6893060803413391, emotion_loss=0.7892525792121887\n",
      "\n",
      "01_20_00:18:29 Seen so far: 390112 samples\n",
      "\n",
      "01_20_00:18:29 --- 2.130643367767334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:30 Training loss at epoch 1 step 12200: 3.0654389381408693\n",
      "\n",
      " This round's valence_loss=1.1234838962554932, arousal_loss=0.9413367509841919, emotion_loss=1.062734842300415\n",
      "\n",
      "01_20_00:18:30 Seen so far: 390432 samples\n",
      "\n",
      "01_20_00:18:30 --- 1.7430369853973389 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:32 Training loss at epoch 1 step 12210: 2.7389721632003785\n",
      "\n",
      " This round's valence_loss=0.7166074514389038, arousal_loss=0.5946694612503052, emotion_loss=1.1292321681976318\n",
      "\n",
      "01_20_00:18:32 Seen so far: 390752 samples\n",
      "\n",
      "01_20_00:18:32 --- 1.853783130645752 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:34 Training loss at epoch 1 step 12220: 3.419076085090637\n",
      "\n",
      " This round's valence_loss=1.0647985935211182, arousal_loss=0.8626210689544678, emotion_loss=0.6656948328018188\n",
      "\n",
      "01_20_00:18:34 Seen so far: 391072 samples\n",
      "\n",
      "01_20_00:18:34 --- 1.5536174774169922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:35 Training loss at epoch 1 step 12230: 3.0146999597549438\n",
      "\n",
      " This round's valence_loss=0.9471095204353333, arousal_loss=0.7979880571365356, emotion_loss=0.779156506061554\n",
      "\n",
      "01_20_00:18:35 Seen so far: 391392 samples\n",
      "\n",
      "01_20_00:18:35 --- 1.7511043548583984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:37 Training loss at epoch 1 step 12240: 2.975634717941284\n",
      "\n",
      " This round's valence_loss=1.2671291828155518, arousal_loss=1.0985219478607178, emotion_loss=0.947007417678833\n",
      "\n",
      "01_20_00:18:37 Seen so far: 391712 samples\n",
      "\n",
      "01_20_00:18:37 --- 1.753664255142212 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:39 Training loss at epoch 1 step 12250: 3.1868972301483156\n",
      "\n",
      " This round's valence_loss=1.5039831399917603, arousal_loss=1.268634557723999, emotion_loss=0.9856972098350525\n",
      "\n",
      "01_20_00:18:39 Seen so far: 392032 samples\n",
      "\n",
      "01_20_00:18:39 --- 1.5983145236968994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:41 Training loss at epoch 1 step 12260: 3.4676203966140746\n",
      "\n",
      " This round's valence_loss=1.4981133937835693, arousal_loss=1.3226525783538818, emotion_loss=1.0527163743972778\n",
      "\n",
      "01_20_00:18:41 Seen so far: 392352 samples\n",
      "\n",
      "01_20_00:18:41 --- 1.9308652877807617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:43 Training loss at epoch 1 step 12270: 2.736596393585205\n",
      "\n",
      " This round's valence_loss=0.8571343421936035, arousal_loss=0.7218389511108398, emotion_loss=0.8783823847770691\n",
      "\n",
      "01_20_00:18:43 Seen so far: 392672 samples\n",
      "\n",
      "01_20_00:18:43 --- 2.1567206382751465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:45 Training loss at epoch 1 step 12280: 2.9883187770843507\n",
      "\n",
      " This round's valence_loss=0.8895734548568726, arousal_loss=0.6914982795715332, emotion_loss=1.037349820137024\n",
      "\n",
      "01_20_00:18:45 Seen so far: 392992 samples\n",
      "\n",
      "01_20_00:18:45 --- 1.8286468982696533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:46 Training loss at epoch 1 step 12290: 3.2672422170639037\n",
      "\n",
      " This round's valence_loss=1.068521499633789, arousal_loss=0.9449875354766846, emotion_loss=0.7354379892349243\n",
      "\n",
      "01_20_00:18:46 Seen so far: 393312 samples\n",
      "\n",
      "01_20_00:18:46 --- 1.708946704864502 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:48 Training loss at epoch 1 step 12300: 2.787230062484741\n",
      "\n",
      " This round's valence_loss=1.207314133644104, arousal_loss=1.0685782432556152, emotion_loss=1.0742478370666504\n",
      "\n",
      "01_20_00:18:48 Seen so far: 393632 samples\n",
      "\n",
      "01_20_00:18:48 --- 1.8156349658966064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:50 Training loss at epoch 1 step 12310: 2.9366403818130493\n",
      "\n",
      " This round's valence_loss=1.0053224563598633, arousal_loss=0.8328408002853394, emotion_loss=0.821258544921875\n",
      "\n",
      "01_20_00:18:50 Seen so far: 393952 samples\n",
      "\n",
      "01_20_00:18:50 --- 1.698432445526123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:52 Training loss at epoch 1 step 12320: 2.7928215742111204\n",
      "\n",
      " This round's valence_loss=0.9072065949440002, arousal_loss=0.7154924869537354, emotion_loss=1.1389315128326416\n",
      "\n",
      "01_20_00:18:52 Seen so far: 394272 samples\n",
      "\n",
      "01_20_00:18:52 --- 1.7144145965576172 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:53 Training loss at epoch 1 step 12330: 3.181186819076538\n",
      "\n",
      " This round's valence_loss=1.5377933979034424, arousal_loss=1.31089186668396, emotion_loss=1.1068984270095825\n",
      "\n",
      "01_20_00:18:53 Seen so far: 394592 samples\n",
      "\n",
      "01_20_00:18:53 --- 1.7158997058868408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:55 Training loss at epoch 1 step 12340: 3.194305920600891\n",
      "\n",
      " This round's valence_loss=0.9687765836715698, arousal_loss=0.8331153392791748, emotion_loss=1.170027494430542\n",
      "\n",
      "01_20_00:18:55 Seen so far: 394912 samples\n",
      "\n",
      "01_20_00:18:55 --- 1.7433128356933594 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:57 Training loss at epoch 1 step 12350: 3.357682800292969\n",
      "\n",
      " This round's valence_loss=1.73868989944458, arousal_loss=1.7324763536453247, emotion_loss=1.2555439472198486\n",
      "\n",
      "01_20_00:18:57 Seen so far: 395232 samples\n",
      "\n",
      "01_20_00:18:57 --- 1.7656149864196777 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:18:59 Training loss at epoch 1 step 12360: 3.058567488193512\n",
      "\n",
      " This round's valence_loss=0.6684005260467529, arousal_loss=0.461922824382782, emotion_loss=0.852645993232727\n",
      "\n",
      "01_20_00:18:59 Seen so far: 395552 samples\n",
      "\n",
      "01_20_00:18:59 --- 1.8643908500671387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:01 Training loss at epoch 1 step 12370: 2.9575225591659544\n",
      "\n",
      " This round's valence_loss=0.4834028482437134, arousal_loss=0.37781822681427, emotion_loss=0.7016956806182861\n",
      "\n",
      "01_20_00:19:01 Seen so far: 395872 samples\n",
      "\n",
      "01_20_00:19:01 --- 1.9478850364685059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:02 Training loss at epoch 1 step 12380: 3.0465812206268312\n",
      "\n",
      " This round's valence_loss=0.7255170941352844, arousal_loss=0.6070961356163025, emotion_loss=1.0291917324066162\n",
      "\n",
      "01_20_00:19:02 Seen so far: 396192 samples\n",
      "\n",
      "01_20_00:19:02 --- 1.8306591510772705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:04 Training loss at epoch 1 step 12390: 2.986559247970581\n",
      "\n",
      " This round's valence_loss=1.1390187740325928, arousal_loss=0.9690345525741577, emotion_loss=1.1246709823608398\n",
      "\n",
      "01_20_00:19:04 Seen so far: 396512 samples\n",
      "\n",
      "01_20_00:19:04 --- 1.7613732814788818 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:06 Training loss at epoch 1 step 12400: 2.880180263519287\n",
      "\n",
      " This round's valence_loss=1.23213791847229, arousal_loss=1.0494599342346191, emotion_loss=0.9028673768043518\n",
      "\n",
      "01_20_00:19:06 Seen so far: 396832 samples\n",
      "\n",
      "01_20_00:19:06 --- 1.8209218978881836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:08 Training loss at epoch 1 step 12410: 3.0819265365600588\n",
      "\n",
      " This round's valence_loss=1.0909481048583984, arousal_loss=0.9637270569801331, emotion_loss=1.247654676437378\n",
      "\n",
      "01_20_00:19:08 Seen so far: 397152 samples\n",
      "\n",
      "01_20_00:19:08 --- 1.846405029296875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:09 Training loss at epoch 1 step 12420: 2.947356867790222\n",
      "\n",
      " This round's valence_loss=0.6621809601783752, arousal_loss=0.48947566747665405, emotion_loss=0.9860367774963379\n",
      "\n",
      "01_20_00:19:09 Seen so far: 397472 samples\n",
      "\n",
      "01_20_00:19:09 --- 1.581191062927246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:11 Training loss at epoch 1 step 12430: 2.9442282915115356\n",
      "\n",
      " This round's valence_loss=1.1231378316879272, arousal_loss=0.9391456246376038, emotion_loss=1.1602630615234375\n",
      "\n",
      "01_20_00:19:11 Seen so far: 397792 samples\n",
      "\n",
      "01_20_00:19:11 --- 1.7638001441955566 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:13 Training loss at epoch 1 step 12440: 2.6430493354797364\n",
      "\n",
      " This round's valence_loss=1.432161569595337, arousal_loss=1.3512271642684937, emotion_loss=0.9581082463264465\n",
      "\n",
      "01_20_00:19:13 Seen so far: 398112 samples\n",
      "\n",
      "01_20_00:19:13 --- 1.8519563674926758 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:15 Training loss at epoch 1 step 12450: 3.149751901626587\n",
      "\n",
      " This round's valence_loss=1.3586821556091309, arousal_loss=1.2411398887634277, emotion_loss=1.0112683773040771\n",
      "\n",
      "01_20_00:19:15 Seen so far: 398432 samples\n",
      "\n",
      "01_20_00:19:15 --- 1.7791688442230225 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:17 Training loss at epoch 1 step 12460: 3.0218286991119383\n",
      "\n",
      " This round's valence_loss=0.7994893789291382, arousal_loss=0.7298901081085205, emotion_loss=0.9062444567680359\n",
      "\n",
      "01_20_00:19:17 Seen so far: 398752 samples\n",
      "\n",
      "01_20_00:19:17 --- 1.94321870803833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:19 Training loss at epoch 1 step 12470: 3.070208764076233\n",
      "\n",
      " This round's valence_loss=1.1502478122711182, arousal_loss=0.9318299293518066, emotion_loss=1.0365149974822998\n",
      "\n",
      "01_20_00:19:19 Seen so far: 399072 samples\n",
      "\n",
      "01_20_00:19:19 --- 1.7114593982696533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:20 Training loss at epoch 1 step 12480: 3.2370330572128294\n",
      "\n",
      " This round's valence_loss=0.7412561178207397, arousal_loss=0.5886902809143066, emotion_loss=1.0644453763961792\n",
      "\n",
      "01_20_00:19:20 Seen so far: 399392 samples\n",
      "\n",
      "01_20_00:19:20 --- 1.7729980945587158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:22 Training loss at epoch 1 step 12490: 3.5166625022888183\n",
      "\n",
      " This round's valence_loss=1.4964911937713623, arousal_loss=1.2798871994018555, emotion_loss=0.6657404899597168\n",
      "\n",
      "01_20_00:19:22 Seen so far: 399712 samples\n",
      "\n",
      "01_20_00:19:22 --- 1.7278144359588623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:24 Training loss at epoch 1 step 12500: 3.230276322364807\n",
      "\n",
      " This round's valence_loss=1.2336392402648926, arousal_loss=1.1122848987579346, emotion_loss=1.1389272212982178\n",
      "\n",
      "01_20_00:19:24 Seen so far: 400032 samples\n",
      "\n",
      "01_20_00:19:24 --- 1.7290959358215332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:25 Training loss at epoch 1 step 12510: 2.9880969166755675\n",
      "\n",
      " This round's valence_loss=1.5172057151794434, arousal_loss=1.332892656326294, emotion_loss=1.1091742515563965\n",
      "\n",
      "01_20_00:19:25 Seen so far: 400352 samples\n",
      "\n",
      "01_20_00:19:25 --- 1.6939287185668945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:27 Training loss at epoch 1 step 12520: 2.6649159669876097\n",
      "\n",
      " This round's valence_loss=0.8571240901947021, arousal_loss=0.6862450838088989, emotion_loss=0.8979617357254028\n",
      "\n",
      "01_20_00:19:27 Seen so far: 400672 samples\n",
      "\n",
      "01_20_00:19:27 --- 1.8432297706604004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:29 Training loss at epoch 1 step 12530: 3.135677361488342\n",
      "\n",
      " This round's valence_loss=0.8974952101707458, arousal_loss=0.8321139216423035, emotion_loss=1.121751070022583\n",
      "\n",
      "01_20_00:19:29 Seen so far: 400992 samples\n",
      "\n",
      "01_20_00:19:29 --- 1.6766235828399658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:31 Training loss at epoch 1 step 12540: 3.0402465581893923\n",
      "\n",
      " This round's valence_loss=1.1002063751220703, arousal_loss=0.9241111278533936, emotion_loss=0.8505966663360596\n",
      "\n",
      "01_20_00:19:31 Seen so far: 401312 samples\n",
      "\n",
      "01_20_00:19:31 --- 1.7949459552764893 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:33 Training loss at epoch 1 step 12550: 2.9172423601150514\n",
      "\n",
      " This round's valence_loss=1.4414637088775635, arousal_loss=1.4012908935546875, emotion_loss=1.1848585605621338\n",
      "\n",
      "01_20_00:19:33 Seen so far: 401632 samples\n",
      "\n",
      "01_20_00:19:33 --- 1.7924320697784424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:34 Training loss at epoch 1 step 12560: 2.8869996547698973\n",
      "\n",
      " This round's valence_loss=1.5528273582458496, arousal_loss=1.4449121952056885, emotion_loss=1.0565335750579834\n",
      "\n",
      "01_20_00:19:34 Seen so far: 401952 samples\n",
      "\n",
      "01_20_00:19:34 --- 1.8019301891326904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:36 Training loss at epoch 1 step 12570: 2.998790144920349\n",
      "\n",
      " This round's valence_loss=1.0991854667663574, arousal_loss=0.9987396001815796, emotion_loss=1.2923394441604614\n",
      "\n",
      "01_20_00:19:36 Seen so far: 402272 samples\n",
      "\n",
      "01_20_00:19:36 --- 1.8182752132415771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:38 Training loss at epoch 1 step 12580: 2.9085275888442994\n",
      "\n",
      " This round's valence_loss=0.7289060354232788, arousal_loss=0.6254415512084961, emotion_loss=1.1260299682617188\n",
      "\n",
      "01_20_00:19:38 Seen so far: 402592 samples\n",
      "\n",
      "01_20_00:19:38 --- 1.8410093784332275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:40 Training loss at epoch 1 step 12590: 3.194052982330322\n",
      "\n",
      " This round's valence_loss=0.837769627571106, arousal_loss=0.743121862411499, emotion_loss=1.1850996017456055\n",
      "\n",
      "01_20_00:19:40 Seen so far: 402912 samples\n",
      "\n",
      "01_20_00:19:40 --- 1.613701343536377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:41 Training loss at epoch 1 step 12600: 3.165266513824463\n",
      "\n",
      " This round's valence_loss=0.679735541343689, arousal_loss=0.4347628355026245, emotion_loss=0.986458957195282\n",
      "\n",
      "01_20_00:19:41 Seen so far: 403232 samples\n",
      "\n",
      "01_20_00:19:41 --- 1.6525318622589111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:43 Training loss at epoch 1 step 12610: 3.1121071338653565\n",
      "\n",
      " This round's valence_loss=1.1744129657745361, arousal_loss=1.080757975578308, emotion_loss=0.8872723579406738\n",
      "\n",
      "01_20_00:19:43 Seen so far: 403552 samples\n",
      "\n",
      "01_20_00:19:43 --- 1.733696460723877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:45 Training loss at epoch 1 step 12620: 2.903120017051697\n",
      "\n",
      " This round's valence_loss=1.2309634685516357, arousal_loss=1.0786455869674683, emotion_loss=1.1793856620788574\n",
      "\n",
      "01_20_00:19:45 Seen so far: 403872 samples\n",
      "\n",
      "01_20_00:19:45 --- 1.7282969951629639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:47 Training loss at epoch 1 step 12630: 2.907995104789734\n",
      "\n",
      " This round's valence_loss=1.3388817310333252, arousal_loss=1.181950330734253, emotion_loss=0.943388819694519\n",
      "\n",
      "01_20_00:19:47 Seen so far: 404192 samples\n",
      "\n",
      "01_20_00:19:47 --- 1.794389009475708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:48 Training loss at epoch 1 step 12640: 2.9330235958099364\n",
      "\n",
      " This round's valence_loss=1.0722476243972778, arousal_loss=0.9593716859817505, emotion_loss=0.7218424081802368\n",
      "\n",
      "01_20_00:19:48 Seen so far: 404512 samples\n",
      "\n",
      "01_20_00:19:48 --- 1.7542805671691895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:50 Training loss at epoch 1 step 12650: 3.2083988428115844\n",
      "\n",
      " This round's valence_loss=1.4053288698196411, arousal_loss=1.3357203006744385, emotion_loss=0.8068972229957581\n",
      "\n",
      "01_20_00:19:50 Seen so far: 404832 samples\n",
      "\n",
      "01_20_00:19:50 --- 1.7367727756500244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:52 Training loss at epoch 1 step 12660: 3.035332274436951\n",
      "\n",
      " This round's valence_loss=1.4903864860534668, arousal_loss=1.3517696857452393, emotion_loss=0.87120121717453\n",
      "\n",
      "01_20_00:19:52 Seen so far: 405152 samples\n",
      "\n",
      "01_20_00:19:52 --- 1.9501066207885742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:54 Training loss at epoch 1 step 12670: 2.9875680685043333\n",
      "\n",
      " This round's valence_loss=1.3290596008300781, arousal_loss=1.2020851373672485, emotion_loss=0.7365097999572754\n",
      "\n",
      "01_20_00:19:54 Seen so far: 405472 samples\n",
      "\n",
      "01_20_00:19:54 --- 1.7843842506408691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:56 Training loss at epoch 1 step 12680: 3.054011082649231\n",
      "\n",
      " This round's valence_loss=1.1930173635482788, arousal_loss=1.1178789138793945, emotion_loss=1.1115806102752686\n",
      "\n",
      "01_20_00:19:56 Seen so far: 405792 samples\n",
      "\n",
      "01_20_00:19:56 --- 1.8953475952148438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:19:58 Training loss at epoch 1 step 12690: 3.170501732826233\n",
      "\n",
      " This round's valence_loss=1.0450483560562134, arousal_loss=1.0220770835876465, emotion_loss=0.9931817650794983\n",
      "\n",
      "01_20_00:19:58 Seen so far: 406112 samples\n",
      "\n",
      "01_20_00:19:58 --- 1.8908207416534424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:00 Training loss at epoch 1 step 12700: 2.8993939757347107\n",
      "\n",
      " This round's valence_loss=1.2250559329986572, arousal_loss=1.074905514717102, emotion_loss=1.1699695587158203\n",
      "\n",
      "01_20_00:20:00 Seen so far: 406432 samples\n",
      "\n",
      "01_20_00:20:00 --- 1.9293665885925293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:11 Training loss at epoch 2 step 0: 3.1633201360702516\n",
      "\n",
      " This round's valence_loss=1.7539684772491455, arousal_loss=1.6943268775939941, emotion_loss=1.1946526765823364\n",
      "\n",
      "01_20_00:20:11 Seen so far: 32 samples\n",
      "\n",
      "01_20_00:20:11 --- 11.414939641952515 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:13 Training loss at epoch 2 step 10: 2.9441755056381225\n",
      "\n",
      " This round's valence_loss=0.7429714202880859, arousal_loss=0.5690258741378784, emotion_loss=0.6510781049728394\n",
      "\n",
      "01_20_00:20:13 Seen so far: 352 samples\n",
      "\n",
      "01_20_00:20:13 --- 1.9895479679107666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:15 Training loss at epoch 2 step 20: 3.1380717754364014\n",
      "\n",
      " This round's valence_loss=1.1344971656799316, arousal_loss=0.979147732257843, emotion_loss=0.7356261014938354\n",
      "\n",
      "01_20_00:20:15 Seen so far: 672 samples\n",
      "\n",
      "01_20_00:20:15 --- 1.8548526763916016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:17 Training loss at epoch 2 step 30: 3.1356435894966124\n",
      "\n",
      " This round's valence_loss=1.1073822975158691, arousal_loss=0.9587273001670837, emotion_loss=1.168799877166748\n",
      "\n",
      "01_20_00:20:17 Seen so far: 992 samples\n",
      "\n",
      "01_20_00:20:17 --- 1.7970173358917236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:18 Training loss at epoch 2 step 40: 3.1728577852249145\n",
      "\n",
      " This round's valence_loss=0.9624417424201965, arousal_loss=0.8512842655181885, emotion_loss=1.0870078802108765\n",
      "\n",
      "01_20_00:20:18 Seen so far: 1312 samples\n",
      "\n",
      "01_20_00:20:18 --- 1.9312360286712646 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:20 Training loss at epoch 2 step 50: 2.8451228380203246\n",
      "\n",
      " This round's valence_loss=1.338747501373291, arousal_loss=1.217984914779663, emotion_loss=0.9334551095962524\n",
      "\n",
      "01_20_00:20:20 Seen so far: 1632 samples\n",
      "\n",
      "01_20_00:20:20 --- 1.80513596534729 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:22 Training loss at epoch 2 step 60: 3.0691534757614134\n",
      "\n",
      " This round's valence_loss=0.9459389448165894, arousal_loss=0.8681762218475342, emotion_loss=0.8106762170791626\n",
      "\n",
      "01_20_00:20:22 Seen so far: 1952 samples\n",
      "\n",
      "01_20_00:20:22 --- 1.833641767501831 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:24 Training loss at epoch 2 step 70: 2.691547393798828\n",
      "\n",
      " This round's valence_loss=0.5911442041397095, arousal_loss=0.3467450439929962, emotion_loss=0.7566598057746887\n",
      "\n",
      "01_20_00:20:24 Seen so far: 2272 samples\n",
      "\n",
      "01_20_00:20:24 --- 1.7979657649993896 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:26 Training loss at epoch 2 step 80: 3.2362929582595825\n",
      "\n",
      " This round's valence_loss=1.80056631565094, arousal_loss=1.7186017036437988, emotion_loss=0.9838101863861084\n",
      "\n",
      "01_20_00:20:26 Seen so far: 2592 samples\n",
      "\n",
      "01_20_00:20:26 --- 1.8193860054016113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:27 Training loss at epoch 2 step 90: 2.804320478439331\n",
      "\n",
      " This round's valence_loss=1.3198822736740112, arousal_loss=1.1760468482971191, emotion_loss=0.6729668974876404\n",
      "\n",
      "01_20_00:20:27 Seen so far: 2912 samples\n",
      "\n",
      "01_20_00:20:27 --- 1.6806843280792236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:29 Training loss at epoch 2 step 100: 2.9808011770248415\n",
      "\n",
      " This round's valence_loss=0.5946910381317139, arousal_loss=0.48823094367980957, emotion_loss=0.987612783908844\n",
      "\n",
      "01_20_00:20:29 Seen so far: 3232 samples\n",
      "\n",
      "01_20_00:20:29 --- 1.777404546737671 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:31 Training loss at epoch 2 step 110: 3.17290256023407\n",
      "\n",
      " This round's valence_loss=1.2453818321228027, arousal_loss=1.0914642810821533, emotion_loss=0.9977177381515503\n",
      "\n",
      "01_20_00:20:31 Seen so far: 3552 samples\n",
      "\n",
      "01_20_00:20:31 --- 1.863224983215332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:33 Training loss at epoch 2 step 120: 3.0961556434631348\n",
      "\n",
      " This round's valence_loss=1.0683540105819702, arousal_loss=0.9767191410064697, emotion_loss=1.584191918373108\n",
      "\n",
      "01_20_00:20:33 Seen so far: 3872 samples\n",
      "\n",
      "01_20_00:20:33 --- 1.7908051013946533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:34 Training loss at epoch 2 step 130: 2.8923079490661623\n",
      "\n",
      " This round's valence_loss=0.5926175713539124, arousal_loss=0.34391093254089355, emotion_loss=1.0748567581176758\n",
      "\n",
      "01_20_00:20:34 Seen so far: 4192 samples\n",
      "\n",
      "01_20_00:20:34 --- 1.6154811382293701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:36 Training loss at epoch 2 step 140: 3.1250773429870606\n",
      "\n",
      " This round's valence_loss=1.3393096923828125, arousal_loss=1.229905366897583, emotion_loss=1.0405584573745728\n",
      "\n",
      "01_20_00:20:36 Seen so far: 4512 samples\n",
      "\n",
      "01_20_00:20:36 --- 1.9526515007019043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:38 Training loss at epoch 2 step 150: 2.9426931142807007\n",
      "\n",
      " This round's valence_loss=0.836531400680542, arousal_loss=0.7143419981002808, emotion_loss=0.9774973392486572\n",
      "\n",
      "01_20_00:20:38 Seen so far: 4832 samples\n",
      "\n",
      "01_20_00:20:38 --- 1.742952585220337 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:40 Training loss at epoch 2 step 160: 2.912750792503357\n",
      "\n",
      " This round's valence_loss=1.0153260231018066, arousal_loss=0.9035464525222778, emotion_loss=1.0533801317214966\n",
      "\n",
      "01_20_00:20:40 Seen so far: 5152 samples\n",
      "\n",
      "01_20_00:20:40 --- 1.8894903659820557 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:42 Training loss at epoch 2 step 170: 3.191253137588501\n",
      "\n",
      " This round's valence_loss=1.3626375198364258, arousal_loss=1.2096035480499268, emotion_loss=0.9290251135826111\n",
      "\n",
      "01_20_00:20:42 Seen so far: 5472 samples\n",
      "\n",
      "01_20_00:20:42 --- 1.7727227210998535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:44 Training loss at epoch 2 step 180: 3.125776243209839\n",
      "\n",
      " This round's valence_loss=1.0766661167144775, arousal_loss=0.9615427255630493, emotion_loss=1.08914315700531\n",
      "\n",
      "01_20_00:20:44 Seen so far: 5792 samples\n",
      "\n",
      "01_20_00:20:44 --- 1.713172197341919 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:45 Training loss at epoch 2 step 190: 3.0215422391891478\n",
      "\n",
      " This round's valence_loss=1.1655902862548828, arousal_loss=0.9568901062011719, emotion_loss=0.63620924949646\n",
      "\n",
      "01_20_00:20:45 Seen so far: 6112 samples\n",
      "\n",
      "01_20_00:20:45 --- 1.9233062267303467 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:47 Training loss at epoch 2 step 200: 2.8757511615753173\n",
      "\n",
      " This round's valence_loss=0.966942548751831, arousal_loss=0.848299503326416, emotion_loss=1.1534109115600586\n",
      "\n",
      "01_20_00:20:47 Seen so far: 6432 samples\n",
      "\n",
      "01_20_00:20:47 --- 1.7692668437957764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:49 Training loss at epoch 2 step 210: 3.0533072471618654\n",
      "\n",
      " This round's valence_loss=1.2303824424743652, arousal_loss=1.103319525718689, emotion_loss=0.9424960613250732\n",
      "\n",
      "01_20_00:20:49 Seen so far: 6752 samples\n",
      "\n",
      "01_20_00:20:49 --- 1.6727609634399414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:51 Training loss at epoch 2 step 220: 2.6841865301132204\n",
      "\n",
      " This round's valence_loss=0.4893447160720825, arousal_loss=0.33275407552719116, emotion_loss=0.7000765800476074\n",
      "\n",
      "01_20_00:20:51 Seen so far: 7072 samples\n",
      "\n",
      "01_20_00:20:51 --- 1.7938423156738281 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:53 Training loss at epoch 2 step 230: 2.899991488456726\n",
      "\n",
      " This round's valence_loss=0.9184496402740479, arousal_loss=0.6808057427406311, emotion_loss=0.6728243827819824\n",
      "\n",
      "01_20_00:20:53 Seen so far: 7392 samples\n",
      "\n",
      "01_20_00:20:53 --- 1.8294401168823242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:54 Training loss at epoch 2 step 240: 2.989240837097168\n",
      "\n",
      " This round's valence_loss=1.1500320434570312, arousal_loss=0.969250500202179, emotion_loss=0.9497010111808777\n",
      "\n",
      "01_20_00:20:54 Seen so far: 7712 samples\n",
      "\n",
      "01_20_00:20:54 --- 1.7147252559661865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:56 Training loss at epoch 2 step 250: 3.213395833969116\n",
      "\n",
      " This round's valence_loss=1.324167013168335, arousal_loss=1.259169101715088, emotion_loss=1.2889561653137207\n",
      "\n",
      "01_20_00:20:56 Seen so far: 8032 samples\n",
      "\n",
      "01_20_00:20:56 --- 1.7335882186889648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:58 Training loss at epoch 2 step 260: 2.9864116668701173\n",
      "\n",
      " This round's valence_loss=0.9508993625640869, arousal_loss=0.8615962266921997, emotion_loss=0.9494266510009766\n",
      "\n",
      "01_20_00:20:58 Seen so far: 8352 samples\n",
      "\n",
      "01_20_00:20:58 --- 1.7493422031402588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:20:59 Training loss at epoch 2 step 270: 3.0712652802467346\n",
      "\n",
      " This round's valence_loss=1.7648577690124512, arousal_loss=1.6534264087677002, emotion_loss=0.919608473777771\n",
      "\n",
      "01_20_00:20:59 Seen so far: 8672 samples\n",
      "\n",
      "01_20_00:20:59 --- 1.6351542472839355 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:01 Training loss at epoch 2 step 280: 2.9530513286590576\n",
      "\n",
      " This round's valence_loss=1.0167293548583984, arousal_loss=0.8277156352996826, emotion_loss=0.8042148351669312\n",
      "\n",
      "01_20_00:21:01 Seen so far: 8992 samples\n",
      "\n",
      "01_20_00:21:01 --- 1.6926379203796387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:03 Training loss at epoch 2 step 290: 3.052481746673584\n",
      "\n",
      " This round's valence_loss=1.07288658618927, arousal_loss=1.013096570968628, emotion_loss=1.010556936264038\n",
      "\n",
      "01_20_00:21:03 Seen so far: 9312 samples\n",
      "\n",
      "01_20_00:21:03 --- 1.8449971675872803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:05 Training loss at epoch 2 step 300: 2.8843855619430543\n",
      "\n",
      " This round's valence_loss=1.111993432044983, arousal_loss=0.9801469445228577, emotion_loss=0.8352057933807373\n",
      "\n",
      "01_20_00:21:05 Seen so far: 9632 samples\n",
      "\n",
      "01_20_00:21:05 --- 1.930459976196289 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:07 Training loss at epoch 2 step 310: 3.021484851837158\n",
      "\n",
      " This round's valence_loss=0.9450437426567078, arousal_loss=0.8165735602378845, emotion_loss=0.7641562223434448\n",
      "\n",
      "01_20_00:21:07 Seen so far: 9952 samples\n",
      "\n",
      "01_20_00:21:07 --- 1.756957769393921 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:08 Training loss at epoch 2 step 320: 3.1188777923583983\n",
      "\n",
      " This round's valence_loss=0.8341436982154846, arousal_loss=0.6941229701042175, emotion_loss=0.8301662802696228\n",
      "\n",
      "01_20_00:21:08 Seen so far: 10272 samples\n",
      "\n",
      "01_20_00:21:08 --- 1.8439850807189941 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:10 Training loss at epoch 2 step 330: 2.9196892261505125\n",
      "\n",
      " This round's valence_loss=0.9919847249984741, arousal_loss=0.7934256792068481, emotion_loss=1.0307918787002563\n",
      "\n",
      "01_20_00:21:10 Seen so far: 10592 samples\n",
      "\n",
      "01_20_00:21:10 --- 1.7582731246948242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:12 Training loss at epoch 2 step 340: 3.0954410791397096\n",
      "\n",
      " This round's valence_loss=1.2597695589065552, arousal_loss=1.0651419162750244, emotion_loss=0.9778623580932617\n",
      "\n",
      "01_20_00:21:12 Seen so far: 10912 samples\n",
      "\n",
      "01_20_00:21:12 --- 1.788172721862793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:14 Training loss at epoch 2 step 350: 2.930648159980774\n",
      "\n",
      " This round's valence_loss=1.3003190755844116, arousal_loss=1.2097212076187134, emotion_loss=1.0873674154281616\n",
      "\n",
      "01_20_00:21:14 Seen so far: 11232 samples\n",
      "\n",
      "01_20_00:21:14 --- 1.7447142601013184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:15 Training loss at epoch 2 step 360: 3.370934581756592\n",
      "\n",
      " This round's valence_loss=1.0920770168304443, arousal_loss=1.011826992034912, emotion_loss=1.163413166999817\n",
      "\n",
      "01_20_00:21:15 Seen so far: 11552 samples\n",
      "\n",
      "01_20_00:21:15 --- 1.6561779975891113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:17 Training loss at epoch 2 step 370: 3.127849245071411\n",
      "\n",
      " This round's valence_loss=1.3585052490234375, arousal_loss=1.2288494110107422, emotion_loss=0.9564616680145264\n",
      "\n",
      "01_20_00:21:17 Seen so far: 11872 samples\n",
      "\n",
      "01_20_00:21:17 --- 1.8694891929626465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:19 Training loss at epoch 2 step 380: 3.210534358024597\n",
      "\n",
      " This round's valence_loss=1.1265443563461304, arousal_loss=0.9340628981590271, emotion_loss=1.0937409400939941\n",
      "\n",
      "01_20_00:21:19 Seen so far: 12192 samples\n",
      "\n",
      "01_20_00:21:19 --- 1.7722651958465576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:21 Training loss at epoch 2 step 390: 3.09531683921814\n",
      "\n",
      " This round's valence_loss=1.1653964519500732, arousal_loss=0.9798347353935242, emotion_loss=1.2129969596862793\n",
      "\n",
      "01_20_00:21:21 Seen so far: 12512 samples\n",
      "\n",
      "01_20_00:21:21 --- 1.683257818222046 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:22 Training loss at epoch 2 step 400: 2.787531590461731\n",
      "\n",
      " This round's valence_loss=1.004611611366272, arousal_loss=0.8791506886482239, emotion_loss=0.6448990702629089\n",
      "\n",
      "01_20_00:21:22 Seen so far: 12832 samples\n",
      "\n",
      "01_20_00:21:22 --- 1.695258378982544 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:24 Training loss at epoch 2 step 410: 3.0155463457107543\n",
      "\n",
      " This round's valence_loss=1.2399457693099976, arousal_loss=1.087191104888916, emotion_loss=1.2382019758224487\n",
      "\n",
      "01_20_00:21:24 Seen so far: 13152 samples\n",
      "\n",
      "01_20_00:21:24 --- 1.778472661972046 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:26 Training loss at epoch 2 step 420: 3.395061230659485\n",
      "\n",
      " This round's valence_loss=1.109292984008789, arousal_loss=0.932716429233551, emotion_loss=0.931060791015625\n",
      "\n",
      "01_20_00:21:26 Seen so far: 13472 samples\n",
      "\n",
      "01_20_00:21:26 --- 1.8031227588653564 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:28 Training loss at epoch 2 step 430: 2.7653823852539063\n",
      "\n",
      " This round's valence_loss=0.7453902959823608, arousal_loss=0.5786693096160889, emotion_loss=1.3976322412490845\n",
      "\n",
      "01_20_00:21:28 Seen so far: 13792 samples\n",
      "\n",
      "01_20_00:21:28 --- 1.7610630989074707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:29 Training loss at epoch 2 step 440: 2.890216064453125\n",
      "\n",
      " This round's valence_loss=0.4360049068927765, arousal_loss=0.2356070578098297, emotion_loss=0.6698201894760132\n",
      "\n",
      "01_20_00:21:29 Seen so far: 14112 samples\n",
      "\n",
      "01_20_00:21:29 --- 1.7197520732879639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:31 Training loss at epoch 2 step 450: 3.2279481291770935\n",
      "\n",
      " This round's valence_loss=1.3742797374725342, arousal_loss=1.2662605047225952, emotion_loss=1.5755269527435303\n",
      "\n",
      "01_20_00:21:31 Seen so far: 14432 samples\n",
      "\n",
      "01_20_00:21:31 --- 1.6994409561157227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:33 Training loss at epoch 2 step 460: 3.214638423919678\n",
      "\n",
      " This round's valence_loss=1.0632827281951904, arousal_loss=0.9509072303771973, emotion_loss=0.792190432548523\n",
      "\n",
      "01_20_00:21:33 Seen so far: 14752 samples\n",
      "\n",
      "01_20_00:21:33 --- 1.6398072242736816 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:35 Training loss at epoch 2 step 470: 3.2802061557769777\n",
      "\n",
      " This round's valence_loss=1.2098796367645264, arousal_loss=1.071061134338379, emotion_loss=0.8880105018615723\n",
      "\n",
      "01_20_00:21:35 Seen so far: 15072 samples\n",
      "\n",
      "01_20_00:21:35 --- 1.688856840133667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:36 Training loss at epoch 2 step 480: 2.960046422481537\n",
      "\n",
      " This round's valence_loss=0.8347904086112976, arousal_loss=0.7791740894317627, emotion_loss=1.4747898578643799\n",
      "\n",
      "01_20_00:21:36 Seen so far: 15392 samples\n",
      "\n",
      "01_20_00:21:36 --- 1.771500587463379 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:38 Training loss at epoch 2 step 490: 2.758542561531067\n",
      "\n",
      " This round's valence_loss=1.0060367584228516, arousal_loss=0.8046543598175049, emotion_loss=1.1088836193084717\n",
      "\n",
      "01_20_00:21:38 Seen so far: 15712 samples\n",
      "\n",
      "01_20_00:21:38 --- 1.658149242401123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:40 Training loss at epoch 2 step 500: 3.200143241882324\n",
      "\n",
      " This round's valence_loss=0.7779747247695923, arousal_loss=0.5993068218231201, emotion_loss=0.9545891284942627\n",
      "\n",
      "01_20_00:21:40 Seen so far: 16032 samples\n",
      "\n",
      "01_20_00:21:40 --- 1.995089054107666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:42 Training loss at epoch 2 step 510: 3.2591381549835203\n",
      "\n",
      " This round's valence_loss=1.5050244331359863, arousal_loss=1.3385009765625, emotion_loss=0.8839641213417053\n",
      "\n",
      "01_20_00:21:42 Seen so far: 16352 samples\n",
      "\n",
      "01_20_00:21:42 --- 1.838688850402832 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:44 Training loss at epoch 2 step 520: 3.0915260791778563\n",
      "\n",
      " This round's valence_loss=1.0155115127563477, arousal_loss=0.8208214044570923, emotion_loss=0.75208979845047\n",
      "\n",
      "01_20_00:21:44 Seen so far: 16672 samples\n",
      "\n",
      "01_20_00:21:44 --- 1.7899951934814453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:45 Training loss at epoch 2 step 530: 2.916053283214569\n",
      "\n",
      " This round's valence_loss=0.850508987903595, arousal_loss=0.7264036536216736, emotion_loss=1.3846633434295654\n",
      "\n",
      "01_20_00:21:45 Seen so far: 16992 samples\n",
      "\n",
      "01_20_00:21:45 --- 1.7999017238616943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:47 Training loss at epoch 2 step 540: 3.2558881998062135\n",
      "\n",
      " This round's valence_loss=1.1357240676879883, arousal_loss=0.9941638112068176, emotion_loss=0.9474666714668274\n",
      "\n",
      "01_20_00:21:47 Seen so far: 17312 samples\n",
      "\n",
      "01_20_00:21:47 --- 1.7823543548583984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:49 Training loss at epoch 2 step 550: 3.2073050260543825\n",
      "\n",
      " This round's valence_loss=0.7350518703460693, arousal_loss=0.6081938743591309, emotion_loss=1.1216695308685303\n",
      "\n",
      "01_20_00:21:49 Seen so far: 17632 samples\n",
      "\n",
      "01_20_00:21:49 --- 1.9293015003204346 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:51 Training loss at epoch 2 step 560: 2.7664509296417235\n",
      "\n",
      " This round's valence_loss=0.9069108963012695, arousal_loss=0.7541540265083313, emotion_loss=0.6186023950576782\n",
      "\n",
      "01_20_00:21:51 Seen so far: 17952 samples\n",
      "\n",
      "01_20_00:21:51 --- 1.8406076431274414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:53 Training loss at epoch 2 step 570: 2.7640798091888428\n",
      "\n",
      " This round's valence_loss=0.8720820546150208, arousal_loss=0.6867931485176086, emotion_loss=0.9112520813941956\n",
      "\n",
      "01_20_00:21:53 Seen so far: 18272 samples\n",
      "\n",
      "01_20_00:21:53 --- 1.7171673774719238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:54 Training loss at epoch 2 step 580: 2.914316987991333\n",
      "\n",
      " This round's valence_loss=1.2703050374984741, arousal_loss=1.1271750926971436, emotion_loss=1.088698148727417\n",
      "\n",
      "01_20_00:21:54 Seen so far: 18592 samples\n",
      "\n",
      "01_20_00:21:54 --- 1.8254289627075195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:56 Training loss at epoch 2 step 590: 2.9547224283218383\n",
      "\n",
      " This round's valence_loss=1.220383644104004, arousal_loss=1.0662070512771606, emotion_loss=1.0744719505310059\n",
      "\n",
      "01_20_00:21:56 Seen so far: 18912 samples\n",
      "\n",
      "01_20_00:21:56 --- 1.8317830562591553 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:21:58 Training loss at epoch 2 step 600: 2.999071741104126\n",
      "\n",
      " This round's valence_loss=1.1717848777770996, arousal_loss=1.0904314517974854, emotion_loss=1.1822776794433594\n",
      "\n",
      "01_20_00:21:58 Seen so far: 19232 samples\n",
      "\n",
      "01_20_00:21:58 --- 1.6680288314819336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:00 Training loss at epoch 2 step 610: 3.176417875289917\n",
      "\n",
      " This round's valence_loss=0.7342380285263062, arousal_loss=0.6363842487335205, emotion_loss=1.0410840511322021\n",
      "\n",
      "01_20_00:22:00 Seen so far: 19552 samples\n",
      "\n",
      "01_20_00:22:00 --- 1.7934107780456543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:02 Training loss at epoch 2 step 620: 2.9560909986495973\n",
      "\n",
      " This round's valence_loss=1.002777099609375, arousal_loss=0.9482898116111755, emotion_loss=1.2066353559494019\n",
      "\n",
      "01_20_00:22:02 Seen so far: 19872 samples\n",
      "\n",
      "01_20_00:22:02 --- 1.772386074066162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:03 Training loss at epoch 2 step 630: 3.077620840072632\n",
      "\n",
      " This round's valence_loss=1.5402460098266602, arousal_loss=1.4522650241851807, emotion_loss=1.1462161540985107\n",
      "\n",
      "01_20_00:22:03 Seen so far: 20192 samples\n",
      "\n",
      "01_20_00:22:03 --- 1.5917537212371826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:05 Training loss at epoch 2 step 640: 2.875639355182648\n",
      "\n",
      " This round's valence_loss=0.7066348791122437, arousal_loss=0.494148850440979, emotion_loss=1.3704578876495361\n",
      "\n",
      "01_20_00:22:05 Seen so far: 20512 samples\n",
      "\n",
      "01_20_00:22:05 --- 1.7488188743591309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:07 Training loss at epoch 2 step 650: 3.2189420461654663\n",
      "\n",
      " This round's valence_loss=0.8844655752182007, arousal_loss=0.7300659418106079, emotion_loss=1.1619257926940918\n",
      "\n",
      "01_20_00:22:07 Seen so far: 20832 samples\n",
      "\n",
      "01_20_00:22:07 --- 1.7096738815307617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:08 Training loss at epoch 2 step 660: 2.9092921733856203\n",
      "\n",
      " This round's valence_loss=1.0480525493621826, arousal_loss=0.9556803703308105, emotion_loss=0.8219122886657715\n",
      "\n",
      "01_20_00:22:08 Seen so far: 21152 samples\n",
      "\n",
      "01_20_00:22:08 --- 1.753539800643921 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:10 Training loss at epoch 2 step 670: 3.1631163954734802\n",
      "\n",
      " This round's valence_loss=1.138392686843872, arousal_loss=1.1354875564575195, emotion_loss=1.1545641422271729\n",
      "\n",
      "01_20_00:22:10 Seen so far: 21472 samples\n",
      "\n",
      "01_20_00:22:10 --- 1.6858668327331543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:12 Training loss at epoch 2 step 680: 3.1370135307312013\n",
      "\n",
      " This round's valence_loss=0.839248776435852, arousal_loss=0.770017147064209, emotion_loss=1.2239081859588623\n",
      "\n",
      "01_20_00:22:12 Seen so far: 21792 samples\n",
      "\n",
      "01_20_00:22:12 --- 1.9421131610870361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:14 Training loss at epoch 2 step 690: 3.2091651439666746\n",
      "\n",
      " This round's valence_loss=1.3347363471984863, arousal_loss=1.25882887840271, emotion_loss=0.7903733849525452\n",
      "\n",
      "01_20_00:22:14 Seen so far: 22112 samples\n",
      "\n",
      "01_20_00:22:14 --- 1.7018837928771973 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:15 Training loss at epoch 2 step 700: 2.971096932888031\n",
      "\n",
      " This round's valence_loss=0.6409071683883667, arousal_loss=0.45189327001571655, emotion_loss=1.0155797004699707\n",
      "\n",
      "01_20_00:22:15 Seen so far: 22432 samples\n",
      "\n",
      "01_20_00:22:15 --- 1.6719410419464111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:17 Training loss at epoch 2 step 710: 2.7237661719322204\n",
      "\n",
      " This round's valence_loss=1.489456295967102, arousal_loss=1.3420708179473877, emotion_loss=1.1409627199172974\n",
      "\n",
      "01_20_00:22:17 Seen so far: 22752 samples\n",
      "\n",
      "01_20_00:22:17 --- 1.7205328941345215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:19 Training loss at epoch 2 step 720: 3.1087470769882204\n",
      "\n",
      " This round's valence_loss=1.1886482238769531, arousal_loss=1.181114673614502, emotion_loss=0.9387978911399841\n",
      "\n",
      "01_20_00:22:19 Seen so far: 23072 samples\n",
      "\n",
      "01_20_00:22:19 --- 1.6943373680114746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:21 Training loss at epoch 2 step 730: 2.9229106426239015\n",
      "\n",
      " This round's valence_loss=0.8807951807975769, arousal_loss=0.7622933387756348, emotion_loss=0.7632016539573669\n",
      "\n",
      "01_20_00:22:21 Seen so far: 23392 samples\n",
      "\n",
      "01_20_00:22:21 --- 1.9865772724151611 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:23 Training loss at epoch 2 step 740: 3.1439006328582764\n",
      "\n",
      " This round's valence_loss=1.2542262077331543, arousal_loss=1.2291593551635742, emotion_loss=0.7633944749832153\n",
      "\n",
      "01_20_00:22:23 Seen so far: 23712 samples\n",
      "\n",
      "01_20_00:22:23 --- 2.070847749710083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:25 Training loss at epoch 2 step 750: 3.1116392612457275\n",
      "\n",
      " This round's valence_loss=1.1954203844070435, arousal_loss=1.0856964588165283, emotion_loss=0.870531439781189\n",
      "\n",
      "01_20_00:22:25 Seen so far: 24032 samples\n",
      "\n",
      "01_20_00:22:25 --- 1.7246026992797852 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:26 Training loss at epoch 2 step 760: 3.159757161140442\n",
      "\n",
      " This round's valence_loss=0.7480183839797974, arousal_loss=0.5930464267730713, emotion_loss=1.149699330329895\n",
      "\n",
      "01_20_00:22:26 Seen so far: 24352 samples\n",
      "\n",
      "01_20_00:22:26 --- 1.843980312347412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:28 Training loss at epoch 2 step 770: 3.2721587896347044\n",
      "\n",
      " This round's valence_loss=0.977156937122345, arousal_loss=0.846412181854248, emotion_loss=1.0840874910354614\n",
      "\n",
      "01_20_00:22:28 Seen so far: 24672 samples\n",
      "\n",
      "01_20_00:22:28 --- 1.8021178245544434 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:30 Training loss at epoch 2 step 780: 2.933427929878235\n",
      "\n",
      " This round's valence_loss=1.1065301895141602, arousal_loss=0.9953925609588623, emotion_loss=0.890657365322113\n",
      "\n",
      "01_20_00:22:30 Seen so far: 24992 samples\n",
      "\n",
      "01_20_00:22:30 --- 1.8185734748840332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:32 Training loss at epoch 2 step 790: 2.9408095121383666\n",
      "\n",
      " This round's valence_loss=1.1658718585968018, arousal_loss=0.9553090333938599, emotion_loss=0.9828629493713379\n",
      "\n",
      "01_20_00:22:32 Seen so far: 25312 samples\n",
      "\n",
      "01_20_00:22:32 --- 1.7314019203186035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:33 Training loss at epoch 2 step 800: 3.4416534185409544\n",
      "\n",
      " This round's valence_loss=1.3610789775848389, arousal_loss=1.1549955606460571, emotion_loss=0.9245017766952515\n",
      "\n",
      "01_20_00:22:33 Seen so far: 25632 samples\n",
      "\n",
      "01_20_00:22:33 --- 1.7127974033355713 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:35 Training loss at epoch 2 step 810: 3.015872824192047\n",
      "\n",
      " This round's valence_loss=1.2318872213363647, arousal_loss=1.1151481866836548, emotion_loss=0.9218270778656006\n",
      "\n",
      "01_20_00:22:35 Seen so far: 25952 samples\n",
      "\n",
      "01_20_00:22:35 --- 1.690911054611206 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:37 Training loss at epoch 2 step 820: 2.9783355951309205\n",
      "\n",
      " This round's valence_loss=0.737139105796814, arousal_loss=0.601632833480835, emotion_loss=0.8262388706207275\n",
      "\n",
      "01_20_00:22:37 Seen so far: 26272 samples\n",
      "\n",
      "01_20_00:22:37 --- 1.6959447860717773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:39 Training loss at epoch 2 step 830: 3.1248342037200927\n",
      "\n",
      " This round's valence_loss=1.0975942611694336, arousal_loss=0.9979872703552246, emotion_loss=1.1102830171585083\n",
      "\n",
      "01_20_00:22:39 Seen so far: 26592 samples\n",
      "\n",
      "01_20_00:22:39 --- 1.8484547138214111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:40 Training loss at epoch 2 step 840: 2.810637652873993\n",
      "\n",
      " This round's valence_loss=1.3109608888626099, arousal_loss=1.2290761470794678, emotion_loss=1.3126957416534424\n",
      "\n",
      "01_20_00:22:40 Seen so far: 26912 samples\n",
      "\n",
      "01_20_00:22:40 --- 1.703594446182251 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:42 Training loss at epoch 2 step 850: 3.048251748085022\n",
      "\n",
      " This round's valence_loss=1.1354739665985107, arousal_loss=0.9332587122917175, emotion_loss=1.3193844556808472\n",
      "\n",
      "01_20_00:22:42 Seen so far: 27232 samples\n",
      "\n",
      "01_20_00:22:42 --- 1.8002469539642334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:44 Training loss at epoch 2 step 860: 2.8939842700958254\n",
      "\n",
      " This round's valence_loss=0.8030532002449036, arousal_loss=0.6266831159591675, emotion_loss=1.1339678764343262\n",
      "\n",
      "01_20_00:22:44 Seen so far: 27552 samples\n",
      "\n",
      "01_20_00:22:44 --- 2.0603110790252686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:46 Training loss at epoch 2 step 870: 2.9312820434570312\n",
      "\n",
      " This round's valence_loss=1.3168357610702515, arousal_loss=1.2257354259490967, emotion_loss=1.3365578651428223\n",
      "\n",
      "01_20_00:22:46 Seen so far: 27872 samples\n",
      "\n",
      "01_20_00:22:46 --- 2.0202555656433105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:48 Training loss at epoch 2 step 880: 3.2578633546829225\n",
      "\n",
      " This round's valence_loss=1.0331177711486816, arousal_loss=0.8372766375541687, emotion_loss=0.7995474338531494\n",
      "\n",
      "01_20_00:22:48 Seen so far: 28192 samples\n",
      "\n",
      "01_20_00:22:48 --- 1.8683345317840576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:50 Training loss at epoch 2 step 890: 3.4347250699996947\n",
      "\n",
      " This round's valence_loss=0.7502084374427795, arousal_loss=0.6302956342697144, emotion_loss=1.0903568267822266\n",
      "\n",
      "01_20_00:22:50 Seen so far: 28512 samples\n",
      "\n",
      "01_20_00:22:50 --- 1.6623871326446533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:52 Training loss at epoch 2 step 900: 2.842593717575073\n",
      "\n",
      " This round's valence_loss=0.8050506711006165, arousal_loss=0.5599730014801025, emotion_loss=0.9278845191001892\n",
      "\n",
      "01_20_00:22:52 Seen so far: 28832 samples\n",
      "\n",
      "01_20_00:22:52 --- 1.791844367980957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:53 Training loss at epoch 2 step 910: 3.2075946807861326\n",
      "\n",
      " This round's valence_loss=1.6609272956848145, arousal_loss=1.5633258819580078, emotion_loss=1.119251012802124\n",
      "\n",
      "01_20_00:22:53 Seen so far: 29152 samples\n",
      "\n",
      "01_20_00:22:53 --- 1.709559679031372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:55 Training loss at epoch 2 step 920: 3.4736077070236204\n",
      "\n",
      " This round's valence_loss=1.2355016469955444, arousal_loss=1.074601173400879, emotion_loss=0.9432312846183777\n",
      "\n",
      "01_20_00:22:55 Seen so far: 29472 samples\n",
      "\n",
      "01_20_00:22:55 --- 1.8100554943084717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:57 Training loss at epoch 2 step 930: 3.0034252643585204\n",
      "\n",
      " This round's valence_loss=0.9643332362174988, arousal_loss=0.8640770316123962, emotion_loss=1.1770278215408325\n",
      "\n",
      "01_20_00:22:57 Seen so far: 29792 samples\n",
      "\n",
      "01_20_00:22:57 --- 1.8373146057128906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:22:59 Training loss at epoch 2 step 940: 3.162406635284424\n",
      "\n",
      " This round's valence_loss=1.4754319190979004, arousal_loss=1.3542345762252808, emotion_loss=0.7283401489257812\n",
      "\n",
      "01_20_00:22:59 Seen so far: 30112 samples\n",
      "\n",
      "01_20_00:22:59 --- 1.9681453704833984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:01 Training loss at epoch 2 step 950: 3.193576288223267\n",
      "\n",
      " This round's valence_loss=1.1472423076629639, arousal_loss=0.9347426295280457, emotion_loss=0.9059714078903198\n",
      "\n",
      "01_20_00:23:01 Seen so far: 30432 samples\n",
      "\n",
      "01_20_00:23:01 --- 1.7081153392791748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:02 Training loss at epoch 2 step 960: 2.939883029460907\n",
      "\n",
      " This round's valence_loss=1.322391152381897, arousal_loss=1.2439165115356445, emotion_loss=1.0378825664520264\n",
      "\n",
      "01_20_00:23:02 Seen so far: 30752 samples\n",
      "\n",
      "01_20_00:23:02 --- 1.7691428661346436 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:04 Training loss at epoch 2 step 970: 3.112039017677307\n",
      "\n",
      " This round's valence_loss=1.224217176437378, arousal_loss=1.0303568840026855, emotion_loss=0.9907746315002441\n",
      "\n",
      "01_20_00:23:04 Seen so far: 31072 samples\n",
      "\n",
      "01_20_00:23:04 --- 1.8659906387329102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:06 Training loss at epoch 2 step 980: 2.9874083757400514\n",
      "\n",
      " This round's valence_loss=1.0302585363388062, arousal_loss=0.9925239086151123, emotion_loss=1.3673033714294434\n",
      "\n",
      "01_20_00:23:06 Seen so far: 31392 samples\n",
      "\n",
      "01_20_00:23:06 --- 1.6737487316131592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:08 Training loss at epoch 2 step 990: 2.800947535037994\n",
      "\n",
      " This round's valence_loss=0.49643874168395996, arousal_loss=0.3295527696609497, emotion_loss=0.9670025706291199\n",
      "\n",
      "01_20_00:23:08 Seen so far: 31712 samples\n",
      "\n",
      "01_20_00:23:08 --- 1.8881144523620605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:10 Training loss at epoch 2 step 1000: 2.782317543029785\n",
      "\n",
      " This round's valence_loss=0.8489371538162231, arousal_loss=0.7031822204589844, emotion_loss=0.6025803089141846\n",
      "\n",
      "01_20_00:23:10 Seen so far: 32032 samples\n",
      "\n",
      "01_20_00:23:10 --- 1.8888788223266602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:12 Training loss at epoch 2 step 1010: 3.0111456871032716\n",
      "\n",
      " This round's valence_loss=0.9952669143676758, arousal_loss=0.8164218664169312, emotion_loss=0.7065820097923279\n",
      "\n",
      "01_20_00:23:12 Seen so far: 32352 samples\n",
      "\n",
      "01_20_00:23:12 --- 2.031818151473999 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:13 Training loss at epoch 2 step 1020: 2.923324966430664\n",
      "\n",
      " This round's valence_loss=1.394733190536499, arousal_loss=1.184859275817871, emotion_loss=1.2080683708190918\n",
      "\n",
      "01_20_00:23:13 Seen so far: 32672 samples\n",
      "\n",
      "01_20_00:23:13 --- 1.6877319812774658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:15 Training loss at epoch 2 step 1030: 2.8188223838806152\n",
      "\n",
      " This round's valence_loss=0.4762905240058899, arousal_loss=0.36420154571533203, emotion_loss=1.1952382326126099\n",
      "\n",
      "01_20_00:23:15 Seen so far: 32992 samples\n",
      "\n",
      "01_20_00:23:15 --- 1.9262213706970215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:17 Training loss at epoch 2 step 1040: 3.102732229232788\n",
      "\n",
      " This round's valence_loss=0.8615630269050598, arousal_loss=0.7148599624633789, emotion_loss=0.7586396932601929\n",
      "\n",
      "01_20_00:23:17 Seen so far: 33312 samples\n",
      "\n",
      "01_20_00:23:17 --- 1.7816259860992432 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:19 Training loss at epoch 2 step 1050: 3.012617063522339\n",
      "\n",
      " This round's valence_loss=1.406670093536377, arousal_loss=1.3524186611175537, emotion_loss=1.0063865184783936\n",
      "\n",
      "01_20_00:23:19 Seen so far: 33632 samples\n",
      "\n",
      "01_20_00:23:19 --- 1.6858913898468018 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:21 Training loss at epoch 2 step 1060: 3.3333489418029787\n",
      "\n",
      " This round's valence_loss=1.2119343280792236, arousal_loss=1.0608117580413818, emotion_loss=0.9054263830184937\n",
      "\n",
      "01_20_00:23:21 Seen so far: 33952 samples\n",
      "\n",
      "01_20_00:23:21 --- 1.8317937850952148 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:23 Training loss at epoch 2 step 1070: 2.908808743953705\n",
      "\n",
      " This round's valence_loss=1.5071964263916016, arousal_loss=1.3245201110839844, emotion_loss=1.0376853942871094\n",
      "\n",
      "01_20_00:23:23 Seen so far: 34272 samples\n",
      "\n",
      "01_20_00:23:23 --- 1.9179539680480957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:24 Training loss at epoch 2 step 1080: 2.935313892364502\n",
      "\n",
      " This round's valence_loss=1.1387994289398193, arousal_loss=0.7763691544532776, emotion_loss=0.4972124397754669\n",
      "\n",
      "01_20_00:23:24 Seen so far: 34592 samples\n",
      "\n",
      "01_20_00:23:24 --- 1.8145735263824463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:26 Training loss at epoch 2 step 1090: 3.067618489265442\n",
      "\n",
      " This round's valence_loss=1.1763660907745361, arousal_loss=1.0440049171447754, emotion_loss=0.9345992803573608\n",
      "\n",
      "01_20_00:23:26 Seen so far: 34912 samples\n",
      "\n",
      "01_20_00:23:26 --- 1.6902155876159668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:28 Training loss at epoch 2 step 1100: 3.3698760271072388\n",
      "\n",
      " This round's valence_loss=0.9360334277153015, arousal_loss=0.7244106531143188, emotion_loss=1.1338244676589966\n",
      "\n",
      "01_20_00:23:28 Seen so far: 35232 samples\n",
      "\n",
      "01_20_00:23:28 --- 1.8272731304168701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:30 Training loss at epoch 2 step 1110: 2.702876615524292\n",
      "\n",
      " This round's valence_loss=0.8552442789077759, arousal_loss=0.699416995048523, emotion_loss=0.7370249032974243\n",
      "\n",
      "01_20_00:23:30 Seen so far: 35552 samples\n",
      "\n",
      "01_20_00:23:30 --- 1.7806763648986816 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:31 Training loss at epoch 2 step 1120: 2.998564624786377\n",
      "\n",
      " This round's valence_loss=1.4070184230804443, arousal_loss=1.3102846145629883, emotion_loss=1.2117588520050049\n",
      "\n",
      "01_20_00:23:31 Seen so far: 35872 samples\n",
      "\n",
      "01_20_00:23:31 --- 1.65901780128479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:33 Training loss at epoch 2 step 1130: 2.97245934009552\n",
      "\n",
      " This round's valence_loss=1.0579005479812622, arousal_loss=0.9394291639328003, emotion_loss=1.40401029586792\n",
      "\n",
      "01_20_00:23:33 Seen so far: 36192 samples\n",
      "\n",
      "01_20_00:23:33 --- 2.0834522247314453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:35 Training loss at epoch 2 step 1140: 3.0933449983596804\n",
      "\n",
      " This round's valence_loss=1.2508916854858398, arousal_loss=1.071911334991455, emotion_loss=0.7681974172592163\n",
      "\n",
      "01_20_00:23:35 Seen so far: 36512 samples\n",
      "\n",
      "01_20_00:23:35 --- 1.8295657634735107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:37 Training loss at epoch 2 step 1150: 2.6747292160987852\n",
      "\n",
      " This round's valence_loss=1.1128454208374023, arousal_loss=0.9754297733306885, emotion_loss=0.9021813869476318\n",
      "\n",
      "01_20_00:23:37 Seen so far: 36832 samples\n",
      "\n",
      "01_20_00:23:37 --- 1.6920170783996582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:39 Training loss at epoch 2 step 1160: 2.9607651948928835\n",
      "\n",
      " This round's valence_loss=0.7325602769851685, arousal_loss=0.6193910241127014, emotion_loss=1.1342780590057373\n",
      "\n",
      "01_20_00:23:39 Seen so far: 37152 samples\n",
      "\n",
      "01_20_00:23:39 --- 1.7062816619873047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:40 Training loss at epoch 2 step 1170: 2.924597072601318\n",
      "\n",
      " This round's valence_loss=1.2271231412887573, arousal_loss=1.108469843864441, emotion_loss=0.8015737533569336\n",
      "\n",
      "01_20_00:23:40 Seen so far: 37472 samples\n",
      "\n",
      "01_20_00:23:40 --- 1.70037841796875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:42 Training loss at epoch 2 step 1180: 2.9738357067108154\n",
      "\n",
      " This round's valence_loss=0.8957022428512573, arousal_loss=0.6780955791473389, emotion_loss=0.7030537128448486\n",
      "\n",
      "01_20_00:23:42 Seen so far: 37792 samples\n",
      "\n",
      "01_20_00:23:42 --- 1.719409465789795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:44 Training loss at epoch 2 step 1190: 2.8521050691604612\n",
      "\n",
      " This round's valence_loss=1.339874505996704, arousal_loss=1.189304232597351, emotion_loss=0.7305988073348999\n",
      "\n",
      "01_20_00:23:44 Seen so far: 38112 samples\n",
      "\n",
      "01_20_00:23:44 --- 1.7207133769989014 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:46 Training loss at epoch 2 step 1200: 2.777687740325928\n",
      "\n",
      " This round's valence_loss=0.7163516283035278, arousal_loss=0.6701270341873169, emotion_loss=0.7552608251571655\n",
      "\n",
      "01_20_00:23:46 Seen so far: 38432 samples\n",
      "\n",
      "01_20_00:23:46 --- 1.8844120502471924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:48 Training loss at epoch 2 step 1210: 2.875587821006775\n",
      "\n",
      " This round's valence_loss=0.8854055404663086, arousal_loss=0.7265478372573853, emotion_loss=0.8456113338470459\n",
      "\n",
      "01_20_00:23:48 Seen so far: 38752 samples\n",
      "\n",
      "01_20_00:23:48 --- 1.879276990890503 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:49 Training loss at epoch 2 step 1220: 2.9319292545318603\n",
      "\n",
      " This round's valence_loss=0.9880396127700806, arousal_loss=0.8338885307312012, emotion_loss=0.918663501739502\n",
      "\n",
      "01_20_00:23:49 Seen so far: 39072 samples\n",
      "\n",
      "01_20_00:23:49 --- 1.7039287090301514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:51 Training loss at epoch 2 step 1230: 3.094430220127106\n",
      "\n",
      " This round's valence_loss=0.8413805961608887, arousal_loss=0.7367721796035767, emotion_loss=0.9646946787834167\n",
      "\n",
      "01_20_00:23:51 Seen so far: 39392 samples\n",
      "\n",
      "01_20_00:23:51 --- 1.7912204265594482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:53 Training loss at epoch 2 step 1240: 3.0475192785263063\n",
      "\n",
      " This round's valence_loss=1.1489136219024658, arousal_loss=0.9762871265411377, emotion_loss=1.1125082969665527\n",
      "\n",
      "01_20_00:23:53 Seen so far: 39712 samples\n",
      "\n",
      "01_20_00:23:53 --- 1.8873896598815918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:55 Training loss at epoch 2 step 1250: 3.254657173156738\n",
      "\n",
      " This round's valence_loss=1.4430696964263916, arousal_loss=1.185025930404663, emotion_loss=0.880584716796875\n",
      "\n",
      "01_20_00:23:55 Seen so far: 40032 samples\n",
      "\n",
      "01_20_00:23:55 --- 1.9307420253753662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:57 Training loss at epoch 2 step 1260: 3.2299343824386595\n",
      "\n",
      " This round's valence_loss=1.0570122003555298, arousal_loss=0.9941667914390564, emotion_loss=1.124549150466919\n",
      "\n",
      "01_20_00:23:57 Seen so far: 40352 samples\n",
      "\n",
      "01_20_00:23:57 --- 1.857691764831543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:23:58 Training loss at epoch 2 step 1270: 3.063326668739319\n",
      "\n",
      " This round's valence_loss=0.9050910472869873, arousal_loss=0.6718553304672241, emotion_loss=1.005071997642517\n",
      "\n",
      "01_20_00:23:58 Seen so far: 40672 samples\n",
      "\n",
      "01_20_00:23:58 --- 1.7106311321258545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:00 Training loss at epoch 2 step 1280: 2.7474145174026487\n",
      "\n",
      " This round's valence_loss=0.7451062202453613, arousal_loss=0.6133602857589722, emotion_loss=1.0676851272583008\n",
      "\n",
      "01_20_00:24:00 Seen so far: 40992 samples\n",
      "\n",
      "01_20_00:24:00 --- 1.7498533725738525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:02 Training loss at epoch 2 step 1290: 2.911174988746643\n",
      "\n",
      " This round's valence_loss=0.6194247007369995, arousal_loss=0.5977632403373718, emotion_loss=1.2469534873962402\n",
      "\n",
      "01_20_00:24:02 Seen so far: 41312 samples\n",
      "\n",
      "01_20_00:24:02 --- 1.783555269241333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:04 Training loss at epoch 2 step 1300: 3.2257238388061524\n",
      "\n",
      " This round's valence_loss=1.251121997833252, arousal_loss=1.0670337677001953, emotion_loss=1.0555146932601929\n",
      "\n",
      "01_20_00:24:04 Seen so far: 41632 samples\n",
      "\n",
      "01_20_00:24:04 --- 1.8152799606323242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:05 Training loss at epoch 2 step 1310: 2.914035439491272\n",
      "\n",
      " This round's valence_loss=1.244920253753662, arousal_loss=1.0523672103881836, emotion_loss=0.9922528862953186\n",
      "\n",
      "01_20_00:24:05 Seen so far: 41952 samples\n",
      "\n",
      "01_20_00:24:05 --- 1.6854748725891113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:07 Training loss at epoch 2 step 1320: 3.0196105241775513\n",
      "\n",
      " This round's valence_loss=1.5899531841278076, arousal_loss=1.430611252784729, emotion_loss=0.8872718811035156\n",
      "\n",
      "01_20_00:24:07 Seen so far: 42272 samples\n",
      "\n",
      "01_20_00:24:07 --- 1.7763891220092773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:09 Training loss at epoch 2 step 1330: 3.2846168518066405\n",
      "\n",
      " This round's valence_loss=0.9314165711402893, arousal_loss=0.7119085788726807, emotion_loss=0.7433276772499084\n",
      "\n",
      "01_20_00:24:09 Seen so far: 42592 samples\n",
      "\n",
      "01_20_00:24:09 --- 1.9033150672912598 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:11 Training loss at epoch 2 step 1340: 3.1685691118240356\n",
      "\n",
      " This round's valence_loss=1.1648006439208984, arousal_loss=1.109956979751587, emotion_loss=1.0941598415374756\n",
      "\n",
      "01_20_00:24:11 Seen so far: 42912 samples\n",
      "\n",
      "01_20_00:24:11 --- 1.8971407413482666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:13 Training loss at epoch 2 step 1350: 3.2813330411911013\n",
      "\n",
      " This round's valence_loss=1.0839972496032715, arousal_loss=0.9837780594825745, emotion_loss=0.9627331495285034\n",
      "\n",
      "01_20_00:24:13 Seen so far: 43232 samples\n",
      "\n",
      "01_20_00:24:13 --- 1.7931888103485107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:15 Training loss at epoch 2 step 1360: 3.177260684967041\n",
      "\n",
      " This round's valence_loss=0.8641136884689331, arousal_loss=0.7127274870872498, emotion_loss=1.1408281326293945\n",
      "\n",
      "01_20_00:24:15 Seen so far: 43552 samples\n",
      "\n",
      "01_20_00:24:15 --- 1.8667731285095215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:16 Training loss at epoch 2 step 1370: 2.6886318922042847\n",
      "\n",
      " This round's valence_loss=0.5662755966186523, arousal_loss=0.32924020290374756, emotion_loss=0.8621799349784851\n",
      "\n",
      "01_20_00:24:16 Seen so far: 43872 samples\n",
      "\n",
      "01_20_00:24:16 --- 1.6284596920013428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:18 Training loss at epoch 2 step 1380: 3.0125965595245363\n",
      "\n",
      " This round's valence_loss=1.5707701444625854, arousal_loss=1.4500068426132202, emotion_loss=0.9520565271377563\n",
      "\n",
      "01_20_00:24:18 Seen so far: 44192 samples\n",
      "\n",
      "01_20_00:24:18 --- 1.8420732021331787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:20 Training loss at epoch 2 step 1390: 2.9942262411117553\n",
      "\n",
      " This round's valence_loss=0.997948169708252, arousal_loss=0.8039196729660034, emotion_loss=0.8776326179504395\n",
      "\n",
      "01_20_00:24:20 Seen so far: 44512 samples\n",
      "\n",
      "01_20_00:24:20 --- 1.935732126235962 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:22 Training loss at epoch 2 step 1400: 3.167459177970886\n",
      "\n",
      " This round's valence_loss=1.8256711959838867, arousal_loss=1.6598763465881348, emotion_loss=0.7823678255081177\n",
      "\n",
      "01_20_00:24:22 Seen so far: 44832 samples\n",
      "\n",
      "01_20_00:24:22 --- 1.720526933670044 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:24 Training loss at epoch 2 step 1410: 2.8097588658332824\n",
      "\n",
      " This round's valence_loss=0.9895296096801758, arousal_loss=0.8920561671257019, emotion_loss=0.6108564138412476\n",
      "\n",
      "01_20_00:24:24 Seen so far: 45152 samples\n",
      "\n",
      "01_20_00:24:24 --- 1.693833827972412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:25 Training loss at epoch 2 step 1420: 2.979745316505432\n",
      "\n",
      " This round's valence_loss=1.5706815719604492, arousal_loss=1.446435809135437, emotion_loss=1.1931813955307007\n",
      "\n",
      "01_20_00:24:25 Seen so far: 45472 samples\n",
      "\n",
      "01_20_00:24:25 --- 1.8439974784851074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:27 Training loss at epoch 2 step 1430: 3.1669564723968504\n",
      "\n",
      " This round's valence_loss=1.3636891841888428, arousal_loss=1.222335696220398, emotion_loss=1.1660417318344116\n",
      "\n",
      "01_20_00:24:27 Seen so far: 45792 samples\n",
      "\n",
      "01_20_00:24:27 --- 1.813966989517212 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:29 Training loss at epoch 2 step 1440: 3.159396505355835\n",
      "\n",
      " This round's valence_loss=1.2399258613586426, arousal_loss=1.059822916984558, emotion_loss=0.9004202485084534\n",
      "\n",
      "01_20_00:24:29 Seen so far: 46112 samples\n",
      "\n",
      "01_20_00:24:29 --- 1.8120992183685303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:31 Training loss at epoch 2 step 1450: 3.190553140640259\n",
      "\n",
      " This round's valence_loss=1.0649875402450562, arousal_loss=0.9703958034515381, emotion_loss=0.9251782894134521\n",
      "\n",
      "01_20_00:24:31 Seen so far: 46432 samples\n",
      "\n",
      "01_20_00:24:31 --- 1.7413854598999023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:33 Training loss at epoch 2 step 1460: 3.29762442111969\n",
      "\n",
      " This round's valence_loss=1.030785322189331, arousal_loss=0.9545203447341919, emotion_loss=1.0199131965637207\n",
      "\n",
      "01_20_00:24:33 Seen so far: 46752 samples\n",
      "\n",
      "01_20_00:24:33 --- 1.8885695934295654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:34 Training loss at epoch 2 step 1470: 2.879368770122528\n",
      "\n",
      " This round's valence_loss=0.7042739391326904, arousal_loss=0.44206422567367554, emotion_loss=0.671859860420227\n",
      "\n",
      "01_20_00:24:34 Seen so far: 47072 samples\n",
      "\n",
      "01_20_00:24:34 --- 1.7770793437957764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:36 Training loss at epoch 2 step 1480: 3.1499075412750246\n",
      "\n",
      " This round's valence_loss=1.122431993484497, arousal_loss=0.9382256865501404, emotion_loss=0.7109004259109497\n",
      "\n",
      "01_20_00:24:36 Seen so far: 47392 samples\n",
      "\n",
      "01_20_00:24:36 --- 1.7042725086212158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:38 Training loss at epoch 2 step 1490: 3.0453142166137694\n",
      "\n",
      " This round's valence_loss=0.5618497133255005, arousal_loss=0.4838443100452423, emotion_loss=0.9485742449760437\n",
      "\n",
      "01_20_00:24:38 Seen so far: 47712 samples\n",
      "\n",
      "01_20_00:24:38 --- 1.7210350036621094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:40 Training loss at epoch 2 step 1500: 2.805121374130249\n",
      "\n",
      " This round's valence_loss=1.1931746006011963, arousal_loss=1.0593260526657104, emotion_loss=1.2371838092803955\n",
      "\n",
      "01_20_00:24:40 Seen so far: 48032 samples\n",
      "\n",
      "01_20_00:24:40 --- 1.8962414264678955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:41 Training loss at epoch 2 step 1510: 2.8955191135406495\n",
      "\n",
      " This round's valence_loss=1.2145060300827026, arousal_loss=1.0692273378372192, emotion_loss=0.9392112493515015\n",
      "\n",
      "01_20_00:24:41 Seen so far: 48352 samples\n",
      "\n",
      "01_20_00:24:41 --- 1.6059000492095947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:43 Training loss at epoch 2 step 1520: 3.2565507650375367\n",
      "\n",
      " This round's valence_loss=1.337430477142334, arousal_loss=1.1726500988006592, emotion_loss=0.9408612251281738\n",
      "\n",
      "01_20_00:24:43 Seen so far: 48672 samples\n",
      "\n",
      "01_20_00:24:43 --- 1.7102408409118652 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:45 Training loss at epoch 2 step 1530: 3.095217156410217\n",
      "\n",
      " This round's valence_loss=0.9964185953140259, arousal_loss=0.8717966079711914, emotion_loss=1.3997890949249268\n",
      "\n",
      "01_20_00:24:45 Seen so far: 48992 samples\n",
      "\n",
      "01_20_00:24:45 --- 1.9947032928466797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:47 Training loss at epoch 2 step 1540: 3.128095269203186\n",
      "\n",
      " This round's valence_loss=1.218310832977295, arousal_loss=1.124422311782837, emotion_loss=1.1355888843536377\n",
      "\n",
      "01_20_00:24:47 Seen so far: 49312 samples\n",
      "\n",
      "01_20_00:24:47 --- 1.9856395721435547 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:49 Training loss at epoch 2 step 1550: 2.9613537549972535\n",
      "\n",
      " This round's valence_loss=1.1631375551223755, arousal_loss=1.1156421899795532, emotion_loss=0.975419282913208\n",
      "\n",
      "01_20_00:24:49 Seen so far: 49632 samples\n",
      "\n",
      "01_20_00:24:49 --- 1.8007323741912842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:50 Training loss at epoch 2 step 1560: 2.8734820604324343\n",
      "\n",
      " This round's valence_loss=1.3081855773925781, arousal_loss=1.1839280128479004, emotion_loss=1.2510278224945068\n",
      "\n",
      "01_20_00:24:50 Seen so far: 49952 samples\n",
      "\n",
      "01_20_00:24:50 --- 1.6704745292663574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:52 Training loss at epoch 2 step 1570: 3.0375019311904907\n",
      "\n",
      " This round's valence_loss=0.9608891010284424, arousal_loss=0.8876069784164429, emotion_loss=1.1774418354034424\n",
      "\n",
      "01_20_00:24:52 Seen so far: 50272 samples\n",
      "\n",
      "01_20_00:24:52 --- 1.6770358085632324 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:54 Training loss at epoch 2 step 1580: 2.8972870111465454\n",
      "\n",
      " This round's valence_loss=1.5995781421661377, arousal_loss=1.4292831420898438, emotion_loss=1.2545146942138672\n",
      "\n",
      "01_20_00:24:54 Seen so far: 50592 samples\n",
      "\n",
      "01_20_00:24:54 --- 1.9260597229003906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:56 Training loss at epoch 2 step 1590: 2.796295368671417\n",
      "\n",
      " This round's valence_loss=0.7765405178070068, arousal_loss=0.5623162388801575, emotion_loss=0.5460909605026245\n",
      "\n",
      "01_20_00:24:56 Seen so far: 50912 samples\n",
      "\n",
      "01_20_00:24:56 --- 1.6207900047302246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:57 Training loss at epoch 2 step 1600: 3.031670165061951\n",
      "\n",
      " This round's valence_loss=1.2825044393539429, arousal_loss=1.194847822189331, emotion_loss=1.1074994802474976\n",
      "\n",
      "01_20_00:24:57 Seen so far: 51232 samples\n",
      "\n",
      "01_20_00:24:57 --- 1.7646191120147705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:24:59 Training loss at epoch 2 step 1610: 2.8911593914031983\n",
      "\n",
      " This round's valence_loss=1.1514912843704224, arousal_loss=0.9229540228843689, emotion_loss=0.9141864776611328\n",
      "\n",
      "01_20_00:24:59 Seen so far: 51552 samples\n",
      "\n",
      "01_20_00:24:59 --- 1.7646172046661377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:01 Training loss at epoch 2 step 1620: 2.840606713294983\n",
      "\n",
      " This round's valence_loss=0.8007561564445496, arousal_loss=0.5517393350601196, emotion_loss=0.8447781205177307\n",
      "\n",
      "01_20_00:25:01 Seen so far: 51872 samples\n",
      "\n",
      "01_20_00:25:01 --- 1.6543471813201904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:03 Training loss at epoch 2 step 1630: 3.1756345510482786\n",
      "\n",
      " This round's valence_loss=0.860364556312561, arousal_loss=0.7090697884559631, emotion_loss=0.5988147258758545\n",
      "\n",
      "01_20_00:25:03 Seen so far: 52192 samples\n",
      "\n",
      "01_20_00:25:03 --- 1.81697678565979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:05 Training loss at epoch 2 step 1640: 2.892644226551056\n",
      "\n",
      " This round's valence_loss=0.9631129503250122, arousal_loss=0.8678950667381287, emotion_loss=1.1610990762710571\n",
      "\n",
      "01_20_00:25:05 Seen so far: 52512 samples\n",
      "\n",
      "01_20_00:25:05 --- 1.80366849899292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:06 Training loss at epoch 2 step 1650: 2.7420154809951782\n",
      "\n",
      " This round's valence_loss=0.9566158056259155, arousal_loss=0.8800468444824219, emotion_loss=1.0825092792510986\n",
      "\n",
      "01_20_00:25:06 Seen so far: 52832 samples\n",
      "\n",
      "01_20_00:25:06 --- 1.8612592220306396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:08 Training loss at epoch 2 step 1660: 3.098120021820068\n",
      "\n",
      " This round's valence_loss=1.3307008743286133, arousal_loss=1.2150664329528809, emotion_loss=1.0459566116333008\n",
      "\n",
      "01_20_00:25:08 Seen so far: 53152 samples\n",
      "\n",
      "01_20_00:25:08 --- 1.7244141101837158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:10 Training loss at epoch 2 step 1670: 3.118560218811035\n",
      "\n",
      " This round's valence_loss=0.9043524265289307, arousal_loss=0.689100980758667, emotion_loss=0.7652651071548462\n",
      "\n",
      "01_20_00:25:10 Seen so far: 53472 samples\n",
      "\n",
      "01_20_00:25:10 --- 1.7156641483306885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:12 Training loss at epoch 2 step 1680: 2.8050166368484497\n",
      "\n",
      " This round's valence_loss=0.8072769641876221, arousal_loss=0.6283348798751831, emotion_loss=0.7671446204185486\n",
      "\n",
      "01_20_00:25:12 Seen so far: 53792 samples\n",
      "\n",
      "01_20_00:25:12 --- 1.8955769538879395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:13 Training loss at epoch 2 step 1690: 2.814646530151367\n",
      "\n",
      " This round's valence_loss=0.6892303228378296, arousal_loss=0.50285804271698, emotion_loss=0.8992466330528259\n",
      "\n",
      "01_20_00:25:13 Seen so far: 54112 samples\n",
      "\n",
      "01_20_00:25:13 --- 1.6153740882873535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:15 Training loss at epoch 2 step 1700: 2.9989951133728026\n",
      "\n",
      " This round's valence_loss=1.090592861175537, arousal_loss=0.9376468658447266, emotion_loss=0.9772657155990601\n",
      "\n",
      "01_20_00:25:15 Seen so far: 54432 samples\n",
      "\n",
      "01_20_00:25:15 --- 1.834542989730835 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:17 Training loss at epoch 2 step 1710: 2.8989258885383604\n",
      "\n",
      " This round's valence_loss=0.9169303178787231, arousal_loss=0.7322444915771484, emotion_loss=0.7646757960319519\n",
      "\n",
      "01_20_00:25:17 Seen so far: 54752 samples\n",
      "\n",
      "01_20_00:25:17 --- 1.682096242904663 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:19 Training loss at epoch 2 step 1720: 3.5107744216918944\n",
      "\n",
      " This round's valence_loss=1.0604491233825684, arousal_loss=0.9586216807365417, emotion_loss=0.9051915407180786\n",
      "\n",
      "01_20_00:25:19 Seen so far: 55072 samples\n",
      "\n",
      "01_20_00:25:19 --- 1.6710841655731201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:20 Training loss at epoch 2 step 1730: 3.199264883995056\n",
      "\n",
      " This round's valence_loss=1.3603092432022095, arousal_loss=1.187182068824768, emotion_loss=1.1120884418487549\n",
      "\n",
      "01_20_00:25:20 Seen so far: 55392 samples\n",
      "\n",
      "01_20_00:25:20 --- 1.8122568130493164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:22 Training loss at epoch 2 step 1740: 3.1457546949386597\n",
      "\n",
      " This round's valence_loss=0.9645341634750366, arousal_loss=0.8182506561279297, emotion_loss=0.7805872559547424\n",
      "\n",
      "01_20_00:25:22 Seen so far: 55712 samples\n",
      "\n",
      "01_20_00:25:22 --- 1.8383686542510986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:24 Training loss at epoch 2 step 1750: 2.8513307094573976\n",
      "\n",
      " This round's valence_loss=1.1185595989227295, arousal_loss=0.9606867432594299, emotion_loss=1.1907731294631958\n",
      "\n",
      "01_20_00:25:24 Seen so far: 56032 samples\n",
      "\n",
      "01_20_00:25:24 --- 1.6857895851135254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:26 Training loss at epoch 2 step 1760: 3.00849130153656\n",
      "\n",
      " This round's valence_loss=0.9107879400253296, arousal_loss=0.8665539026260376, emotion_loss=0.9633703827857971\n",
      "\n",
      "01_20_00:25:26 Seen so far: 56352 samples\n",
      "\n",
      "01_20_00:25:26 --- 1.8034977912902832 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:27 Training loss at epoch 2 step 1770: 2.6341213941574098\n",
      "\n",
      " This round's valence_loss=1.103759527206421, arousal_loss=1.0130667686462402, emotion_loss=1.4162585735321045\n",
      "\n",
      "01_20_00:25:27 Seen so far: 56672 samples\n",
      "\n",
      "01_20_00:25:27 --- 1.7902777194976807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:29 Training loss at epoch 2 step 1780: 2.945944404602051\n",
      "\n",
      " This round's valence_loss=0.9280838966369629, arousal_loss=0.8268301486968994, emotion_loss=0.7788056135177612\n",
      "\n",
      "01_20_00:25:29 Seen so far: 56992 samples\n",
      "\n",
      "01_20_00:25:29 --- 1.6589057445526123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:31 Training loss at epoch 2 step 1790: 2.9595915555953978\n",
      "\n",
      " This round's valence_loss=0.9840822815895081, arousal_loss=0.8523181080818176, emotion_loss=0.9365206360816956\n",
      "\n",
      "01_20_00:25:31 Seen so far: 57312 samples\n",
      "\n",
      "01_20_00:25:31 --- 1.8171865940093994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:33 Training loss at epoch 2 step 1800: 3.2916457891464233\n",
      "\n",
      " This round's valence_loss=1.0188921689987183, arousal_loss=0.8310674428939819, emotion_loss=0.9441512823104858\n",
      "\n",
      "01_20_00:25:33 Seen so far: 57632 samples\n",
      "\n",
      "01_20_00:25:33 --- 1.8658456802368164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:35 Training loss at epoch 2 step 1810: 3.039694273471832\n",
      "\n",
      " This round's valence_loss=1.2525116205215454, arousal_loss=1.1292409896850586, emotion_loss=0.9833357930183411\n",
      "\n",
      "01_20_00:25:35 Seen so far: 57952 samples\n",
      "\n",
      "01_20_00:25:35 --- 1.8561680316925049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:36 Training loss at epoch 2 step 1820: 2.7298382759094237\n",
      "\n",
      " This round's valence_loss=0.8503749370574951, arousal_loss=0.7284255027770996, emotion_loss=0.8918597102165222\n",
      "\n",
      "01_20_00:25:36 Seen so far: 58272 samples\n",
      "\n",
      "01_20_00:25:36 --- 1.658975601196289 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:38 Training loss at epoch 2 step 1830: 3.214549708366394\n",
      "\n",
      " This round's valence_loss=0.7965445518493652, arousal_loss=0.7002357840538025, emotion_loss=1.4391670227050781\n",
      "\n",
      "01_20_00:25:38 Seen so far: 58592 samples\n",
      "\n",
      "01_20_00:25:38 --- 1.8223860263824463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:40 Training loss at epoch 2 step 1840: 3.1447365522384643\n",
      "\n",
      " This round's valence_loss=1.1035468578338623, arousal_loss=0.9630221724510193, emotion_loss=0.8861508369445801\n",
      "\n",
      "01_20_00:25:40 Seen so far: 58912 samples\n",
      "\n",
      "01_20_00:25:40 --- 1.6803491115570068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:42 Training loss at epoch 2 step 1850: 3.3027762174606323\n",
      "\n",
      " This round's valence_loss=1.230701208114624, arousal_loss=1.1074838638305664, emotion_loss=0.7966040372848511\n",
      "\n",
      "01_20_00:25:42 Seen so far: 59232 samples\n",
      "\n",
      "01_20_00:25:42 --- 1.8442339897155762 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:43 Training loss at epoch 2 step 1860: 2.9593618154525756\n",
      "\n",
      " This round's valence_loss=0.8741722106933594, arousal_loss=0.6958204507827759, emotion_loss=1.0003166198730469\n",
      "\n",
      "01_20_00:25:43 Seen so far: 59552 samples\n",
      "\n",
      "01_20_00:25:43 --- 1.6096019744873047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:45 Training loss at epoch 2 step 1870: 2.972782254219055\n",
      "\n",
      " This round's valence_loss=1.6561847925186157, arousal_loss=1.588858723640442, emotion_loss=1.0997192859649658\n",
      "\n",
      "01_20_00:25:45 Seen so far: 59872 samples\n",
      "\n",
      "01_20_00:25:45 --- 1.6564345359802246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:47 Training loss at epoch 2 step 1880: 3.0343199491500856\n",
      "\n",
      " This round's valence_loss=1.0604435205459595, arousal_loss=0.9956976175308228, emotion_loss=0.9533013105392456\n",
      "\n",
      "01_20_00:25:47 Seen so far: 60192 samples\n",
      "\n",
      "01_20_00:25:47 --- 1.8067433834075928 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:48 Training loss at epoch 2 step 1890: 3.104406142234802\n",
      "\n",
      " This round's valence_loss=1.3398339748382568, arousal_loss=1.223043441772461, emotion_loss=1.0380185842514038\n",
      "\n",
      "01_20_00:25:48 Seen so far: 60512 samples\n",
      "\n",
      "01_20_00:25:48 --- 1.6369495391845703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:50 Training loss at epoch 2 step 1900: 2.93860239982605\n",
      "\n",
      " This round's valence_loss=1.2925529479980469, arousal_loss=1.2086232900619507, emotion_loss=0.8205599784851074\n",
      "\n",
      "01_20_00:25:50 Seen so far: 60832 samples\n",
      "\n",
      "01_20_00:25:50 --- 1.556682825088501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:52 Training loss at epoch 2 step 1910: 3.1310394048690795\n",
      "\n",
      " This round's valence_loss=0.7960860729217529, arousal_loss=0.5823496580123901, emotion_loss=0.8057693243026733\n",
      "\n",
      "01_20_00:25:52 Seen so far: 61152 samples\n",
      "\n",
      "01_20_00:25:52 --- 1.840545415878296 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:53 Training loss at epoch 2 step 1920: 2.8757091045379637\n",
      "\n",
      " This round's valence_loss=1.5539205074310303, arousal_loss=1.4737532138824463, emotion_loss=1.3865678310394287\n",
      "\n",
      "01_20_00:25:53 Seen so far: 61472 samples\n",
      "\n",
      "01_20_00:25:53 --- 1.5896880626678467 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:55 Training loss at epoch 2 step 1930: 2.9115907073020937\n",
      "\n",
      " This round's valence_loss=0.8793516159057617, arousal_loss=0.709883451461792, emotion_loss=1.112775206565857\n",
      "\n",
      "01_20_00:25:55 Seen so far: 61792 samples\n",
      "\n",
      "01_20_00:25:55 --- 1.922006607055664 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:57 Training loss at epoch 2 step 1940: 3.0070399761199953\n",
      "\n",
      " This round's valence_loss=1.1753002405166626, arousal_loss=0.9608701467514038, emotion_loss=1.0454579591751099\n",
      "\n",
      "01_20_00:25:57 Seen so far: 62112 samples\n",
      "\n",
      "01_20_00:25:57 --- 1.7387323379516602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:25:59 Training loss at epoch 2 step 1950: 3.052221894264221\n",
      "\n",
      " This round's valence_loss=1.236625075340271, arousal_loss=1.0929481983184814, emotion_loss=1.3270859718322754\n",
      "\n",
      "01_20_00:25:59 Seen so far: 62432 samples\n",
      "\n",
      "01_20_00:25:59 --- 1.7472093105316162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:01 Training loss at epoch 2 step 1960: 3.1577598810195924\n",
      "\n",
      " This round's valence_loss=0.8217818737030029, arousal_loss=0.6125272512435913, emotion_loss=1.0848348140716553\n",
      "\n",
      "01_20_00:26:01 Seen so far: 62752 samples\n",
      "\n",
      "01_20_00:26:01 --- 1.7410600185394287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:02 Training loss at epoch 2 step 1970: 3.0056967973709106\n",
      "\n",
      " This round's valence_loss=1.1879520416259766, arousal_loss=1.0779495239257812, emotion_loss=0.7079472541809082\n",
      "\n",
      "01_20_00:26:02 Seen so far: 63072 samples\n",
      "\n",
      "01_20_00:26:02 --- 1.8295106887817383 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:04 Training loss at epoch 2 step 1980: 2.80678973197937\n",
      "\n",
      " This round's valence_loss=1.0661442279815674, arousal_loss=0.9802840948104858, emotion_loss=0.9347657561302185\n",
      "\n",
      "01_20_00:26:04 Seen so far: 63392 samples\n",
      "\n",
      "01_20_00:26:04 --- 1.7138440608978271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:06 Training loss at epoch 2 step 1990: 3.2387946367263796\n",
      "\n",
      " This round's valence_loss=1.7048723697662354, arousal_loss=1.5576772689819336, emotion_loss=1.0205185413360596\n",
      "\n",
      "01_20_00:26:06 Seen so far: 63712 samples\n",
      "\n",
      "01_20_00:26:06 --- 1.8216135501861572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:08 Training loss at epoch 2 step 2000: 3.2785247325897218\n",
      "\n",
      " This round's valence_loss=1.7082825899124146, arousal_loss=1.5404739379882812, emotion_loss=0.833959698677063\n",
      "\n",
      "01_20_00:26:08 Seen so far: 64032 samples\n",
      "\n",
      "01_20_00:26:08 --- 1.8613183498382568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:10 Training loss at epoch 2 step 2010: 3.2914021015167236\n",
      "\n",
      " This round's valence_loss=1.405134677886963, arousal_loss=1.319005012512207, emotion_loss=1.0681228637695312\n",
      "\n",
      "01_20_00:26:10 Seen so far: 64352 samples\n",
      "\n",
      "01_20_00:26:10 --- 1.7707045078277588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:11 Training loss at epoch 2 step 2020: 2.738009715080261\n",
      "\n",
      " This round's valence_loss=1.08760666847229, arousal_loss=0.9370529055595398, emotion_loss=0.8265138864517212\n",
      "\n",
      "01_20_00:26:11 Seen so far: 64672 samples\n",
      "\n",
      "01_20_00:26:11 --- 1.7560501098632812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:13 Training loss at epoch 2 step 2030: 2.965453863143921\n",
      "\n",
      " This round's valence_loss=0.8241870999336243, arousal_loss=0.6034934520721436, emotion_loss=0.7340708374977112\n",
      "\n",
      "01_20_00:26:13 Seen so far: 64992 samples\n",
      "\n",
      "01_20_00:26:13 --- 1.9982314109802246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:15 Training loss at epoch 2 step 2040: 3.0046939611434937\n",
      "\n",
      " This round's valence_loss=0.8520556688308716, arousal_loss=0.7179850339889526, emotion_loss=0.8309128284454346\n",
      "\n",
      "01_20_00:26:15 Seen so far: 65312 samples\n",
      "\n",
      "01_20_00:26:15 --- 1.8715944290161133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:17 Training loss at epoch 2 step 2050: 2.8126258850097656\n",
      "\n",
      " This round's valence_loss=0.9525829553604126, arousal_loss=0.8597463369369507, emotion_loss=0.6594669818878174\n",
      "\n",
      "01_20_00:26:17 Seen so far: 65632 samples\n",
      "\n",
      "01_20_00:26:17 --- 1.940009355545044 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:19 Training loss at epoch 2 step 2060: 2.7406938791275026\n",
      "\n",
      " This round's valence_loss=1.1258783340454102, arousal_loss=0.9182624220848083, emotion_loss=1.2196564674377441\n",
      "\n",
      "01_20_00:26:19 Seen so far: 65952 samples\n",
      "\n",
      "01_20_00:26:19 --- 1.7554268836975098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:20 Training loss at epoch 2 step 2070: 3.2603959798812867\n",
      "\n",
      " This round's valence_loss=1.0651733875274658, arousal_loss=0.9833458662033081, emotion_loss=1.2498493194580078\n",
      "\n",
      "01_20_00:26:20 Seen so far: 66272 samples\n",
      "\n",
      "01_20_00:26:20 --- 1.629774570465088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:22 Training loss at epoch 2 step 2080: 3.26806058883667\n",
      "\n",
      " This round's valence_loss=1.3122605085372925, arousal_loss=1.067878246307373, emotion_loss=1.0790001153945923\n",
      "\n",
      "01_20_00:26:22 Seen so far: 66592 samples\n",
      "\n",
      "01_20_00:26:22 --- 1.8885436058044434 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:24 Training loss at epoch 2 step 2090: 3.2605554819107057\n",
      "\n",
      " This round's valence_loss=1.279012680053711, arousal_loss=1.053515911102295, emotion_loss=0.8087774515151978\n",
      "\n",
      "01_20_00:26:24 Seen so far: 66912 samples\n",
      "\n",
      "01_20_00:26:24 --- 1.6349577903747559 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:26 Training loss at epoch 2 step 2100: 3.074038362503052\n",
      "\n",
      " This round's valence_loss=0.6388223171234131, arousal_loss=0.5543167591094971, emotion_loss=1.3002102375030518\n",
      "\n",
      "01_20_00:26:26 Seen so far: 67232 samples\n",
      "\n",
      "01_20_00:26:26 --- 1.55448579788208 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:27 Training loss at epoch 2 step 2110: 3.1287190318107605\n",
      "\n",
      " This round's valence_loss=1.4583934545516968, arousal_loss=1.3345786333084106, emotion_loss=1.2512803077697754\n",
      "\n",
      "01_20_00:26:27 Seen so far: 67552 samples\n",
      "\n",
      "01_20_00:26:27 --- 1.7739458084106445 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:29 Training loss at epoch 2 step 2120: 3.122130846977234\n",
      "\n",
      " This round's valence_loss=1.7855368852615356, arousal_loss=1.6884363889694214, emotion_loss=1.0561909675598145\n",
      "\n",
      "01_20_00:26:29 Seen so far: 67872 samples\n",
      "\n",
      "01_20_00:26:29 --- 1.8014743328094482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:31 Training loss at epoch 2 step 2130: 3.4889617919921876\n",
      "\n",
      " This round's valence_loss=0.7074614763259888, arousal_loss=0.6090859174728394, emotion_loss=1.2382481098175049\n",
      "\n",
      "01_20_00:26:31 Seen so far: 68192 samples\n",
      "\n",
      "01_20_00:26:31 --- 1.8015432357788086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:33 Training loss at epoch 2 step 2140: 3.5321446895599364\n",
      "\n",
      " This round's valence_loss=1.0478720664978027, arousal_loss=0.8372759819030762, emotion_loss=1.3577513694763184\n",
      "\n",
      "01_20_00:26:33 Seen so far: 68512 samples\n",
      "\n",
      "01_20_00:26:33 --- 1.821847915649414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:35 Training loss at epoch 2 step 2150: 3.229769396781921\n",
      "\n",
      " This round's valence_loss=1.4579576253890991, arousal_loss=1.3461799621582031, emotion_loss=1.0227956771850586\n",
      "\n",
      "01_20_00:26:35 Seen so far: 68832 samples\n",
      "\n",
      "01_20_00:26:35 --- 1.7831449508666992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:36 Training loss at epoch 2 step 2160: 3.1511240243911742\n",
      "\n",
      " This round's valence_loss=1.3399401903152466, arousal_loss=1.1984297037124634, emotion_loss=1.1186199188232422\n",
      "\n",
      "01_20_00:26:36 Seen so far: 69152 samples\n",
      "\n",
      "01_20_00:26:36 --- 1.8156554698944092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:38 Training loss at epoch 2 step 2170: 2.822947382926941\n",
      "\n",
      " This round's valence_loss=1.0252726078033447, arousal_loss=0.825391411781311, emotion_loss=0.9279556274414062\n",
      "\n",
      "01_20_00:26:38 Seen so far: 69472 samples\n",
      "\n",
      "01_20_00:26:38 --- 1.6621310710906982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:40 Training loss at epoch 2 step 2180: 3.2534233570098876\n",
      "\n",
      " This round's valence_loss=1.4223589897155762, arousal_loss=1.3545809984207153, emotion_loss=1.175274133682251\n",
      "\n",
      "01_20_00:26:40 Seen so far: 69792 samples\n",
      "\n",
      "01_20_00:26:40 --- 1.766397476196289 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:42 Training loss at epoch 2 step 2190: 2.949770188331604\n",
      "\n",
      " This round's valence_loss=0.9979507923126221, arousal_loss=0.8468139171600342, emotion_loss=0.6332517862319946\n",
      "\n",
      "01_20_00:26:42 Seen so far: 70112 samples\n",
      "\n",
      "01_20_00:26:42 --- 1.768876552581787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:43 Training loss at epoch 2 step 2200: 2.5104267954826356\n",
      "\n",
      " This round's valence_loss=1.082348108291626, arousal_loss=0.9264154434204102, emotion_loss=0.8041173219680786\n",
      "\n",
      "01_20_00:26:43 Seen so far: 70432 samples\n",
      "\n",
      "01_20_00:26:43 --- 1.7984917163848877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:45 Training loss at epoch 2 step 2210: 2.970289921760559\n",
      "\n",
      " This round's valence_loss=0.8723759055137634, arousal_loss=0.72776859998703, emotion_loss=0.7999323010444641\n",
      "\n",
      "01_20_00:26:45 Seen so far: 70752 samples\n",
      "\n",
      "01_20_00:26:45 --- 1.8597807884216309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:47 Training loss at epoch 2 step 2220: 2.964389204978943\n",
      "\n",
      " This round's valence_loss=0.9852511882781982, arousal_loss=0.8811941146850586, emotion_loss=0.7974151968955994\n",
      "\n",
      "01_20_00:26:47 Seen so far: 71072 samples\n",
      "\n",
      "01_20_00:26:47 --- 1.9043805599212646 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:49 Training loss at epoch 2 step 2230: 3.264356088638306\n",
      "\n",
      " This round's valence_loss=1.4605580568313599, arousal_loss=1.3930625915527344, emotion_loss=1.1544955968856812\n",
      "\n",
      "01_20_00:26:49 Seen so far: 71392 samples\n",
      "\n",
      "01_20_00:26:49 --- 1.756314754486084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:51 Training loss at epoch 2 step 2240: 2.762185525894165\n",
      "\n",
      " This round's valence_loss=0.575778603553772, arousal_loss=0.3376949727535248, emotion_loss=1.0017108917236328\n",
      "\n",
      "01_20_00:26:51 Seen so far: 71712 samples\n",
      "\n",
      "01_20_00:26:51 --- 1.7944362163543701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:53 Training loss at epoch 2 step 2250: 3.1952001810073853\n",
      "\n",
      " This round's valence_loss=0.8254150152206421, arousal_loss=0.742280125617981, emotion_loss=1.1408681869506836\n",
      "\n",
      "01_20_00:26:53 Seen so far: 72032 samples\n",
      "\n",
      "01_20_00:26:53 --- 1.8914680480957031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:54 Training loss at epoch 2 step 2260: 2.8666789650917055\n",
      "\n",
      " This round's valence_loss=1.215151309967041, arousal_loss=1.134164571762085, emotion_loss=1.0664913654327393\n",
      "\n",
      "01_20_00:26:54 Seen so far: 72352 samples\n",
      "\n",
      "01_20_00:26:54 --- 1.8183338642120361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:56 Training loss at epoch 2 step 2270: 3.1158782958984377\n",
      "\n",
      " This round's valence_loss=1.2704576253890991, arousal_loss=1.0717952251434326, emotion_loss=1.009990930557251\n",
      "\n",
      "01_20_00:26:56 Seen so far: 72672 samples\n",
      "\n",
      "01_20_00:26:56 --- 1.7958528995513916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:26:58 Training loss at epoch 2 step 2280: 2.935822677612305\n",
      "\n",
      " This round's valence_loss=1.109771966934204, arousal_loss=0.9573956727981567, emotion_loss=1.0066004991531372\n",
      "\n",
      "01_20_00:26:58 Seen so far: 72992 samples\n",
      "\n",
      "01_20_00:26:58 --- 1.8826007843017578 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:00 Training loss at epoch 2 step 2290: 3.270126461982727\n",
      "\n",
      " This round's valence_loss=1.217966079711914, arousal_loss=1.1060729026794434, emotion_loss=1.231174349784851\n",
      "\n",
      "01_20_00:27:00 Seen so far: 73312 samples\n",
      "\n",
      "01_20_00:27:00 --- 1.6352651119232178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:01 Training loss at epoch 2 step 2300: 3.0467029094696043\n",
      "\n",
      " This round's valence_loss=0.8381756544113159, arousal_loss=0.6864211559295654, emotion_loss=1.099290370941162\n",
      "\n",
      "01_20_00:27:01 Seen so far: 73632 samples\n",
      "\n",
      "01_20_00:27:01 --- 1.650589942932129 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:03 Training loss at epoch 2 step 2310: 2.7545429348945616\n",
      "\n",
      " This round's valence_loss=1.2231481075286865, arousal_loss=1.1127614974975586, emotion_loss=0.8581697940826416\n",
      "\n",
      "01_20_00:27:03 Seen so far: 73952 samples\n",
      "\n",
      "01_20_00:27:03 --- 1.6723458766937256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:05 Training loss at epoch 2 step 2320: 2.7999451398849486\n",
      "\n",
      " This round's valence_loss=0.8674945831298828, arousal_loss=0.7253208756446838, emotion_loss=0.9600633382797241\n",
      "\n",
      "01_20_00:27:05 Seen so far: 74272 samples\n",
      "\n",
      "01_20_00:27:05 --- 1.8168771266937256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:07 Training loss at epoch 2 step 2330: 3.086843204498291\n",
      "\n",
      " This round's valence_loss=0.9978936314582825, arousal_loss=0.8754889965057373, emotion_loss=0.8958771228790283\n",
      "\n",
      "01_20_00:27:07 Seen so far: 74592 samples\n",
      "\n",
      "01_20_00:27:07 --- 1.8158292770385742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:08 Training loss at epoch 2 step 2340: 3.158705234527588\n",
      "\n",
      " This round's valence_loss=1.6290966272354126, arousal_loss=1.5660595893859863, emotion_loss=0.8921704292297363\n",
      "\n",
      "01_20_00:27:08 Seen so far: 74912 samples\n",
      "\n",
      "01_20_00:27:08 --- 1.8478600978851318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:10 Training loss at epoch 2 step 2350: 2.9406936883926393\n",
      "\n",
      " This round's valence_loss=0.999356746673584, arousal_loss=0.8346723318099976, emotion_loss=0.6304484605789185\n",
      "\n",
      "01_20_00:27:10 Seen so far: 75232 samples\n",
      "\n",
      "01_20_00:27:10 --- 1.801642894744873 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:12 Training loss at epoch 2 step 2360: 3.0975630044937135\n",
      "\n",
      " This round's valence_loss=1.3408222198486328, arousal_loss=1.2045618295669556, emotion_loss=1.1730823516845703\n",
      "\n",
      "01_20_00:27:12 Seen so far: 75552 samples\n",
      "\n",
      "01_20_00:27:12 --- 1.6660659313201904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:14 Training loss at epoch 2 step 2370: 2.7482287883758545\n",
      "\n",
      " This round's valence_loss=0.5956448316574097, arousal_loss=0.33087724447250366, emotion_loss=0.6828569173812866\n",
      "\n",
      "01_20_00:27:14 Seen so far: 75872 samples\n",
      "\n",
      "01_20_00:27:14 --- 1.8283679485321045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:15 Training loss at epoch 2 step 2380: 2.682609438896179\n",
      "\n",
      " This round's valence_loss=0.9670616984367371, arousal_loss=0.8002451658248901, emotion_loss=0.8068774938583374\n",
      "\n",
      "01_20_00:27:15 Seen so far: 76192 samples\n",
      "\n",
      "01_20_00:27:15 --- 1.6713013648986816 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:17 Training loss at epoch 2 step 2390: 3.3511887550354005\n",
      "\n",
      " This round's valence_loss=1.0921077728271484, arousal_loss=0.9598788619041443, emotion_loss=0.7108511328697205\n",
      "\n",
      "01_20_00:27:17 Seen so far: 76512 samples\n",
      "\n",
      "01_20_00:27:17 --- 1.6337509155273438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:19 Training loss at epoch 2 step 2400: 2.7906978130340576\n",
      "\n",
      " This round's valence_loss=0.8727248311042786, arousal_loss=0.7575187683105469, emotion_loss=0.6933637857437134\n",
      "\n",
      "01_20_00:27:19 Seen so far: 76832 samples\n",
      "\n",
      "01_20_00:27:19 --- 1.8207685947418213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:21 Training loss at epoch 2 step 2410: 2.9850875616073607\n",
      "\n",
      " This round's valence_loss=0.985649824142456, arousal_loss=0.7915010452270508, emotion_loss=0.667210578918457\n",
      "\n",
      "01_20_00:27:21 Seen so far: 77152 samples\n",
      "\n",
      "01_20_00:27:21 --- 1.786130666732788 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:23 Training loss at epoch 2 step 2420: 3.0970406532287598\n",
      "\n",
      " This round's valence_loss=1.4243425130844116, arousal_loss=1.3213518857955933, emotion_loss=0.8830639719963074\n",
      "\n",
      "01_20_00:27:23 Seen so far: 77472 samples\n",
      "\n",
      "01_20_00:27:23 --- 1.928041696548462 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:24 Training loss at epoch 2 step 2430: 3.2484113931655885\n",
      "\n",
      " This round's valence_loss=1.2246677875518799, arousal_loss=1.099094033241272, emotion_loss=1.0151166915893555\n",
      "\n",
      "01_20_00:27:24 Seen so far: 77792 samples\n",
      "\n",
      "01_20_00:27:24 --- 1.6922075748443604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:26 Training loss at epoch 2 step 2440: 3.0849501132965087\n",
      "\n",
      " This round's valence_loss=0.9267838001251221, arousal_loss=0.8054611682891846, emotion_loss=1.12859308719635\n",
      "\n",
      "01_20_00:27:26 Seen so far: 78112 samples\n",
      "\n",
      "01_20_00:27:26 --- 1.685326099395752 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:28 Training loss at epoch 2 step 2450: 3.049134850502014\n",
      "\n",
      " This round's valence_loss=0.8787206411361694, arousal_loss=0.7534475326538086, emotion_loss=1.1507610082626343\n",
      "\n",
      "01_20_00:27:28 Seen so far: 78432 samples\n",
      "\n",
      "01_20_00:27:28 --- 1.7610266208648682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:30 Training loss at epoch 2 step 2460: 3.037963938713074\n",
      "\n",
      " This round's valence_loss=1.1185390949249268, arousal_loss=0.961675763130188, emotion_loss=1.1600046157836914\n",
      "\n",
      "01_20_00:27:30 Seen so far: 78752 samples\n",
      "\n",
      "01_20_00:27:30 --- 1.8217179775238037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:32 Training loss at epoch 2 step 2470: 3.05935537815094\n",
      "\n",
      " This round's valence_loss=0.9851983785629272, arousal_loss=0.8639041781425476, emotion_loss=1.130861520767212\n",
      "\n",
      "01_20_00:27:32 Seen so far: 79072 samples\n",
      "\n",
      "01_20_00:27:32 --- 1.9304389953613281 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:33 Training loss at epoch 2 step 2480: 2.9532851219177245\n",
      "\n",
      " This round's valence_loss=0.9804379940032959, arousal_loss=0.8465485572814941, emotion_loss=0.9295932650566101\n",
      "\n",
      "01_20_00:27:33 Seen so far: 79392 samples\n",
      "\n",
      "01_20_00:27:33 --- 1.81538724899292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:35 Training loss at epoch 2 step 2490: 2.4271966457366942\n",
      "\n",
      " This round's valence_loss=0.8789318203926086, arousal_loss=0.7096610069274902, emotion_loss=0.6365918517112732\n",
      "\n",
      "01_20_00:27:35 Seen so far: 79712 samples\n",
      "\n",
      "01_20_00:27:35 --- 1.7400588989257812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:37 Training loss at epoch 2 step 2500: 3.1730169534683226\n",
      "\n",
      " This round's valence_loss=1.1594297885894775, arousal_loss=0.9064267873764038, emotion_loss=0.8393129110336304\n",
      "\n",
      "01_20_00:27:37 Seen so far: 80032 samples\n",
      "\n",
      "01_20_00:27:37 --- 1.6789805889129639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:38 Training loss at epoch 2 step 2510: 3.369019055366516\n",
      "\n",
      " This round's valence_loss=1.121093988418579, arousal_loss=0.9602887630462646, emotion_loss=0.8575305342674255\n",
      "\n",
      "01_20_00:27:38 Seen so far: 80352 samples\n",
      "\n",
      "01_20_00:27:38 --- 1.6828794479370117 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:40 Training loss at epoch 2 step 2520: 3.2046521425247194\n",
      "\n",
      " This round's valence_loss=1.324916958808899, arousal_loss=1.2291138172149658, emotion_loss=0.9129875898361206\n",
      "\n",
      "01_20_00:27:40 Seen so far: 80672 samples\n",
      "\n",
      "01_20_00:27:40 --- 1.8003768920898438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:42 Training loss at epoch 2 step 2530: 3.0971019506454467\n",
      "\n",
      " This round's valence_loss=1.0183205604553223, arousal_loss=0.8098763227462769, emotion_loss=1.0138498544692993\n",
      "\n",
      "01_20_00:27:42 Seen so far: 80992 samples\n",
      "\n",
      "01_20_00:27:42 --- 1.7623703479766846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:44 Training loss at epoch 2 step 2540: 3.0665102005004883\n",
      "\n",
      " This round's valence_loss=0.9907686710357666, arousal_loss=0.8440788984298706, emotion_loss=0.9558248519897461\n",
      "\n",
      "01_20_00:27:44 Seen so far: 81312 samples\n",
      "\n",
      "01_20_00:27:44 --- 1.7339704036712646 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:45 Training loss at epoch 2 step 2550: 3.1422030210494993\n",
      "\n",
      " This round's valence_loss=1.426289677619934, arousal_loss=1.305861473083496, emotion_loss=1.1542201042175293\n",
      "\n",
      "01_20_00:27:45 Seen so far: 81632 samples\n",
      "\n",
      "01_20_00:27:45 --- 1.6984584331512451 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:47 Training loss at epoch 2 step 2560: 2.8990293025970457\n",
      "\n",
      " This round's valence_loss=0.9324244856834412, arousal_loss=0.715389609336853, emotion_loss=1.068253993988037\n",
      "\n",
      "01_20_00:27:47 Seen so far: 81952 samples\n",
      "\n",
      "01_20_00:27:47 --- 1.7472913265228271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:49 Training loss at epoch 2 step 2570: 3.0077708959579468\n",
      "\n",
      " This round's valence_loss=0.8015464544296265, arousal_loss=0.6312922239303589, emotion_loss=0.9080042243003845\n",
      "\n",
      "01_20_00:27:49 Seen so far: 82272 samples\n",
      "\n",
      "01_20_00:27:49 --- 1.7535877227783203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:51 Training loss at epoch 2 step 2580: 2.709131097793579\n",
      "\n",
      " This round's valence_loss=1.591928482055664, arousal_loss=1.4397331476211548, emotion_loss=0.8160390853881836\n",
      "\n",
      "01_20_00:27:51 Seen so far: 82592 samples\n",
      "\n",
      "01_20_00:27:51 --- 1.6412513256072998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:52 Training loss at epoch 2 step 2590: 3.0393478870391846\n",
      "\n",
      " This round's valence_loss=0.8997273445129395, arousal_loss=0.6703604459762573, emotion_loss=0.6156755685806274\n",
      "\n",
      "01_20_00:27:52 Seen so far: 82912 samples\n",
      "\n",
      "01_20_00:27:52 --- 1.7939479351043701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:54 Training loss at epoch 2 step 2600: 2.922824478149414\n",
      "\n",
      " This round's valence_loss=0.5268923044204712, arousal_loss=0.33925506472587585, emotion_loss=0.9550397992134094\n",
      "\n",
      "01_20_00:27:54 Seen so far: 83232 samples\n",
      "\n",
      "01_20_00:27:54 --- 1.948554515838623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:56 Training loss at epoch 2 step 2610: 2.9160264253616335\n",
      "\n",
      " This round's valence_loss=1.0635838508605957, arousal_loss=0.939427375793457, emotion_loss=0.9207408428192139\n",
      "\n",
      "01_20_00:27:56 Seen so far: 83552 samples\n",
      "\n",
      "01_20_00:27:56 --- 1.5933969020843506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:58 Training loss at epoch 2 step 2620: 3.452268695831299\n",
      "\n",
      " This round's valence_loss=1.4979074001312256, arousal_loss=1.3363250494003296, emotion_loss=0.9669266939163208\n",
      "\n",
      "01_20_00:27:58 Seen so far: 83872 samples\n",
      "\n",
      "01_20_00:27:58 --- 1.7788712978363037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:27:59 Training loss at epoch 2 step 2630: 2.8161041021347044\n",
      "\n",
      " This round's valence_loss=1.1252110004425049, arousal_loss=0.999800443649292, emotion_loss=1.177408218383789\n",
      "\n",
      "01_20_00:27:59 Seen so far: 84192 samples\n",
      "\n",
      "01_20_00:27:59 --- 1.7982962131500244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:01 Training loss at epoch 2 step 2640: 3.039333534240723\n",
      "\n",
      " This round's valence_loss=1.0521056652069092, arousal_loss=0.8322290778160095, emotion_loss=0.7375824451446533\n",
      "\n",
      "01_20_00:28:01 Seen so far: 84512 samples\n",
      "\n",
      "01_20_00:28:01 --- 1.8958196640014648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:03 Training loss at epoch 2 step 2650: 2.901073956489563\n",
      "\n",
      " This round's valence_loss=0.869102954864502, arousal_loss=0.6824907064437866, emotion_loss=0.9896332025527954\n",
      "\n",
      "01_20_00:28:03 Seen so far: 84832 samples\n",
      "\n",
      "01_20_00:28:03 --- 1.8286335468292236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:05 Training loss at epoch 2 step 2660: 3.005064845085144\n",
      "\n",
      " This round's valence_loss=1.147049903869629, arousal_loss=0.9345941543579102, emotion_loss=0.8712288737297058\n",
      "\n",
      "01_20_00:28:05 Seen so far: 85152 samples\n",
      "\n",
      "01_20_00:28:05 --- 1.8469631671905518 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:07 Training loss at epoch 2 step 2670: 3.146003842353821\n",
      "\n",
      " This round's valence_loss=1.0071768760681152, arousal_loss=0.6891552805900574, emotion_loss=0.7608675360679626\n",
      "\n",
      "01_20_00:28:07 Seen so far: 85472 samples\n",
      "\n",
      "01_20_00:28:07 --- 1.7755632400512695 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:09 Training loss at epoch 2 step 2680: 3.094833254814148\n",
      "\n",
      " This round's valence_loss=1.227150321006775, arousal_loss=1.0514912605285645, emotion_loss=0.8017547130584717\n",
      "\n",
      "01_20_00:28:09 Seen so far: 85792 samples\n",
      "\n",
      "01_20_00:28:09 --- 1.6972565650939941 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:10 Training loss at epoch 2 step 2690: 2.9003223180770874\n",
      "\n",
      " This round's valence_loss=1.2534065246582031, arousal_loss=1.0465166568756104, emotion_loss=0.7849593162536621\n",
      "\n",
      "01_20_00:28:10 Seen so far: 86112 samples\n",
      "\n",
      "01_20_00:28:10 --- 1.690936803817749 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:12 Training loss at epoch 2 step 2700: 3.1241361618041994\n",
      "\n",
      " This round's valence_loss=0.9257116913795471, arousal_loss=0.8283832669258118, emotion_loss=0.9174641370773315\n",
      "\n",
      "01_20_00:28:12 Seen so far: 86432 samples\n",
      "\n",
      "01_20_00:28:12 --- 1.6674916744232178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:14 Training loss at epoch 2 step 2710: 3.3692145347595215\n",
      "\n",
      " This round's valence_loss=1.3499518632888794, arousal_loss=1.2067022323608398, emotion_loss=0.9174025058746338\n",
      "\n",
      "01_20_00:28:14 Seen so far: 86752 samples\n",
      "\n",
      "01_20_00:28:14 --- 1.6441729068756104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:15 Training loss at epoch 2 step 2720: 2.9450377225875854\n",
      "\n",
      " This round's valence_loss=1.4439616203308105, arousal_loss=1.326634407043457, emotion_loss=0.6330388784408569\n",
      "\n",
      "01_20_00:28:15 Seen so far: 87072 samples\n",
      "\n",
      "01_20_00:28:15 --- 1.6892545223236084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:17 Training loss at epoch 2 step 2730: 3.085618567466736\n",
      "\n",
      " This round's valence_loss=0.8987765312194824, arousal_loss=0.8413440585136414, emotion_loss=1.1684975624084473\n",
      "\n",
      "01_20_00:28:17 Seen so far: 87392 samples\n",
      "\n",
      "01_20_00:28:17 --- 1.618847131729126 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:19 Training loss at epoch 2 step 2740: 3.110978925228119\n",
      "\n",
      " This round's valence_loss=1.2881767749786377, arousal_loss=1.1754558086395264, emotion_loss=0.9052974581718445\n",
      "\n",
      "01_20_00:28:19 Seen so far: 87712 samples\n",
      "\n",
      "01_20_00:28:19 --- 1.7135226726531982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:20 Training loss at epoch 2 step 2750: 3.358907198905945\n",
      "\n",
      " This round's valence_loss=1.363625407218933, arousal_loss=1.1888689994812012, emotion_loss=1.0076552629470825\n",
      "\n",
      "01_20_00:28:20 Seen so far: 88032 samples\n",
      "\n",
      "01_20_00:28:20 --- 1.800175428390503 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:22 Training loss at epoch 2 step 2760: 2.9055400609970095\n",
      "\n",
      " This round's valence_loss=1.164724588394165, arousal_loss=1.074446439743042, emotion_loss=1.0023550987243652\n",
      "\n",
      "01_20_00:28:22 Seen so far: 88352 samples\n",
      "\n",
      "01_20_00:28:22 --- 1.687695026397705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:24 Training loss at epoch 2 step 2770: 3.0717110633850098\n",
      "\n",
      " This round's valence_loss=0.9693998694419861, arousal_loss=0.8065274953842163, emotion_loss=0.8343988656997681\n",
      "\n",
      "01_20_00:28:24 Seen so far: 88672 samples\n",
      "\n",
      "01_20_00:28:24 --- 1.7757527828216553 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:26 Training loss at epoch 2 step 2780: 2.9767405509948732\n",
      "\n",
      " This round's valence_loss=1.3534047603607178, arousal_loss=1.2209067344665527, emotion_loss=0.9481484889984131\n",
      "\n",
      "01_20_00:28:26 Seen so far: 88992 samples\n",
      "\n",
      "01_20_00:28:26 --- 1.8627593517303467 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:28 Training loss at epoch 2 step 2790: 3.1918909788131713\n",
      "\n",
      " This round's valence_loss=1.1916718482971191, arousal_loss=1.1121063232421875, emotion_loss=0.9627729058265686\n",
      "\n",
      "01_20_00:28:28 Seen so far: 89312 samples\n",
      "\n",
      "01_20_00:28:28 --- 1.887845754623413 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:29 Training loss at epoch 2 step 2800: 3.0782719612121583\n",
      "\n",
      " This round's valence_loss=1.1783865690231323, arousal_loss=1.0862727165222168, emotion_loss=1.0641775131225586\n",
      "\n",
      "01_20_00:28:29 Seen so far: 89632 samples\n",
      "\n",
      "01_20_00:28:29 --- 1.7395613193511963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:31 Training loss at epoch 2 step 2810: 2.9257248878479003\n",
      "\n",
      " This round's valence_loss=1.2654420137405396, arousal_loss=1.0724384784698486, emotion_loss=0.761591911315918\n",
      "\n",
      "01_20_00:28:31 Seen so far: 89952 samples\n",
      "\n",
      "01_20_00:28:31 --- 1.8318595886230469 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:33 Training loss at epoch 2 step 2820: 2.761043334007263\n",
      "\n",
      " This round's valence_loss=0.43862271308898926, arousal_loss=0.36934447288513184, emotion_loss=1.0481581687927246\n",
      "\n",
      "01_20_00:28:33 Seen so far: 90272 samples\n",
      "\n",
      "01_20_00:28:33 --- 1.916541337966919 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:35 Training loss at epoch 2 step 2830: 3.213761579990387\n",
      "\n",
      " This round's valence_loss=1.6424179077148438, arousal_loss=1.464745044708252, emotion_loss=1.0391836166381836\n",
      "\n",
      "01_20_00:28:35 Seen so far: 90592 samples\n",
      "\n",
      "01_20_00:28:35 --- 1.606745958328247 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:36 Training loss at epoch 2 step 2840: 2.836425256729126\n",
      "\n",
      " This round's valence_loss=1.094321846961975, arousal_loss=0.9583117961883545, emotion_loss=0.7231464982032776\n",
      "\n",
      "01_20_00:28:36 Seen so far: 90912 samples\n",
      "\n",
      "01_20_00:28:36 --- 1.6460356712341309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:38 Training loss at epoch 2 step 2850: 3.1129645824432375\n",
      "\n",
      " This round's valence_loss=0.7962300777435303, arousal_loss=0.5729670524597168, emotion_loss=0.879759669303894\n",
      "\n",
      "01_20_00:28:38 Seen so far: 91232 samples\n",
      "\n",
      "01_20_00:28:38 --- 1.820387601852417 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:40 Training loss at epoch 2 step 2860: 3.1044927716255186\n",
      "\n",
      " This round's valence_loss=1.1142148971557617, arousal_loss=1.019054651260376, emotion_loss=1.1529698371887207\n",
      "\n",
      "01_20_00:28:40 Seen so far: 91552 samples\n",
      "\n",
      "01_20_00:28:40 --- 1.6474075317382812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:42 Training loss at epoch 2 step 2870: 3.0937249183654787\n",
      "\n",
      " This round's valence_loss=1.3884289264678955, arousal_loss=1.3401880264282227, emotion_loss=1.0170049667358398\n",
      "\n",
      "01_20_00:28:42 Seen so far: 91872 samples\n",
      "\n",
      "01_20_00:28:42 --- 1.7915196418762207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:43 Training loss at epoch 2 step 2880: 3.432757830619812\n",
      "\n",
      " This round's valence_loss=1.4222676753997803, arousal_loss=1.3492069244384766, emotion_loss=1.049553632736206\n",
      "\n",
      "01_20_00:28:43 Seen so far: 92192 samples\n",
      "\n",
      "01_20_00:28:43 --- 1.7224397659301758 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:45 Training loss at epoch 2 step 2890: 3.050758409500122\n",
      "\n",
      " This round's valence_loss=1.564676284790039, arousal_loss=1.4881906509399414, emotion_loss=1.117747187614441\n",
      "\n",
      "01_20_00:28:45 Seen so far: 92512 samples\n",
      "\n",
      "01_20_00:28:45 --- 1.8707313537597656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:47 Training loss at epoch 2 step 2900: 2.9559908866882325\n",
      "\n",
      " This round's valence_loss=1.4258410930633545, arousal_loss=1.3201792240142822, emotion_loss=1.1208875179290771\n",
      "\n",
      "01_20_00:28:47 Seen so far: 92832 samples\n",
      "\n",
      "01_20_00:28:47 --- 1.9266695976257324 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:49 Training loss at epoch 2 step 2910: 3.1549813032150267\n",
      "\n",
      " This round's valence_loss=1.3096108436584473, arousal_loss=1.2343165874481201, emotion_loss=0.9263465404510498\n",
      "\n",
      "01_20_00:28:49 Seen so far: 93152 samples\n",
      "\n",
      "01_20_00:28:49 --- 1.9091966152191162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:51 Training loss at epoch 2 step 2920: 2.8462211012840273\n",
      "\n",
      " This round's valence_loss=1.66550612449646, arousal_loss=1.5797593593597412, emotion_loss=0.749314546585083\n",
      "\n",
      "01_20_00:28:51 Seen so far: 93472 samples\n",
      "\n",
      "01_20_00:28:51 --- 2.108558177947998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:53 Training loss at epoch 2 step 2930: 3.1557614326477053\n",
      "\n",
      " This round's valence_loss=1.150391697883606, arousal_loss=1.1105213165283203, emotion_loss=1.145371675491333\n",
      "\n",
      "01_20_00:28:53 Seen so far: 93792 samples\n",
      "\n",
      "01_20_00:28:53 --- 1.6645030975341797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:55 Training loss at epoch 2 step 2940: 2.605893301963806\n",
      "\n",
      " This round's valence_loss=1.1148579120635986, arousal_loss=0.9627895355224609, emotion_loss=0.7784088850021362\n",
      "\n",
      "01_20_00:28:55 Seen so far: 94112 samples\n",
      "\n",
      "01_20_00:28:55 --- 1.9943678379058838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:57 Training loss at epoch 2 step 2950: 3.17853364944458\n",
      "\n",
      " This round's valence_loss=1.2444357872009277, arousal_loss=1.0878195762634277, emotion_loss=1.1010491847991943\n",
      "\n",
      "01_20_00:28:57 Seen so far: 94432 samples\n",
      "\n",
      "01_20_00:28:57 --- 1.7849512100219727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:28:58 Training loss at epoch 2 step 2960: 3.3174565076828\n",
      "\n",
      " This round's valence_loss=1.5151445865631104, arousal_loss=1.4782211780548096, emotion_loss=0.9741600751876831\n",
      "\n",
      "01_20_00:28:58 Seen so far: 94752 samples\n",
      "\n",
      "01_20_00:28:58 --- 1.6977665424346924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:00 Training loss at epoch 2 step 2970: 3.271064829826355\n",
      "\n",
      " This round's valence_loss=1.0274901390075684, arousal_loss=0.8459392189979553, emotion_loss=1.106534481048584\n",
      "\n",
      "01_20_00:29:00 Seen so far: 95072 samples\n",
      "\n",
      "01_20_00:29:00 --- 1.6618342399597168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:02 Training loss at epoch 2 step 2980: 3.1011537671089173\n",
      "\n",
      " This round's valence_loss=1.457567811012268, arousal_loss=1.316215991973877, emotion_loss=0.9369148015975952\n",
      "\n",
      "01_20_00:29:02 Seen so far: 95392 samples\n",
      "\n",
      "01_20_00:29:02 --- 1.7244594097137451 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:03 Training loss at epoch 2 step 2990: 2.838650703430176\n",
      "\n",
      " This round's valence_loss=1.094567060470581, arousal_loss=0.9630953073501587, emotion_loss=1.1042495965957642\n",
      "\n",
      "01_20_00:29:03 Seen so far: 95712 samples\n",
      "\n",
      "01_20_00:29:03 --- 1.6484510898590088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:05 Training loss at epoch 2 step 3000: 2.9659827709198\n",
      "\n",
      " This round's valence_loss=0.8719125390052795, arousal_loss=0.6792266964912415, emotion_loss=0.941446840763092\n",
      "\n",
      "01_20_00:29:05 Seen so far: 96032 samples\n",
      "\n",
      "01_20_00:29:05 --- 1.805971622467041 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:07 Training loss at epoch 2 step 3010: 3.021738123893738\n",
      "\n",
      " This round's valence_loss=1.0730385780334473, arousal_loss=0.9766761660575867, emotion_loss=0.9584510922431946\n",
      "\n",
      "01_20_00:29:07 Seen so far: 96352 samples\n",
      "\n",
      "01_20_00:29:07 --- 1.736006259918213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:09 Training loss at epoch 2 step 3020: 2.783052349090576\n",
      "\n",
      " This round's valence_loss=1.2253365516662598, arousal_loss=1.0822687149047852, emotion_loss=0.9013091325759888\n",
      "\n",
      "01_20_00:29:09 Seen so far: 96672 samples\n",
      "\n",
      "01_20_00:29:09 --- 1.9121973514556885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:10 Training loss at epoch 2 step 3030: 3.216041088104248\n",
      "\n",
      " This round's valence_loss=1.4598238468170166, arousal_loss=1.3066058158874512, emotion_loss=1.001986026763916\n",
      "\n",
      "01_20_00:29:10 Seen so far: 96992 samples\n",
      "\n",
      "01_20_00:29:10 --- 1.6471083164215088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:12 Training loss at epoch 2 step 3040: 2.893723893165588\n",
      "\n",
      " This round's valence_loss=1.0960663557052612, arousal_loss=0.961819589138031, emotion_loss=1.2274614572525024\n",
      "\n",
      "01_20_00:29:12 Seen so far: 97312 samples\n",
      "\n",
      "01_20_00:29:12 --- 1.621131420135498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:14 Training loss at epoch 2 step 3050: 3.0962487697601317\n",
      "\n",
      " This round's valence_loss=1.0357258319854736, arousal_loss=0.8199722766876221, emotion_loss=1.0257817506790161\n",
      "\n",
      "01_20_00:29:14 Seen so far: 97632 samples\n",
      "\n",
      "01_20_00:29:14 --- 1.7511951923370361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:15 Training loss at epoch 2 step 3060: 2.929625415802002\n",
      "\n",
      " This round's valence_loss=1.0492191314697266, arousal_loss=0.961898684501648, emotion_loss=1.051923394203186\n",
      "\n",
      "01_20_00:29:15 Seen so far: 97952 samples\n",
      "\n",
      "01_20_00:29:15 --- 1.7147095203399658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:17 Training loss at epoch 2 step 3070: 3.1725817680358888\n",
      "\n",
      " This round's valence_loss=0.8242461681365967, arousal_loss=0.7095069885253906, emotion_loss=0.9128763675689697\n",
      "\n",
      "01_20_00:29:17 Seen so far: 98272 samples\n",
      "\n",
      "01_20_00:29:17 --- 1.7616443634033203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:19 Training loss at epoch 2 step 3080: 3.0212182283401487\n",
      "\n",
      " This round's valence_loss=1.090293049812317, arousal_loss=1.0127935409545898, emotion_loss=0.8113387227058411\n",
      "\n",
      "01_20_00:29:19 Seen so far: 98592 samples\n",
      "\n",
      "01_20_00:29:19 --- 1.833329677581787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:21 Training loss at epoch 2 step 3090: 3.0588741660118104\n",
      "\n",
      " This round's valence_loss=1.5541483163833618, arousal_loss=1.4631576538085938, emotion_loss=0.8185582160949707\n",
      "\n",
      "01_20_00:29:21 Seen so far: 98912 samples\n",
      "\n",
      "01_20_00:29:21 --- 1.8004653453826904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:23 Training loss at epoch 2 step 3100: 2.9375587701797485\n",
      "\n",
      " This round's valence_loss=0.8290891647338867, arousal_loss=0.6966521739959717, emotion_loss=0.7973543405532837\n",
      "\n",
      "01_20_00:29:23 Seen so far: 99232 samples\n",
      "\n",
      "01_20_00:29:23 --- 1.8975512981414795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:24 Training loss at epoch 2 step 3110: 2.9864810943603515\n",
      "\n",
      " This round's valence_loss=0.9577715396881104, arousal_loss=0.8463289737701416, emotion_loss=0.9043941497802734\n",
      "\n",
      "01_20_00:29:24 Seen so far: 99552 samples\n",
      "\n",
      "01_20_00:29:24 --- 1.7185893058776855 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:26 Training loss at epoch 2 step 3120: 3.2725470066070557\n",
      "\n",
      " This round's valence_loss=1.483919620513916, arousal_loss=1.280442476272583, emotion_loss=0.6969848275184631\n",
      "\n",
      "01_20_00:29:26 Seen so far: 99872 samples\n",
      "\n",
      "01_20_00:29:26 --- 1.7983078956604004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:28 Training loss at epoch 2 step 3130: 3.203836750984192\n",
      "\n",
      " This round's valence_loss=1.1305993795394897, arousal_loss=0.9509800672531128, emotion_loss=1.1443272829055786\n",
      "\n",
      "01_20_00:29:28 Seen so far: 100192 samples\n",
      "\n",
      "01_20_00:29:28 --- 1.5989460945129395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:30 Training loss at epoch 2 step 3140: 2.9829099416732787\n",
      "\n",
      " This round's valence_loss=1.099405288696289, arousal_loss=0.984096109867096, emotion_loss=0.9348878860473633\n",
      "\n",
      "01_20_00:29:30 Seen so far: 100512 samples\n",
      "\n",
      "01_20_00:29:30 --- 1.6201088428497314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:31 Training loss at epoch 2 step 3150: 3.1332913637161255\n",
      "\n",
      " This round's valence_loss=1.102808952331543, arousal_loss=0.985954999923706, emotion_loss=1.1052271127700806\n",
      "\n",
      "01_20_00:29:31 Seen so far: 100832 samples\n",
      "\n",
      "01_20_00:29:31 --- 1.6784627437591553 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:33 Training loss at epoch 2 step 3160: 2.7928036212921143\n",
      "\n",
      " This round's valence_loss=1.166556477546692, arousal_loss=0.9736519455909729, emotion_loss=1.2443475723266602\n",
      "\n",
      "01_20_00:29:33 Seen so far: 101152 samples\n",
      "\n",
      "01_20_00:29:33 --- 1.693899393081665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:35 Training loss at epoch 2 step 3170: 3.1518411159515383\n",
      "\n",
      " This round's valence_loss=0.8498975038528442, arousal_loss=0.7065664529800415, emotion_loss=1.2750544548034668\n",
      "\n",
      "01_20_00:29:35 Seen so far: 101472 samples\n",
      "\n",
      "01_20_00:29:35 --- 1.647233009338379 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:36 Training loss at epoch 2 step 3180: 2.9644113063812254\n",
      "\n",
      " This round's valence_loss=0.6647636890411377, arousal_loss=0.44457781314849854, emotion_loss=1.139716625213623\n",
      "\n",
      "01_20_00:29:36 Seen so far: 101792 samples\n",
      "\n",
      "01_20_00:29:36 --- 1.7179701328277588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:38 Training loss at epoch 2 step 3190: 2.95653817653656\n",
      "\n",
      " This round's valence_loss=0.9631680250167847, arousal_loss=0.8566492795944214, emotion_loss=0.9582698345184326\n",
      "\n",
      "01_20_00:29:38 Seen so far: 102112 samples\n",
      "\n",
      "01_20_00:29:38 --- 1.7314460277557373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:40 Training loss at epoch 2 step 3200: 3.3083717703819273\n",
      "\n",
      " This round's valence_loss=1.4079993963241577, arousal_loss=1.3150922060012817, emotion_loss=0.9282248616218567\n",
      "\n",
      "01_20_00:29:40 Seen so far: 102432 samples\n",
      "\n",
      "01_20_00:29:40 --- 1.7875585556030273 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:41 Training loss at epoch 2 step 3210: 3.5108529329299927\n",
      "\n",
      " This round's valence_loss=1.1980416774749756, arousal_loss=0.9588513374328613, emotion_loss=0.6297899484634399\n",
      "\n",
      "01_20_00:29:41 Seen so far: 102752 samples\n",
      "\n",
      "01_20_00:29:41 --- 1.684560775756836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:43 Training loss at epoch 2 step 3220: 3.2202253103256226\n",
      "\n",
      " This round's valence_loss=1.4006624221801758, arousal_loss=1.3223421573638916, emotion_loss=1.2795170545578003\n",
      "\n",
      "01_20_00:29:43 Seen so far: 103072 samples\n",
      "\n",
      "01_20_00:29:43 --- 1.8492670059204102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:45 Training loss at epoch 2 step 3230: 3.0744421243667603\n",
      "\n",
      " This round's valence_loss=1.1826659440994263, arousal_loss=0.9209067821502686, emotion_loss=0.7282495498657227\n",
      "\n",
      "01_20_00:29:45 Seen so far: 103392 samples\n",
      "\n",
      "01_20_00:29:45 --- 1.6715784072875977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:47 Training loss at epoch 2 step 3240: 3.2175927639007567\n",
      "\n",
      " This round's valence_loss=1.2003644704818726, arousal_loss=1.0947213172912598, emotion_loss=0.6811581254005432\n",
      "\n",
      "01_20_00:29:47 Seen so far: 103712 samples\n",
      "\n",
      "01_20_00:29:47 --- 1.773728609085083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:49 Training loss at epoch 2 step 3250: 2.954360473155975\n",
      "\n",
      " This round's valence_loss=0.8636807203292847, arousal_loss=0.6917046308517456, emotion_loss=1.3043036460876465\n",
      "\n",
      "01_20_00:29:49 Seen so far: 104032 samples\n",
      "\n",
      "01_20_00:29:49 --- 1.7628438472747803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:50 Training loss at epoch 2 step 3260: 3.058753478527069\n",
      "\n",
      " This round's valence_loss=1.221129298210144, arousal_loss=1.0828304290771484, emotion_loss=0.9388477206230164\n",
      "\n",
      "01_20_00:29:50 Seen so far: 104352 samples\n",
      "\n",
      "01_20_00:29:50 --- 1.9196641445159912 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:52 Training loss at epoch 2 step 3270: 2.99242901802063\n",
      "\n",
      " This round's valence_loss=0.6972094774246216, arousal_loss=0.5959992408752441, emotion_loss=0.8674261569976807\n",
      "\n",
      "01_20_00:29:52 Seen so far: 104672 samples\n",
      "\n",
      "01_20_00:29:52 --- 1.8827900886535645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:54 Training loss at epoch 2 step 3280: 2.999090814590454\n",
      "\n",
      " This round's valence_loss=1.1421101093292236, arousal_loss=0.9487043023109436, emotion_loss=0.9534860849380493\n",
      "\n",
      "01_20_00:29:54 Seen so far: 104992 samples\n",
      "\n",
      "01_20_00:29:54 --- 1.8475141525268555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:56 Training loss at epoch 2 step 3290: 3.038244843482971\n",
      "\n",
      " This round's valence_loss=0.9354057312011719, arousal_loss=0.8839886784553528, emotion_loss=1.3021377325057983\n",
      "\n",
      "01_20_00:29:56 Seen so far: 105312 samples\n",
      "\n",
      "01_20_00:29:56 --- 1.718369722366333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:58 Training loss at epoch 2 step 3300: 2.760521984100342\n",
      "\n",
      " This round's valence_loss=1.3325097560882568, arousal_loss=1.1620659828186035, emotion_loss=0.8452607989311218\n",
      "\n",
      "01_20_00:29:58 Seen so far: 105632 samples\n",
      "\n",
      "01_20_00:29:58 --- 1.66497802734375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:29:59 Training loss at epoch 2 step 3310: 2.925037670135498\n",
      "\n",
      " This round's valence_loss=1.1262062788009644, arousal_loss=0.9944300651550293, emotion_loss=1.2294895648956299\n",
      "\n",
      "01_20_00:29:59 Seen so far: 105952 samples\n",
      "\n",
      "01_20_00:29:59 --- 1.6156697273254395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:01 Training loss at epoch 2 step 3320: 3.37108633518219\n",
      "\n",
      " This round's valence_loss=1.344104528427124, arousal_loss=1.194938063621521, emotion_loss=0.7430731058120728\n",
      "\n",
      "01_20_00:30:01 Seen so far: 106272 samples\n",
      "\n",
      "01_20_00:30:01 --- 1.686676025390625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:03 Training loss at epoch 2 step 3330: 2.8755050182342528\n",
      "\n",
      " This round's valence_loss=1.0379691123962402, arousal_loss=0.8325473070144653, emotion_loss=0.8587385416030884\n",
      "\n",
      "01_20_00:30:03 Seen so far: 106592 samples\n",
      "\n",
      "01_20_00:30:03 --- 1.7483265399932861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:04 Training loss at epoch 2 step 3340: 3.096800994873047\n",
      "\n",
      " This round's valence_loss=1.1651394367218018, arousal_loss=0.9653928279876709, emotion_loss=0.6271811127662659\n",
      "\n",
      "01_20_00:30:04 Seen so far: 106912 samples\n",
      "\n",
      "01_20_00:30:04 --- 1.8568060398101807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:06 Training loss at epoch 2 step 3350: 3.151135206222534\n",
      "\n",
      " This round's valence_loss=0.9820877909660339, arousal_loss=0.8906062841415405, emotion_loss=1.1467463970184326\n",
      "\n",
      "01_20_00:30:06 Seen so far: 107232 samples\n",
      "\n",
      "01_20_00:30:06 --- 1.6325328350067139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:08 Training loss at epoch 2 step 3360: 3.068131458759308\n",
      "\n",
      " This round's valence_loss=1.0591928958892822, arousal_loss=0.8606255054473877, emotion_loss=1.170792579650879\n",
      "\n",
      "01_20_00:30:08 Seen so far: 107552 samples\n",
      "\n",
      "01_20_00:30:08 --- 1.7157127857208252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:10 Training loss at epoch 2 step 3370: 3.0478970766067506\n",
      "\n",
      " This round's valence_loss=0.9641950130462646, arousal_loss=0.8761018514633179, emotion_loss=0.8983681797981262\n",
      "\n",
      "01_20_00:30:10 Seen so far: 107872 samples\n",
      "\n",
      "01_20_00:30:10 --- 1.8795015811920166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:11 Training loss at epoch 2 step 3380: 2.785531210899353\n",
      "\n",
      " This round's valence_loss=0.9442135095596313, arousal_loss=0.8607497811317444, emotion_loss=1.2682857513427734\n",
      "\n",
      "01_20_00:30:11 Seen so far: 108192 samples\n",
      "\n",
      "01_20_00:30:11 --- 1.7682127952575684 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:13 Training loss at epoch 2 step 3390: 2.9917490482330322\n",
      "\n",
      " This round's valence_loss=0.6916017532348633, arousal_loss=0.46805596351623535, emotion_loss=1.0946660041809082\n",
      "\n",
      "01_20_00:30:13 Seen so far: 108512 samples\n",
      "\n",
      "01_20_00:30:13 --- 1.7274961471557617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:15 Training loss at epoch 2 step 3400: 3.0368619203567504\n",
      "\n",
      " This round's valence_loss=1.3676388263702393, arousal_loss=1.2245053052902222, emotion_loss=1.2153712511062622\n",
      "\n",
      "01_20_00:30:15 Seen so far: 108832 samples\n",
      "\n",
      "01_20_00:30:15 --- 1.738217830657959 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:17 Training loss at epoch 2 step 3410: 3.36094217300415\n",
      "\n",
      " This round's valence_loss=0.8054325580596924, arousal_loss=0.7086058855056763, emotion_loss=0.9629359841346741\n",
      "\n",
      "01_20_00:30:17 Seen so far: 109152 samples\n",
      "\n",
      "01_20_00:30:17 --- 1.7643542289733887 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:19 Training loss at epoch 2 step 3420: 3.527055859565735\n",
      "\n",
      " This round's valence_loss=1.6526051759719849, arousal_loss=1.525592565536499, emotion_loss=0.712100088596344\n",
      "\n",
      "01_20_00:30:19 Seen so far: 109472 samples\n",
      "\n",
      "01_20_00:30:19 --- 1.9218382835388184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:20 Training loss at epoch 2 step 3430: 3.0734909772872925\n",
      "\n",
      " This round's valence_loss=1.58046555519104, arousal_loss=1.5854134559631348, emotion_loss=0.6616079211235046\n",
      "\n",
      "01_20_00:30:20 Seen so far: 109792 samples\n",
      "\n",
      "01_20_00:30:20 --- 1.7189292907714844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:22 Training loss at epoch 2 step 3440: 3.368674302101135\n",
      "\n",
      " This round's valence_loss=0.7610560655593872, arousal_loss=0.6521583795547485, emotion_loss=1.163667917251587\n",
      "\n",
      "01_20_00:30:22 Seen so far: 110112 samples\n",
      "\n",
      "01_20_00:30:22 --- 1.7094061374664307 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:24 Training loss at epoch 2 step 3450: 3.26433744430542\n",
      "\n",
      " This round's valence_loss=1.3707966804504395, arousal_loss=1.320136308670044, emotion_loss=1.275362253189087\n",
      "\n",
      "01_20_00:30:24 Seen so far: 110432 samples\n",
      "\n",
      "01_20_00:30:24 --- 1.6365981101989746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:25 Training loss at epoch 2 step 3460: 3.342015337944031\n",
      "\n",
      " This round's valence_loss=1.2978134155273438, arousal_loss=1.2026331424713135, emotion_loss=1.0009948015213013\n",
      "\n",
      "01_20_00:30:25 Seen so far: 110752 samples\n",
      "\n",
      "01_20_00:30:25 --- 1.816756010055542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:27 Training loss at epoch 2 step 3470: 2.978702425956726\n",
      "\n",
      " This round's valence_loss=0.6779892444610596, arousal_loss=0.6142188310623169, emotion_loss=1.0134906768798828\n",
      "\n",
      "01_20_00:30:27 Seen so far: 111072 samples\n",
      "\n",
      "01_20_00:30:27 --- 1.721261739730835 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:29 Training loss at epoch 2 step 3480: 3.0780835151672363\n",
      "\n",
      " This round's valence_loss=0.9138835668563843, arousal_loss=0.864700198173523, emotion_loss=1.3177748918533325\n",
      "\n",
      "01_20_00:30:29 Seen so far: 111392 samples\n",
      "\n",
      "01_20_00:30:29 --- 1.7876341342926025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:31 Training loss at epoch 2 step 3490: 2.7841006755828857\n",
      "\n",
      " This round's valence_loss=0.923335075378418, arousal_loss=0.852368175983429, emotion_loss=0.9670535326004028\n",
      "\n",
      "01_20_00:30:31 Seen so far: 111712 samples\n",
      "\n",
      "01_20_00:30:31 --- 1.8082687854766846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:33 Training loss at epoch 2 step 3500: 2.751372516155243\n",
      "\n",
      " This round's valence_loss=1.1459559202194214, arousal_loss=0.9932284355163574, emotion_loss=1.0311447381973267\n",
      "\n",
      "01_20_00:30:33 Seen so far: 112032 samples\n",
      "\n",
      "01_20_00:30:33 --- 1.755098819732666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:34 Training loss at epoch 2 step 3510: 2.8593927025794983\n",
      "\n",
      " This round's valence_loss=0.7407423257827759, arousal_loss=0.6425954103469849, emotion_loss=1.1391563415527344\n",
      "\n",
      "01_20_00:30:34 Seen so far: 112352 samples\n",
      "\n",
      "01_20_00:30:34 --- 1.6492068767547607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:36 Training loss at epoch 2 step 3520: 3.4592931509017943\n",
      "\n",
      " This round's valence_loss=1.1037499904632568, arousal_loss=0.9612123966217041, emotion_loss=1.0572166442871094\n",
      "\n",
      "01_20_00:30:36 Seen so far: 112672 samples\n",
      "\n",
      "01_20_00:30:36 --- 1.876509428024292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:38 Training loss at epoch 2 step 3530: 2.779569458961487\n",
      "\n",
      " This round's valence_loss=0.7557443380355835, arousal_loss=0.6326872110366821, emotion_loss=1.0428240299224854\n",
      "\n",
      "01_20_00:30:38 Seen so far: 112992 samples\n",
      "\n",
      "01_20_00:30:38 --- 1.665869951248169 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:40 Training loss at epoch 2 step 3540: 2.6798914670944214\n",
      "\n",
      " This round's valence_loss=0.8855302333831787, arousal_loss=0.669587254524231, emotion_loss=0.988984227180481\n",
      "\n",
      "01_20_00:30:40 Seen so far: 113312 samples\n",
      "\n",
      "01_20_00:30:40 --- 1.8334786891937256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:42 Training loss at epoch 2 step 3550: 2.65230313539505\n",
      "\n",
      " This round's valence_loss=0.7245835065841675, arousal_loss=0.6028679609298706, emotion_loss=0.8023884296417236\n",
      "\n",
      "01_20_00:30:42 Seen so far: 113632 samples\n",
      "\n",
      "01_20_00:30:42 --- 1.9755616188049316 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:43 Training loss at epoch 2 step 3560: 3.5166396617889406\n",
      "\n",
      " This round's valence_loss=1.453498125076294, arousal_loss=1.2957217693328857, emotion_loss=1.00510835647583\n",
      "\n",
      "01_20_00:30:43 Seen so far: 113952 samples\n",
      "\n",
      "01_20_00:30:43 --- 1.7236711978912354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:45 Training loss at epoch 2 step 3570: 3.0501447439193727\n",
      "\n",
      " This round's valence_loss=1.0162646770477295, arousal_loss=0.9357236623764038, emotion_loss=0.9422866106033325\n",
      "\n",
      "01_20_00:30:45 Seen so far: 114272 samples\n",
      "\n",
      "01_20_00:30:45 --- 1.7114603519439697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:47 Training loss at epoch 2 step 3580: 2.8210857629776003\n",
      "\n",
      " This round's valence_loss=0.7699630260467529, arousal_loss=0.5844593048095703, emotion_loss=0.9923503398895264\n",
      "\n",
      "01_20_00:30:47 Seen so far: 114592 samples\n",
      "\n",
      "01_20_00:30:47 --- 1.9975996017456055 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:49 Training loss at epoch 2 step 3590: 3.108039748668671\n",
      "\n",
      " This round's valence_loss=1.1329119205474854, arousal_loss=1.021936058998108, emotion_loss=1.0726879835128784\n",
      "\n",
      "01_20_00:30:49 Seen so far: 114912 samples\n",
      "\n",
      "01_20_00:30:49 --- 1.6190345287322998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:50 Training loss at epoch 2 step 3600: 3.5325329065322877\n",
      "\n",
      " This round's valence_loss=1.6913721561431885, arousal_loss=1.5562251806259155, emotion_loss=0.8464425802230835\n",
      "\n",
      "01_20_00:30:50 Seen so far: 115232 samples\n",
      "\n",
      "01_20_00:30:50 --- 1.759767770767212 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:52 Training loss at epoch 2 step 3610: 3.070165419578552\n",
      "\n",
      " This round's valence_loss=1.369708776473999, arousal_loss=1.3503737449645996, emotion_loss=1.2036269903182983\n",
      "\n",
      "01_20_00:30:52 Seen so far: 115552 samples\n",
      "\n",
      "01_20_00:30:52 --- 1.6146204471588135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:54 Training loss at epoch 2 step 3620: 2.977458930015564\n",
      "\n",
      " This round's valence_loss=0.5243399739265442, arousal_loss=0.3655950129032135, emotion_loss=0.9820854663848877\n",
      "\n",
      "01_20_00:30:54 Seen so far: 115872 samples\n",
      "\n",
      "01_20_00:30:54 --- 1.8009774684906006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:55 Training loss at epoch 2 step 3630: 3.2083382844924926\n",
      "\n",
      " This round's valence_loss=1.0843422412872314, arousal_loss=1.0041894912719727, emotion_loss=1.2462215423583984\n",
      "\n",
      "01_20_00:30:55 Seen so far: 116192 samples\n",
      "\n",
      "01_20_00:30:55 --- 1.657477617263794 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:57 Training loss at epoch 2 step 3640: 2.9569932579994203\n",
      "\n",
      " This round's valence_loss=0.6142674684524536, arousal_loss=0.4778779447078705, emotion_loss=0.9042352437973022\n",
      "\n",
      "01_20_00:30:57 Seen so far: 116512 samples\n",
      "\n",
      "01_20_00:30:57 --- 1.7196943759918213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:30:59 Training loss at epoch 2 step 3650: 2.968888020515442\n",
      "\n",
      " This round's valence_loss=0.9585946798324585, arousal_loss=0.8373805284500122, emotion_loss=1.546966552734375\n",
      "\n",
      "01_20_00:30:59 Seen so far: 116832 samples\n",
      "\n",
      "01_20_00:30:59 --- 1.6805684566497803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:01 Training loss at epoch 2 step 3660: 2.84576210975647\n",
      "\n",
      " This round's valence_loss=0.8506990671157837, arousal_loss=0.6868569254875183, emotion_loss=0.8278481960296631\n",
      "\n",
      "01_20_00:31:01 Seen so far: 117152 samples\n",
      "\n",
      "01_20_00:31:01 --- 1.8751945495605469 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:02 Training loss at epoch 2 step 3670: 2.823050880432129\n",
      "\n",
      " This round's valence_loss=0.6024335026741028, arousal_loss=0.4720383882522583, emotion_loss=1.065253734588623\n",
      "\n",
      "01_20_00:31:02 Seen so far: 117472 samples\n",
      "\n",
      "01_20_00:31:02 --- 1.7218985557556152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:04 Training loss at epoch 2 step 3680: 3.017937219142914\n",
      "\n",
      " This round's valence_loss=1.0011142492294312, arousal_loss=0.9249637126922607, emotion_loss=0.947385311126709\n",
      "\n",
      "01_20_00:31:04 Seen so far: 117792 samples\n",
      "\n",
      "01_20_00:31:04 --- 1.7986016273498535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:06 Training loss at epoch 2 step 3690: 3.2782860517501833\n",
      "\n",
      " This round's valence_loss=1.552377462387085, arousal_loss=1.4651422500610352, emotion_loss=0.9657934904098511\n",
      "\n",
      "01_20_00:31:06 Seen so far: 118112 samples\n",
      "\n",
      "01_20_00:31:06 --- 1.6877460479736328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:08 Training loss at epoch 2 step 3700: 2.9691330432891845\n",
      "\n",
      " This round's valence_loss=1.2712082862854004, arousal_loss=1.0244439840316772, emotion_loss=0.6056870818138123\n",
      "\n",
      "01_20_00:31:08 Seen so far: 118432 samples\n",
      "\n",
      "01_20_00:31:08 --- 1.8015029430389404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:10 Training loss at epoch 2 step 3710: 3.2111227989196776\n",
      "\n",
      " This round's valence_loss=1.1479136943817139, arousal_loss=0.9354546666145325, emotion_loss=0.9115591049194336\n",
      "\n",
      "01_20_00:31:10 Seen so far: 118752 samples\n",
      "\n",
      "01_20_00:31:10 --- 1.7985637187957764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:11 Training loss at epoch 2 step 3720: 3.0622259855270384\n",
      "\n",
      " This round's valence_loss=1.3174854516983032, arousal_loss=1.2403457164764404, emotion_loss=0.9949398040771484\n",
      "\n",
      "01_20_00:31:11 Seen so far: 119072 samples\n",
      "\n",
      "01_20_00:31:11 --- 1.8217425346374512 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:13 Training loss at epoch 2 step 3730: 3.0128718852996825\n",
      "\n",
      " This round's valence_loss=0.956294596195221, arousal_loss=0.7185537815093994, emotion_loss=0.7823653221130371\n",
      "\n",
      "01_20_00:31:13 Seen so far: 119392 samples\n",
      "\n",
      "01_20_00:31:13 --- 1.7214031219482422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:15 Training loss at epoch 2 step 3740: 2.9878342390060424\n",
      "\n",
      " This round's valence_loss=1.3671722412109375, arousal_loss=1.1499706506729126, emotion_loss=1.143847107887268\n",
      "\n",
      "01_20_00:31:15 Seen so far: 119712 samples\n",
      "\n",
      "01_20_00:31:15 --- 1.6051292419433594 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:16 Training loss at epoch 2 step 3750: 2.875838589668274\n",
      "\n",
      " This round's valence_loss=0.8452872633934021, arousal_loss=0.6045727729797363, emotion_loss=1.066633939743042\n",
      "\n",
      "01_20_00:31:16 Seen so far: 120032 samples\n",
      "\n",
      "01_20_00:31:16 --- 1.6895637512207031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:18 Training loss at epoch 2 step 3760: 3.2760984659194947\n",
      "\n",
      " This round's valence_loss=1.2119181156158447, arousal_loss=1.0819895267486572, emotion_loss=0.8099385499954224\n",
      "\n",
      "01_20_00:31:18 Seen so far: 120352 samples\n",
      "\n",
      "01_20_00:31:18 --- 1.8268206119537354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:20 Training loss at epoch 2 step 3770: 3.210840034484863\n",
      "\n",
      " This round's valence_loss=1.1851069927215576, arousal_loss=1.0494712591171265, emotion_loss=0.6350555419921875\n",
      "\n",
      "01_20_00:31:20 Seen so far: 120672 samples\n",
      "\n",
      "01_20_00:31:20 --- 1.7080755233764648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:22 Training loss at epoch 2 step 3780: 3.2102716684341432\n",
      "\n",
      " This round's valence_loss=1.1952065229415894, arousal_loss=1.0691732168197632, emotion_loss=0.8002687096595764\n",
      "\n",
      "01_20_00:31:22 Seen so far: 120992 samples\n",
      "\n",
      "01_20_00:31:22 --- 1.9555573463439941 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:24 Training loss at epoch 2 step 3790: 2.8223329544067384\n",
      "\n",
      " This round's valence_loss=0.8206110000610352, arousal_loss=0.7155110836029053, emotion_loss=1.0624432563781738\n",
      "\n",
      "01_20_00:31:24 Seen so far: 121312 samples\n",
      "\n",
      "01_20_00:31:24 --- 1.737513780593872 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:25 Training loss at epoch 2 step 3800: 2.9687817096710205\n",
      "\n",
      " This round's valence_loss=1.3890379667282104, arousal_loss=1.160989761352539, emotion_loss=0.8520040512084961\n",
      "\n",
      "01_20_00:31:25 Seen so far: 121632 samples\n",
      "\n",
      "01_20_00:31:25 --- 1.7450547218322754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:27 Training loss at epoch 2 step 3810: 3.0021485328674316\n",
      "\n",
      " This round's valence_loss=0.6638442277908325, arousal_loss=0.5563898086547852, emotion_loss=1.2610503435134888\n",
      "\n",
      "01_20_00:31:27 Seen so far: 121952 samples\n",
      "\n",
      "01_20_00:31:27 --- 1.7702484130859375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:29 Training loss at epoch 2 step 3820: 3.349933362007141\n",
      "\n",
      " This round's valence_loss=1.180087685585022, arousal_loss=1.088170051574707, emotion_loss=0.9784137010574341\n",
      "\n",
      "01_20_00:31:29 Seen so far: 122272 samples\n",
      "\n",
      "01_20_00:31:29 --- 1.8843472003936768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:31 Training loss at epoch 2 step 3830: 2.592096948623657\n",
      "\n",
      " This round's valence_loss=1.0929133892059326, arousal_loss=1.0209875106811523, emotion_loss=1.0491442680358887\n",
      "\n",
      "01_20_00:31:31 Seen so far: 122592 samples\n",
      "\n",
      "01_20_00:31:31 --- 1.8123173713684082 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:33 Training loss at epoch 2 step 3840: 2.9468743324279787\n",
      "\n",
      " This round's valence_loss=0.9255502223968506, arousal_loss=0.8769378662109375, emotion_loss=1.1116517782211304\n",
      "\n",
      "01_20_00:31:33 Seen so far: 122912 samples\n",
      "\n",
      "01_20_00:31:33 --- 1.722557544708252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:34 Training loss at epoch 2 step 3850: 3.1095536947250366\n",
      "\n",
      " This round's valence_loss=1.205709457397461, arousal_loss=1.0995879173278809, emotion_loss=0.9500582218170166\n",
      "\n",
      "01_20_00:31:34 Seen so far: 123232 samples\n",
      "\n",
      "01_20_00:31:34 --- 1.6839089393615723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:36 Training loss at epoch 2 step 3860: 3.0580816149711607\n",
      "\n",
      " This round's valence_loss=1.112658977508545, arousal_loss=0.9783347845077515, emotion_loss=0.9952172040939331\n",
      "\n",
      "01_20_00:31:36 Seen so far: 123552 samples\n",
      "\n",
      "01_20_00:31:36 --- 1.7476580142974854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:38 Training loss at epoch 2 step 3870: 2.743368983268738\n",
      "\n",
      " This round's valence_loss=1.293046474456787, arousal_loss=1.2764763832092285, emotion_loss=0.9595520496368408\n",
      "\n",
      "01_20_00:31:38 Seen so far: 123872 samples\n",
      "\n",
      "01_20_00:31:38 --- 1.7918527126312256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:40 Training loss at epoch 2 step 3880: 3.3459588050842286\n",
      "\n",
      " This round's valence_loss=1.0033745765686035, arousal_loss=0.8176424503326416, emotion_loss=0.9512760043144226\n",
      "\n",
      "01_20_00:31:40 Seen so far: 124192 samples\n",
      "\n",
      "01_20_00:31:40 --- 1.9023716449737549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:41 Training loss at epoch 2 step 3890: 2.920783281326294\n",
      "\n",
      " This round's valence_loss=1.266160249710083, arousal_loss=1.1042068004608154, emotion_loss=1.3511096239089966\n",
      "\n",
      "01_20_00:31:41 Seen so far: 124512 samples\n",
      "\n",
      "01_20_00:31:41 --- 1.5935227870941162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:43 Training loss at epoch 2 step 3900: 3.038237714767456\n",
      "\n",
      " This round's valence_loss=1.3331242799758911, arousal_loss=1.2114232778549194, emotion_loss=0.8767578601837158\n",
      "\n",
      "01_20_00:31:43 Seen so far: 124832 samples\n",
      "\n",
      "01_20_00:31:43 --- 1.8309845924377441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:45 Training loss at epoch 2 step 3910: 3.1379019737243654\n",
      "\n",
      " This round's valence_loss=1.4099242687225342, arousal_loss=1.3282852172851562, emotion_loss=1.0843819379806519\n",
      "\n",
      "01_20_00:31:45 Seen so far: 125152 samples\n",
      "\n",
      "01_20_00:31:45 --- 1.6445047855377197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:47 Training loss at epoch 2 step 3920: 3.2312379837036134\n",
      "\n",
      " This round's valence_loss=1.1990195512771606, arousal_loss=1.0882633924484253, emotion_loss=1.0520219802856445\n",
      "\n",
      "01_20_00:31:47 Seen so far: 125472 samples\n",
      "\n",
      "01_20_00:31:47 --- 1.8402659893035889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:48 Training loss at epoch 2 step 3930: 2.9867992639541625\n",
      "\n",
      " This round's valence_loss=1.0978248119354248, arousal_loss=0.9592192769050598, emotion_loss=1.0713579654693604\n",
      "\n",
      "01_20_00:31:48 Seen so far: 125792 samples\n",
      "\n",
      "01_20_00:31:48 --- 1.7024247646331787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:50 Training loss at epoch 2 step 3940: 3.3724273681640624\n",
      "\n",
      " This round's valence_loss=1.3408091068267822, arousal_loss=1.2060198783874512, emotion_loss=0.8973151445388794\n",
      "\n",
      "01_20_00:31:50 Seen so far: 126112 samples\n",
      "\n",
      "01_20_00:31:50 --- 1.8028769493103027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:52 Training loss at epoch 2 step 3950: 2.846034026145935\n",
      "\n",
      " This round's valence_loss=0.9550613164901733, arousal_loss=0.8639576435089111, emotion_loss=1.2258585691452026\n",
      "\n",
      "01_20_00:31:52 Seen so far: 126432 samples\n",
      "\n",
      "01_20_00:31:52 --- 1.563014030456543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:53 Training loss at epoch 2 step 3960: 2.8133405685424804\n",
      "\n",
      " This round's valence_loss=0.922167956829071, arousal_loss=0.8742914199829102, emotion_loss=1.27095365524292\n",
      "\n",
      "01_20_00:31:53 Seen so far: 126752 samples\n",
      "\n",
      "01_20_00:31:53 --- 1.7831649780273438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:55 Training loss at epoch 2 step 3970: 3.007733178138733\n",
      "\n",
      " This round's valence_loss=1.172802448272705, arousal_loss=1.087483525276184, emotion_loss=1.2528085708618164\n",
      "\n",
      "01_20_00:31:55 Seen so far: 127072 samples\n",
      "\n",
      "01_20_00:31:55 --- 1.6388187408447266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:57 Training loss at epoch 2 step 3980: 3.0165632486343386\n",
      "\n",
      " This round's valence_loss=1.3349618911743164, arousal_loss=1.1792852878570557, emotion_loss=1.1265794038772583\n",
      "\n",
      "01_20_00:31:57 Seen so far: 127392 samples\n",
      "\n",
      "01_20_00:31:57 --- 1.653486728668213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:31:58 Training loss at epoch 2 step 3990: 3.1062122344970704\n",
      "\n",
      " This round's valence_loss=1.178297996520996, arousal_loss=1.062578797340393, emotion_loss=1.0242981910705566\n",
      "\n",
      "01_20_00:31:58 Seen so far: 127712 samples\n",
      "\n",
      "01_20_00:31:58 --- 1.5850467681884766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:00 Training loss at epoch 2 step 4000: 2.842070436477661\n",
      "\n",
      " This round's valence_loss=1.5431510210037231, arousal_loss=1.4476405382156372, emotion_loss=0.7714532613754272\n",
      "\n",
      "01_20_00:32:00 Seen so far: 128032 samples\n",
      "\n",
      "01_20_00:32:00 --- 1.7194287776947021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:02 Training loss at epoch 2 step 4010: 3.023293471336365\n",
      "\n",
      " This round's valence_loss=1.735090970993042, arousal_loss=1.5622637271881104, emotion_loss=0.8150031566619873\n",
      "\n",
      "01_20_00:32:02 Seen so far: 128352 samples\n",
      "\n",
      "01_20_00:32:02 --- 1.7261581420898438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:04 Training loss at epoch 2 step 4020: 3.199041962623596\n",
      "\n",
      " This round's valence_loss=1.0777404308319092, arousal_loss=0.9651971459388733, emotion_loss=1.2280505895614624\n",
      "\n",
      "01_20_00:32:04 Seen so far: 128672 samples\n",
      "\n",
      "01_20_00:32:04 --- 1.8008267879486084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:05 Training loss at epoch 2 step 4030: 2.82588677406311\n",
      "\n",
      " This round's valence_loss=0.508929967880249, arousal_loss=0.34062454104423523, emotion_loss=0.8439385294914246\n",
      "\n",
      "01_20_00:32:05 Seen so far: 128992 samples\n",
      "\n",
      "01_20_00:32:05 --- 1.827009916305542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:07 Training loss at epoch 2 step 4040: 2.803692841529846\n",
      "\n",
      " This round's valence_loss=1.0110085010528564, arousal_loss=0.877467930316925, emotion_loss=1.017787218093872\n",
      "\n",
      "01_20_00:32:07 Seen so far: 129312 samples\n",
      "\n",
      "01_20_00:32:07 --- 1.850656509399414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:09 Training loss at epoch 2 step 4050: 2.8275648593902587\n",
      "\n",
      " This round's valence_loss=0.9649875164031982, arousal_loss=0.8808819055557251, emotion_loss=0.907540500164032\n",
      "\n",
      "01_20_00:32:09 Seen so far: 129632 samples\n",
      "\n",
      "01_20_00:32:09 --- 1.769120454788208 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:11 Training loss at epoch 2 step 4060: 3.27169451713562\n",
      "\n",
      " This round's valence_loss=0.9315134286880493, arousal_loss=0.7052654027938843, emotion_loss=0.8372873067855835\n",
      "\n",
      "01_20_00:32:11 Seen so far: 129952 samples\n",
      "\n",
      "01_20_00:32:11 --- 1.8515777587890625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:13 Training loss at epoch 2 step 4070: 2.7777234077453614\n",
      "\n",
      " This round's valence_loss=0.7928058505058289, arousal_loss=0.572115421295166, emotion_loss=0.7226132154464722\n",
      "\n",
      "01_20_00:32:13 Seen so far: 130272 samples\n",
      "\n",
      "01_20_00:32:13 --- 1.702852725982666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:14 Training loss at epoch 2 step 4080: 3.109793949127197\n",
      "\n",
      " This round's valence_loss=1.1495440006256104, arousal_loss=0.9589789509773254, emotion_loss=0.9258751273155212\n",
      "\n",
      "01_20_00:32:14 Seen so far: 130592 samples\n",
      "\n",
      "01_20_00:32:14 --- 1.8427932262420654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:16 Training loss at epoch 2 step 4090: 2.9975873708724974\n",
      "\n",
      " This round's valence_loss=0.9586082696914673, arousal_loss=0.8563939332962036, emotion_loss=0.979855477809906\n",
      "\n",
      "01_20_00:32:16 Seen so far: 130912 samples\n",
      "\n",
      "01_20_00:32:16 --- 1.7028331756591797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:18 Training loss at epoch 2 step 4100: 3.049056053161621\n",
      "\n",
      " This round's valence_loss=0.7603346109390259, arousal_loss=0.618539035320282, emotion_loss=0.867856502532959\n",
      "\n",
      "01_20_00:32:18 Seen so far: 131232 samples\n",
      "\n",
      "01_20_00:32:18 --- 1.586592674255371 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:20 Training loss at epoch 2 step 4110: 2.992803859710693\n",
      "\n",
      " This round's valence_loss=1.3068265914916992, arousal_loss=1.1633775234222412, emotion_loss=0.8893638849258423\n",
      "\n",
      "01_20_00:32:20 Seen so far: 131552 samples\n",
      "\n",
      "01_20_00:32:20 --- 1.8348278999328613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:21 Training loss at epoch 2 step 4120: 3.110958123207092\n",
      "\n",
      " This round's valence_loss=1.2816557884216309, arousal_loss=1.2490720748901367, emotion_loss=1.100348711013794\n",
      "\n",
      "01_20_00:32:21 Seen so far: 131872 samples\n",
      "\n",
      "01_20_00:32:21 --- 1.6792478561401367 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:23 Training loss at epoch 2 step 4130: 2.699952220916748\n",
      "\n",
      " This round's valence_loss=0.887043833732605, arousal_loss=0.7718726396560669, emotion_loss=0.8552139401435852\n",
      "\n",
      "01_20_00:32:23 Seen so far: 132192 samples\n",
      "\n",
      "01_20_00:32:23 --- 1.815519094467163 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:25 Training loss at epoch 2 step 4140: 3.3337783098220823\n",
      "\n",
      " This round's valence_loss=1.3100013732910156, arousal_loss=1.2171224355697632, emotion_loss=0.7632557153701782\n",
      "\n",
      "01_20_00:32:25 Seen so far: 132512 samples\n",
      "\n",
      "01_20_00:32:25 --- 1.7222614288330078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:26 Training loss at epoch 2 step 4150: 3.29844868183136\n",
      "\n",
      " This round's valence_loss=1.398810863494873, arousal_loss=1.3525354862213135, emotion_loss=0.7304283380508423\n",
      "\n",
      "01_20_00:32:26 Seen so far: 132832 samples\n",
      "\n",
      "01_20_00:32:26 --- 1.7600336074829102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:28 Training loss at epoch 2 step 4160: 2.9093172550201416\n",
      "\n",
      " This round's valence_loss=1.0785012245178223, arousal_loss=1.0072087049484253, emotion_loss=1.2844858169555664\n",
      "\n",
      "01_20_00:32:28 Seen so far: 133152 samples\n",
      "\n",
      "01_20_00:32:28 --- 1.781151294708252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:30 Training loss at epoch 2 step 4170: 3.130416488647461\n",
      "\n",
      " This round's valence_loss=1.2100849151611328, arousal_loss=1.0498892068862915, emotion_loss=1.1926257610321045\n",
      "\n",
      "01_20_00:32:30 Seen so far: 133472 samples\n",
      "\n",
      "01_20_00:32:30 --- 1.8973197937011719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:32 Training loss at epoch 2 step 4180: 2.965388262271881\n",
      "\n",
      " This round's valence_loss=1.4231665134429932, arousal_loss=1.3048157691955566, emotion_loss=1.0402175188064575\n",
      "\n",
      "01_20_00:32:32 Seen so far: 133792 samples\n",
      "\n",
      "01_20_00:32:32 --- 1.876380443572998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:34 Training loss at epoch 2 step 4190: 3.1238124847412108\n",
      "\n",
      " This round's valence_loss=0.8724948763847351, arousal_loss=0.7611957788467407, emotion_loss=1.0544992685317993\n",
      "\n",
      "01_20_00:32:34 Seen so far: 134112 samples\n",
      "\n",
      "01_20_00:32:34 --- 1.783963680267334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:35 Training loss at epoch 2 step 4200: 3.105966305732727\n",
      "\n",
      " This round's valence_loss=0.9375343322753906, arousal_loss=0.6755967140197754, emotion_loss=0.6671849489212036\n",
      "\n",
      "01_20_00:32:35 Seen so far: 134432 samples\n",
      "\n",
      "01_20_00:32:35 --- 1.6606330871582031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:37 Training loss at epoch 2 step 4210: 2.8984471559524536\n",
      "\n",
      " This round's valence_loss=1.046324372291565, arousal_loss=0.819638192653656, emotion_loss=0.8214441537857056\n",
      "\n",
      "01_20_00:32:37 Seen so far: 134752 samples\n",
      "\n",
      "01_20_00:32:37 --- 1.660918951034546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:39 Training loss at epoch 2 step 4220: 2.987098479270935\n",
      "\n",
      " This round's valence_loss=0.7281713485717773, arousal_loss=0.6329096555709839, emotion_loss=1.1611106395721436\n",
      "\n",
      "01_20_00:32:39 Seen so far: 135072 samples\n",
      "\n",
      "01_20_00:32:39 --- 1.8007516860961914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:41 Training loss at epoch 2 step 4230: 3.266955590248108\n",
      "\n",
      " This round's valence_loss=1.1455979347229004, arousal_loss=0.9456734657287598, emotion_loss=1.357189655303955\n",
      "\n",
      "01_20_00:32:41 Seen so far: 135392 samples\n",
      "\n",
      "01_20_00:32:41 --- 1.651153326034546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:42 Training loss at epoch 2 step 4240: 2.9758195996284487\n",
      "\n",
      " This round's valence_loss=0.721298098564148, arousal_loss=0.45549753308296204, emotion_loss=1.1242542266845703\n",
      "\n",
      "01_20_00:32:42 Seen so far: 135712 samples\n",
      "\n",
      "01_20_00:32:42 --- 1.6806466579437256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:44 Training loss at epoch 2 step 4250: 3.321138525009155\n",
      "\n",
      " This round's valence_loss=0.895825207233429, arousal_loss=0.8237786293029785, emotion_loss=1.341999888420105\n",
      "\n",
      "01_20_00:32:44 Seen so far: 136032 samples\n",
      "\n",
      "01_20_00:32:44 --- 1.7389848232269287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:46 Training loss at epoch 2 step 4260: 3.1046031713485718\n",
      "\n",
      " This round's valence_loss=1.444812297821045, arousal_loss=1.2807137966156006, emotion_loss=1.1377462148666382\n",
      "\n",
      "01_20_00:32:46 Seen so far: 136352 samples\n",
      "\n",
      "01_20_00:32:46 --- 1.7832138538360596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:48 Training loss at epoch 2 step 4270: 3.2638677597045898\n",
      "\n",
      " This round's valence_loss=1.0256664752960205, arousal_loss=0.8785088658332825, emotion_loss=1.1285624504089355\n",
      "\n",
      "01_20_00:32:48 Seen so far: 136672 samples\n",
      "\n",
      "01_20_00:32:48 --- 1.8036682605743408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:49 Training loss at epoch 2 step 4280: 3.0411927938461303\n",
      "\n",
      " This round's valence_loss=1.3794398307800293, arousal_loss=1.2190452814102173, emotion_loss=0.6704283952713013\n",
      "\n",
      "01_20_00:32:49 Seen so far: 136992 samples\n",
      "\n",
      "01_20_00:32:49 --- 1.7352800369262695 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:51 Training loss at epoch 2 step 4290: 3.392913341522217\n",
      "\n",
      " This round's valence_loss=1.064096212387085, arousal_loss=0.9743266105651855, emotion_loss=1.3294497728347778\n",
      "\n",
      "01_20_00:32:51 Seen so far: 137312 samples\n",
      "\n",
      "01_20_00:32:51 --- 1.7474446296691895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:53 Training loss at epoch 2 step 4300: 3.157964992523193\n",
      "\n",
      " This round's valence_loss=1.2014071941375732, arousal_loss=1.0806353092193604, emotion_loss=1.0094225406646729\n",
      "\n",
      "01_20_00:32:53 Seen so far: 137632 samples\n",
      "\n",
      "01_20_00:32:53 --- 1.7185008525848389 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:55 Training loss at epoch 2 step 4310: 2.8644017219543456\n",
      "\n",
      " This round's valence_loss=1.0083932876586914, arousal_loss=0.8259249329566956, emotion_loss=0.8314944505691528\n",
      "\n",
      "01_20_00:32:55 Seen so far: 137952 samples\n",
      "\n",
      "01_20_00:32:55 --- 1.762984037399292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:56 Training loss at epoch 2 step 4320: 3.0629205226898195\n",
      "\n",
      " This round's valence_loss=1.801651954650879, arousal_loss=1.717490792274475, emotion_loss=0.8537585735321045\n",
      "\n",
      "01_20_00:32:56 Seen so far: 138272 samples\n",
      "\n",
      "01_20_00:32:56 --- 1.8417391777038574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:32:58 Training loss at epoch 2 step 4330: 3.0064882755279543\n",
      "\n",
      " This round's valence_loss=1.085457682609558, arousal_loss=0.9771479368209839, emotion_loss=1.188331127166748\n",
      "\n",
      "01_20_00:32:58 Seen so far: 138592 samples\n",
      "\n",
      "01_20_00:32:58 --- 1.7810773849487305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:00 Training loss at epoch 2 step 4340: 3.294483280181885\n",
      "\n",
      " This round's valence_loss=1.4670085906982422, arousal_loss=1.2959113121032715, emotion_loss=0.6604399085044861\n",
      "\n",
      "01_20_00:33:00 Seen so far: 138912 samples\n",
      "\n",
      "01_20_00:33:00 --- 1.8551270961761475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:02 Training loss at epoch 2 step 4350: 3.0382163524627686\n",
      "\n",
      " This round's valence_loss=1.080721139907837, arousal_loss=1.031381607055664, emotion_loss=0.9162316918373108\n",
      "\n",
      "01_20_00:33:02 Seen so far: 139232 samples\n",
      "\n",
      "01_20_00:33:02 --- 1.7495245933532715 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:04 Training loss at epoch 2 step 4360: 2.9822243809700013\n",
      "\n",
      " This round's valence_loss=1.2130579948425293, arousal_loss=1.0611921548843384, emotion_loss=1.1111469268798828\n",
      "\n",
      "01_20_00:33:04 Seen so far: 139552 samples\n",
      "\n",
      "01_20_00:33:04 --- 1.8530142307281494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:05 Training loss at epoch 2 step 4370: 3.004700469970703\n",
      "\n",
      " This round's valence_loss=0.6522828340530396, arousal_loss=0.5234061479568481, emotion_loss=1.243224024772644\n",
      "\n",
      "01_20_00:33:05 Seen so far: 139872 samples\n",
      "\n",
      "01_20_00:33:05 --- 1.779261589050293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:07 Training loss at epoch 2 step 4380: 3.465569090843201\n",
      "\n",
      " This round's valence_loss=1.0952439308166504, arousal_loss=0.9122004508972168, emotion_loss=1.3445463180541992\n",
      "\n",
      "01_20_00:33:07 Seen so far: 140192 samples\n",
      "\n",
      "01_20_00:33:07 --- 1.6255109310150146 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:09 Training loss at epoch 2 step 4390: 3.2836941719055175\n",
      "\n",
      " This round's valence_loss=0.9603169560432434, arousal_loss=0.720367431640625, emotion_loss=0.981683611869812\n",
      "\n",
      "01_20_00:33:09 Seen so far: 140512 samples\n",
      "\n",
      "01_20_00:33:09 --- 1.83268141746521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:11 Training loss at epoch 2 step 4400: 2.9141746044158934\n",
      "\n",
      " This round's valence_loss=1.6809788942337036, arousal_loss=1.5415749549865723, emotion_loss=1.0823614597320557\n",
      "\n",
      "01_20_00:33:11 Seen so far: 140832 samples\n",
      "\n",
      "01_20_00:33:11 --- 1.732071876525879 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:12 Training loss at epoch 2 step 4410: 2.85689195394516\n",
      "\n",
      " This round's valence_loss=0.787787914276123, arousal_loss=0.6116058230400085, emotion_loss=1.1773719787597656\n",
      "\n",
      "01_20_00:33:12 Seen so far: 141152 samples\n",
      "\n",
      "01_20_00:33:12 --- 1.6691339015960693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:14 Training loss at epoch 2 step 4420: 2.8885063409805296\n",
      "\n",
      " This round's valence_loss=1.1769376993179321, arousal_loss=1.0621912479400635, emotion_loss=1.0973272323608398\n",
      "\n",
      "01_20_00:33:14 Seen so far: 141472 samples\n",
      "\n",
      "01_20_00:33:14 --- 1.7070975303649902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:16 Training loss at epoch 2 step 4430: 3.391829776763916\n",
      "\n",
      " This round's valence_loss=1.3022183179855347, arousal_loss=1.1729092597961426, emotion_loss=1.1809245347976685\n",
      "\n",
      "01_20_00:33:16 Seen so far: 141792 samples\n",
      "\n",
      "01_20_00:33:16 --- 1.656930923461914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:18 Training loss at epoch 2 step 4440: 2.9301189184188843\n",
      "\n",
      " This round's valence_loss=1.2286945581436157, arousal_loss=1.0992581844329834, emotion_loss=1.0147970914840698\n",
      "\n",
      "01_20_00:33:18 Seen so far: 142112 samples\n",
      "\n",
      "01_20_00:33:18 --- 1.882810354232788 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:19 Training loss at epoch 2 step 4450: 3.1178571939468385\n",
      "\n",
      " This round's valence_loss=0.964840829372406, arousal_loss=0.8060786724090576, emotion_loss=0.8864023089408875\n",
      "\n",
      "01_20_00:33:19 Seen so far: 142432 samples\n",
      "\n",
      "01_20_00:33:19 --- 1.7925755977630615 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:21 Training loss at epoch 2 step 4460: 3.3048322796821594\n",
      "\n",
      " This round's valence_loss=1.8022565841674805, arousal_loss=1.6556549072265625, emotion_loss=0.9092025756835938\n",
      "\n",
      "01_20_00:33:21 Seen so far: 142752 samples\n",
      "\n",
      "01_20_00:33:21 --- 1.7147586345672607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:23 Training loss at epoch 2 step 4470: 2.719801700115204\n",
      "\n",
      " This round's valence_loss=0.8734460473060608, arousal_loss=0.7387769222259521, emotion_loss=0.6400025486946106\n",
      "\n",
      "01_20_00:33:23 Seen so far: 143072 samples\n",
      "\n",
      "01_20_00:33:23 --- 1.5959160327911377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:24 Training loss at epoch 2 step 4480: 2.80111163854599\n",
      "\n",
      " This round's valence_loss=1.2000337839126587, arousal_loss=1.1116611957550049, emotion_loss=0.941616415977478\n",
      "\n",
      "01_20_00:33:24 Seen so far: 143392 samples\n",
      "\n",
      "01_20_00:33:24 --- 1.6211318969726562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:26 Training loss at epoch 2 step 4490: 3.037374997138977\n",
      "\n",
      " This round's valence_loss=0.9727523326873779, arousal_loss=0.7949780225753784, emotion_loss=0.670924186706543\n",
      "\n",
      "01_20_00:33:26 Seen so far: 143712 samples\n",
      "\n",
      "01_20_00:33:26 --- 1.687129020690918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:28 Training loss at epoch 2 step 4500: 2.6904052734375\n",
      "\n",
      " This round's valence_loss=1.1289161443710327, arousal_loss=0.9835985898971558, emotion_loss=0.8841152191162109\n",
      "\n",
      "01_20_00:33:28 Seen so far: 144032 samples\n",
      "\n",
      "01_20_00:33:28 --- 1.7201292514801025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:30 Training loss at epoch 2 step 4510: 3.0877880215644837\n",
      "\n",
      " This round's valence_loss=1.0190839767456055, arousal_loss=0.8296876549720764, emotion_loss=0.9933532476425171\n",
      "\n",
      "01_20_00:33:30 Seen so far: 144352 samples\n",
      "\n",
      "01_20_00:33:30 --- 1.9902958869934082 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:32 Training loss at epoch 2 step 4520: 2.955175828933716\n",
      "\n",
      " This round's valence_loss=1.1057720184326172, arousal_loss=0.9882063865661621, emotion_loss=0.8810708522796631\n",
      "\n",
      "01_20_00:33:32 Seen so far: 144672 samples\n",
      "\n",
      "01_20_00:33:32 --- 2.001016855239868 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:33 Training loss at epoch 2 step 4530: 2.720717930793762\n",
      "\n",
      " This round's valence_loss=0.8569461107254028, arousal_loss=0.5838440656661987, emotion_loss=0.8171283006668091\n",
      "\n",
      "01_20_00:33:33 Seen so far: 144992 samples\n",
      "\n",
      "01_20_00:33:33 --- 1.7880845069885254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:35 Training loss at epoch 2 step 4540: 3.2144649505615233\n",
      "\n",
      " This round's valence_loss=0.7537254691123962, arousal_loss=0.5900993943214417, emotion_loss=1.0141453742980957\n",
      "\n",
      "01_20_00:33:35 Seen so far: 145312 samples\n",
      "\n",
      "01_20_00:33:35 --- 1.92818021774292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:37 Training loss at epoch 2 step 4550: 2.93279709815979\n",
      "\n",
      " This round's valence_loss=1.2925885915756226, arousal_loss=1.0828871726989746, emotion_loss=0.9098696708679199\n",
      "\n",
      "01_20_00:33:37 Seen so far: 145632 samples\n",
      "\n",
      "01_20_00:33:37 --- 1.8721354007720947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:39 Training loss at epoch 2 step 4560: 2.759375548362732\n",
      "\n",
      " This round's valence_loss=0.6441622972488403, arousal_loss=0.49614429473876953, emotion_loss=0.9351717829704285\n",
      "\n",
      "01_20_00:33:39 Seen so far: 145952 samples\n",
      "\n",
      "01_20_00:33:39 --- 1.6737852096557617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:41 Training loss at epoch 2 step 4570: 2.828032410144806\n",
      "\n",
      " This round's valence_loss=1.1354939937591553, arousal_loss=0.9906478524208069, emotion_loss=0.9858269095420837\n",
      "\n",
      "01_20_00:33:41 Seen so far: 146272 samples\n",
      "\n",
      "01_20_00:33:41 --- 1.716465711593628 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:42 Training loss at epoch 2 step 4580: 2.74260892868042\n",
      "\n",
      " This round's valence_loss=0.7753570079803467, arousal_loss=0.7403758764266968, emotion_loss=1.091470718383789\n",
      "\n",
      "01_20_00:33:42 Seen so far: 146592 samples\n",
      "\n",
      "01_20_00:33:42 --- 1.699354887008667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:44 Training loss at epoch 2 step 4590: 2.8466495633125306\n",
      "\n",
      " This round's valence_loss=1.6386032104492188, arousal_loss=1.4364714622497559, emotion_loss=0.7848008275032043\n",
      "\n",
      "01_20_00:33:44 Seen so far: 146912 samples\n",
      "\n",
      "01_20_00:33:44 --- 1.5494143962860107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:46 Training loss at epoch 2 step 4600: 2.9808572053909304\n",
      "\n",
      " This round's valence_loss=1.0268282890319824, arousal_loss=0.8251188397407532, emotion_loss=0.962273120880127\n",
      "\n",
      "01_20_00:33:46 Seen so far: 147232 samples\n",
      "\n",
      "01_20_00:33:46 --- 1.7697184085845947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:47 Training loss at epoch 2 step 4610: 2.7276255011558534\n",
      "\n",
      " This round's valence_loss=0.6044666767120361, arousal_loss=0.3216578960418701, emotion_loss=0.6716057062149048\n",
      "\n",
      "01_20_00:33:47 Seen so far: 147552 samples\n",
      "\n",
      "01_20_00:33:47 --- 1.7696928977966309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:49 Training loss at epoch 2 step 4620: 2.768147122859955\n",
      "\n",
      " This round's valence_loss=0.6287988424301147, arousal_loss=0.428018182516098, emotion_loss=0.8436007499694824\n",
      "\n",
      "01_20_00:33:49 Seen so far: 147872 samples\n",
      "\n",
      "01_20_00:33:49 --- 1.7386679649353027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:51 Training loss at epoch 2 step 4630: 3.1400009393692017\n",
      "\n",
      " This round's valence_loss=1.5246169567108154, arousal_loss=1.4193689823150635, emotion_loss=0.9868059158325195\n",
      "\n",
      "01_20_00:33:51 Seen so far: 148192 samples\n",
      "\n",
      "01_20_00:33:51 --- 1.6950888633728027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:53 Training loss at epoch 2 step 4640: 3.160278654098511\n",
      "\n",
      " This round's valence_loss=1.3838099241256714, arousal_loss=1.3615643978118896, emotion_loss=0.8578856587409973\n",
      "\n",
      "01_20_00:33:53 Seen so far: 148512 samples\n",
      "\n",
      "01_20_00:33:53 --- 2.0115716457366943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:55 Training loss at epoch 2 step 4650: 2.8248155236244203\n",
      "\n",
      " This round's valence_loss=1.0885522365570068, arousal_loss=0.9450455904006958, emotion_loss=1.0659151077270508\n",
      "\n",
      "01_20_00:33:55 Seen so far: 148832 samples\n",
      "\n",
      "01_20_00:33:55 --- 1.9531376361846924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:57 Training loss at epoch 2 step 4660: 2.9972654819488525\n",
      "\n",
      " This round's valence_loss=1.3264007568359375, arousal_loss=1.2044117450714111, emotion_loss=1.0486969947814941\n",
      "\n",
      "01_20_00:33:57 Seen so far: 149152 samples\n",
      "\n",
      "01_20_00:33:57 --- 1.9220094680786133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:33:59 Training loss at epoch 2 step 4670: 2.9702542304992674\n",
      "\n",
      " This round's valence_loss=1.0570478439331055, arousal_loss=0.9845099449157715, emotion_loss=1.2122167348861694\n",
      "\n",
      "01_20_00:33:59 Seen so far: 149472 samples\n",
      "\n",
      "01_20_00:33:59 --- 1.885436773300171 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:00 Training loss at epoch 2 step 4680: 3.2559606313705443\n",
      "\n",
      " This round's valence_loss=0.8534337878227234, arousal_loss=0.7262868881225586, emotion_loss=0.8436111211776733\n",
      "\n",
      "01_20_00:34:00 Seen so far: 149792 samples\n",
      "\n",
      "01_20_00:34:00 --- 1.8450024127960205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:02 Training loss at epoch 2 step 4690: 3.052238607406616\n",
      "\n",
      " This round's valence_loss=0.7414344549179077, arousal_loss=0.5952026844024658, emotion_loss=0.9787195324897766\n",
      "\n",
      "01_20_00:34:02 Seen so far: 150112 samples\n",
      "\n",
      "01_20_00:34:02 --- 1.6950161457061768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:04 Training loss at epoch 2 step 4700: 2.8030749559402466\n",
      "\n",
      " This round's valence_loss=1.247589349746704, arousal_loss=1.0716898441314697, emotion_loss=0.8075414896011353\n",
      "\n",
      "01_20_00:34:04 Seen so far: 150432 samples\n",
      "\n",
      "01_20_00:34:04 --- 1.7073862552642822 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:06 Training loss at epoch 2 step 4710: 3.2483763694763184\n",
      "\n",
      " This round's valence_loss=0.8626827001571655, arousal_loss=0.6685362458229065, emotion_loss=0.9272197484970093\n",
      "\n",
      "01_20_00:34:06 Seen so far: 150752 samples\n",
      "\n",
      "01_20_00:34:06 --- 1.6781611442565918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:07 Training loss at epoch 2 step 4720: 3.096337604522705\n",
      "\n",
      " This round's valence_loss=0.8986983299255371, arousal_loss=0.8350108861923218, emotion_loss=1.1607871055603027\n",
      "\n",
      "01_20_00:34:07 Seen so far: 151072 samples\n",
      "\n",
      "01_20_00:34:07 --- 1.8335249423980713 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:09 Training loss at epoch 2 step 4730: 3.007302927970886\n",
      "\n",
      " This round's valence_loss=0.8237432837486267, arousal_loss=0.7535851001739502, emotion_loss=1.3920717239379883\n",
      "\n",
      "01_20_00:34:09 Seen so far: 151392 samples\n",
      "\n",
      "01_20_00:34:09 --- 1.6946227550506592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:11 Training loss at epoch 2 step 4740: 2.902739953994751\n",
      "\n",
      " This round's valence_loss=1.3156917095184326, arousal_loss=1.255426049232483, emotion_loss=0.7810882329940796\n",
      "\n",
      "01_20_00:34:11 Seen so far: 151712 samples\n",
      "\n",
      "01_20_00:34:11 --- 1.6467030048370361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:12 Training loss at epoch 2 step 4750: 3.137288498878479\n",
      "\n",
      " This round's valence_loss=1.0478925704956055, arousal_loss=1.0093237161636353, emotion_loss=1.0581769943237305\n",
      "\n",
      "01_20_00:34:12 Seen so far: 152032 samples\n",
      "\n",
      "01_20_00:34:12 --- 1.6875724792480469 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:14 Training loss at epoch 2 step 4760: 3.407936382293701\n",
      "\n",
      " This round's valence_loss=1.2284679412841797, arousal_loss=1.0774481296539307, emotion_loss=1.0278156995773315\n",
      "\n",
      "01_20_00:34:14 Seen so far: 152352 samples\n",
      "\n",
      "01_20_00:34:14 --- 1.819843053817749 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:16 Training loss at epoch 2 step 4770: 3.1107258558273316\n",
      "\n",
      " This round's valence_loss=1.1197562217712402, arousal_loss=0.9617918729782104, emotion_loss=1.0232234001159668\n",
      "\n",
      "01_20_00:34:16 Seen so far: 152672 samples\n",
      "\n",
      "01_20_00:34:16 --- 1.671743631362915 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:18 Training loss at epoch 2 step 4780: 3.030173349380493\n",
      "\n",
      " This round's valence_loss=0.8253458738327026, arousal_loss=0.6641343832015991, emotion_loss=1.060726284980774\n",
      "\n",
      "01_20_00:34:18 Seen so far: 152992 samples\n",
      "\n",
      "01_20_00:34:18 --- 1.6970648765563965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:19 Training loss at epoch 2 step 4790: 3.419949436187744\n",
      "\n",
      " This round's valence_loss=1.541895866394043, arousal_loss=1.4511699676513672, emotion_loss=0.8154287338256836\n",
      "\n",
      "01_20_00:34:19 Seen so far: 153312 samples\n",
      "\n",
      "01_20_00:34:19 --- 1.8615272045135498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:21 Training loss at epoch 2 step 4800: 2.9490408420562746\n",
      "\n",
      " This round's valence_loss=1.2748100757598877, arousal_loss=1.086031198501587, emotion_loss=0.833791971206665\n",
      "\n",
      "01_20_00:34:21 Seen so far: 153632 samples\n",
      "\n",
      "01_20_00:34:21 --- 1.7326250076293945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:23 Training loss at epoch 2 step 4810: 3.1271856784820558\n",
      "\n",
      " This round's valence_loss=0.9881594777107239, arousal_loss=0.8712584972381592, emotion_loss=1.1455585956573486\n",
      "\n",
      "01_20_00:34:23 Seen so far: 153952 samples\n",
      "\n",
      "01_20_00:34:23 --- 1.7258048057556152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:25 Training loss at epoch 2 step 4820: 3.0318051099777223\n",
      "\n",
      " This round's valence_loss=1.0408378839492798, arousal_loss=0.8257502317428589, emotion_loss=1.0889701843261719\n",
      "\n",
      "01_20_00:34:25 Seen so far: 154272 samples\n",
      "\n",
      "01_20_00:34:25 --- 1.7155709266662598 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:26 Training loss at epoch 2 step 4830: 3.1296679258346556\n",
      "\n",
      " This round's valence_loss=1.467771053314209, arousal_loss=1.3485569953918457, emotion_loss=1.2288519144058228\n",
      "\n",
      "01_20_00:34:26 Seen so far: 154592 samples\n",
      "\n",
      "01_20_00:34:26 --- 1.7719111442565918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:28 Training loss at epoch 2 step 4840: 3.0562436819076537\n",
      "\n",
      " This round's valence_loss=1.0166606903076172, arousal_loss=0.8815373182296753, emotion_loss=1.2730605602264404\n",
      "\n",
      "01_20_00:34:28 Seen so far: 154912 samples\n",
      "\n",
      "01_20_00:34:28 --- 1.7205147743225098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:30 Training loss at epoch 2 step 4850: 3.0035918235778807\n",
      "\n",
      " This round's valence_loss=1.0652283430099487, arousal_loss=1.0025534629821777, emotion_loss=0.8788045644760132\n",
      "\n",
      "01_20_00:34:30 Seen so far: 155232 samples\n",
      "\n",
      "01_20_00:34:30 --- 1.813661813735962 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:32 Training loss at epoch 2 step 4860: 3.0351060390472413\n",
      "\n",
      " This round's valence_loss=0.8888309001922607, arousal_loss=0.6988822221755981, emotion_loss=0.7831301689147949\n",
      "\n",
      "01_20_00:34:32 Seen so far: 155552 samples\n",
      "\n",
      "01_20_00:34:32 --- 1.7579524517059326 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:34 Training loss at epoch 2 step 4870: 2.9300002813339234\n",
      "\n",
      " This round's valence_loss=0.9751123189926147, arousal_loss=0.8797342777252197, emotion_loss=1.0075575113296509\n",
      "\n",
      "01_20_00:34:34 Seen so far: 155872 samples\n",
      "\n",
      "01_20_00:34:34 --- 2.0300934314727783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:36 Training loss at epoch 2 step 4880: 2.6952293634414675\n",
      "\n",
      " This round's valence_loss=1.0624420642852783, arousal_loss=1.0189586877822876, emotion_loss=1.1225826740264893\n",
      "\n",
      "01_20_00:34:36 Seen so far: 156192 samples\n",
      "\n",
      "01_20_00:34:36 --- 1.9201207160949707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:37 Training loss at epoch 2 step 4890: 2.8940484523773193\n",
      "\n",
      " This round's valence_loss=1.4286285638809204, arousal_loss=1.3424420356750488, emotion_loss=1.2635955810546875\n",
      "\n",
      "01_20_00:34:37 Seen so far: 156512 samples\n",
      "\n",
      "01_20_00:34:37 --- 1.6112775802612305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:39 Training loss at epoch 2 step 4900: 2.944333720207214\n",
      "\n",
      " This round's valence_loss=0.6666409373283386, arousal_loss=0.5248704552650452, emotion_loss=0.8674585223197937\n",
      "\n",
      "01_20_00:34:39 Seen so far: 156832 samples\n",
      "\n",
      "01_20_00:34:39 --- 1.8345017433166504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:41 Training loss at epoch 2 step 4910: 3.2477193593978884\n",
      "\n",
      " This round's valence_loss=0.6130762696266174, arousal_loss=0.49678850173950195, emotion_loss=0.9245855808258057\n",
      "\n",
      "01_20_00:34:41 Seen so far: 157152 samples\n",
      "\n",
      "01_20_00:34:41 --- 1.7857182025909424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:43 Training loss at epoch 2 step 4920: 3.171480679512024\n",
      "\n",
      " This round's valence_loss=0.9742006063461304, arousal_loss=0.8739535212516785, emotion_loss=1.124801754951477\n",
      "\n",
      "01_20_00:34:43 Seen so far: 157472 samples\n",
      "\n",
      "01_20_00:34:43 --- 1.8718976974487305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:45 Training loss at epoch 2 step 4930: 2.7226016998291014\n",
      "\n",
      " This round's valence_loss=0.8719127774238586, arousal_loss=0.7548294067382812, emotion_loss=0.664779782295227\n",
      "\n",
      "01_20_00:34:45 Seen so far: 157792 samples\n",
      "\n",
      "01_20_00:34:45 --- 1.899324893951416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:46 Training loss at epoch 2 step 4940: 2.922934651374817\n",
      "\n",
      " This round's valence_loss=1.1059339046478271, arousal_loss=0.9940552711486816, emotion_loss=0.9902436137199402\n",
      "\n",
      "01_20_00:34:46 Seen so far: 158112 samples\n",
      "\n",
      "01_20_00:34:46 --- 1.7050294876098633 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:48 Training loss at epoch 2 step 4950: 3.164493989944458\n",
      "\n",
      " This round's valence_loss=1.4745427370071411, arousal_loss=1.3511756658554077, emotion_loss=1.1954030990600586\n",
      "\n",
      "01_20_00:34:48 Seen so far: 158432 samples\n",
      "\n",
      "01_20_00:34:48 --- 1.8556969165802002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:50 Training loss at epoch 2 step 4960: 3.1887446641921997\n",
      "\n",
      " This round's valence_loss=1.2039523124694824, arousal_loss=1.117354393005371, emotion_loss=0.9733309745788574\n",
      "\n",
      "01_20_00:34:50 Seen so far: 158752 samples\n",
      "\n",
      "01_20_00:34:50 --- 1.7505931854248047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:52 Training loss at epoch 2 step 4970: 2.648155760765076\n",
      "\n",
      " This round's valence_loss=1.2257038354873657, arousal_loss=1.094196081161499, emotion_loss=0.8018367290496826\n",
      "\n",
      "01_20_00:34:52 Seen so far: 159072 samples\n",
      "\n",
      "01_20_00:34:52 --- 1.8406188488006592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:54 Training loss at epoch 2 step 4980: 3.21597421169281\n",
      "\n",
      " This round's valence_loss=1.766934871673584, arousal_loss=1.6693429946899414, emotion_loss=1.391692876815796\n",
      "\n",
      "01_20_00:34:54 Seen so far: 159392 samples\n",
      "\n",
      "01_20_00:34:54 --- 1.8827645778656006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:55 Training loss at epoch 2 step 4990: 2.77470623254776\n",
      "\n",
      " This round's valence_loss=0.7595086693763733, arousal_loss=0.6022422909736633, emotion_loss=1.155627727508545\n",
      "\n",
      "01_20_00:34:55 Seen so far: 159712 samples\n",
      "\n",
      "01_20_00:34:55 --- 1.721832513809204 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:57 Training loss at epoch 2 step 5000: 2.921937084197998\n",
      "\n",
      " This round's valence_loss=1.2151904106140137, arousal_loss=1.0666948556900024, emotion_loss=0.8638743758201599\n",
      "\n",
      "01_20_00:34:57 Seen so far: 160032 samples\n",
      "\n",
      "01_20_00:34:57 --- 1.7504379749298096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:34:59 Training loss at epoch 2 step 5010: 3.0206023931503294\n",
      "\n",
      " This round's valence_loss=1.2839891910552979, arousal_loss=1.1996841430664062, emotion_loss=1.4044544696807861\n",
      "\n",
      "01_20_00:34:59 Seen so far: 160352 samples\n",
      "\n",
      "01_20_00:34:59 --- 1.6119279861450195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:01 Training loss at epoch 2 step 5020: 2.953859305381775\n",
      "\n",
      " This round's valence_loss=1.1240187883377075, arousal_loss=0.9777383208274841, emotion_loss=1.0912007093429565\n",
      "\n",
      "01_20_00:35:01 Seen so far: 160672 samples\n",
      "\n",
      "01_20_00:35:01 --- 1.8412799835205078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:02 Training loss at epoch 2 step 5030: 3.1079848289489744\n",
      "\n",
      " This round's valence_loss=1.2017464637756348, arousal_loss=1.104707956314087, emotion_loss=1.2142255306243896\n",
      "\n",
      "01_20_00:35:02 Seen so far: 160992 samples\n",
      "\n",
      "01_20_00:35:02 --- 1.778527021408081 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:04 Training loss at epoch 2 step 5040: 3.1243993997573853\n",
      "\n",
      " This round's valence_loss=1.0658483505249023, arousal_loss=0.8330521583557129, emotion_loss=0.8035796880722046\n",
      "\n",
      "01_20_00:35:04 Seen so far: 161312 samples\n",
      "\n",
      "01_20_00:35:04 --- 1.6620736122131348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:06 Training loss at epoch 2 step 5050: 3.10209801197052\n",
      "\n",
      " This round's valence_loss=1.1941087245941162, arousal_loss=1.0030900239944458, emotion_loss=1.1634056568145752\n",
      "\n",
      "01_20_00:35:06 Seen so far: 161632 samples\n",
      "\n",
      "01_20_00:35:06 --- 1.6947479248046875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:07 Training loss at epoch 2 step 5060: 2.9596754550933837\n",
      "\n",
      " This round's valence_loss=0.9689487218856812, arousal_loss=0.8366521596908569, emotion_loss=0.7185350656509399\n",
      "\n",
      "01_20_00:35:07 Seen so far: 161952 samples\n",
      "\n",
      "01_20_00:35:07 --- 1.6958661079406738 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:09 Training loss at epoch 2 step 5070: 3.2251259088516235\n",
      "\n",
      " This round's valence_loss=0.933634877204895, arousal_loss=0.8778775930404663, emotion_loss=1.3310527801513672\n",
      "\n",
      "01_20_00:35:09 Seen so far: 162272 samples\n",
      "\n",
      "01_20_00:35:09 --- 1.6577553749084473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:11 Training loss at epoch 2 step 5080: 3.041738438606262\n",
      "\n",
      " This round's valence_loss=0.7467840909957886, arousal_loss=0.6643074750900269, emotion_loss=1.1502528190612793\n",
      "\n",
      "01_20_00:35:11 Seen so far: 162592 samples\n",
      "\n",
      "01_20_00:35:11 --- 1.625227451324463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:13 Training loss at epoch 2 step 5090: 2.8838536024093626\n",
      "\n",
      " This round's valence_loss=1.1066792011260986, arousal_loss=0.996428370475769, emotion_loss=0.828652024269104\n",
      "\n",
      "01_20_00:35:13 Seen so far: 162912 samples\n",
      "\n",
      "01_20_00:35:13 --- 1.8250494003295898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:14 Training loss at epoch 2 step 5100: 3.3005990743637086\n",
      "\n",
      " This round's valence_loss=1.6403192281723022, arousal_loss=1.5711910724639893, emotion_loss=1.43384850025177\n",
      "\n",
      "01_20_00:35:14 Seen so far: 163232 samples\n",
      "\n",
      "01_20_00:35:14 --- 1.7780423164367676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:16 Training loss at epoch 2 step 5110: 3.468834972381592\n",
      "\n",
      " This round's valence_loss=1.9711260795593262, arousal_loss=1.9675254821777344, emotion_loss=1.2574517726898193\n",
      "\n",
      "01_20_00:35:16 Seen so far: 163552 samples\n",
      "\n",
      "01_20_00:35:16 --- 1.849226474761963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:18 Training loss at epoch 2 step 5120: 2.73359272480011\n",
      "\n",
      " This round's valence_loss=0.9367260932922363, arousal_loss=0.7334664463996887, emotion_loss=0.8319796323776245\n",
      "\n",
      "01_20_00:35:18 Seen so far: 163872 samples\n",
      "\n",
      "01_20_00:35:18 --- 1.7477176189422607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:20 Training loss at epoch 2 step 5130: 3.299539089202881\n",
      "\n",
      " This round's valence_loss=1.5499651432037354, arousal_loss=1.3419418334960938, emotion_loss=0.8984336853027344\n",
      "\n",
      "01_20_00:35:20 Seen so far: 164192 samples\n",
      "\n",
      "01_20_00:35:20 --- 1.7319509983062744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:21 Training loss at epoch 2 step 5140: 3.104770612716675\n",
      "\n",
      " This round's valence_loss=1.2721540927886963, arousal_loss=1.066277027130127, emotion_loss=0.8897000551223755\n",
      "\n",
      "01_20_00:35:21 Seen so far: 164512 samples\n",
      "\n",
      "01_20_00:35:22 --- 1.8186321258544922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:23 Training loss at epoch 2 step 5150: 3.045988178253174\n",
      "\n",
      " This round's valence_loss=1.2011995315551758, arousal_loss=1.101468801498413, emotion_loss=1.126855492591858\n",
      "\n",
      "01_20_00:35:23 Seen so far: 164832 samples\n",
      "\n",
      "01_20_00:35:23 --- 1.7401947975158691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:25 Training loss at epoch 2 step 5160: 3.2326874256134035\n",
      "\n",
      " This round's valence_loss=1.2499215602874756, arousal_loss=1.0860955715179443, emotion_loss=0.9396588206291199\n",
      "\n",
      "01_20_00:35:25 Seen so far: 165152 samples\n",
      "\n",
      "01_20_00:35:25 --- 1.8222179412841797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:27 Training loss at epoch 2 step 5170: 3.2075090408325195\n",
      "\n",
      " This round's valence_loss=1.1850160360336304, arousal_loss=1.0564136505126953, emotion_loss=0.9358980059623718\n",
      "\n",
      "01_20_00:35:27 Seen so far: 165472 samples\n",
      "\n",
      "01_20_00:35:27 --- 1.9665672779083252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:29 Training loss at epoch 2 step 5180: 3.084277367591858\n",
      "\n",
      " This round's valence_loss=1.3485232591629028, arousal_loss=1.2078510522842407, emotion_loss=0.725541353225708\n",
      "\n",
      "01_20_00:35:29 Seen so far: 165792 samples\n",
      "\n",
      "01_20_00:35:29 --- 1.8456740379333496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:31 Training loss at epoch 2 step 5190: 3.249762678146362\n",
      "\n",
      " This round's valence_loss=1.2615660429000854, arousal_loss=1.1141853332519531, emotion_loss=0.9790182113647461\n",
      "\n",
      "01_20_00:35:31 Seen so far: 166112 samples\n",
      "\n",
      "01_20_00:35:31 --- 1.8470017910003662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:32 Training loss at epoch 2 step 5200: 2.8098401069641112\n",
      "\n",
      " This round's valence_loss=0.9459614753723145, arousal_loss=0.8121267557144165, emotion_loss=0.913589596748352\n",
      "\n",
      "01_20_00:35:32 Seen so far: 166432 samples\n",
      "\n",
      "01_20_00:35:32 --- 1.5966877937316895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:34 Training loss at epoch 2 step 5210: 3.168113088607788\n",
      "\n",
      " This round's valence_loss=0.739995539188385, arousal_loss=0.6087427139282227, emotion_loss=1.027937650680542\n",
      "\n",
      "01_20_00:35:34 Seen so far: 166752 samples\n",
      "\n",
      "01_20_00:35:34 --- 1.7637417316436768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:36 Training loss at epoch 2 step 5220: 3.1383215188980103\n",
      "\n",
      " This round's valence_loss=0.9888312816619873, arousal_loss=0.8568787574768066, emotion_loss=0.9262694716453552\n",
      "\n",
      "01_20_00:35:36 Seen so far: 167072 samples\n",
      "\n",
      "01_20_00:35:36 --- 1.6962811946868896 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:37 Training loss at epoch 2 step 5230: 3.3719525814056395\n",
      "\n",
      " This round's valence_loss=0.6449097990989685, arousal_loss=0.4924313426017761, emotion_loss=0.6538184881210327\n",
      "\n",
      "01_20_00:35:37 Seen so far: 167392 samples\n",
      "\n",
      "01_20_00:35:37 --- 1.6616604328155518 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:39 Training loss at epoch 2 step 5240: 3.1823644638061523\n",
      "\n",
      " This round's valence_loss=1.5665886402130127, arousal_loss=1.4731197357177734, emotion_loss=1.1303155422210693\n",
      "\n",
      "01_20_00:35:39 Seen so far: 167712 samples\n",
      "\n",
      "01_20_00:35:39 --- 1.7066495418548584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:41 Training loss at epoch 2 step 5250: 2.899329423904419\n",
      "\n",
      " This round's valence_loss=0.5217858552932739, arousal_loss=0.36429351568222046, emotion_loss=0.8165444135665894\n",
      "\n",
      "01_20_00:35:41 Seen so far: 168032 samples\n",
      "\n",
      "01_20_00:35:41 --- 1.9773459434509277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:43 Training loss at epoch 2 step 5260: 3.007888412475586\n",
      "\n",
      " This round's valence_loss=1.520989179611206, arousal_loss=1.3334835767745972, emotion_loss=1.0142543315887451\n",
      "\n",
      "01_20_00:35:43 Seen so far: 168352 samples\n",
      "\n",
      "01_20_00:35:43 --- 1.9242100715637207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:45 Training loss at epoch 2 step 5270: 2.9373071670532225\n",
      "\n",
      " This round's valence_loss=0.6806813478469849, arousal_loss=0.4646499454975128, emotion_loss=1.0432443618774414\n",
      "\n",
      "01_20_00:35:45 Seen so far: 168672 samples\n",
      "\n",
      "01_20_00:35:45 --- 1.8209104537963867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:47 Training loss at epoch 2 step 5280: 3.0232057571411133\n",
      "\n",
      " This round's valence_loss=1.007645845413208, arousal_loss=0.8852095603942871, emotion_loss=1.3348476886749268\n",
      "\n",
      "01_20_00:35:47 Seen so far: 168992 samples\n",
      "\n",
      "01_20_00:35:47 --- 1.9858274459838867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:49 Training loss at epoch 2 step 5290: 3.05604350566864\n",
      "\n",
      " This round's valence_loss=1.222475290298462, arousal_loss=1.0651086568832397, emotion_loss=0.981086015701294\n",
      "\n",
      "01_20_00:35:49 Seen so far: 169312 samples\n",
      "\n",
      "01_20_00:35:49 --- 1.770223617553711 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:50 Training loss at epoch 2 step 5300: 2.8177361249923707\n",
      "\n",
      " This round's valence_loss=1.337216854095459, arousal_loss=1.2010282278060913, emotion_loss=1.161150336265564\n",
      "\n",
      "01_20_00:35:50 Seen so far: 169632 samples\n",
      "\n",
      "01_20_00:35:50 --- 1.8692092895507812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:52 Training loss at epoch 2 step 5310: 2.767038130760193\n",
      "\n",
      " This round's valence_loss=0.7989053726196289, arousal_loss=0.7256718873977661, emotion_loss=1.0697920322418213\n",
      "\n",
      "01_20_00:35:52 Seen so far: 169952 samples\n",
      "\n",
      "01_20_00:35:52 --- 1.777578353881836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:54 Training loss at epoch 2 step 5320: 2.9581992864608764\n",
      "\n",
      " This round's valence_loss=0.7589148879051208, arousal_loss=0.5861866474151611, emotion_loss=0.9271346926689148\n",
      "\n",
      "01_20_00:35:54 Seen so far: 170272 samples\n",
      "\n",
      "01_20_00:35:54 --- 1.6847732067108154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:56 Training loss at epoch 2 step 5330: 3.5875199317932127\n",
      "\n",
      " This round's valence_loss=0.8756057024002075, arousal_loss=0.7498701810836792, emotion_loss=1.1900544166564941\n",
      "\n",
      "01_20_00:35:56 Seen so far: 170592 samples\n",
      "\n",
      "01_20_00:35:56 --- 1.6134769916534424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:57 Training loss at epoch 2 step 5340: 2.9960857629776\n",
      "\n",
      " This round's valence_loss=0.8167895078659058, arousal_loss=0.5549215078353882, emotion_loss=0.9225491285324097\n",
      "\n",
      "01_20_00:35:57 Seen so far: 170912 samples\n",
      "\n",
      "01_20_00:35:57 --- 1.5357117652893066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:35:59 Training loss at epoch 2 step 5350: 2.7087106227874758\n",
      "\n",
      " This round's valence_loss=0.8320499658584595, arousal_loss=0.722088098526001, emotion_loss=0.8746613264083862\n",
      "\n",
      "01_20_00:35:59 Seen so far: 171232 samples\n",
      "\n",
      "01_20_00:35:59 --- 1.704869270324707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:01 Training loss at epoch 2 step 5360: 2.9789632320404054\n",
      "\n",
      " This round's valence_loss=0.8739084005355835, arousal_loss=0.721993625164032, emotion_loss=0.991360068321228\n",
      "\n",
      "01_20_00:36:01 Seen so far: 171552 samples\n",
      "\n",
      "01_20_00:36:01 --- 1.8258140087127686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:02 Training loss at epoch 2 step 5370: 2.770111656188965\n",
      "\n",
      " This round's valence_loss=0.9670925736427307, arousal_loss=0.7964158058166504, emotion_loss=0.8975189328193665\n",
      "\n",
      "01_20_00:36:02 Seen so far: 171872 samples\n",
      "\n",
      "01_20_00:36:02 --- 1.815427541732788 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:04 Training loss at epoch 2 step 5380: 3.0131005525588987\n",
      "\n",
      " This round's valence_loss=0.7723633050918579, arousal_loss=0.594355583190918, emotion_loss=0.8983315229415894\n",
      "\n",
      "01_20_00:36:04 Seen so far: 172192 samples\n",
      "\n",
      "01_20_00:36:04 --- 1.6392402648925781 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:06 Training loss at epoch 2 step 5390: 3.1937607526779175\n",
      "\n",
      " This round's valence_loss=1.7583959102630615, arousal_loss=1.6564658880233765, emotion_loss=1.250739336013794\n",
      "\n",
      "01_20_00:36:06 Seen so far: 172512 samples\n",
      "\n",
      "01_20_00:36:06 --- 1.7974395751953125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:08 Training loss at epoch 2 step 5400: 2.8897204637527465\n",
      "\n",
      " This round's valence_loss=0.8584855794906616, arousal_loss=0.7058035135269165, emotion_loss=1.0924530029296875\n",
      "\n",
      "01_20_00:36:08 Seen so far: 172832 samples\n",
      "\n",
      "01_20_00:36:08 --- 1.8213739395141602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:09 Training loss at epoch 2 step 5410: 2.9995803356170656\n",
      "\n",
      " This round's valence_loss=1.227278232574463, arousal_loss=1.1089882850646973, emotion_loss=1.3311102390289307\n",
      "\n",
      "01_20_00:36:09 Seen so far: 173152 samples\n",
      "\n",
      "01_20_00:36:09 --- 1.6993603706359863 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:11 Training loss at epoch 2 step 5420: 2.8375725507736207\n",
      "\n",
      " This round's valence_loss=1.6125550270080566, arousal_loss=1.451399564743042, emotion_loss=1.0611718893051147\n",
      "\n",
      "01_20_00:36:11 Seen so far: 173472 samples\n",
      "\n",
      "01_20_00:36:11 --- 1.7275655269622803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:13 Training loss at epoch 2 step 5430: 2.729703688621521\n",
      "\n",
      " This round's valence_loss=1.1146469116210938, arousal_loss=0.9635827541351318, emotion_loss=1.135164737701416\n",
      "\n",
      "01_20_00:36:13 Seen so far: 173792 samples\n",
      "\n",
      "01_20_00:36:13 --- 1.61185884475708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:14 Training loss at epoch 2 step 5440: 2.6988826751708985\n",
      "\n",
      " This round's valence_loss=1.2333664894104004, arousal_loss=1.0515129566192627, emotion_loss=1.0177732706069946\n",
      "\n",
      "01_20_00:36:14 Seen so far: 174112 samples\n",
      "\n",
      "01_20_00:36:14 --- 1.684295415878296 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:16 Training loss at epoch 2 step 5450: 2.85822172164917\n",
      "\n",
      " This round's valence_loss=0.6219879984855652, arousal_loss=0.5406920909881592, emotion_loss=0.7535155415534973\n",
      "\n",
      "01_20_00:36:16 Seen so far: 174432 samples\n",
      "\n",
      "01_20_00:36:16 --- 1.768911361694336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:18 Training loss at epoch 2 step 5460: 2.8458383798599245\n",
      "\n",
      " This round's valence_loss=0.659989595413208, arousal_loss=0.5267433524131775, emotion_loss=1.0758106708526611\n",
      "\n",
      "01_20_00:36:18 Seen so far: 174752 samples\n",
      "\n",
      "01_20_00:36:18 --- 1.788398265838623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:20 Training loss at epoch 2 step 5470: 3.1521371841430663\n",
      "\n",
      " This round's valence_loss=1.4572019577026367, arousal_loss=1.3040218353271484, emotion_loss=0.7768009305000305\n",
      "\n",
      "01_20_00:36:20 Seen so far: 175072 samples\n",
      "\n",
      "01_20_00:36:20 --- 1.9708642959594727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:22 Training loss at epoch 2 step 5480: 3.080696702003479\n",
      "\n",
      " This round's valence_loss=1.342698335647583, arousal_loss=1.2207562923431396, emotion_loss=1.224989891052246\n",
      "\n",
      "01_20_00:36:22 Seen so far: 175392 samples\n",
      "\n",
      "01_20_00:36:22 --- 1.7369306087493896 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:24 Training loss at epoch 2 step 5490: 2.9766048192977905\n",
      "\n",
      " This round's valence_loss=1.2432910203933716, arousal_loss=1.1271324157714844, emotion_loss=0.9710571765899658\n",
      "\n",
      "01_20_00:36:24 Seen so far: 175712 samples\n",
      "\n",
      "01_20_00:36:24 --- 1.8337111473083496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:26 Training loss at epoch 2 step 5500: 3.164587378501892\n",
      "\n",
      " This round's valence_loss=1.2825756072998047, arousal_loss=1.1808068752288818, emotion_loss=0.8688194155693054\n",
      "\n",
      "01_20_00:36:26 Seen so far: 176032 samples\n",
      "\n",
      "01_20_00:36:26 --- 2.019864320755005 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:28 Training loss at epoch 2 step 5510: 2.6813048720359802\n",
      "\n",
      " This round's valence_loss=0.5235641002655029, arousal_loss=0.3374161720275879, emotion_loss=0.6993345022201538\n",
      "\n",
      "01_20_00:36:28 Seen so far: 176352 samples\n",
      "\n",
      "01_20_00:36:28 --- 1.9464366436004639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:29 Training loss at epoch 2 step 5520: 2.8321406722068785\n",
      "\n",
      " This round's valence_loss=0.9486747980117798, arousal_loss=0.8399428129196167, emotion_loss=0.9783832430839539\n",
      "\n",
      "01_20_00:36:29 Seen so far: 176672 samples\n",
      "\n",
      "01_20_00:36:29 --- 1.7668719291687012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:31 Training loss at epoch 2 step 5530: 3.016839051246643\n",
      "\n",
      " This round's valence_loss=1.1488301753997803, arousal_loss=0.9481163024902344, emotion_loss=0.8494760990142822\n",
      "\n",
      "01_20_00:36:31 Seen so far: 176992 samples\n",
      "\n",
      "01_20_00:36:31 --- 1.7533948421478271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:33 Training loss at epoch 2 step 5540: 3.4505789041519166\n",
      "\n",
      " This round's valence_loss=1.2963200807571411, arousal_loss=1.2057628631591797, emotion_loss=1.1039609909057617\n",
      "\n",
      "01_20_00:36:33 Seen so far: 177312 samples\n",
      "\n",
      "01_20_00:36:33 --- 1.73940110206604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:35 Training loss at epoch 2 step 5550: 3.087421345710754\n",
      "\n",
      " This round's valence_loss=1.2216527462005615, arousal_loss=1.099339485168457, emotion_loss=1.2033898830413818\n",
      "\n",
      "01_20_00:36:35 Seen so far: 177632 samples\n",
      "\n",
      "01_20_00:36:35 --- 1.7449448108673096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:36 Training loss at epoch 2 step 5560: 2.9731432437896728\n",
      "\n",
      " This round's valence_loss=0.9766519069671631, arousal_loss=0.8530490398406982, emotion_loss=0.9527937173843384\n",
      "\n",
      "01_20_00:36:36 Seen so far: 177952 samples\n",
      "\n",
      "01_20_00:36:36 --- 1.803015947341919 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:38 Training loss at epoch 2 step 5570: 3.2686517238616943\n",
      "\n",
      " This round's valence_loss=0.8007473945617676, arousal_loss=0.7797970771789551, emotion_loss=1.0704991817474365\n",
      "\n",
      "01_20_00:36:38 Seen so far: 178272 samples\n",
      "\n",
      "01_20_00:36:38 --- 1.8627924919128418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:40 Training loss at epoch 2 step 5580: 3.301031541824341\n",
      "\n",
      " This round's valence_loss=1.2757539749145508, arousal_loss=1.1189467906951904, emotion_loss=0.6210660934448242\n",
      "\n",
      "01_20_00:36:40 Seen so far: 178592 samples\n",
      "\n",
      "01_20_00:36:40 --- 1.8950707912445068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:42 Training loss at epoch 2 step 5590: 3.2410853266716004\n",
      "\n",
      " This round's valence_loss=1.09669828414917, arousal_loss=0.9553486108779907, emotion_loss=0.956283688545227\n",
      "\n",
      "01_20_00:36:42 Seen so far: 178912 samples\n",
      "\n",
      "01_20_00:36:42 --- 1.7706117630004883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:43 Training loss at epoch 2 step 5600: 2.926022744178772\n",
      "\n",
      " This round's valence_loss=0.7935593128204346, arousal_loss=0.5868625044822693, emotion_loss=0.8121363520622253\n",
      "\n",
      "01_20_00:36:43 Seen so far: 179232 samples\n",
      "\n",
      "01_20_00:36:43 --- 1.6560430526733398 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:45 Training loss at epoch 2 step 5610: 3.2368524789810182\n",
      "\n",
      " This round's valence_loss=1.6092058420181274, arousal_loss=1.4837310314178467, emotion_loss=1.1860146522521973\n",
      "\n",
      "01_20_00:36:45 Seen so far: 179552 samples\n",
      "\n",
      "01_20_00:36:45 --- 1.831789255142212 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:47 Training loss at epoch 2 step 5620: 2.957945966720581\n",
      "\n",
      " This round's valence_loss=1.0561320781707764, arousal_loss=0.9906046390533447, emotion_loss=1.1391814947128296\n",
      "\n",
      "01_20_00:36:47 Seen so far: 179872 samples\n",
      "\n",
      "01_20_00:36:47 --- 1.7681922912597656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:49 Training loss at epoch 2 step 5630: 3.384117603302002\n",
      "\n",
      " This round's valence_loss=1.2032190561294556, arousal_loss=1.0835145711898804, emotion_loss=1.1013447046279907\n",
      "\n",
      "01_20_00:36:49 Seen so far: 180192 samples\n",
      "\n",
      "01_20_00:36:49 --- 1.7421886920928955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:51 Training loss at epoch 2 step 5640: 2.8177659034729006\n",
      "\n",
      " This round's valence_loss=1.0053095817565918, arousal_loss=0.9640210866928101, emotion_loss=0.8399691581726074\n",
      "\n",
      "01_20_00:36:51 Seen so far: 180512 samples\n",
      "\n",
      "01_20_00:36:51 --- 1.7248892784118652 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:52 Training loss at epoch 2 step 5650: 3.2151534080505373\n",
      "\n",
      " This round's valence_loss=1.1907135248184204, arousal_loss=1.1123952865600586, emotion_loss=1.3852736949920654\n",
      "\n",
      "01_20_00:36:52 Seen so far: 180832 samples\n",
      "\n",
      "01_20_00:36:52 --- 1.7083733081817627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:54 Training loss at epoch 2 step 5660: 2.820130777359009\n",
      "\n",
      " This round's valence_loss=1.0278555154800415, arousal_loss=0.8758278489112854, emotion_loss=0.9993362426757812\n",
      "\n",
      "01_20_00:36:54 Seen so far: 181152 samples\n",
      "\n",
      "01_20_00:36:54 --- 1.772000789642334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:56 Training loss at epoch 2 step 5670: 3.5593465089797975\n",
      "\n",
      " This round's valence_loss=1.3788783550262451, arousal_loss=1.2375577688217163, emotion_loss=0.9267739653587341\n",
      "\n",
      "01_20_00:36:56 Seen so far: 181472 samples\n",
      "\n",
      "01_20_00:36:56 --- 1.6718473434448242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:57 Training loss at epoch 2 step 5680: 2.944370889663696\n",
      "\n",
      " This round's valence_loss=1.456022024154663, arousal_loss=1.3049784898757935, emotion_loss=0.8548146486282349\n",
      "\n",
      "01_20_00:36:57 Seen so far: 181792 samples\n",
      "\n",
      "01_20_00:36:57 --- 1.7306323051452637 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:36:59 Training loss at epoch 2 step 5690: 2.7884354114532472\n",
      "\n",
      " This round's valence_loss=1.3097054958343506, arousal_loss=1.0215351581573486, emotion_loss=0.8200496435165405\n",
      "\n",
      "01_20_00:36:59 Seen so far: 182112 samples\n",
      "\n",
      "01_20_00:36:59 --- 1.7402994632720947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:01 Training loss at epoch 2 step 5700: 3.4071780681610107\n",
      "\n",
      " This round's valence_loss=0.7082966566085815, arousal_loss=0.6144224405288696, emotion_loss=1.1414419412612915\n",
      "\n",
      "01_20_00:37:01 Seen so far: 182432 samples\n",
      "\n",
      "01_20_00:37:01 --- 1.7304673194885254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:03 Training loss at epoch 2 step 5710: 2.950314295291901\n",
      "\n",
      " This round's valence_loss=1.1153416633605957, arousal_loss=0.979783296585083, emotion_loss=0.6431223154067993\n",
      "\n",
      "01_20_00:37:03 Seen so far: 182752 samples\n",
      "\n",
      "01_20_00:37:03 --- 1.7399177551269531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:04 Training loss at epoch 2 step 5720: 3.1159738063812257\n",
      "\n",
      " This round's valence_loss=1.7768332958221436, arousal_loss=1.708325743675232, emotion_loss=1.0767449140548706\n",
      "\n",
      "01_20_00:37:04 Seen so far: 183072 samples\n",
      "\n",
      "01_20_00:37:04 --- 1.7032253742218018 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:06 Training loss at epoch 2 step 5730: 3.294822263717651\n",
      "\n",
      " This round's valence_loss=0.9842296838760376, arousal_loss=0.8725837469100952, emotion_loss=0.6997945308685303\n",
      "\n",
      "01_20_00:37:06 Seen so far: 183392 samples\n",
      "\n",
      "01_20_00:37:06 --- 1.8263518810272217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:08 Training loss at epoch 2 step 5740: 3.19840521812439\n",
      "\n",
      " This round's valence_loss=1.1474133729934692, arousal_loss=0.9312155246734619, emotion_loss=0.8144374489784241\n",
      "\n",
      "01_20_00:37:08 Seen so far: 183712 samples\n",
      "\n",
      "01_20_00:37:08 --- 1.7344675064086914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:10 Training loss at epoch 2 step 5750: 3.0711656332015993\n",
      "\n",
      " This round's valence_loss=1.1965572834014893, arousal_loss=0.8970348834991455, emotion_loss=0.6660939455032349\n",
      "\n",
      "01_20_00:37:10 Seen so far: 184032 samples\n",
      "\n",
      "01_20_00:37:10 --- 1.6907386779785156 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:11 Training loss at epoch 2 step 5760: 2.931207203865051\n",
      "\n",
      " This round's valence_loss=1.105388879776001, arousal_loss=0.931941568851471, emotion_loss=1.0273401737213135\n",
      "\n",
      "01_20_00:37:11 Seen so far: 184352 samples\n",
      "\n",
      "01_20_00:37:11 --- 1.7989940643310547 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:13 Training loss at epoch 2 step 5770: 3.22111656665802\n",
      "\n",
      " This round's valence_loss=1.048506259918213, arousal_loss=1.0348622798919678, emotion_loss=1.4266552925109863\n",
      "\n",
      "01_20_00:37:13 Seen so far: 184672 samples\n",
      "\n",
      "01_20_00:37:13 --- 1.7058322429656982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:15 Training loss at epoch 2 step 5780: 2.718330717086792\n",
      "\n",
      " This round's valence_loss=0.9776884317398071, arousal_loss=0.8500747680664062, emotion_loss=0.9512719511985779\n",
      "\n",
      "01_20_00:37:15 Seen so far: 184992 samples\n",
      "\n",
      "01_20_00:37:15 --- 1.8182423114776611 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:17 Training loss at epoch 2 step 5790: 2.944342827796936\n",
      "\n",
      " This round's valence_loss=1.4739940166473389, arousal_loss=1.3113266229629517, emotion_loss=0.8704842329025269\n",
      "\n",
      "01_20_00:37:17 Seen so far: 185312 samples\n",
      "\n",
      "01_20_00:37:17 --- 1.7206733226776123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:18 Training loss at epoch 2 step 5800: 2.6689558029174805\n",
      "\n",
      " This round's valence_loss=1.0847759246826172, arousal_loss=0.952938437461853, emotion_loss=0.8952478170394897\n",
      "\n",
      "01_20_00:37:18 Seen so far: 185632 samples\n",
      "\n",
      "01_20_00:37:18 --- 1.6749162673950195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:20 Training loss at epoch 2 step 5810: 3.2950159072875977\n",
      "\n",
      " This round's valence_loss=1.21750009059906, arousal_loss=1.078474760055542, emotion_loss=1.1593453884124756\n",
      "\n",
      "01_20_00:37:20 Seen so far: 185952 samples\n",
      "\n",
      "01_20_00:37:20 --- 1.9376194477081299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:22 Training loss at epoch 2 step 5820: 3.110690248012543\n",
      "\n",
      " This round's valence_loss=1.4493743181228638, arousal_loss=1.350118637084961, emotion_loss=0.5682742595672607\n",
      "\n",
      "01_20_00:37:22 Seen so far: 186272 samples\n",
      "\n",
      "01_20_00:37:22 --- 1.8245115280151367 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:24 Training loss at epoch 2 step 5830: 3.202920079231262\n",
      "\n",
      " This round's valence_loss=1.3670814037322998, arousal_loss=1.1825087070465088, emotion_loss=0.9967371225357056\n",
      "\n",
      "01_20_00:37:24 Seen so far: 186592 samples\n",
      "\n",
      "01_20_00:37:24 --- 1.7571725845336914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:26 Training loss at epoch 2 step 5840: 2.8287821292877195\n",
      "\n",
      " This round's valence_loss=0.6140566468238831, arousal_loss=0.5248951315879822, emotion_loss=0.9507597088813782\n",
      "\n",
      "01_20_00:37:26 Seen so far: 186912 samples\n",
      "\n",
      "01_20_00:37:26 --- 1.756230354309082 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:27 Training loss at epoch 2 step 5850: 3.0166260957717896\n",
      "\n",
      " This round's valence_loss=0.5850445032119751, arousal_loss=0.47836700081825256, emotion_loss=1.2140780687332153\n",
      "\n",
      "01_20_00:37:27 Seen so far: 187232 samples\n",
      "\n",
      "01_20_00:37:27 --- 1.790236473083496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:29 Training loss at epoch 2 step 5860: 3.0922160387039184\n",
      "\n",
      " This round's valence_loss=0.6442478895187378, arousal_loss=0.513023853302002, emotion_loss=1.1584423780441284\n",
      "\n",
      "01_20_00:37:29 Seen so far: 187552 samples\n",
      "\n",
      "01_20_00:37:29 --- 1.699561595916748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:31 Training loss at epoch 2 step 5870: 3.0877302169799803\n",
      "\n",
      " This round's valence_loss=0.8804005980491638, arousal_loss=0.7352371215820312, emotion_loss=0.6108853220939636\n",
      "\n",
      "01_20_00:37:31 Seen so far: 187872 samples\n",
      "\n",
      "01_20_00:37:31 --- 1.7037382125854492 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:32 Training loss at epoch 2 step 5880: 2.9829961538314818\n",
      "\n",
      " This round's valence_loss=0.8714745044708252, arousal_loss=0.7190871238708496, emotion_loss=0.8416702151298523\n",
      "\n",
      "01_20_00:37:32 Seen so far: 188192 samples\n",
      "\n",
      "01_20_00:37:32 --- 1.678579330444336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:34 Training loss at epoch 2 step 5890: 3.0593077898025514\n",
      "\n",
      " This round's valence_loss=1.726806879043579, arousal_loss=1.600188970565796, emotion_loss=1.0723190307617188\n",
      "\n",
      "01_20_00:37:34 Seen so far: 188512 samples\n",
      "\n",
      "01_20_00:37:34 --- 1.8481707572937012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:36 Training loss at epoch 2 step 5900: 2.8622230529785155\n",
      "\n",
      " This round's valence_loss=0.8799424767494202, arousal_loss=0.7127773761749268, emotion_loss=0.7338011860847473\n",
      "\n",
      "01_20_00:37:36 Seen so far: 188832 samples\n",
      "\n",
      "01_20_00:37:36 --- 1.7462961673736572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:38 Training loss at epoch 2 step 5910: 2.9691587924957275\n",
      "\n",
      " This round's valence_loss=0.9092665910720825, arousal_loss=0.7611993551254272, emotion_loss=0.782214879989624\n",
      "\n",
      "01_20_00:37:38 Seen so far: 189152 samples\n",
      "\n",
      "01_20_00:37:38 --- 1.808516263961792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:40 Training loss at epoch 2 step 5920: 3.1169650554656982\n",
      "\n",
      " This round's valence_loss=1.308439016342163, arousal_loss=1.0822253227233887, emotion_loss=0.9464961886405945\n",
      "\n",
      "01_20_00:37:40 Seen so far: 189472 samples\n",
      "\n",
      "01_20_00:37:40 --- 1.8250584602355957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:41 Training loss at epoch 2 step 5930: 3.0617419719696044\n",
      "\n",
      " This round's valence_loss=1.4235780239105225, arousal_loss=1.3362174034118652, emotion_loss=0.9934195280075073\n",
      "\n",
      "01_20_00:37:41 Seen so far: 189792 samples\n",
      "\n",
      "01_20_00:37:41 --- 1.7097532749176025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:43 Training loss at epoch 2 step 5940: 2.9778163909912108\n",
      "\n",
      " This round's valence_loss=0.8490003347396851, arousal_loss=0.7185397148132324, emotion_loss=0.8993990421295166\n",
      "\n",
      "01_20_00:37:43 Seen so far: 190112 samples\n",
      "\n",
      "01_20_00:37:43 --- 1.7053031921386719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:45 Training loss at epoch 2 step 5950: 2.923767352104187\n",
      "\n",
      " This round's valence_loss=0.948677659034729, arousal_loss=0.8653428554534912, emotion_loss=1.2762700319290161\n",
      "\n",
      "01_20_00:37:45 Seen so far: 190432 samples\n",
      "\n",
      "01_20_00:37:45 --- 1.7838225364685059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:47 Training loss at epoch 2 step 5960: 2.9774823427200316\n",
      "\n",
      " This round's valence_loss=0.9922906756401062, arousal_loss=0.8892070651054382, emotion_loss=0.9630155563354492\n",
      "\n",
      "01_20_00:37:47 Seen so far: 190752 samples\n",
      "\n",
      "01_20_00:37:47 --- 1.7896413803100586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:49 Training loss at epoch 2 step 5970: 3.278398132324219\n",
      "\n",
      " This round's valence_loss=1.1205703020095825, arousal_loss=0.9734575748443604, emotion_loss=1.1939284801483154\n",
      "\n",
      "01_20_00:37:49 Seen so far: 191072 samples\n",
      "\n",
      "01_20_00:37:49 --- 1.812105655670166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:50 Training loss at epoch 2 step 5980: 2.978124260902405\n",
      "\n",
      " This round's valence_loss=0.7102477550506592, arousal_loss=0.6992007493972778, emotion_loss=1.1163041591644287\n",
      "\n",
      "01_20_00:37:50 Seen so far: 191392 samples\n",
      "\n",
      "01_20_00:37:50 --- 1.8283746242523193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:52 Training loss at epoch 2 step 5990: 2.7799651622772217\n",
      "\n",
      " This round's valence_loss=0.5368856191635132, arousal_loss=0.423678994178772, emotion_loss=1.0002458095550537\n",
      "\n",
      "01_20_00:37:52 Seen so far: 191712 samples\n",
      "\n",
      "01_20_00:37:52 --- 1.7860124111175537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:54 Training loss at epoch 2 step 6000: 2.97765257358551\n",
      "\n",
      " This round's valence_loss=0.9926135540008545, arousal_loss=0.8163489103317261, emotion_loss=0.8609672784805298\n",
      "\n",
      "01_20_00:37:54 Seen so far: 192032 samples\n",
      "\n",
      "01_20_00:37:54 --- 1.8262355327606201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:56 Training loss at epoch 2 step 6010: 3.249843788146973\n",
      "\n",
      " This round's valence_loss=1.4727108478546143, arousal_loss=1.363387107849121, emotion_loss=1.1683032512664795\n",
      "\n",
      "01_20_00:37:56 Seen so far: 192352 samples\n",
      "\n",
      "01_20_00:37:56 --- 1.7258012294769287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:57 Training loss at epoch 2 step 6020: 3.1169127225875854\n",
      "\n",
      " This round's valence_loss=1.2115767002105713, arousal_loss=0.9694955348968506, emotion_loss=0.9544252157211304\n",
      "\n",
      "01_20_00:37:57 Seen so far: 192672 samples\n",
      "\n",
      "01_20_00:37:57 --- 1.7233176231384277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:37:59 Training loss at epoch 2 step 6030: 3.1738917589187623\n",
      "\n",
      " This round's valence_loss=1.1600114107131958, arousal_loss=1.1399462223052979, emotion_loss=1.1999940872192383\n",
      "\n",
      "01_20_00:37:59 Seen so far: 192992 samples\n",
      "\n",
      "01_20_00:37:59 --- 1.864452600479126 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:01 Training loss at epoch 2 step 6040: 2.8422390818595886\n",
      "\n",
      " This round's valence_loss=1.4950252771377563, arousal_loss=1.3483127355575562, emotion_loss=0.8287210464477539\n",
      "\n",
      "01_20_00:38:01 Seen so far: 193312 samples\n",
      "\n",
      "01_20_00:38:01 --- 1.5900745391845703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:03 Training loss at epoch 2 step 6050: 2.8056004285812377\n",
      "\n",
      " This round's valence_loss=1.1320507526397705, arousal_loss=0.9545844793319702, emotion_loss=1.037900447845459\n",
      "\n",
      "01_20_00:38:03 Seen so far: 193632 samples\n",
      "\n",
      "01_20_00:38:03 --- 2.0199344158172607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:05 Training loss at epoch 2 step 6060: 3.421654534339905\n",
      "\n",
      " This round's valence_loss=1.2235260009765625, arousal_loss=1.0706815719604492, emotion_loss=1.1758365631103516\n",
      "\n",
      "01_20_00:38:05 Seen so far: 193952 samples\n",
      "\n",
      "01_20_00:38:05 --- 1.8216652870178223 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:06 Training loss at epoch 2 step 6070: 2.8658109068870545\n",
      "\n",
      " This round's valence_loss=0.6322380900382996, arousal_loss=0.4737684726715088, emotion_loss=0.9731329679489136\n",
      "\n",
      "01_20_00:38:06 Seen so far: 194272 samples\n",
      "\n",
      "01_20_00:38:06 --- 1.7387182712554932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:08 Training loss at epoch 2 step 6080: 3.1201411485671997\n",
      "\n",
      " This round's valence_loss=0.966019868850708, arousal_loss=0.8528448343276978, emotion_loss=0.9772767424583435\n",
      "\n",
      "01_20_00:38:08 Seen so far: 194592 samples\n",
      "\n",
      "01_20_00:38:08 --- 1.714768886566162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:10 Training loss at epoch 2 step 6090: 2.9271700382232666\n",
      "\n",
      " This round's valence_loss=0.7407644987106323, arousal_loss=0.46350735425949097, emotion_loss=0.6658876538276672\n",
      "\n",
      "01_20_00:38:10 Seen so far: 194912 samples\n",
      "\n",
      "01_20_00:38:10 --- 1.7143003940582275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:12 Training loss at epoch 2 step 6100: 2.8838735818862915\n",
      "\n",
      " This round's valence_loss=1.9206581115722656, arousal_loss=1.8175909519195557, emotion_loss=0.870825469493866\n",
      "\n",
      "01_20_00:38:12 Seen so far: 195232 samples\n",
      "\n",
      "01_20_00:38:12 --- 1.7826409339904785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:13 Training loss at epoch 2 step 6110: 2.910320830345154\n",
      "\n",
      " This round's valence_loss=1.234424352645874, arousal_loss=1.02619206905365, emotion_loss=0.6220582723617554\n",
      "\n",
      "01_20_00:38:13 Seen so far: 195552 samples\n",
      "\n",
      "01_20_00:38:13 --- 1.7938673496246338 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:15 Training loss at epoch 2 step 6120: 3.031517219543457\n",
      "\n",
      " This round's valence_loss=1.3498649597167969, arousal_loss=1.2228237390518188, emotion_loss=0.7209864854812622\n",
      "\n",
      "01_20_00:38:15 Seen so far: 195872 samples\n",
      "\n",
      "01_20_00:38:15 --- 1.7211544513702393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:17 Training loss at epoch 2 step 6130: 2.814649486541748\n",
      "\n",
      " This round's valence_loss=0.9661973714828491, arousal_loss=0.6724783182144165, emotion_loss=0.8474189639091492\n",
      "\n",
      "01_20_00:38:17 Seen so far: 196192 samples\n",
      "\n",
      "01_20_00:38:17 --- 1.8659987449645996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:19 Training loss at epoch 2 step 6140: 2.8167547225952148\n",
      "\n",
      " This round's valence_loss=1.3747432231903076, arousal_loss=1.223085880279541, emotion_loss=0.6248326301574707\n",
      "\n",
      "01_20_00:38:19 Seen so far: 196512 samples\n",
      "\n",
      "01_20_00:38:19 --- 1.735060214996338 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:21 Training loss at epoch 2 step 6150: 3.0085330963134767\n",
      "\n",
      " This round's valence_loss=0.739578366279602, arousal_loss=0.6376842260360718, emotion_loss=1.1164573431015015\n",
      "\n",
      "01_20_00:38:21 Seen so far: 196832 samples\n",
      "\n",
      "01_20_00:38:21 --- 1.7871665954589844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:22 Training loss at epoch 2 step 6160: 2.8554569244384767\n",
      "\n",
      " This round's valence_loss=1.3389809131622314, arousal_loss=1.1793574094772339, emotion_loss=0.922012984752655\n",
      "\n",
      "01_20_00:38:22 Seen so far: 197152 samples\n",
      "\n",
      "01_20_00:38:22 --- 1.822533369064331 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:24 Training loss at epoch 2 step 6170: 2.9631283044815064\n",
      "\n",
      " This round's valence_loss=0.6856815814971924, arousal_loss=0.5934339761734009, emotion_loss=0.9457052946090698\n",
      "\n",
      "01_20_00:38:24 Seen so far: 197472 samples\n",
      "\n",
      "01_20_00:38:24 --- 1.5808484554290771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:26 Training loss at epoch 2 step 6180: 3.004299688339233\n",
      "\n",
      " This round's valence_loss=1.0880156755447388, arousal_loss=0.9837762117385864, emotion_loss=0.8879326581954956\n",
      "\n",
      "01_20_00:38:26 Seen so far: 197792 samples\n",
      "\n",
      "01_20_00:38:26 --- 1.7275445461273193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:28 Training loss at epoch 2 step 6190: 2.928739047050476\n",
      "\n",
      " This round's valence_loss=1.2562175989151, arousal_loss=1.1044950485229492, emotion_loss=0.8779438734054565\n",
      "\n",
      "01_20_00:38:28 Seen so far: 198112 samples\n",
      "\n",
      "01_20_00:38:28 --- 1.8493165969848633 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:29 Training loss at epoch 2 step 6200: 3.2668399572372437\n",
      "\n",
      " This round's valence_loss=0.8829858899116516, arousal_loss=0.7428637742996216, emotion_loss=0.9212803840637207\n",
      "\n",
      "01_20_00:38:29 Seen so far: 198432 samples\n",
      "\n",
      "01_20_00:38:29 --- 1.8701486587524414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:31 Training loss at epoch 2 step 6210: 3.2326339960098265\n",
      "\n",
      " This round's valence_loss=1.4408516883850098, arousal_loss=1.3505284786224365, emotion_loss=1.0922455787658691\n",
      "\n",
      "01_20_00:38:31 Seen so far: 198752 samples\n",
      "\n",
      "01_20_00:38:31 --- 1.8216586112976074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:33 Training loss at epoch 2 step 6220: 3.4139901399612427\n",
      "\n",
      " This round's valence_loss=1.2119166851043701, arousal_loss=1.1059998273849487, emotion_loss=1.349448800086975\n",
      "\n",
      "01_20_00:38:33 Seen so far: 199072 samples\n",
      "\n",
      "01_20_00:38:33 --- 1.6993305683135986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:35 Training loss at epoch 2 step 6230: 2.9983323216438293\n",
      "\n",
      " This round's valence_loss=1.2493422031402588, arousal_loss=1.1168181896209717, emotion_loss=1.1888296604156494\n",
      "\n",
      "01_20_00:38:35 Seen so far: 199392 samples\n",
      "\n",
      "01_20_00:38:35 --- 1.710737943649292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:36 Training loss at epoch 2 step 6240: 3.316135549545288\n",
      "\n",
      " This round's valence_loss=0.7782652378082275, arousal_loss=0.5518879890441895, emotion_loss=0.9790804982185364\n",
      "\n",
      "01_20_00:38:36 Seen so far: 199712 samples\n",
      "\n",
      "01_20_00:38:36 --- 1.7929472923278809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:38 Training loss at epoch 2 step 6250: 3.1669100761413573\n",
      "\n",
      " This round's valence_loss=1.3768116235733032, arousal_loss=1.3134942054748535, emotion_loss=1.2695980072021484\n",
      "\n",
      "01_20_00:38:38 Seen so far: 200032 samples\n",
      "\n",
      "01_20_00:38:38 --- 1.8877637386322021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:40 Training loss at epoch 2 step 6260: 3.0036476612091065\n",
      "\n",
      " This round's valence_loss=0.880427360534668, arousal_loss=0.6750094890594482, emotion_loss=0.8154106736183167\n",
      "\n",
      "01_20_00:38:40 Seen so far: 200352 samples\n",
      "\n",
      "01_20_00:38:40 --- 1.8686563968658447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:42 Training loss at epoch 2 step 6270: 2.813197922706604\n",
      "\n",
      " This round's valence_loss=0.7456249594688416, arousal_loss=0.5806745886802673, emotion_loss=0.6046257019042969\n",
      "\n",
      "01_20_00:38:42 Seen so far: 200672 samples\n",
      "\n",
      "01_20_00:38:42 --- 1.8037550449371338 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:44 Training loss at epoch 2 step 6280: 2.7583862423896788\n",
      "\n",
      " This round's valence_loss=1.1590988636016846, arousal_loss=1.0931166410446167, emotion_loss=0.9691574573516846\n",
      "\n",
      "01_20_00:38:44 Seen so far: 200992 samples\n",
      "\n",
      "01_20_00:38:44 --- 1.8779537677764893 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:46 Training loss at epoch 2 step 6290: 2.862324333190918\n",
      "\n",
      " This round's valence_loss=0.713316798210144, arousal_loss=0.6371884942054749, emotion_loss=1.1012423038482666\n",
      "\n",
      "01_20_00:38:46 Seen so far: 201312 samples\n",
      "\n",
      "01_20_00:38:46 --- 1.6519544124603271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:47 Training loss at epoch 2 step 6300: 3.270196270942688\n",
      "\n",
      " This round's valence_loss=1.2517619132995605, arousal_loss=1.0795402526855469, emotion_loss=0.9042963981628418\n",
      "\n",
      "01_20_00:38:47 Seen so far: 201632 samples\n",
      "\n",
      "01_20_00:38:47 --- 1.6895296573638916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:49 Training loss at epoch 2 step 6310: 2.8738978147506713\n",
      "\n",
      " This round's valence_loss=0.9850896596908569, arousal_loss=0.8779908418655396, emotion_loss=1.1507651805877686\n",
      "\n",
      "01_20_00:38:49 Seen so far: 201952 samples\n",
      "\n",
      "01_20_00:38:49 --- 1.7077233791351318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:50 Training loss at epoch 2 step 6320: 3.1837684154510497\n",
      "\n",
      " This round's valence_loss=0.9675894975662231, arousal_loss=0.8159434795379639, emotion_loss=0.8979852795600891\n",
      "\n",
      "01_20_00:38:50 Seen so far: 202272 samples\n",
      "\n",
      "01_20_00:38:50 --- 1.564394235610962 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:52 Training loss at epoch 2 step 6330: 2.8432241678237915\n",
      "\n",
      " This round's valence_loss=1.2474486827850342, arousal_loss=1.063776969909668, emotion_loss=1.0638387203216553\n",
      "\n",
      "01_20_00:38:52 Seen so far: 202592 samples\n",
      "\n",
      "01_20_00:38:52 --- 1.7288544178009033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:54 Training loss at epoch 2 step 6340: 3.2198465347290037\n",
      "\n",
      " This round's valence_loss=0.5982393622398376, arousal_loss=0.5338822603225708, emotion_loss=0.8203263282775879\n",
      "\n",
      "01_20_00:38:54 Seen so far: 202912 samples\n",
      "\n",
      "01_20_00:38:54 --- 1.9534335136413574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:56 Training loss at epoch 2 step 6350: 2.7229212522506714\n",
      "\n",
      " This round's valence_loss=0.5829372406005859, arousal_loss=0.42835062742233276, emotion_loss=0.6892097592353821\n",
      "\n",
      "01_20_00:38:56 Seen so far: 203232 samples\n",
      "\n",
      "01_20_00:38:56 --- 1.7791540622711182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:58 Training loss at epoch 2 step 6360: 2.8679348468780517\n",
      "\n",
      " This round's valence_loss=0.9765802025794983, arousal_loss=0.8209205865859985, emotion_loss=0.888915479183197\n",
      "\n",
      "01_20_00:38:58 Seen so far: 203552 samples\n",
      "\n",
      "01_20_00:38:58 --- 1.6458511352539062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:38:59 Training loss at epoch 2 step 6370: 3.195127248764038\n",
      "\n",
      " This round's valence_loss=1.559310793876648, arousal_loss=1.435289740562439, emotion_loss=0.7856935262680054\n",
      "\n",
      "01_20_00:38:59 Seen so far: 203872 samples\n",
      "\n",
      "01_20_00:38:59 --- 1.7294731140136719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:01 Training loss at epoch 2 step 6380: 3.1132061958312987\n",
      "\n",
      " This round's valence_loss=0.9296976327896118, arousal_loss=0.8618361949920654, emotion_loss=1.2779436111450195\n",
      "\n",
      "01_20_00:39:01 Seen so far: 204192 samples\n",
      "\n",
      "01_20_00:39:01 --- 1.7837698459625244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:03 Training loss at epoch 2 step 6390: 3.1068952083587646\n",
      "\n",
      " This round's valence_loss=1.1281509399414062, arousal_loss=1.012422800064087, emotion_loss=0.9016934633255005\n",
      "\n",
      "01_20_00:39:03 Seen so far: 204512 samples\n",
      "\n",
      "01_20_00:39:03 --- 1.641829013824463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:05 Training loss at epoch 2 step 6400: 3.3173537492752074\n",
      "\n",
      " This round's valence_loss=0.8649893403053284, arousal_loss=0.7107956409454346, emotion_loss=1.2762600183486938\n",
      "\n",
      "01_20_00:39:05 Seen so far: 204832 samples\n",
      "\n",
      "01_20_00:39:05 --- 1.9868762493133545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:06 Training loss at epoch 2 step 6410: 2.967225122451782\n",
      "\n",
      " This round's valence_loss=1.4227113723754883, arousal_loss=1.3850326538085938, emotion_loss=0.8899750113487244\n",
      "\n",
      "01_20_00:39:06 Seen so far: 205152 samples\n",
      "\n",
      "01_20_00:39:06 --- 1.6860756874084473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:08 Training loss at epoch 2 step 6420: 3.129141592979431\n",
      "\n",
      " This round's valence_loss=1.1254605054855347, arousal_loss=1.0295778512954712, emotion_loss=0.9749242663383484\n",
      "\n",
      "01_20_00:39:08 Seen so far: 205472 samples\n",
      "\n",
      "01_20_00:39:08 --- 1.861785888671875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:10 Training loss at epoch 2 step 6430: 2.8866378545761107\n",
      "\n",
      " This round's valence_loss=1.3376855850219727, arousal_loss=1.2022993564605713, emotion_loss=0.9851791858673096\n",
      "\n",
      "01_20_00:39:10 Seen so far: 205792 samples\n",
      "\n",
      "01_20_00:39:10 --- 1.6727418899536133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:12 Training loss at epoch 2 step 6440: 2.792274737358093\n",
      "\n",
      " This round's valence_loss=1.5004451274871826, arousal_loss=1.4755803346633911, emotion_loss=0.9606415033340454\n",
      "\n",
      "01_20_00:39:12 Seen so far: 206112 samples\n",
      "\n",
      "01_20_00:39:12 --- 1.6179747581481934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:13 Training loss at epoch 2 step 6450: 3.1791669368743896\n",
      "\n",
      " This round's valence_loss=1.0550272464752197, arousal_loss=0.9710077047348022, emotion_loss=1.0075385570526123\n",
      "\n",
      "01_20_00:39:13 Seen so far: 206432 samples\n",
      "\n",
      "01_20_00:39:13 --- 1.7216134071350098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:15 Training loss at epoch 2 step 6460: 2.9541340112686156\n",
      "\n",
      " This round's valence_loss=0.8950108289718628, arousal_loss=0.6965152025222778, emotion_loss=0.8404062986373901\n",
      "\n",
      "01_20_00:39:15 Seen so far: 206752 samples\n",
      "\n",
      "01_20_00:39:15 --- 1.6414363384246826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:17 Training loss at epoch 2 step 6470: 3.1082557678222655\n",
      "\n",
      " This round's valence_loss=1.0487221479415894, arousal_loss=0.9682028293609619, emotion_loss=0.9560040831565857\n",
      "\n",
      "01_20_00:39:17 Seen so far: 207072 samples\n",
      "\n",
      "01_20_00:39:17 --- 1.803372859954834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:18 Training loss at epoch 2 step 6480: 3.037957239151001\n",
      "\n",
      " This round's valence_loss=0.8582133054733276, arousal_loss=0.712683916091919, emotion_loss=0.9782781600952148\n",
      "\n",
      "01_20_00:39:18 Seen so far: 207392 samples\n",
      "\n",
      "01_20_00:39:18 --- 1.7278249263763428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:20 Training loss at epoch 2 step 6490: 2.9841702461242674\n",
      "\n",
      " This round's valence_loss=1.3405499458312988, arousal_loss=1.1763801574707031, emotion_loss=0.947838544845581\n",
      "\n",
      "01_20_00:39:20 Seen so far: 207712 samples\n",
      "\n",
      "01_20_00:39:20 --- 1.875560998916626 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:22 Training loss at epoch 2 step 6500: 3.186696481704712\n",
      "\n",
      " This round's valence_loss=1.0910043716430664, arousal_loss=1.0018796920776367, emotion_loss=0.878045916557312\n",
      "\n",
      "01_20_00:39:22 Seen so far: 208032 samples\n",
      "\n",
      "01_20_00:39:22 --- 1.7154994010925293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:24 Training loss at epoch 2 step 6510: 2.795700526237488\n",
      "\n",
      " This round's valence_loss=1.2743055820465088, arousal_loss=1.0853532552719116, emotion_loss=0.9345729351043701\n",
      "\n",
      "01_20_00:39:24 Seen so far: 208352 samples\n",
      "\n",
      "01_20_00:39:24 --- 1.8342046737670898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:26 Training loss at epoch 2 step 6520: 2.881001091003418\n",
      "\n",
      " This round's valence_loss=0.9179377555847168, arousal_loss=0.7026064395904541, emotion_loss=0.7537769675254822\n",
      "\n",
      "01_20_00:39:26 Seen so far: 208672 samples\n",
      "\n",
      "01_20_00:39:26 --- 1.6919870376586914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:28 Training loss at epoch 2 step 6530: 2.849996471405029\n",
      "\n",
      " This round's valence_loss=0.8813794851303101, arousal_loss=0.70199054479599, emotion_loss=0.8760521411895752\n",
      "\n",
      "01_20_00:39:28 Seen so far: 208992 samples\n",
      "\n",
      "01_20_00:39:28 --- 2.0194079875946045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:29 Training loss at epoch 2 step 6540: 2.9406538009643555\n",
      "\n",
      " This round's valence_loss=0.8856443166732788, arousal_loss=0.717024564743042, emotion_loss=0.8253753185272217\n",
      "\n",
      "01_20_00:39:29 Seen so far: 209312 samples\n",
      "\n",
      "01_20_00:39:29 --- 1.7790021896362305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:31 Training loss at epoch 2 step 6550: 2.8988549947738647\n",
      "\n",
      " This round's valence_loss=0.8937969207763672, arousal_loss=0.6784942150115967, emotion_loss=0.7623648643493652\n",
      "\n",
      "01_20_00:39:31 Seen so far: 209632 samples\n",
      "\n",
      "01_20_00:39:31 --- 1.7148029804229736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:33 Training loss at epoch 2 step 6560: 2.927248740196228\n",
      "\n",
      " This round's valence_loss=0.9826878905296326, arousal_loss=0.8432880640029907, emotion_loss=1.1135073900222778\n",
      "\n",
      "01_20_00:39:33 Seen so far: 209952 samples\n",
      "\n",
      "01_20_00:39:33 --- 1.781515121459961 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:35 Training loss at epoch 2 step 6570: 2.847257447242737\n",
      "\n",
      " This round's valence_loss=0.994152843952179, arousal_loss=0.8245887756347656, emotion_loss=0.4870060980319977\n",
      "\n",
      "01_20_00:39:35 Seen so far: 210272 samples\n",
      "\n",
      "01_20_00:39:35 --- 1.8043229579925537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:36 Training loss at epoch 2 step 6580: 2.9096353530883787\n",
      "\n",
      " This round's valence_loss=0.9172379970550537, arousal_loss=0.855646014213562, emotion_loss=1.0103065967559814\n",
      "\n",
      "01_20_00:39:36 Seen so far: 210592 samples\n",
      "\n",
      "01_20_00:39:36 --- 1.7087798118591309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:38 Training loss at epoch 2 step 6590: 2.5410099029541016\n",
      "\n",
      " This round's valence_loss=0.7819298505783081, arousal_loss=0.6052889823913574, emotion_loss=0.947419285774231\n",
      "\n",
      "01_20_00:39:38 Seen so far: 210912 samples\n",
      "\n",
      "01_20_00:39:38 --- 1.7823841571807861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:40 Training loss at epoch 2 step 6600: 2.959028422832489\n",
      "\n",
      " This round's valence_loss=0.7993481159210205, arousal_loss=0.7043414115905762, emotion_loss=1.0092090368270874\n",
      "\n",
      "01_20_00:39:40 Seen so far: 211232 samples\n",
      "\n",
      "01_20_00:39:40 --- 1.5542469024658203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:42 Training loss at epoch 2 step 6610: 2.9948780059814455\n",
      "\n",
      " This round's valence_loss=1.4617865085601807, arousal_loss=1.3452651500701904, emotion_loss=0.9857668280601501\n",
      "\n",
      "01_20_00:39:42 Seen so far: 211552 samples\n",
      "\n",
      "01_20_00:39:42 --- 1.8991267681121826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:43 Training loss at epoch 2 step 6620: 2.8306089997291566\n",
      "\n",
      " This round's valence_loss=1.3009743690490723, arousal_loss=1.2167811393737793, emotion_loss=1.1243669986724854\n",
      "\n",
      "01_20_00:39:43 Seen so far: 211872 samples\n",
      "\n",
      "01_20_00:39:43 --- 1.5960018634796143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:45 Training loss at epoch 2 step 6630: 2.9313835859298707\n",
      "\n",
      " This round's valence_loss=1.3992466926574707, arousal_loss=1.234192132949829, emotion_loss=1.24186372756958\n",
      "\n",
      "01_20_00:39:45 Seen so far: 212192 samples\n",
      "\n",
      "01_20_00:39:45 --- 2.027507781982422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:47 Training loss at epoch 2 step 6640: 3.045969820022583\n",
      "\n",
      " This round's valence_loss=0.7333581447601318, arousal_loss=0.5659528970718384, emotion_loss=0.9108734130859375\n",
      "\n",
      "01_20_00:39:47 Seen so far: 212512 samples\n",
      "\n",
      "01_20_00:39:47 --- 1.9609241485595703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:49 Training loss at epoch 2 step 6650: 3.0058697700500487\n",
      "\n",
      " This round's valence_loss=1.2969385385513306, arousal_loss=1.045356035232544, emotion_loss=1.1486905813217163\n",
      "\n",
      "01_20_00:39:49 Seen so far: 212832 samples\n",
      "\n",
      "01_20_00:39:49 --- 1.76517915725708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:51 Training loss at epoch 2 step 6660: 3.3147171258926393\n",
      "\n",
      " This round's valence_loss=1.1890318393707275, arousal_loss=1.1507370471954346, emotion_loss=1.2655653953552246\n",
      "\n",
      "01_20_00:39:51 Seen so far: 213152 samples\n",
      "\n",
      "01_20_00:39:51 --- 1.7189693450927734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:52 Training loss at epoch 2 step 6670: 3.353643274307251\n",
      "\n",
      " This round's valence_loss=1.1705517768859863, arousal_loss=1.077683448791504, emotion_loss=0.9390665292739868\n",
      "\n",
      "01_20_00:39:52 Seen so far: 213472 samples\n",
      "\n",
      "01_20_00:39:52 --- 1.652860164642334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:54 Training loss at epoch 2 step 6680: 3.153457832336426\n",
      "\n",
      " This round's valence_loss=0.6850916147232056, arousal_loss=0.6458861827850342, emotion_loss=1.5723743438720703\n",
      "\n",
      "01_20_00:39:54 Seen so far: 213792 samples\n",
      "\n",
      "01_20_00:39:54 --- 1.9167675971984863 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:56 Training loss at epoch 2 step 6690: 3.0066503524780273\n",
      "\n",
      " This round's valence_loss=1.0212526321411133, arousal_loss=0.8728482127189636, emotion_loss=0.9718413949012756\n",
      "\n",
      "01_20_00:39:56 Seen so far: 214112 samples\n",
      "\n",
      "01_20_00:39:56 --- 1.6947884559631348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:39:58 Training loss at epoch 2 step 6700: 3.3149924278259277\n",
      "\n",
      " This round's valence_loss=1.0612578392028809, arousal_loss=0.9507625699043274, emotion_loss=0.902972936630249\n",
      "\n",
      "01_20_00:39:58 Seen so far: 214432 samples\n",
      "\n",
      "01_20_00:39:58 --- 1.6835265159606934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:00 Training loss at epoch 2 step 6710: 3.3154950857162477\n",
      "\n",
      " This round's valence_loss=0.7604032158851624, arousal_loss=0.7912161350250244, emotion_loss=1.0589417219161987\n",
      "\n",
      "01_20_00:40:00 Seen so far: 214752 samples\n",
      "\n",
      "01_20_00:40:00 --- 1.9015989303588867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:01 Training loss at epoch 2 step 6720: 3.2340899467468263\n",
      "\n",
      " This round's valence_loss=0.8463186025619507, arousal_loss=0.720398485660553, emotion_loss=1.1192257404327393\n",
      "\n",
      "01_20_00:40:01 Seen so far: 215072 samples\n",
      "\n",
      "01_20_00:40:01 --- 1.908020257949829 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:03 Training loss at epoch 2 step 6730: 3.1742523431777956\n",
      "\n",
      " This round's valence_loss=1.42989182472229, arousal_loss=1.3318167924880981, emotion_loss=0.9982675909996033\n",
      "\n",
      "01_20_00:40:03 Seen so far: 215392 samples\n",
      "\n",
      "01_20_00:40:03 --- 1.7481513023376465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:05 Training loss at epoch 2 step 6740: 2.6931230425834656\n",
      "\n",
      " This round's valence_loss=0.8957459330558777, arousal_loss=0.7187943458557129, emotion_loss=0.6941693425178528\n",
      "\n",
      "01_20_00:40:05 Seen so far: 215712 samples\n",
      "\n",
      "01_20_00:40:05 --- 1.8747270107269287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:07 Training loss at epoch 2 step 6750: 2.9381545305252077\n",
      "\n",
      " This round's valence_loss=0.7864036560058594, arousal_loss=0.5540446639060974, emotion_loss=0.8660123348236084\n",
      "\n",
      "01_20_00:40:07 Seen so far: 216032 samples\n",
      "\n",
      "01_20_00:40:07 --- 1.7276718616485596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:09 Training loss at epoch 2 step 6760: 3.0213043808937075\n",
      "\n",
      " This round's valence_loss=1.1664397716522217, arousal_loss=1.100569486618042, emotion_loss=1.0591180324554443\n",
      "\n",
      "01_20_00:40:09 Seen so far: 216352 samples\n",
      "\n",
      "01_20_00:40:09 --- 1.8914377689361572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:10 Training loss at epoch 2 step 6770: 2.7943138599395754\n",
      "\n",
      " This round's valence_loss=1.295790433883667, arousal_loss=1.0878078937530518, emotion_loss=0.7022107243537903\n",
      "\n",
      "01_20_00:40:10 Seen so far: 216672 samples\n",
      "\n",
      "01_20_00:40:10 --- 1.7508695125579834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:12 Training loss at epoch 2 step 6780: 3.0083035707473753\n",
      "\n",
      " This round's valence_loss=1.1742137670516968, arousal_loss=1.060011863708496, emotion_loss=1.3262946605682373\n",
      "\n",
      "01_20_00:40:12 Seen so far: 216992 samples\n",
      "\n",
      "01_20_00:40:12 --- 1.8412408828735352 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:14 Training loss at epoch 2 step 6790: 3.006289505958557\n",
      "\n",
      " This round's valence_loss=1.0513916015625, arousal_loss=0.9571473002433777, emotion_loss=1.031792402267456\n",
      "\n",
      "01_20_00:40:14 Seen so far: 217312 samples\n",
      "\n",
      "01_20_00:40:14 --- 1.7795500755310059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:16 Training loss at epoch 2 step 6800: 3.1048659563064573\n",
      "\n",
      " This round's valence_loss=1.0158162117004395, arousal_loss=0.8208065032958984, emotion_loss=0.8875008821487427\n",
      "\n",
      "01_20_00:40:16 Seen so far: 217632 samples\n",
      "\n",
      "01_20_00:40:16 --- 1.75685453414917 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:18 Training loss at epoch 2 step 6810: 2.857641577720642\n",
      "\n",
      " This round's valence_loss=1.1989219188690186, arousal_loss=1.1255943775177002, emotion_loss=1.4246647357940674\n",
      "\n",
      "01_20_00:40:18 Seen so far: 217952 samples\n",
      "\n",
      "01_20_00:40:18 --- 1.6745896339416504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:19 Training loss at epoch 2 step 6820: 3.1596498012542726\n",
      "\n",
      " This round's valence_loss=1.243654727935791, arousal_loss=1.0882370471954346, emotion_loss=0.9754511117935181\n",
      "\n",
      "01_20_00:40:19 Seen so far: 218272 samples\n",
      "\n",
      "01_20_00:40:19 --- 1.6883325576782227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:21 Training loss at epoch 2 step 6830: 3.0327428340911866\n",
      "\n",
      " This round's valence_loss=0.6758334636688232, arousal_loss=0.5775998830795288, emotion_loss=1.0464528799057007\n",
      "\n",
      "01_20_00:40:21 Seen so far: 218592 samples\n",
      "\n",
      "01_20_00:40:21 --- 1.6667733192443848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:23 Training loss at epoch 2 step 6840: 2.9581836700439452\n",
      "\n",
      " This round's valence_loss=0.8251367807388306, arousal_loss=0.7020363807678223, emotion_loss=0.6776965260505676\n",
      "\n",
      "01_20_00:40:23 Seen so far: 218912 samples\n",
      "\n",
      "01_20_00:40:23 --- 1.8510262966156006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:25 Training loss at epoch 2 step 6850: 3.2208381414413454\n",
      "\n",
      " This round's valence_loss=0.6619149446487427, arousal_loss=0.689384937286377, emotion_loss=1.1622788906097412\n",
      "\n",
      "01_20_00:40:25 Seen so far: 219232 samples\n",
      "\n",
      "01_20_00:40:25 --- 1.9131429195404053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:26 Training loss at epoch 2 step 6860: 3.1129321575164797\n",
      "\n",
      " This round's valence_loss=0.8171837329864502, arousal_loss=0.6792155504226685, emotion_loss=0.9657757878303528\n",
      "\n",
      "01_20_00:40:26 Seen so far: 219552 samples\n",
      "\n",
      "01_20_00:40:26 --- 1.8431651592254639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:28 Training loss at epoch 2 step 6870: 2.844780707359314\n",
      "\n",
      " This round's valence_loss=0.7497836351394653, arousal_loss=0.5954217910766602, emotion_loss=1.0311596393585205\n",
      "\n",
      "01_20_00:40:28 Seen so far: 219872 samples\n",
      "\n",
      "01_20_00:40:28 --- 1.7986557483673096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:30 Training loss at epoch 2 step 6880: 2.925275993347168\n",
      "\n",
      " This round's valence_loss=0.8837771415710449, arousal_loss=0.6936969757080078, emotion_loss=0.6694914102554321\n",
      "\n",
      "01_20_00:40:30 Seen so far: 220192 samples\n",
      "\n",
      "01_20_00:40:30 --- 1.8058397769927979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:32 Training loss at epoch 2 step 6890: 3.112012505531311\n",
      "\n",
      " This round's valence_loss=1.4080398082733154, arousal_loss=1.3085888624191284, emotion_loss=1.2029664516448975\n",
      "\n",
      "01_20_00:40:32 Seen so far: 220512 samples\n",
      "\n",
      "01_20_00:40:32 --- 1.8804419040679932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:34 Training loss at epoch 2 step 6900: 3.1046761751174925\n",
      "\n",
      " This round's valence_loss=0.6568642854690552, arousal_loss=0.48393478989601135, emotion_loss=0.7740100026130676\n",
      "\n",
      "01_20_00:40:34 Seen so far: 220832 samples\n",
      "\n",
      "01_20_00:40:34 --- 1.7484230995178223 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:36 Training loss at epoch 2 step 6910: 2.8224568605422973\n",
      "\n",
      " This round's valence_loss=0.8852081298828125, arousal_loss=0.7295542359352112, emotion_loss=0.8705933094024658\n",
      "\n",
      "01_20_00:40:36 Seen so far: 221152 samples\n",
      "\n",
      "01_20_00:40:36 --- 1.8723514080047607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:37 Training loss at epoch 2 step 6920: 2.9927399873733522\n",
      "\n",
      " This round's valence_loss=1.3952271938323975, arousal_loss=1.2697234153747559, emotion_loss=0.7447159886360168\n",
      "\n",
      "01_20_00:40:37 Seen so far: 221472 samples\n",
      "\n",
      "01_20_00:40:37 --- 1.8260600566864014 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:39 Training loss at epoch 2 step 6930: 3.0139961004257203\n",
      "\n",
      " This round's valence_loss=0.958310067653656, arousal_loss=0.8247155547142029, emotion_loss=0.9079399704933167\n",
      "\n",
      "01_20_00:40:39 Seen so far: 221792 samples\n",
      "\n",
      "01_20_00:40:39 --- 1.8125126361846924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:41 Training loss at epoch 2 step 6940: 3.082187867164612\n",
      "\n",
      " This round's valence_loss=0.7006446123123169, arousal_loss=0.6547654867172241, emotion_loss=1.2450802326202393\n",
      "\n",
      "01_20_00:40:41 Seen so far: 222112 samples\n",
      "\n",
      "01_20_00:40:41 --- 1.6563541889190674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:42 Training loss at epoch 2 step 6950: 3.2096025228500364\n",
      "\n",
      " This round's valence_loss=0.9162274599075317, arousal_loss=0.6912986040115356, emotion_loss=0.8628492951393127\n",
      "\n",
      "01_20_00:40:42 Seen so far: 222432 samples\n",
      "\n",
      "01_20_00:40:42 --- 1.6196870803833008 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:44 Training loss at epoch 2 step 6960: 3.192514729499817\n",
      "\n",
      " This round's valence_loss=1.200739860534668, arousal_loss=1.111074686050415, emotion_loss=1.4215941429138184\n",
      "\n",
      "01_20_00:40:44 Seen so far: 222752 samples\n",
      "\n",
      "01_20_00:40:44 --- 1.7594022750854492 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:46 Training loss at epoch 2 step 6970: 3.0645307540893554\n",
      "\n",
      " This round's valence_loss=0.9556249380111694, arousal_loss=0.8257211446762085, emotion_loss=1.2657005786895752\n",
      "\n",
      "01_20_00:40:46 Seen so far: 223072 samples\n",
      "\n",
      "01_20_00:40:46 --- 1.7897627353668213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:48 Training loss at epoch 2 step 6980: 3.0619368076324465\n",
      "\n",
      " This round's valence_loss=1.263291835784912, arousal_loss=1.0465242862701416, emotion_loss=0.8086821436882019\n",
      "\n",
      "01_20_00:40:48 Seen so far: 223392 samples\n",
      "\n",
      "01_20_00:40:48 --- 1.7658462524414062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:50 Training loss at epoch 2 step 6990: 3.0830591678619386\n",
      "\n",
      " This round's valence_loss=1.0755976438522339, arousal_loss=0.9565091133117676, emotion_loss=1.1221829652786255\n",
      "\n",
      "01_20_00:40:50 Seen so far: 223712 samples\n",
      "\n",
      "01_20_00:40:50 --- 1.7292327880859375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:51 Training loss at epoch 2 step 7000: 2.9364277601242064\n",
      "\n",
      " This round's valence_loss=0.7520562410354614, arousal_loss=0.5980110168457031, emotion_loss=0.7964024543762207\n",
      "\n",
      "01_20_00:40:51 Seen so far: 224032 samples\n",
      "\n",
      "01_20_00:40:51 --- 1.8172516822814941 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:53 Training loss at epoch 2 step 7010: 2.977610635757446\n",
      "\n",
      " This round's valence_loss=1.0371679067611694, arousal_loss=0.8024908304214478, emotion_loss=0.787659764289856\n",
      "\n",
      "01_20_00:40:53 Seen so far: 224352 samples\n",
      "\n",
      "01_20_00:40:53 --- 1.8629069328308105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:55 Training loss at epoch 2 step 7020: 2.938794660568237\n",
      "\n",
      " This round's valence_loss=1.0138249397277832, arousal_loss=0.8983283042907715, emotion_loss=0.929641604423523\n",
      "\n",
      "01_20_00:40:55 Seen so far: 224672 samples\n",
      "\n",
      "01_20_00:40:55 --- 1.852691888809204 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:57 Training loss at epoch 2 step 7030: 2.838090181350708\n",
      "\n",
      " This round's valence_loss=1.2374486923217773, arousal_loss=1.0674843788146973, emotion_loss=0.9555371403694153\n",
      "\n",
      "01_20_00:40:57 Seen so far: 224992 samples\n",
      "\n",
      "01_20_00:40:57 --- 1.8040149211883545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:40:59 Training loss at epoch 2 step 7040: 3.0706347465515136\n",
      "\n",
      " This round's valence_loss=0.9568579196929932, arousal_loss=0.7010471820831299, emotion_loss=1.2693431377410889\n",
      "\n",
      "01_20_00:40:59 Seen so far: 225312 samples\n",
      "\n",
      "01_20_00:40:59 --- 1.7540113925933838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:00 Training loss at epoch 2 step 7050: 2.896419358253479\n",
      "\n",
      " This round's valence_loss=0.9316742420196533, arousal_loss=0.7559927701950073, emotion_loss=1.1883759498596191\n",
      "\n",
      "01_20_00:41:00 Seen so far: 225632 samples\n",
      "\n",
      "01_20_00:41:00 --- 1.8005216121673584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:02 Training loss at epoch 2 step 7060: 2.7475571155548097\n",
      "\n",
      " This round's valence_loss=1.4117071628570557, arousal_loss=1.302429437637329, emotion_loss=1.1667685508728027\n",
      "\n",
      "01_20_00:41:02 Seen so far: 225952 samples\n",
      "\n",
      "01_20_00:41:02 --- 1.9259600639343262 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:04 Training loss at epoch 2 step 7070: 2.829133653640747\n",
      "\n",
      " This round's valence_loss=1.2167034149169922, arousal_loss=1.0845948457717896, emotion_loss=0.5769637823104858\n",
      "\n",
      "01_20_00:41:04 Seen so far: 226272 samples\n",
      "\n",
      "01_20_00:41:04 --- 1.6895971298217773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:06 Training loss at epoch 2 step 7080: 3.020404243469238\n",
      "\n",
      " This round's valence_loss=0.921826958656311, arousal_loss=0.9600149393081665, emotion_loss=0.985863447189331\n",
      "\n",
      "01_20_00:41:06 Seen so far: 226592 samples\n",
      "\n",
      "01_20_00:41:06 --- 1.672621250152588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:08 Training loss at epoch 2 step 7090: 3.1379228830337524\n",
      "\n",
      " This round's valence_loss=1.8045027256011963, arousal_loss=1.7476847171783447, emotion_loss=1.1670386791229248\n",
      "\n",
      "01_20_00:41:08 Seen so far: 226912 samples\n",
      "\n",
      "01_20_00:41:08 --- 1.800703525543213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:09 Training loss at epoch 2 step 7100: 2.6739277839660645\n",
      "\n",
      " This round's valence_loss=1.0294619798660278, arousal_loss=0.8465646505355835, emotion_loss=0.9753508567810059\n",
      "\n",
      "01_20_00:41:09 Seen so far: 227232 samples\n",
      "\n",
      "01_20_00:41:09 --- 1.6836943626403809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:11 Training loss at epoch 2 step 7110: 3.224242353439331\n",
      "\n",
      " This round's valence_loss=1.043245792388916, arousal_loss=0.9328901767730713, emotion_loss=0.88254714012146\n",
      "\n",
      "01_20_00:41:11 Seen so far: 227552 samples\n",
      "\n",
      "01_20_00:41:11 --- 1.8234474658966064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:13 Training loss at epoch 2 step 7120: 2.9265016317367554\n",
      "\n",
      " This round's valence_loss=0.7412863969802856, arousal_loss=0.5921453237533569, emotion_loss=1.177835464477539\n",
      "\n",
      "01_20_00:41:13 Seen so far: 227872 samples\n",
      "\n",
      "01_20_00:41:13 --- 1.809089183807373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:15 Training loss at epoch 2 step 7130: 2.80887770652771\n",
      "\n",
      " This round's valence_loss=1.540284514427185, arousal_loss=1.4493263959884644, emotion_loss=0.9522817730903625\n",
      "\n",
      "01_20_00:41:15 Seen so far: 228192 samples\n",
      "\n",
      "01_20_00:41:15 --- 1.9000344276428223 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:17 Training loss at epoch 2 step 7140: 2.8971368789672853\n",
      "\n",
      " This round's valence_loss=0.8068565130233765, arousal_loss=0.6094135046005249, emotion_loss=0.6918083429336548\n",
      "\n",
      "01_20_00:41:17 Seen so far: 228512 samples\n",
      "\n",
      "01_20_00:41:17 --- 1.857691764831543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:18 Training loss at epoch 2 step 7150: 3.4119443893432617\n",
      "\n",
      " This round's valence_loss=1.177797555923462, arousal_loss=1.032073736190796, emotion_loss=0.7901871800422668\n",
      "\n",
      "01_20_00:41:18 Seen so far: 228832 samples\n",
      "\n",
      "01_20_00:41:18 --- 1.7476303577423096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:20 Training loss at epoch 2 step 7160: 3.080888366699219\n",
      "\n",
      " This round's valence_loss=1.2764036655426025, arousal_loss=1.2044692039489746, emotion_loss=0.9484281539916992\n",
      "\n",
      "01_20_00:41:20 Seen so far: 229152 samples\n",
      "\n",
      "01_20_00:41:20 --- 1.701202154159546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:22 Training loss at epoch 2 step 7170: 2.965938138961792\n",
      "\n",
      " This round's valence_loss=0.7508203983306885, arousal_loss=0.6177865266799927, emotion_loss=1.041164755821228\n",
      "\n",
      "01_20_00:41:22 Seen so far: 229472 samples\n",
      "\n",
      "01_20_00:41:22 --- 1.907472848892212 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:24 Training loss at epoch 2 step 7180: 3.621000123023987\n",
      "\n",
      " This round's valence_loss=1.1974663734436035, arousal_loss=1.1688729524612427, emotion_loss=0.9067146182060242\n",
      "\n",
      "01_20_00:41:24 Seen so far: 229792 samples\n",
      "\n",
      "01_20_00:41:24 --- 1.8022284507751465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:26 Training loss at epoch 2 step 7190: 3.2637914419174194\n",
      "\n",
      " This round's valence_loss=1.1545286178588867, arousal_loss=0.8995183110237122, emotion_loss=0.9983504414558411\n",
      "\n",
      "01_20_00:41:26 Seen so far: 230112 samples\n",
      "\n",
      "01_20_00:41:26 --- 1.8447129726409912 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:27 Training loss at epoch 2 step 7200: 3.138981509208679\n",
      "\n",
      " This round's valence_loss=1.1968574523925781, arousal_loss=1.0752776861190796, emotion_loss=0.9344680905342102\n",
      "\n",
      "01_20_00:41:27 Seen so far: 230432 samples\n",
      "\n",
      "01_20_00:41:27 --- 1.674767255783081 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:29 Training loss at epoch 2 step 7210: 2.9330922603607177\n",
      "\n",
      " This round's valence_loss=1.2602952718734741, arousal_loss=1.0566517114639282, emotion_loss=1.2957806587219238\n",
      "\n",
      "01_20_00:41:29 Seen so far: 230752 samples\n",
      "\n",
      "01_20_00:41:29 --- 1.7180428504943848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:31 Training loss at epoch 2 step 7220: 2.9449586629867555\n",
      "\n",
      " This round's valence_loss=1.2572416067123413, arousal_loss=1.0445778369903564, emotion_loss=0.6446000337600708\n",
      "\n",
      "01_20_00:41:31 Seen so far: 231072 samples\n",
      "\n",
      "01_20_00:41:31 --- 1.8798904418945312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:33 Training loss at epoch 2 step 7230: 2.9539963722229006\n",
      "\n",
      " This round's valence_loss=1.257340908050537, arousal_loss=1.2279863357543945, emotion_loss=1.0555968284606934\n",
      "\n",
      "01_20_00:41:33 Seen so far: 231392 samples\n",
      "\n",
      "01_20_00:41:33 --- 1.7173230648040771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:34 Training loss at epoch 2 step 7240: 2.7644182205200196\n",
      "\n",
      " This round's valence_loss=0.6734048128128052, arousal_loss=0.45037195086479187, emotion_loss=0.8853038549423218\n",
      "\n",
      "01_20_00:41:34 Seen so far: 231712 samples\n",
      "\n",
      "01_20_00:41:34 --- 1.8485846519470215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:36 Training loss at epoch 2 step 7250: 2.911377692222595\n",
      "\n",
      " This round's valence_loss=0.9232109785079956, arousal_loss=0.7326103448867798, emotion_loss=1.2620350122451782\n",
      "\n",
      "01_20_00:41:36 Seen so far: 232032 samples\n",
      "\n",
      "01_20_00:41:36 --- 1.7890729904174805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:38 Training loss at epoch 2 step 7260: 3.1958651781082152\n",
      "\n",
      " This round's valence_loss=0.7148473262786865, arousal_loss=0.6384248733520508, emotion_loss=0.8871434330940247\n",
      "\n",
      "01_20_00:41:38 Seen so far: 232352 samples\n",
      "\n",
      "01_20_00:41:38 --- 1.6707813739776611 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:40 Training loss at epoch 2 step 7270: 2.862702476978302\n",
      "\n",
      " This round's valence_loss=0.7118986248970032, arousal_loss=0.6282211542129517, emotion_loss=1.2542550563812256\n",
      "\n",
      "01_20_00:41:40 Seen so far: 232672 samples\n",
      "\n",
      "01_20_00:41:40 --- 1.8637244701385498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:41 Training loss at epoch 2 step 7280: 3.0741243839263914\n",
      "\n",
      " This round's valence_loss=0.7050670981407166, arousal_loss=0.6146782636642456, emotion_loss=1.271116018295288\n",
      "\n",
      "01_20_00:41:41 Seen so far: 232992 samples\n",
      "\n",
      "01_20_00:41:41 --- 1.7041163444519043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:43 Training loss at epoch 2 step 7290: 3.005298638343811\n",
      "\n",
      " This round's valence_loss=1.0814646482467651, arousal_loss=1.0249922275543213, emotion_loss=1.160569429397583\n",
      "\n",
      "01_20_00:41:43 Seen so far: 233312 samples\n",
      "\n",
      "01_20_00:41:43 --- 1.8743019104003906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:45 Training loss at epoch 2 step 7300: 3.057434153556824\n",
      "\n",
      " This round's valence_loss=1.0742689371109009, arousal_loss=0.9801188707351685, emotion_loss=1.0992021560668945\n",
      "\n",
      "01_20_00:41:45 Seen so far: 233632 samples\n",
      "\n",
      "01_20_00:41:45 --- 1.8369147777557373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:47 Training loss at epoch 2 step 7310: 3.5271819829940796\n",
      "\n",
      " This round's valence_loss=1.4048575162887573, arousal_loss=1.2287280559539795, emotion_loss=0.8914321064949036\n",
      "\n",
      "01_20_00:41:47 Seen so far: 233952 samples\n",
      "\n",
      "01_20_00:41:47 --- 1.831082820892334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:49 Training loss at epoch 2 step 7320: 2.7782071828842163\n",
      "\n",
      " This round's valence_loss=0.9514967203140259, arousal_loss=0.8571920990943909, emotion_loss=1.117323398590088\n",
      "\n",
      "01_20_00:41:49 Seen so far: 234272 samples\n",
      "\n",
      "01_20_00:41:49 --- 1.8027262687683105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:51 Training loss at epoch 2 step 7330: 2.9884196639060976\n",
      "\n",
      " This round's valence_loss=1.2259132862091064, arousal_loss=1.0770576000213623, emotion_loss=0.7957186698913574\n",
      "\n",
      "01_20_00:41:51 Seen so far: 234592 samples\n",
      "\n",
      "01_20_00:41:51 --- 1.9887762069702148 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:52 Training loss at epoch 2 step 7340: 3.0858301401138304\n",
      "\n",
      " This round's valence_loss=1.2966848611831665, arousal_loss=1.0501344203948975, emotion_loss=0.9601258635520935\n",
      "\n",
      "01_20_00:41:52 Seen so far: 234912 samples\n",
      "\n",
      "01_20_00:41:52 --- 1.6876518726348877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:54 Training loss at epoch 2 step 7350: 2.991122579574585\n",
      "\n",
      " This round's valence_loss=0.708842396736145, arousal_loss=0.6283010244369507, emotion_loss=1.0176210403442383\n",
      "\n",
      "01_20_00:41:54 Seen so far: 235232 samples\n",
      "\n",
      "01_20_00:41:54 --- 1.8231205940246582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:56 Training loss at epoch 2 step 7360: 2.939668297767639\n",
      "\n",
      " This round's valence_loss=1.1004542112350464, arousal_loss=0.9457927942276001, emotion_loss=0.7666692733764648\n",
      "\n",
      "01_20_00:41:56 Seen so far: 235552 samples\n",
      "\n",
      "01_20_00:41:56 --- 1.7462177276611328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:41:58 Training loss at epoch 2 step 7370: 3.025080180168152\n",
      "\n",
      " This round's valence_loss=1.0195176601409912, arousal_loss=0.8713016510009766, emotion_loss=1.1068601608276367\n",
      "\n",
      "01_20_00:41:58 Seen so far: 235872 samples\n",
      "\n",
      "01_20_00:41:58 --- 1.8773322105407715 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:00 Training loss at epoch 2 step 7380: 2.944751524925232\n",
      "\n",
      " This round's valence_loss=0.6774150133132935, arousal_loss=0.4824361205101013, emotion_loss=1.0564929246902466\n",
      "\n",
      "01_20_00:42:00 Seen so far: 236192 samples\n",
      "\n",
      "01_20_00:42:00 --- 1.7861778736114502 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:01 Training loss at epoch 2 step 7390: 3.1382937908172606\n",
      "\n",
      " This round's valence_loss=1.1964093446731567, arousal_loss=1.132033109664917, emotion_loss=1.5247044563293457\n",
      "\n",
      "01_20_00:42:01 Seen so far: 236512 samples\n",
      "\n",
      "01_20_00:42:01 --- 1.7552149295806885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:03 Training loss at epoch 2 step 7400: 2.914186954498291\n",
      "\n",
      " This round's valence_loss=0.7062100172042847, arousal_loss=0.6119483709335327, emotion_loss=1.0936973094940186\n",
      "\n",
      "01_20_00:42:03 Seen so far: 236832 samples\n",
      "\n",
      "01_20_00:42:03 --- 1.6341314315795898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:05 Training loss at epoch 2 step 7410: 2.9436233282089233\n",
      "\n",
      " This round's valence_loss=0.8914926052093506, arousal_loss=0.7259331941604614, emotion_loss=0.6763638257980347\n",
      "\n",
      "01_20_00:42:05 Seen so far: 237152 samples\n",
      "\n",
      "01_20_00:42:05 --- 1.8935599327087402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:07 Training loss at epoch 2 step 7420: 3.1557002782821657\n",
      "\n",
      " This round's valence_loss=0.780370831489563, arousal_loss=0.7452532052993774, emotion_loss=0.8570809364318848\n",
      "\n",
      "01_20_00:42:07 Seen so far: 237472 samples\n",
      "\n",
      "01_20_00:42:07 --- 1.8360846042633057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:09 Training loss at epoch 2 step 7430: 2.987798976898193\n",
      "\n",
      " This round's valence_loss=0.7706823945045471, arousal_loss=0.5703942775726318, emotion_loss=0.9145920276641846\n",
      "\n",
      "01_20_00:42:09 Seen so far: 237792 samples\n",
      "\n",
      "01_20_00:42:09 --- 1.7775006294250488 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:10 Training loss at epoch 2 step 7440: 3.342725419998169\n",
      "\n",
      " This round's valence_loss=1.4916681051254272, arousal_loss=1.4368736743927002, emotion_loss=0.8117393851280212\n",
      "\n",
      "01_20_00:42:10 Seen so far: 238112 samples\n",
      "\n",
      "01_20_00:42:10 --- 1.6537494659423828 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:12 Training loss at epoch 2 step 7450: 2.9660711765289305\n",
      "\n",
      " This round's valence_loss=0.8257749080657959, arousal_loss=0.7314435243606567, emotion_loss=0.9109436273574829\n",
      "\n",
      "01_20_00:42:12 Seen so far: 238432 samples\n",
      "\n",
      "01_20_00:42:12 --- 1.8807029724121094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:14 Training loss at epoch 2 step 7460: 2.9166752576828\n",
      "\n",
      " This round's valence_loss=0.7504243850708008, arousal_loss=0.6231482625007629, emotion_loss=1.0476784706115723\n",
      "\n",
      "01_20_00:42:14 Seen so far: 238752 samples\n",
      "\n",
      "01_20_00:42:14 --- 1.827899694442749 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:16 Training loss at epoch 2 step 7470: 3.1565845012664795\n",
      "\n",
      " This round's valence_loss=1.2187995910644531, arousal_loss=1.1396677494049072, emotion_loss=1.4187638759613037\n",
      "\n",
      "01_20_00:42:16 Seen so far: 239072 samples\n",
      "\n",
      "01_20_00:42:16 --- 2.031527042388916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:18 Training loss at epoch 2 step 7480: 2.831446099281311\n",
      "\n",
      " This round's valence_loss=1.3623697757720947, arousal_loss=1.3251988887786865, emotion_loss=1.3249876499176025\n",
      "\n",
      "01_20_00:42:18 Seen so far: 239392 samples\n",
      "\n",
      "01_20_00:42:18 --- 1.6813125610351562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:19 Training loss at epoch 2 step 7490: 3.351101112365723\n",
      "\n",
      " This round's valence_loss=1.2990708351135254, arousal_loss=1.179136872291565, emotion_loss=0.935332179069519\n",
      "\n",
      "01_20_00:42:19 Seen so far: 239712 samples\n",
      "\n",
      "01_20_00:42:19 --- 1.7777976989746094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:21 Training loss at epoch 2 step 7500: 3.1141467094421387\n",
      "\n",
      " This round's valence_loss=1.300445556640625, arousal_loss=1.2614073753356934, emotion_loss=0.8846567869186401\n",
      "\n",
      "01_20_00:42:21 Seen so far: 240032 samples\n",
      "\n",
      "01_20_00:42:21 --- 1.789797067642212 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:23 Training loss at epoch 2 step 7510: 2.89108202457428\n",
      "\n",
      " This round's valence_loss=1.1645891666412354, arousal_loss=0.9740419387817383, emotion_loss=1.034017562866211\n",
      "\n",
      "01_20_00:42:23 Seen so far: 240352 samples\n",
      "\n",
      "01_20_00:42:23 --- 1.8029966354370117 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:25 Training loss at epoch 2 step 7520: 3.054441285133362\n",
      "\n",
      " This round's valence_loss=1.155347228050232, arousal_loss=1.147623062133789, emotion_loss=1.009657621383667\n",
      "\n",
      "01_20_00:42:25 Seen so far: 240672 samples\n",
      "\n",
      "01_20_00:42:25 --- 1.6385552883148193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:26 Training loss at epoch 2 step 7530: 2.8891473531723024\n",
      "\n",
      " This round's valence_loss=0.9856398701667786, arousal_loss=0.8130334615707397, emotion_loss=0.7778851389884949\n",
      "\n",
      "01_20_00:42:26 Seen so far: 240992 samples\n",
      "\n",
      "01_20_00:42:26 --- 1.7657148838043213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:28 Training loss at epoch 2 step 7540: 3.0721726179122926\n",
      "\n",
      " This round's valence_loss=1.5896875858306885, arousal_loss=1.492456078529358, emotion_loss=1.020206332206726\n",
      "\n",
      "01_20_00:42:28 Seen so far: 241312 samples\n",
      "\n",
      "01_20_00:42:28 --- 1.5903832912445068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:30 Training loss at epoch 2 step 7550: 3.0478874921798704\n",
      "\n",
      " This round's valence_loss=1.3069713115692139, arousal_loss=1.2257676124572754, emotion_loss=0.7307606935501099\n",
      "\n",
      "01_20_00:42:30 Seen so far: 241632 samples\n",
      "\n",
      "01_20_00:42:30 --- 1.7005853652954102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:31 Training loss at epoch 2 step 7560: 2.9833699226379395\n",
      "\n",
      " This round's valence_loss=1.291374921798706, arousal_loss=1.0565781593322754, emotion_loss=0.9739639759063721\n",
      "\n",
      "01_20_00:42:31 Seen so far: 241952 samples\n",
      "\n",
      "01_20_00:42:31 --- 1.7200932502746582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:33 Training loss at epoch 2 step 7570: 3.1368152141571044\n",
      "\n",
      " This round's valence_loss=1.3298664093017578, arousal_loss=1.191969871520996, emotion_loss=0.9588207006454468\n",
      "\n",
      "01_20_00:42:33 Seen so far: 242272 samples\n",
      "\n",
      "01_20_00:42:33 --- 1.5724859237670898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:35 Training loss at epoch 2 step 7580: 3.0041749715805053\n",
      "\n",
      " This round's valence_loss=1.1248040199279785, arousal_loss=0.9370169639587402, emotion_loss=0.7747973799705505\n",
      "\n",
      "01_20_00:42:35 Seen so far: 242592 samples\n",
      "\n",
      "01_20_00:42:35 --- 1.712895393371582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:36 Training loss at epoch 2 step 7590: 3.1898176193237306\n",
      "\n",
      " This round's valence_loss=1.0129311084747314, arousal_loss=0.8639395236968994, emotion_loss=0.9644951224327087\n",
      "\n",
      "01_20_00:42:36 Seen so far: 242912 samples\n",
      "\n",
      "01_20_00:42:36 --- 1.7105965614318848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:38 Training loss at epoch 2 step 7600: 2.9630223751068114\n",
      "\n",
      " This round's valence_loss=1.4320547580718994, arousal_loss=1.2990808486938477, emotion_loss=1.0382907390594482\n",
      "\n",
      "01_20_00:42:38 Seen so far: 243232 samples\n",
      "\n",
      "01_20_00:42:38 --- 1.6836438179016113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:40 Training loss at epoch 2 step 7610: 2.9330780267715455\n",
      "\n",
      " This round's valence_loss=1.1618335247039795, arousal_loss=0.976834774017334, emotion_loss=0.6633202433586121\n",
      "\n",
      "01_20_00:42:40 Seen so far: 243552 samples\n",
      "\n",
      "01_20_00:42:40 --- 1.8709020614624023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:42 Training loss at epoch 2 step 7620: 3.0360238313674928\n",
      "\n",
      " This round's valence_loss=1.4333072900772095, arousal_loss=1.3337116241455078, emotion_loss=1.0506062507629395\n",
      "\n",
      "01_20_00:42:42 Seen so far: 243872 samples\n",
      "\n",
      "01_20_00:42:42 --- 1.8012385368347168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:44 Training loss at epoch 2 step 7630: 3.1061959743499754\n",
      "\n",
      " This round's valence_loss=0.9693175554275513, arousal_loss=0.8660486936569214, emotion_loss=1.3659459352493286\n",
      "\n",
      "01_20_00:42:44 Seen so far: 244192 samples\n",
      "\n",
      "01_20_00:42:44 --- 1.7280359268188477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:45 Training loss at epoch 2 step 7640: 2.9444721937179565\n",
      "\n",
      " This round's valence_loss=1.1013227701187134, arousal_loss=0.9576493501663208, emotion_loss=0.8201581239700317\n",
      "\n",
      "01_20_00:42:45 Seen so far: 244512 samples\n",
      "\n",
      "01_20_00:42:45 --- 1.6831519603729248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:47 Training loss at epoch 2 step 7650: 3.4596051454544066\n",
      "\n",
      " This round's valence_loss=1.3197287321090698, arousal_loss=1.2092504501342773, emotion_loss=1.1027196645736694\n",
      "\n",
      "01_20_00:42:47 Seen so far: 244832 samples\n",
      "\n",
      "01_20_00:42:47 --- 1.7568037509918213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:49 Training loss at epoch 2 step 7660: 2.758734631538391\n",
      "\n",
      " This round's valence_loss=0.9181474447250366, arousal_loss=0.8165900707244873, emotion_loss=1.2306015491485596\n",
      "\n",
      "01_20_00:42:49 Seen so far: 245152 samples\n",
      "\n",
      "01_20_00:42:49 --- 1.7363598346710205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:50 Training loss at epoch 2 step 7670: 2.818681800365448\n",
      "\n",
      " This round's valence_loss=1.1268928050994873, arousal_loss=1.0439364910125732, emotion_loss=0.9560691118240356\n",
      "\n",
      "01_20_00:42:50 Seen so far: 245472 samples\n",
      "\n",
      "01_20_00:42:50 --- 1.7356107234954834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:52 Training loss at epoch 2 step 7680: 3.021424984931946\n",
      "\n",
      " This round's valence_loss=1.091538667678833, arousal_loss=0.9254461526870728, emotion_loss=0.9141565561294556\n",
      "\n",
      "01_20_00:42:52 Seen so far: 245792 samples\n",
      "\n",
      "01_20_00:42:52 --- 1.7788794040679932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:54 Training loss at epoch 2 step 7690: 3.0292906761169434\n",
      "\n",
      " This round's valence_loss=1.3478807210922241, arousal_loss=1.202804684638977, emotion_loss=1.0827662944793701\n",
      "\n",
      "01_20_00:42:54 Seen so far: 246112 samples\n",
      "\n",
      "01_20_00:42:54 --- 1.7300269603729248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:56 Training loss at epoch 2 step 7700: 3.3865376234054567\n",
      "\n",
      " This round's valence_loss=0.9165599346160889, arousal_loss=0.6802049875259399, emotion_loss=0.7461519837379456\n",
      "\n",
      "01_20_00:42:56 Seen so far: 246432 samples\n",
      "\n",
      "01_20_00:42:56 --- 1.712209939956665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:58 Training loss at epoch 2 step 7710: 3.34340443611145\n",
      "\n",
      " This round's valence_loss=1.6238081455230713, arousal_loss=1.4571326971054077, emotion_loss=1.0503047704696655\n",
      "\n",
      "01_20_00:42:58 Seen so far: 246752 samples\n",
      "\n",
      "01_20_00:42:58 --- 1.8194329738616943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:42:59 Training loss at epoch 2 step 7720: 2.8208062291145324\n",
      "\n",
      " This round's valence_loss=1.2562847137451172, arousal_loss=1.1125108003616333, emotion_loss=1.0807220935821533\n",
      "\n",
      "01_20_00:42:59 Seen so far: 247072 samples\n",
      "\n",
      "01_20_00:42:59 --- 1.721834421157837 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:01 Training loss at epoch 2 step 7730: 3.017858290672302\n",
      "\n",
      " This round's valence_loss=1.2846763134002686, arousal_loss=1.0868314504623413, emotion_loss=1.0031559467315674\n",
      "\n",
      "01_20_00:43:01 Seen so far: 247392 samples\n",
      "\n",
      "01_20_00:43:01 --- 1.7032968997955322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:03 Training loss at epoch 2 step 7740: 2.828793168067932\n",
      "\n",
      " This round's valence_loss=1.2115569114685059, arousal_loss=1.0637061595916748, emotion_loss=0.8239479064941406\n",
      "\n",
      "01_20_00:43:03 Seen so far: 247712 samples\n",
      "\n",
      "01_20_00:43:03 --- 1.7519230842590332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:04 Training loss at epoch 2 step 7750: 3.0852533340454102\n",
      "\n",
      " This round's valence_loss=0.8711527585983276, arousal_loss=0.7372246980667114, emotion_loss=1.0588648319244385\n",
      "\n",
      "01_20_00:43:04 Seen so far: 248032 samples\n",
      "\n",
      "01_20_00:43:04 --- 1.804717779159546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:06 Training loss at epoch 2 step 7760: 3.1220047235488892\n",
      "\n",
      " This round's valence_loss=0.8068601489067078, arousal_loss=0.8161565065383911, emotion_loss=0.9149620532989502\n",
      "\n",
      "01_20_00:43:06 Seen so far: 248352 samples\n",
      "\n",
      "01_20_00:43:06 --- 1.6992475986480713 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:08 Training loss at epoch 2 step 7770: 3.1790983200073244\n",
      "\n",
      " This round's valence_loss=0.8341027498245239, arousal_loss=0.727186918258667, emotion_loss=0.9577779769897461\n",
      "\n",
      "01_20_00:43:08 Seen so far: 248672 samples\n",
      "\n",
      "01_20_00:43:08 --- 1.8695306777954102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:10 Training loss at epoch 2 step 7780: 3.009597063064575\n",
      "\n",
      " This round's valence_loss=1.354130506515503, arousal_loss=1.221069574356079, emotion_loss=0.9064944982528687\n",
      "\n",
      "01_20_00:43:10 Seen so far: 248992 samples\n",
      "\n",
      "01_20_00:43:10 --- 2.0232698917388916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:12 Training loss at epoch 2 step 7790: 2.98989999294281\n",
      "\n",
      " This round's valence_loss=0.951858639717102, arousal_loss=0.821256160736084, emotion_loss=1.0831133127212524\n",
      "\n",
      "01_20_00:43:12 Seen so far: 249312 samples\n",
      "\n",
      "01_20_00:43:12 --- 1.7936573028564453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:14 Training loss at epoch 2 step 7800: 3.3190181732177733\n",
      "\n",
      " This round's valence_loss=1.4707310199737549, arousal_loss=1.359365701675415, emotion_loss=1.2020490169525146\n",
      "\n",
      "01_20_00:43:14 Seen so far: 249632 samples\n",
      "\n",
      "01_20_00:43:14 --- 2.0017526149749756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:16 Training loss at epoch 2 step 7810: 2.865813636779785\n",
      "\n",
      " This round's valence_loss=1.1146929264068604, arousal_loss=0.9821147918701172, emotion_loss=0.8622614741325378\n",
      "\n",
      "01_20_00:43:16 Seen so far: 249952 samples\n",
      "\n",
      "01_20_00:43:16 --- 1.6289381980895996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:17 Training loss at epoch 2 step 7820: 2.980789542198181\n",
      "\n",
      " This round's valence_loss=0.9235565066337585, arousal_loss=0.8628890514373779, emotion_loss=1.0266399383544922\n",
      "\n",
      "01_20_00:43:17 Seen so far: 250272 samples\n",
      "\n",
      "01_20_00:43:17 --- 1.6388845443725586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:19 Training loss at epoch 2 step 7830: 2.8291375637054443\n",
      "\n",
      " This round's valence_loss=0.5100951790809631, arousal_loss=0.4408077299594879, emotion_loss=1.2056232690811157\n",
      "\n",
      "01_20_00:43:19 Seen so far: 250592 samples\n",
      "\n",
      "01_20_00:43:19 --- 1.7744865417480469 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:21 Training loss at epoch 2 step 7840: 3.1317379474639893\n",
      "\n",
      " This round's valence_loss=1.1518466472625732, arousal_loss=0.9846546053886414, emotion_loss=0.9492520689964294\n",
      "\n",
      "01_20_00:43:21 Seen so far: 250912 samples\n",
      "\n",
      "01_20_00:43:21 --- 1.7217342853546143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:23 Training loss at epoch 2 step 7850: 3.138133716583252\n",
      "\n",
      " This round's valence_loss=1.1191518306732178, arousal_loss=0.9380838871002197, emotion_loss=0.9609935283660889\n",
      "\n",
      "01_20_00:43:23 Seen so far: 251232 samples\n",
      "\n",
      "01_20_00:43:23 --- 1.853158950805664 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:24 Training loss at epoch 2 step 7860: 2.7105461835861204\n",
      "\n",
      " This round's valence_loss=0.8852993249893188, arousal_loss=0.6709185838699341, emotion_loss=0.8892332911491394\n",
      "\n",
      "01_20_00:43:24 Seen so far: 251552 samples\n",
      "\n",
      "01_20_00:43:24 --- 1.8649461269378662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:26 Training loss at epoch 2 step 7870: 2.680905318260193\n",
      "\n",
      " This round's valence_loss=0.8108630180358887, arousal_loss=0.7598692178726196, emotion_loss=0.9833348393440247\n",
      "\n",
      "01_20_00:43:26 Seen so far: 251872 samples\n",
      "\n",
      "01_20_00:43:26 --- 1.79313063621521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:28 Training loss at epoch 2 step 7880: 2.9998146057128907\n",
      "\n",
      " This round's valence_loss=1.1034353971481323, arousal_loss=1.0137981176376343, emotion_loss=0.9615526795387268\n",
      "\n",
      "01_20_00:43:28 Seen so far: 252192 samples\n",
      "\n",
      "01_20_00:43:28 --- 1.6184289455413818 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:30 Training loss at epoch 2 step 7890: 3.024810791015625\n",
      "\n",
      " This round's valence_loss=1.46891188621521, arousal_loss=1.313690185546875, emotion_loss=0.8108911514282227\n",
      "\n",
      "01_20_00:43:30 Seen so far: 252512 samples\n",
      "\n",
      "01_20_00:43:30 --- 1.7719612121582031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:31 Training loss at epoch 2 step 7900: 2.919129228591919\n",
      "\n",
      " This round's valence_loss=0.9799818396568298, arousal_loss=0.840224027633667, emotion_loss=0.8849165439605713\n",
      "\n",
      "01_20_00:43:31 Seen so far: 252832 samples\n",
      "\n",
      "01_20_00:43:31 --- 1.7197158336639404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:33 Training loss at epoch 2 step 7910: 3.0975284337997437\n",
      "\n",
      " This round's valence_loss=1.0758545398712158, arousal_loss=0.9540555477142334, emotion_loss=1.2491220235824585\n",
      "\n",
      "01_20_00:43:33 Seen so far: 253152 samples\n",
      "\n",
      "01_20_00:43:33 --- 1.7313997745513916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:35 Training loss at epoch 2 step 7920: 3.1332568645477297\n",
      "\n",
      " This round's valence_loss=0.9468239545822144, arousal_loss=0.8614479303359985, emotion_loss=1.0975167751312256\n",
      "\n",
      "01_20_00:43:35 Seen so far: 253472 samples\n",
      "\n",
      "01_20_00:43:35 --- 1.738572120666504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:37 Training loss at epoch 2 step 7930: 3.053419065475464\n",
      "\n",
      " This round's valence_loss=1.1037583351135254, arousal_loss=0.9277288913726807, emotion_loss=0.9939102530479431\n",
      "\n",
      "01_20_00:43:37 Seen so far: 253792 samples\n",
      "\n",
      "01_20_00:43:37 --- 1.9459867477416992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:39 Training loss at epoch 2 step 7940: 2.950455379486084\n",
      "\n",
      " This round's valence_loss=0.8052330017089844, arousal_loss=0.7639654874801636, emotion_loss=1.2092938423156738\n",
      "\n",
      "01_20_00:43:39 Seen so far: 254112 samples\n",
      "\n",
      "01_20_00:43:39 --- 1.960273265838623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:40 Training loss at epoch 2 step 7950: 2.9136462450027465\n",
      "\n",
      " This round's valence_loss=0.4171004891395569, arousal_loss=0.2566604018211365, emotion_loss=1.088548183441162\n",
      "\n",
      "01_20_00:43:40 Seen so far: 254432 samples\n",
      "\n",
      "01_20_00:43:40 --- 1.7501983642578125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:42 Training loss at epoch 2 step 7960: 2.863365960121155\n",
      "\n",
      " This round's valence_loss=1.0923689603805542, arousal_loss=0.9734265208244324, emotion_loss=1.0368906259536743\n",
      "\n",
      "01_20_00:43:42 Seen so far: 254752 samples\n",
      "\n",
      "01_20_00:43:42 --- 1.731764793395996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:44 Training loss at epoch 2 step 7970: 2.9160874128341674\n",
      "\n",
      " This round's valence_loss=0.8944031000137329, arousal_loss=0.772312343120575, emotion_loss=0.8016681671142578\n",
      "\n",
      "01_20_00:43:44 Seen so far: 255072 samples\n",
      "\n",
      "01_20_00:43:44 --- 1.7519097328186035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:46 Training loss at epoch 2 step 7980: 3.2942134976387023\n",
      "\n",
      " This round's valence_loss=1.5360729694366455, arousal_loss=1.4464843273162842, emotion_loss=1.3216841220855713\n",
      "\n",
      "01_20_00:43:46 Seen so far: 255392 samples\n",
      "\n",
      "01_20_00:43:46 --- 1.8235654830932617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:47 Training loss at epoch 2 step 7990: 2.826771640777588\n",
      "\n",
      " This round's valence_loss=0.7309157848358154, arousal_loss=0.585237979888916, emotion_loss=1.1612366437911987\n",
      "\n",
      "01_20_00:43:47 Seen so far: 255712 samples\n",
      "\n",
      "01_20_00:43:47 --- 1.7900447845458984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:49 Training loss at epoch 2 step 8000: 2.99318391084671\n",
      "\n",
      " This round's valence_loss=0.8028557896614075, arousal_loss=0.7315492630004883, emotion_loss=1.0761170387268066\n",
      "\n",
      "01_20_00:43:49 Seen so far: 256032 samples\n",
      "\n",
      "01_20_00:43:49 --- 1.7069942951202393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:51 Training loss at epoch 2 step 8010: 2.9622914791107178\n",
      "\n",
      " This round's valence_loss=0.89714515209198, arousal_loss=0.7518734931945801, emotion_loss=0.9526402950286865\n",
      "\n",
      "01_20_00:43:51 Seen so far: 256352 samples\n",
      "\n",
      "01_20_00:43:51 --- 1.795175313949585 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:53 Training loss at epoch 2 step 8020: 3.113273859024048\n",
      "\n",
      " This round's valence_loss=1.1395204067230225, arousal_loss=0.9701555967330933, emotion_loss=1.0111480951309204\n",
      "\n",
      "01_20_00:43:53 Seen so far: 256672 samples\n",
      "\n",
      "01_20_00:43:53 --- 1.821012258529663 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:54 Training loss at epoch 2 step 8030: 3.096390450000763\n",
      "\n",
      " This round's valence_loss=1.319716215133667, arousal_loss=1.239654541015625, emotion_loss=1.1451537609100342\n",
      "\n",
      "01_20_00:43:54 Seen so far: 256992 samples\n",
      "\n",
      "01_20_00:43:54 --- 1.5907108783721924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:56 Training loss at epoch 2 step 8040: 2.732856297492981\n",
      "\n",
      " This round's valence_loss=1.0609426498413086, arousal_loss=0.9624598026275635, emotion_loss=1.230085849761963\n",
      "\n",
      "01_20_00:43:56 Seen so far: 257312 samples\n",
      "\n",
      "01_20_00:43:56 --- 1.749851942062378 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:43:58 Training loss at epoch 2 step 8050: 3.2542293071746826\n",
      "\n",
      " This round's valence_loss=1.3302242755889893, arousal_loss=1.2165250778198242, emotion_loss=0.9799221158027649\n",
      "\n",
      "01_20_00:43:58 Seen so far: 257632 samples\n",
      "\n",
      "01_20_00:43:58 --- 1.8800156116485596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:00 Training loss at epoch 2 step 8060: 3.0607722282409666\n",
      "\n",
      " This round's valence_loss=1.0853681564331055, arousal_loss=0.9788594245910645, emotion_loss=0.6981644034385681\n",
      "\n",
      "01_20_00:44:00 Seen so far: 257952 samples\n",
      "\n",
      "01_20_00:44:00 --- 1.8038303852081299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:02 Training loss at epoch 2 step 8070: 2.794581723213196\n",
      "\n",
      " This round's valence_loss=1.0629466772079468, arousal_loss=0.9459556341171265, emotion_loss=1.0285383462905884\n",
      "\n",
      "01_20_00:44:02 Seen so far: 258272 samples\n",
      "\n",
      "01_20_00:44:02 --- 1.6869750022888184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:03 Training loss at epoch 2 step 8080: 2.9942363262176515\n",
      "\n",
      " This round's valence_loss=1.5927753448486328, arousal_loss=1.439213514328003, emotion_loss=1.019841194152832\n",
      "\n",
      "01_20_00:44:03 Seen so far: 258592 samples\n",
      "\n",
      "01_20_00:44:03 --- 1.5706942081451416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:05 Training loss at epoch 2 step 8090: 3.2373341798782347\n",
      "\n",
      " This round's valence_loss=0.9551789164543152, arousal_loss=0.8364262580871582, emotion_loss=1.1919324398040771\n",
      "\n",
      "01_20_00:44:05 Seen so far: 258912 samples\n",
      "\n",
      "01_20_00:44:05 --- 1.813993215560913 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:07 Training loss at epoch 2 step 8100: 2.8107084035873413\n",
      "\n",
      " This round's valence_loss=1.347468376159668, arousal_loss=1.1998822689056396, emotion_loss=0.9366891384124756\n",
      "\n",
      "01_20_00:44:07 Seen so far: 259232 samples\n",
      "\n",
      "01_20_00:44:07 --- 1.7544474601745605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:08 Training loss at epoch 2 step 8110: 2.9568490862846373\n",
      "\n",
      " This round's valence_loss=0.9935973882675171, arousal_loss=0.8794955015182495, emotion_loss=1.1868433952331543\n",
      "\n",
      "01_20_00:44:08 Seen so far: 259552 samples\n",
      "\n",
      "01_20_00:44:08 --- 1.8223645687103271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:10 Training loss at epoch 2 step 8120: 3.023154592514038\n",
      "\n",
      " This round's valence_loss=1.2787306308746338, arousal_loss=1.1892458200454712, emotion_loss=0.8036631941795349\n",
      "\n",
      "01_20_00:44:10 Seen so far: 259872 samples\n",
      "\n",
      "01_20_00:44:10 --- 1.744584321975708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:12 Training loss at epoch 2 step 8130: 3.035919189453125\n",
      "\n",
      " This round's valence_loss=0.642135500907898, arousal_loss=0.4175703525543213, emotion_loss=0.8176997303962708\n",
      "\n",
      "01_20_00:44:12 Seen so far: 260192 samples\n",
      "\n",
      "01_20_00:44:12 --- 1.8679039478302002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:14 Training loss at epoch 2 step 8140: 3.0584628343582154\n",
      "\n",
      " This round's valence_loss=0.7035629749298096, arousal_loss=0.4043509364128113, emotion_loss=0.625098705291748\n",
      "\n",
      "01_20_00:44:14 Seen so far: 260512 samples\n",
      "\n",
      "01_20_00:44:14 --- 1.6884517669677734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:16 Training loss at epoch 2 step 8150: 2.8829838514328\n",
      "\n",
      " This round's valence_loss=1.4882290363311768, arousal_loss=1.3129007816314697, emotion_loss=0.9155667424201965\n",
      "\n",
      "01_20_00:44:16 Seen so far: 260832 samples\n",
      "\n",
      "01_20_00:44:16 --- 1.8941328525543213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:17 Training loss at epoch 2 step 8160: 3.171473264694214\n",
      "\n",
      " This round's valence_loss=1.2067525386810303, arousal_loss=1.1030677556991577, emotion_loss=1.097819447517395\n",
      "\n",
      "01_20_00:44:17 Seen so far: 261152 samples\n",
      "\n",
      "01_20_00:44:17 --- 1.7898459434509277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:19 Training loss at epoch 2 step 8170: 2.99601628780365\n",
      "\n",
      " This round's valence_loss=1.2529256343841553, arousal_loss=1.2185931205749512, emotion_loss=1.0528490543365479\n",
      "\n",
      "01_20_00:44:19 Seen so far: 261472 samples\n",
      "\n",
      "01_20_00:44:19 --- 1.8185129165649414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:21 Training loss at epoch 2 step 8180: 3.0389463901519775\n",
      "\n",
      " This round's valence_loss=1.250781536102295, arousal_loss=1.1017712354660034, emotion_loss=1.0464779138565063\n",
      "\n",
      "01_20_00:44:21 Seen so far: 261792 samples\n",
      "\n",
      "01_20_00:44:21 --- 1.757357120513916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:23 Training loss at epoch 2 step 8190: 3.1966543436050414\n",
      "\n",
      " This round's valence_loss=1.2239885330200195, arousal_loss=1.067274570465088, emotion_loss=0.9972498416900635\n",
      "\n",
      "01_20_00:44:23 Seen so far: 262112 samples\n",
      "\n",
      "01_20_00:44:23 --- 1.838479995727539 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:25 Training loss at epoch 2 step 8200: 2.956952357292175\n",
      "\n",
      " This round's valence_loss=1.0930352210998535, arousal_loss=0.9920421838760376, emotion_loss=1.3742989301681519\n",
      "\n",
      "01_20_00:44:25 Seen so far: 262432 samples\n",
      "\n",
      "01_20_00:44:25 --- 2.0112252235412598 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:27 Training loss at epoch 2 step 8210: 3.192847180366516\n",
      "\n",
      " This round's valence_loss=1.2033876180648804, arousal_loss=0.9766350984573364, emotion_loss=0.5903259515762329\n",
      "\n",
      "01_20_00:44:27 Seen so far: 262752 samples\n",
      "\n",
      "01_20_00:44:27 --- 1.9414141178131104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:29 Training loss at epoch 2 step 8220: 2.6022184014320375\n",
      "\n",
      " This round's valence_loss=1.298403263092041, arousal_loss=1.0805853605270386, emotion_loss=1.0092134475708008\n",
      "\n",
      "01_20_00:44:29 Seen so far: 263072 samples\n",
      "\n",
      "01_20_00:44:29 --- 1.78102445602417 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:30 Training loss at epoch 2 step 8230: 2.7270185708999635\n",
      "\n",
      " This round's valence_loss=1.1181950569152832, arousal_loss=0.981413722038269, emotion_loss=1.0711067914962769\n",
      "\n",
      "01_20_00:44:30 Seen so far: 263392 samples\n",
      "\n",
      "01_20_00:44:30 --- 1.8301889896392822 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:32 Training loss at epoch 2 step 8240: 3.0436445236206056\n",
      "\n",
      " This round's valence_loss=0.7722699642181396, arousal_loss=0.6062576770782471, emotion_loss=0.9202616214752197\n",
      "\n",
      "01_20_00:44:32 Seen so far: 263712 samples\n",
      "\n",
      "01_20_00:44:32 --- 1.6827104091644287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:34 Training loss at epoch 2 step 8250: 2.946990466117859\n",
      "\n",
      " This round's valence_loss=1.0306564569473267, arousal_loss=0.8099292516708374, emotion_loss=0.6562212705612183\n",
      "\n",
      "01_20_00:44:34 Seen so far: 264032 samples\n",
      "\n",
      "01_20_00:44:34 --- 1.8178060054779053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:36 Training loss at epoch 2 step 8260: 3.3229803085327148\n",
      "\n",
      " This round's valence_loss=1.1098790168762207, arousal_loss=0.9493973255157471, emotion_loss=1.0251150131225586\n",
      "\n",
      "01_20_00:44:36 Seen so far: 264352 samples\n",
      "\n",
      "01_20_00:44:36 --- 1.7478325366973877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:38 Training loss at epoch 2 step 8270: 2.9212151050567625\n",
      "\n",
      " This round's valence_loss=1.3157472610473633, arousal_loss=1.0835984945297241, emotion_loss=0.8122895359992981\n",
      "\n",
      "01_20_00:44:38 Seen so far: 264672 samples\n",
      "\n",
      "01_20_00:44:38 --- 1.9150941371917725 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:40 Training loss at epoch 2 step 8280: 3.209204840660095\n",
      "\n",
      " This round's valence_loss=0.7223281860351562, arousal_loss=0.5858423709869385, emotion_loss=0.8955758810043335\n",
      "\n",
      "01_20_00:44:40 Seen so far: 264992 samples\n",
      "\n",
      "01_20_00:44:40 --- 1.9028136730194092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:41 Training loss at epoch 2 step 8290: 2.837569975852966\n",
      "\n",
      " This round's valence_loss=1.0088913440704346, arousal_loss=0.8537013530731201, emotion_loss=1.0407682657241821\n",
      "\n",
      "01_20_00:44:41 Seen so far: 265312 samples\n",
      "\n",
      "01_20_00:44:41 --- 1.676938533782959 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:43 Training loss at epoch 2 step 8300: 2.8443208932876587\n",
      "\n",
      " This round's valence_loss=1.4331567287445068, arousal_loss=1.3362982273101807, emotion_loss=1.1872823238372803\n",
      "\n",
      "01_20_00:44:43 Seen so far: 265632 samples\n",
      "\n",
      "01_20_00:44:43 --- 1.8402509689331055 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:45 Training loss at epoch 2 step 8310: 3.049339246749878\n",
      "\n",
      " This round's valence_loss=0.9474447965621948, arousal_loss=0.7341198921203613, emotion_loss=1.0832302570343018\n",
      "\n",
      "01_20_00:44:45 Seen so far: 265952 samples\n",
      "\n",
      "01_20_00:44:45 --- 1.7834751605987549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:47 Training loss at epoch 2 step 8320: 2.993002510070801\n",
      "\n",
      " This round's valence_loss=0.8176774978637695, arousal_loss=0.7303242683410645, emotion_loss=1.2610259056091309\n",
      "\n",
      "01_20_00:44:47 Seen so far: 266272 samples\n",
      "\n",
      "01_20_00:44:47 --- 1.6768403053283691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:48 Training loss at epoch 2 step 8330: 2.8942177057266236\n",
      "\n",
      " This round's valence_loss=1.432773232460022, arousal_loss=1.3269429206848145, emotion_loss=0.9601771831512451\n",
      "\n",
      "01_20_00:44:48 Seen so far: 266592 samples\n",
      "\n",
      "01_20_00:44:48 --- 1.8960630893707275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:50 Training loss at epoch 2 step 8340: 3.0087701797485353\n",
      "\n",
      " This round's valence_loss=0.8373074531555176, arousal_loss=0.7081660628318787, emotion_loss=0.9563385248184204\n",
      "\n",
      "01_20_00:44:50 Seen so far: 266912 samples\n",
      "\n",
      "01_20_00:44:50 --- 1.7480006217956543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:52 Training loss at epoch 2 step 8350: 2.837080919742584\n",
      "\n",
      " This round's valence_loss=0.5447055101394653, arousal_loss=0.37759286165237427, emotion_loss=0.8976859450340271\n",
      "\n",
      "01_20_00:44:52 Seen so far: 267232 samples\n",
      "\n",
      "01_20_00:44:52 --- 1.664189100265503 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:54 Training loss at epoch 2 step 8360: 2.699332320690155\n",
      "\n",
      " This round's valence_loss=0.5404964685440063, arousal_loss=0.31805986166000366, emotion_loss=0.8270742297172546\n",
      "\n",
      "01_20_00:44:54 Seen so far: 267552 samples\n",
      "\n",
      "01_20_00:44:54 --- 1.7606892585754395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:55 Training loss at epoch 2 step 8370: 3.2257251501083375\n",
      "\n",
      " This round's valence_loss=0.7951618432998657, arousal_loss=0.5884410738945007, emotion_loss=0.9619303941726685\n",
      "\n",
      "01_20_00:44:55 Seen so far: 267872 samples\n",
      "\n",
      "01_20_00:44:55 --- 1.8189094066619873 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:57 Training loss at epoch 2 step 8380: 3.3187951326370237\n",
      "\n",
      " This round's valence_loss=1.2269879579544067, arousal_loss=1.0919053554534912, emotion_loss=0.8749423027038574\n",
      "\n",
      "01_20_00:44:57 Seen so far: 268192 samples\n",
      "\n",
      "01_20_00:44:57 --- 1.5236270427703857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:44:59 Training loss at epoch 2 step 8390: 3.022090125083923\n",
      "\n",
      " This round's valence_loss=1.1266257762908936, arousal_loss=0.988695502281189, emotion_loss=0.7320159673690796\n",
      "\n",
      "01_20_00:44:59 Seen so far: 268512 samples\n",
      "\n",
      "01_20_00:44:59 --- 1.70237398147583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:00 Training loss at epoch 2 step 8400: 3.182971382141113\n",
      "\n",
      " This round's valence_loss=1.041118860244751, arousal_loss=0.8129489421844482, emotion_loss=0.7627784609794617\n",
      "\n",
      "01_20_00:45:00 Seen so far: 268832 samples\n",
      "\n",
      "01_20_00:45:00 --- 1.7108161449432373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:02 Training loss at epoch 2 step 8410: 2.809589910507202\n",
      "\n",
      " This round's valence_loss=0.7224509119987488, arousal_loss=0.493667870759964, emotion_loss=0.8833397626876831\n",
      "\n",
      "01_20_00:45:02 Seen so far: 269152 samples\n",
      "\n",
      "01_20_00:45:02 --- 1.6015748977661133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:04 Training loss at epoch 2 step 8420: 3.292054533958435\n",
      "\n",
      " This round's valence_loss=1.4617071151733398, arousal_loss=1.3152539730072021, emotion_loss=1.0892226696014404\n",
      "\n",
      "01_20_00:45:04 Seen so far: 269472 samples\n",
      "\n",
      "01_20_00:45:04 --- 1.6175472736358643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:05 Training loss at epoch 2 step 8430: 3.086118221282959\n",
      "\n",
      " This round's valence_loss=1.3132975101470947, arousal_loss=1.044647455215454, emotion_loss=1.0088790655136108\n",
      "\n",
      "01_20_00:45:05 Seen so far: 269792 samples\n",
      "\n",
      "01_20_00:45:05 --- 1.646043300628662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:07 Training loss at epoch 2 step 8440: 3.094157338142395\n",
      "\n",
      " This round's valence_loss=1.1317682266235352, arousal_loss=0.9621914625167847, emotion_loss=0.7566621899604797\n",
      "\n",
      "01_20_00:45:07 Seen so far: 270112 samples\n",
      "\n",
      "01_20_00:45:07 --- 1.8829610347747803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:09 Training loss at epoch 2 step 8450: 3.131687808036804\n",
      "\n",
      " This round's valence_loss=0.6946687698364258, arousal_loss=0.5622851848602295, emotion_loss=1.210542917251587\n",
      "\n",
      "01_20_00:45:09 Seen so far: 270432 samples\n",
      "\n",
      "01_20_00:45:09 --- 1.6903791427612305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:11 Training loss at epoch 2 step 8460: 2.9163885593414305\n",
      "\n",
      " This round's valence_loss=0.8187927007675171, arousal_loss=0.7288744449615479, emotion_loss=1.360353946685791\n",
      "\n",
      "01_20_00:45:11 Seen so far: 270752 samples\n",
      "\n",
      "01_20_00:45:11 --- 1.812924861907959 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:12 Training loss at epoch 2 step 8470: 3.1928072929382325\n",
      "\n",
      " This round's valence_loss=0.8766018748283386, arousal_loss=0.7089509963989258, emotion_loss=0.9720907807350159\n",
      "\n",
      "01_20_00:45:12 Seen so far: 271072 samples\n",
      "\n",
      "01_20_00:45:12 --- 1.7097008228302002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:14 Training loss at epoch 2 step 8480: 2.9827252864837646\n",
      "\n",
      " This round's valence_loss=1.0798144340515137, arousal_loss=1.0024359226226807, emotion_loss=0.9490010142326355\n",
      "\n",
      "01_20_00:45:14 Seen so far: 271392 samples\n",
      "\n",
      "01_20_00:45:14 --- 1.7518723011016846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:16 Training loss at epoch 2 step 8490: 2.60506157875061\n",
      "\n",
      " This round's valence_loss=0.8080307245254517, arousal_loss=0.7317052483558655, emotion_loss=1.1840474605560303\n",
      "\n",
      "01_20_00:45:16 Seen so far: 271712 samples\n",
      "\n",
      "01_20_00:45:16 --- 1.6951508522033691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:18 Training loss at epoch 2 step 8500: 3.1114732027053833\n",
      "\n",
      " This round's valence_loss=1.3247101306915283, arousal_loss=1.1854628324508667, emotion_loss=0.785079836845398\n",
      "\n",
      "01_20_00:45:18 Seen so far: 272032 samples\n",
      "\n",
      "01_20_00:45:18 --- 1.9323997497558594 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:19 Training loss at epoch 2 step 8510: 2.704437279701233\n",
      "\n",
      " This round's valence_loss=0.5902724266052246, arousal_loss=0.5111837387084961, emotion_loss=1.0778512954711914\n",
      "\n",
      "01_20_00:45:19 Seen so far: 272352 samples\n",
      "\n",
      "01_20_00:45:19 --- 1.7197699546813965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:21 Training loss at epoch 2 step 8520: 3.1044899225234985\n",
      "\n",
      " This round's valence_loss=0.8661385774612427, arousal_loss=0.6936193108558655, emotion_loss=1.092186689376831\n",
      "\n",
      "01_20_00:45:21 Seen so far: 272672 samples\n",
      "\n",
      "01_20_00:45:21 --- 1.687213659286499 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:23 Training loss at epoch 2 step 8530: 2.875131130218506\n",
      "\n",
      " This round's valence_loss=1.3120067119598389, arousal_loss=1.1935975551605225, emotion_loss=0.8778042197227478\n",
      "\n",
      "01_20_00:45:23 Seen so far: 272992 samples\n",
      "\n",
      "01_20_00:45:23 --- 1.7264831066131592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:25 Training loss at epoch 2 step 8540: 3.042281174659729\n",
      "\n",
      " This round's valence_loss=0.9534251689910889, arousal_loss=0.8339856863021851, emotion_loss=1.0652157068252563\n",
      "\n",
      "01_20_00:45:25 Seen so far: 273312 samples\n",
      "\n",
      "01_20_00:45:25 --- 1.8450040817260742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:26 Training loss at epoch 2 step 8550: 2.91308708190918\n",
      "\n",
      " This round's valence_loss=1.3458200693130493, arousal_loss=1.2008991241455078, emotion_loss=0.819240391254425\n",
      "\n",
      "01_20_00:45:26 Seen so far: 273632 samples\n",
      "\n",
      "01_20_00:45:26 --- 1.7590820789337158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:28 Training loss at epoch 2 step 8560: 3.1643041133880616\n",
      "\n",
      " This round's valence_loss=1.2973945140838623, arousal_loss=1.1814870834350586, emotion_loss=0.4716898202896118\n",
      "\n",
      "01_20_00:45:28 Seen so far: 273952 samples\n",
      "\n",
      "01_20_00:45:28 --- 1.7370648384094238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:30 Training loss at epoch 2 step 8570: 2.7917410373687743\n",
      "\n",
      " This round's valence_loss=0.8969415426254272, arousal_loss=0.7333678007125854, emotion_loss=0.6739748120307922\n",
      "\n",
      "01_20_00:45:30 Seen so far: 274272 samples\n",
      "\n",
      "01_20_00:45:30 --- 1.7803425788879395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:32 Training loss at epoch 2 step 8580: 3.0982901096343993\n",
      "\n",
      " This round's valence_loss=0.862151563167572, arousal_loss=0.7450975179672241, emotion_loss=1.433030605316162\n",
      "\n",
      "01_20_00:45:32 Seen so far: 274592 samples\n",
      "\n",
      "01_20_00:45:32 --- 1.663494348526001 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:33 Training loss at epoch 2 step 8590: 2.692034101486206\n",
      "\n",
      " This round's valence_loss=1.4226421117782593, arousal_loss=1.327641487121582, emotion_loss=0.7529710531234741\n",
      "\n",
      "01_20_00:45:33 Seen so far: 274912 samples\n",
      "\n",
      "01_20_00:45:33 --- 1.6314284801483154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:35 Training loss at epoch 2 step 8600: 3.032008695602417\n",
      "\n",
      " This round's valence_loss=0.8994699716567993, arousal_loss=0.7484009861946106, emotion_loss=0.9704636335372925\n",
      "\n",
      "01_20_00:45:35 Seen so far: 275232 samples\n",
      "\n",
      "01_20_00:45:35 --- 1.821911096572876 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:37 Training loss at epoch 2 step 8610: 3.0463564872741697\n",
      "\n",
      " This round's valence_loss=0.8957829475402832, arousal_loss=0.6890525817871094, emotion_loss=0.658545732498169\n",
      "\n",
      "01_20_00:45:37 Seen so far: 275552 samples\n",
      "\n",
      "01_20_00:45:37 --- 1.7373871803283691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:39 Training loss at epoch 2 step 8620: 3.1686832785606383\n",
      "\n",
      " This round's valence_loss=0.9372107982635498, arousal_loss=0.8920648097991943, emotion_loss=0.8466737866401672\n",
      "\n",
      "01_20_00:45:39 Seen so far: 275872 samples\n",
      "\n",
      "01_20_00:45:39 --- 1.8828725814819336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:40 Training loss at epoch 2 step 8630: 3.058463978767395\n",
      "\n",
      " This round's valence_loss=1.581159234046936, arousal_loss=1.5251588821411133, emotion_loss=1.0885777473449707\n",
      "\n",
      "01_20_00:45:40 Seen so far: 276192 samples\n",
      "\n",
      "01_20_00:45:40 --- 1.6558427810668945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:42 Training loss at epoch 2 step 8640: 2.9131712079048158\n",
      "\n",
      " This round's valence_loss=0.9616515636444092, arousal_loss=0.8748652935028076, emotion_loss=0.9325191378593445\n",
      "\n",
      "01_20_00:45:42 Seen so far: 276512 samples\n",
      "\n",
      "01_20_00:45:42 --- 1.8863017559051514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:44 Training loss at epoch 2 step 8650: 2.7136068820953367\n",
      "\n",
      " This round's valence_loss=0.6157615780830383, arousal_loss=0.4771254062652588, emotion_loss=0.8036363124847412\n",
      "\n",
      "01_20_00:45:44 Seen so far: 276832 samples\n",
      "\n",
      "01_20_00:45:44 --- 2.1048696041107178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:46 Training loss at epoch 2 step 8660: 3.0410373210906982\n",
      "\n",
      " This round's valence_loss=1.1228625774383545, arousal_loss=0.9473967552185059, emotion_loss=1.354046106338501\n",
      "\n",
      "01_20_00:45:46 Seen so far: 277152 samples\n",
      "\n",
      "01_20_00:45:46 --- 1.802591323852539 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:48 Training loss at epoch 2 step 8670: 2.842664349079132\n",
      "\n",
      " This round's valence_loss=0.7445172667503357, arousal_loss=0.6206380724906921, emotion_loss=0.9848717451095581\n",
      "\n",
      "01_20_00:45:48 Seen so far: 277472 samples\n",
      "\n",
      "01_20_00:45:48 --- 1.835688591003418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:50 Training loss at epoch 2 step 8680: 2.8525927782058718\n",
      "\n",
      " This round's valence_loss=1.0701950788497925, arousal_loss=1.0083478689193726, emotion_loss=1.0069602727890015\n",
      "\n",
      "01_20_00:45:50 Seen so far: 277792 samples\n",
      "\n",
      "01_20_00:45:50 --- 2.078458786010742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:52 Training loss at epoch 2 step 8690: 2.7541598081588745\n",
      "\n",
      " This round's valence_loss=0.9167212247848511, arousal_loss=0.7335503101348877, emotion_loss=0.8221355676651001\n",
      "\n",
      "01_20_00:45:52 Seen so far: 278112 samples\n",
      "\n",
      "01_20_00:45:52 --- 1.68536376953125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:53 Training loss at epoch 2 step 8700: 3.150761365890503\n",
      "\n",
      " This round's valence_loss=1.3078136444091797, arousal_loss=1.2068499326705933, emotion_loss=1.1621592044830322\n",
      "\n",
      "01_20_00:45:53 Seen so far: 278432 samples\n",
      "\n",
      "01_20_00:45:53 --- 1.7129347324371338 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:55 Training loss at epoch 2 step 8710: 3.1506540536880494\n",
      "\n",
      " This round's valence_loss=1.097091794013977, arousal_loss=1.0439836978912354, emotion_loss=0.960797905921936\n",
      "\n",
      "01_20_00:45:55 Seen so far: 278752 samples\n",
      "\n",
      "01_20_00:45:55 --- 1.6887145042419434 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:57 Training loss at epoch 2 step 8720: 2.9262999534606933\n",
      "\n",
      " This round's valence_loss=1.7409814596176147, arousal_loss=1.5397909879684448, emotion_loss=1.335018277168274\n",
      "\n",
      "01_20_00:45:57 Seen so far: 279072 samples\n",
      "\n",
      "01_20_00:45:57 --- 1.869701623916626 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:45:59 Training loss at epoch 2 step 8730: 2.8604947566986083\n",
      "\n",
      " This round's valence_loss=0.9559799432754517, arousal_loss=0.715635359287262, emotion_loss=0.7158292531967163\n",
      "\n",
      "01_20_00:45:59 Seen so far: 279392 samples\n",
      "\n",
      "01_20_00:45:59 --- 1.8016235828399658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:01 Training loss at epoch 2 step 8740: 3.0895215272903442\n",
      "\n",
      " This round's valence_loss=1.070176124572754, arousal_loss=1.002441644668579, emotion_loss=1.0077672004699707\n",
      "\n",
      "01_20_00:46:01 Seen so far: 279712 samples\n",
      "\n",
      "01_20_00:46:01 --- 1.7231459617614746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:02 Training loss at epoch 2 step 8750: 3.0735272645950316\n",
      "\n",
      " This round's valence_loss=0.9520534873008728, arousal_loss=0.8418768644332886, emotion_loss=1.108191728591919\n",
      "\n",
      "01_20_00:46:02 Seen so far: 280032 samples\n",
      "\n",
      "01_20_00:46:02 --- 1.92716383934021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:04 Training loss at epoch 2 step 8760: 2.894021248817444\n",
      "\n",
      " This round's valence_loss=1.1408140659332275, arousal_loss=1.1004705429077148, emotion_loss=0.9815537929534912\n",
      "\n",
      "01_20_00:46:04 Seen so far: 280352 samples\n",
      "\n",
      "01_20_00:46:04 --- 1.7309596538543701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:06 Training loss at epoch 2 step 8770: 3.1655749082565308\n",
      "\n",
      " This round's valence_loss=0.8150310516357422, arousal_loss=0.8208296298980713, emotion_loss=0.9413760900497437\n",
      "\n",
      "01_20_00:46:06 Seen so far: 280672 samples\n",
      "\n",
      "01_20_00:46:06 --- 1.6962401866912842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:07 Training loss at epoch 2 step 8780: 2.8074897050857546\n",
      "\n",
      " This round's valence_loss=0.846077561378479, arousal_loss=0.7046449184417725, emotion_loss=1.2812917232513428\n",
      "\n",
      "01_20_00:46:07 Seen so far: 280992 samples\n",
      "\n",
      "01_20_00:46:07 --- 1.6175024509429932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:09 Training loss at epoch 2 step 8790: 3.009691667556763\n",
      "\n",
      " This round's valence_loss=1.3255935907363892, arousal_loss=1.2284932136535645, emotion_loss=0.9831277132034302\n",
      "\n",
      "01_20_00:46:09 Seen so far: 281312 samples\n",
      "\n",
      "01_20_00:46:09 --- 1.6285383701324463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:11 Training loss at epoch 2 step 8800: 3.1279957771301268\n",
      "\n",
      " This round's valence_loss=1.0871713161468506, arousal_loss=1.0162851810455322, emotion_loss=0.8435959219932556\n",
      "\n",
      "01_20_00:46:11 Seen so far: 281632 samples\n",
      "\n",
      "01_20_00:46:11 --- 1.6758687496185303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:12 Training loss at epoch 2 step 8810: 2.867866110801697\n",
      "\n",
      " This round's valence_loss=1.3359242677688599, arousal_loss=1.2054182291030884, emotion_loss=0.691745400428772\n",
      "\n",
      "01_20_00:46:12 Seen so far: 281952 samples\n",
      "\n",
      "01_20_00:46:12 --- 1.6111273765563965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:14 Training loss at epoch 2 step 8820: 2.971327066421509\n",
      "\n",
      " This round's valence_loss=0.9520323872566223, arousal_loss=0.8074977397918701, emotion_loss=0.9315732717514038\n",
      "\n",
      "01_20_00:46:14 Seen so far: 282272 samples\n",
      "\n",
      "01_20_00:46:14 --- 1.677614688873291 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:16 Training loss at epoch 2 step 8830: 3.049363875389099\n",
      "\n",
      " This round's valence_loss=0.8775503039360046, arousal_loss=0.7534563541412354, emotion_loss=1.363756537437439\n",
      "\n",
      "01_20_00:46:16 Seen so far: 282592 samples\n",
      "\n",
      "01_20_00:46:16 --- 1.912567138671875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:18 Training loss at epoch 2 step 8840: 2.9215627193450926\n",
      "\n",
      " This round's valence_loss=0.8953883051872253, arousal_loss=0.6903681755065918, emotion_loss=0.897441029548645\n",
      "\n",
      "01_20_00:46:18 Seen so far: 282912 samples\n",
      "\n",
      "01_20_00:46:18 --- 1.8672895431518555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:20 Training loss at epoch 2 step 8850: 3.1478856563568116\n",
      "\n",
      " This round's valence_loss=1.669283390045166, arousal_loss=1.5870258808135986, emotion_loss=0.5912659168243408\n",
      "\n",
      "01_20_00:46:20 Seen so far: 283232 samples\n",
      "\n",
      "01_20_00:46:20 --- 1.9037246704101562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:21 Training loss at epoch 2 step 8860: 3.111806130409241\n",
      "\n",
      " This round's valence_loss=0.9934896230697632, arousal_loss=0.8727107048034668, emotion_loss=0.9313246607780457\n",
      "\n",
      "01_20_00:46:21 Seen so far: 283552 samples\n",
      "\n",
      "01_20_00:46:21 --- 1.7153751850128174 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:23 Training loss at epoch 2 step 8870: 3.062475633621216\n",
      "\n",
      " This round's valence_loss=1.1441006660461426, arousal_loss=0.9829584956169128, emotion_loss=0.9071170091629028\n",
      "\n",
      "01_20_00:46:23 Seen so far: 283872 samples\n",
      "\n",
      "01_20_00:46:23 --- 1.7348473072052002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:25 Training loss at epoch 2 step 8880: 2.740064024925232\n",
      "\n",
      " This round's valence_loss=0.7967276573181152, arousal_loss=0.7223944067955017, emotion_loss=0.878089964389801\n",
      "\n",
      "01_20_00:46:25 Seen so far: 284192 samples\n",
      "\n",
      "01_20_00:46:25 --- 1.910783290863037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:27 Training loss at epoch 2 step 8890: 3.0273438453674317\n",
      "\n",
      " This round's valence_loss=1.3413505554199219, arousal_loss=1.1871006488800049, emotion_loss=0.8403286933898926\n",
      "\n",
      "01_20_00:46:27 Seen so far: 284512 samples\n",
      "\n",
      "01_20_00:46:27 --- 1.8623876571655273 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:29 Training loss at epoch 2 step 8900: 2.937234139442444\n",
      "\n",
      " This round's valence_loss=1.0782358646392822, arousal_loss=0.985456645488739, emotion_loss=0.7097901701927185\n",
      "\n",
      "01_20_00:46:29 Seen so far: 284832 samples\n",
      "\n",
      "01_20_00:46:29 --- 1.7335608005523682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:30 Training loss at epoch 2 step 8910: 2.9668926000595093\n",
      "\n",
      " This round's valence_loss=0.9243451356887817, arousal_loss=0.8152997493743896, emotion_loss=1.2552533149719238\n",
      "\n",
      "01_20_00:46:30 Seen so far: 285152 samples\n",
      "\n",
      "01_20_00:46:30 --- 1.6787731647491455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:32 Training loss at epoch 2 step 8920: 3.151494288444519\n",
      "\n",
      " This round's valence_loss=1.1064198017120361, arousal_loss=0.8298493027687073, emotion_loss=0.7576095461845398\n",
      "\n",
      "01_20_00:46:32 Seen so far: 285472 samples\n",
      "\n",
      "01_20_00:46:32 --- 1.805896520614624 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:34 Training loss at epoch 2 step 8930: 2.993637132644653\n",
      "\n",
      " This round's valence_loss=1.0003435611724854, arousal_loss=0.8190421462059021, emotion_loss=0.9573497772216797\n",
      "\n",
      "01_20_00:46:34 Seen so far: 285792 samples\n",
      "\n",
      "01_20_00:46:34 --- 1.702885389328003 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:36 Training loss at epoch 2 step 8940: 3.04209246635437\n",
      "\n",
      " This round's valence_loss=0.7706105709075928, arousal_loss=0.5923001170158386, emotion_loss=1.1703863143920898\n",
      "\n",
      "01_20_00:46:36 Seen so far: 286112 samples\n",
      "\n",
      "01_20_00:46:36 --- 1.6293816566467285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:37 Training loss at epoch 2 step 8950: 3.2232186555862428\n",
      "\n",
      " This round's valence_loss=1.2960171699523926, arousal_loss=1.261393427848816, emotion_loss=1.31807541847229\n",
      "\n",
      "01_20_00:46:37 Seen so far: 286432 samples\n",
      "\n",
      "01_20_00:46:37 --- 1.6467111110687256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:39 Training loss at epoch 2 step 8960: 2.88752601146698\n",
      "\n",
      " This round's valence_loss=1.1424779891967773, arousal_loss=1.0305860042572021, emotion_loss=0.9641057252883911\n",
      "\n",
      "01_20_00:46:39 Seen so far: 286752 samples\n",
      "\n",
      "01_20_00:46:39 --- 1.7397491931915283 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:41 Training loss at epoch 2 step 8970: 3.0101348638534544\n",
      "\n",
      " This round's valence_loss=0.6107548475265503, arousal_loss=0.4591418504714966, emotion_loss=0.8912017941474915\n",
      "\n",
      "01_20_00:46:41 Seen so far: 287072 samples\n",
      "\n",
      "01_20_00:46:41 --- 1.7880167961120605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:42 Training loss at epoch 2 step 8980: 3.153563928604126\n",
      "\n",
      " This round's valence_loss=1.1875526905059814, arousal_loss=1.0552504062652588, emotion_loss=1.0605499744415283\n",
      "\n",
      "01_20_00:46:42 Seen so far: 287392 samples\n",
      "\n",
      "01_20_00:46:42 --- 1.589369535446167 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:44 Training loss at epoch 2 step 8990: 3.349011719226837\n",
      "\n",
      " This round's valence_loss=1.464308500289917, arousal_loss=1.3256006240844727, emotion_loss=1.0687357187271118\n",
      "\n",
      "01_20_00:46:44 Seen so far: 287712 samples\n",
      "\n",
      "01_20_00:46:44 --- 1.769338846206665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:46 Training loss at epoch 2 step 9000: 3.237149167060852\n",
      "\n",
      " This round's valence_loss=0.9653123021125793, arousal_loss=0.8503928184509277, emotion_loss=0.9848155975341797\n",
      "\n",
      "01_20_00:46:46 Seen so far: 288032 samples\n",
      "\n",
      "01_20_00:46:46 --- 1.7517623901367188 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:48 Training loss at epoch 2 step 9010: 3.0963109016418455\n",
      "\n",
      " This round's valence_loss=1.056382179260254, arousal_loss=0.8246210217475891, emotion_loss=0.8836049437522888\n",
      "\n",
      "01_20_00:46:48 Seen so far: 288352 samples\n",
      "\n",
      "01_20_00:46:48 --- 1.7446119785308838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:49 Training loss at epoch 2 step 9020: 3.0362441539764404\n",
      "\n",
      " This round's valence_loss=1.4297709465026855, arousal_loss=1.3317196369171143, emotion_loss=1.0216448307037354\n",
      "\n",
      "01_20_00:46:49 Seen so far: 288672 samples\n",
      "\n",
      "01_20_00:46:49 --- 1.7816722393035889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:51 Training loss at epoch 2 step 9030: 2.7582406759262086\n",
      "\n",
      " This round's valence_loss=1.0126231908798218, arousal_loss=0.8044066429138184, emotion_loss=0.8658835887908936\n",
      "\n",
      "01_20_00:46:51 Seen so far: 288992 samples\n",
      "\n",
      "01_20_00:46:51 --- 1.6151933670043945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:53 Training loss at epoch 2 step 9040: 2.9236674308776855\n",
      "\n",
      " This round's valence_loss=1.306424617767334, arousal_loss=1.2056500911712646, emotion_loss=1.17379891872406\n",
      "\n",
      "01_20_00:46:53 Seen so far: 289312 samples\n",
      "\n",
      "01_20_00:46:53 --- 1.673426628112793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:55 Training loss at epoch 2 step 9050: 2.9493569135665894\n",
      "\n",
      " This round's valence_loss=1.090376615524292, arousal_loss=1.0107934474945068, emotion_loss=0.8979536294937134\n",
      "\n",
      "01_20_00:46:55 Seen so far: 289632 samples\n",
      "\n",
      "01_20_00:46:55 --- 1.8739092350006104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:57 Training loss at epoch 2 step 9060: 3.1255359411239625\n",
      "\n",
      " This round's valence_loss=0.9617416262626648, arousal_loss=0.8461908102035522, emotion_loss=1.6050362586975098\n",
      "\n",
      "01_20_00:46:57 Seen so far: 289952 samples\n",
      "\n",
      "01_20_00:46:57 --- 2.0427780151367188 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:46:58 Training loss at epoch 2 step 9070: 2.836209225654602\n",
      "\n",
      " This round's valence_loss=0.738193154335022, arousal_loss=0.5955222249031067, emotion_loss=1.0421850681304932\n",
      "\n",
      "01_20_00:46:58 Seen so far: 290272 samples\n",
      "\n",
      "01_20_00:46:58 --- 1.7854349613189697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:00 Training loss at epoch 2 step 9080: 3.1166024684906004\n",
      "\n",
      " This round's valence_loss=0.9607542753219604, arousal_loss=0.8484318256378174, emotion_loss=1.1884915828704834\n",
      "\n",
      "01_20_00:47:00 Seen so far: 290592 samples\n",
      "\n",
      "01_20_00:47:00 --- 1.8769190311431885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:02 Training loss at epoch 2 step 9090: 3.109837055206299\n",
      "\n",
      " This round's valence_loss=1.0951428413391113, arousal_loss=0.9384716749191284, emotion_loss=0.6742027997970581\n",
      "\n",
      "01_20_00:47:02 Seen so far: 290912 samples\n",
      "\n",
      "01_20_00:47:02 --- 1.7269172668457031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:04 Training loss at epoch 2 step 9100: 3.1371145486831664\n",
      "\n",
      " This round's valence_loss=1.2656452655792236, arousal_loss=1.062175989151001, emotion_loss=1.1352546215057373\n",
      "\n",
      "01_20_00:47:04 Seen so far: 291232 samples\n",
      "\n",
      "01_20_00:47:04 --- 1.8503823280334473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:06 Training loss at epoch 2 step 9110: 2.9278003931045533\n",
      "\n",
      " This round's valence_loss=1.1374763250350952, arousal_loss=0.9718109965324402, emotion_loss=0.9474574327468872\n",
      "\n",
      "01_20_00:47:06 Seen so far: 291552 samples\n",
      "\n",
      "01_20_00:47:06 --- 1.9365270137786865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:07 Training loss at epoch 2 step 9120: 3.0958511352539064\n",
      "\n",
      " This round's valence_loss=0.9701366424560547, arousal_loss=0.8501571416854858, emotion_loss=0.7322995662689209\n",
      "\n",
      "01_20_00:47:07 Seen so far: 291872 samples\n",
      "\n",
      "01_20_00:47:07 --- 1.7218549251556396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:09 Training loss at epoch 2 step 9130: 3.0827316522598265\n",
      "\n",
      " This round's valence_loss=1.0067522525787354, arousal_loss=0.8558893203735352, emotion_loss=0.5941610336303711\n",
      "\n",
      "01_20_00:47:09 Seen so far: 292192 samples\n",
      "\n",
      "01_20_00:47:09 --- 1.897456169128418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:11 Training loss at epoch 2 step 9140: 3.023283338546753\n",
      "\n",
      " This round's valence_loss=0.7950229644775391, arousal_loss=0.7227253913879395, emotion_loss=0.9312258958816528\n",
      "\n",
      "01_20_00:47:11 Seen so far: 292512 samples\n",
      "\n",
      "01_20_00:47:11 --- 1.8806970119476318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:13 Training loss at epoch 2 step 9150: 3.2129191517829896\n",
      "\n",
      " This round's valence_loss=0.8055319786071777, arousal_loss=0.6060583591461182, emotion_loss=1.2314177751541138\n",
      "\n",
      "01_20_00:47:13 Seen so far: 292832 samples\n",
      "\n",
      "01_20_00:47:13 --- 1.751877784729004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:15 Training loss at epoch 2 step 9160: 3.2122441053390505\n",
      "\n",
      " This round's valence_loss=1.4280871152877808, arousal_loss=1.3532044887542725, emotion_loss=1.2307360172271729\n",
      "\n",
      "01_20_00:47:15 Seen so far: 293152 samples\n",
      "\n",
      "01_20_00:47:15 --- 1.8336119651794434 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:17 Training loss at epoch 2 step 9170: 3.497199058532715\n",
      "\n",
      " This round's valence_loss=1.1798095703125, arousal_loss=1.1220605373382568, emotion_loss=0.9392486810684204\n",
      "\n",
      "01_20_00:47:17 Seen so far: 293472 samples\n",
      "\n",
      "01_20_00:47:17 --- 1.748173713684082 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:18 Training loss at epoch 2 step 9180: 2.834936785697937\n",
      "\n",
      " This round's valence_loss=0.9334577322006226, arousal_loss=0.8429014682769775, emotion_loss=0.8184360861778259\n",
      "\n",
      "01_20_00:47:18 Seen so far: 293792 samples\n",
      "\n",
      "01_20_00:47:18 --- 1.7329206466674805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:20 Training loss at epoch 2 step 9190: 2.8812742948532106\n",
      "\n",
      " This round's valence_loss=0.9296934604644775, arousal_loss=0.6774351596832275, emotion_loss=1.0069485902786255\n",
      "\n",
      "01_20_00:47:20 Seen so far: 294112 samples\n",
      "\n",
      "01_20_00:47:20 --- 1.6451189517974854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:22 Training loss at epoch 2 step 9200: 3.226312017440796\n",
      "\n",
      " This round's valence_loss=0.921363353729248, arousal_loss=0.8274457454681396, emotion_loss=1.090946912765503\n",
      "\n",
      "01_20_00:47:22 Seen so far: 294432 samples\n",
      "\n",
      "01_20_00:47:22 --- 1.733139991760254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:23 Training loss at epoch 2 step 9210: 2.7811004281044007\n",
      "\n",
      " This round's valence_loss=1.5640194416046143, arousal_loss=1.436372995376587, emotion_loss=0.762690007686615\n",
      "\n",
      "01_20_00:47:23 Seen so far: 294752 samples\n",
      "\n",
      "01_20_00:47:23 --- 1.721102237701416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:25 Training loss at epoch 2 step 9220: 3.00121431350708\n",
      "\n",
      " This round's valence_loss=1.117996096611023, arousal_loss=0.9888878464698792, emotion_loss=0.9524957537651062\n",
      "\n",
      "01_20_00:47:25 Seen so far: 295072 samples\n",
      "\n",
      "01_20_00:47:25 --- 1.7225074768066406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:27 Training loss at epoch 2 step 9230: 2.8782541036605833\n",
      "\n",
      " This round's valence_loss=0.885265052318573, arousal_loss=0.7721281051635742, emotion_loss=1.0361151695251465\n",
      "\n",
      "01_20_00:47:27 Seen so far: 295392 samples\n",
      "\n",
      "01_20_00:47:27 --- 1.8707103729248047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:29 Training loss at epoch 2 step 9240: 2.702583575248718\n",
      "\n",
      " This round's valence_loss=1.0675427913665771, arousal_loss=0.9665805101394653, emotion_loss=0.6541415452957153\n",
      "\n",
      "01_20_00:47:29 Seen so far: 295712 samples\n",
      "\n",
      "01_20_00:47:29 --- 1.6423275470733643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:31 Training loss at epoch 2 step 9250: 3.06698100566864\n",
      "\n",
      " This round's valence_loss=1.4784266948699951, arousal_loss=1.2841869592666626, emotion_loss=0.6436346769332886\n",
      "\n",
      "01_20_00:47:31 Seen so far: 296032 samples\n",
      "\n",
      "01_20_00:47:31 --- 1.8738067150115967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:32 Training loss at epoch 2 step 9260: 2.5502400398254395\n",
      "\n",
      " This round's valence_loss=1.090987205505371, arousal_loss=0.9786494970321655, emotion_loss=0.7814172506332397\n",
      "\n",
      "01_20_00:47:32 Seen so far: 296352 samples\n",
      "\n",
      "01_20_00:47:32 --- 1.7752327919006348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:34 Training loss at epoch 2 step 9270: 3.161627006530762\n",
      "\n",
      " This round's valence_loss=0.9446162581443787, arousal_loss=0.8295037150382996, emotion_loss=0.9067592620849609\n",
      "\n",
      "01_20_00:47:34 Seen so far: 296672 samples\n",
      "\n",
      "01_20_00:47:34 --- 1.679027795791626 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:36 Training loss at epoch 2 step 9280: 3.1663702487945558\n",
      "\n",
      " This round's valence_loss=1.1221182346343994, arousal_loss=0.934184193611145, emotion_loss=0.7671462893486023\n",
      "\n",
      "01_20_00:47:36 Seen so far: 296992 samples\n",
      "\n",
      "01_20_00:47:36 --- 1.7653298377990723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:38 Training loss at epoch 2 step 9290: 2.820889186859131\n",
      "\n",
      " This round's valence_loss=1.2065937519073486, arousal_loss=1.1120280027389526, emotion_loss=0.8487136363983154\n",
      "\n",
      "01_20_00:47:38 Seen so far: 297312 samples\n",
      "\n",
      "01_20_00:47:38 --- 1.8429298400878906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:39 Training loss at epoch 2 step 9300: 3.1091432571411133\n",
      "\n",
      " This round's valence_loss=1.0411087274551392, arousal_loss=0.9772834777832031, emotion_loss=1.0562397241592407\n",
      "\n",
      "01_20_00:47:39 Seen so far: 297632 samples\n",
      "\n",
      "01_20_00:47:39 --- 1.7619259357452393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:41 Training loss at epoch 2 step 9310: 3.0647745370864867\n",
      "\n",
      " This round's valence_loss=0.9887949228286743, arousal_loss=0.823951005935669, emotion_loss=0.8354398012161255\n",
      "\n",
      "01_20_00:47:41 Seen so far: 297952 samples\n",
      "\n",
      "01_20_00:47:41 --- 1.73978853225708 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:43 Training loss at epoch 2 step 9320: 2.8632216453552246\n",
      "\n",
      " This round's valence_loss=1.133340835571289, arousal_loss=0.9766873717308044, emotion_loss=0.9827584028244019\n",
      "\n",
      "01_20_00:47:43 Seen so far: 298272 samples\n",
      "\n",
      "01_20_00:47:43 --- 1.7497031688690186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:44 Training loss at epoch 2 step 9330: 3.0455970764160156\n",
      "\n",
      " This round's valence_loss=1.2261162996292114, arousal_loss=1.0674867630004883, emotion_loss=0.6829255819320679\n",
      "\n",
      "01_20_00:47:44 Seen so far: 298592 samples\n",
      "\n",
      "01_20_00:47:44 --- 1.5749008655548096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:46 Training loss at epoch 2 step 9340: 3.2681430339813233\n",
      "\n",
      " This round's valence_loss=1.409651756286621, arousal_loss=1.3572039604187012, emotion_loss=1.0619087219238281\n",
      "\n",
      "01_20_00:47:46 Seen so far: 298912 samples\n",
      "\n",
      "01_20_00:47:46 --- 1.8372082710266113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:48 Training loss at epoch 2 step 9350: 3.087551236152649\n",
      "\n",
      " This round's valence_loss=1.2021015882492065, arousal_loss=1.0942808389663696, emotion_loss=0.8578959107398987\n",
      "\n",
      "01_20_00:47:48 Seen so far: 299232 samples\n",
      "\n",
      "01_20_00:47:48 --- 1.8040592670440674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:50 Training loss at epoch 2 step 9360: 3.046281123161316\n",
      "\n",
      " This round's valence_loss=1.562330722808838, arousal_loss=1.4259834289550781, emotion_loss=0.9414448738098145\n",
      "\n",
      "01_20_00:47:50 Seen so far: 299552 samples\n",
      "\n",
      "01_20_00:47:50 --- 1.7797520160675049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:52 Training loss at epoch 2 step 9370: 2.7514052629470824\n",
      "\n",
      " This round's valence_loss=1.1017844676971436, arousal_loss=0.962584376335144, emotion_loss=0.6781684756278992\n",
      "\n",
      "01_20_00:47:52 Seen so far: 299872 samples\n",
      "\n",
      "01_20_00:47:52 --- 1.7222819328308105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:54 Training loss at epoch 2 step 9380: 2.7450387716293334\n",
      "\n",
      " This round's valence_loss=1.084136962890625, arousal_loss=0.9984143972396851, emotion_loss=1.1938713788986206\n",
      "\n",
      "01_20_00:47:54 Seen so far: 300192 samples\n",
      "\n",
      "01_20_00:47:54 --- 2.0274417400360107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:55 Training loss at epoch 2 step 9390: 3.0452982425689696\n",
      "\n",
      " This round's valence_loss=0.5545274019241333, arousal_loss=0.338641881942749, emotion_loss=0.921952486038208\n",
      "\n",
      "01_20_00:47:55 Seen so far: 300512 samples\n",
      "\n",
      "01_20_00:47:55 --- 1.6383013725280762 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:57 Training loss at epoch 2 step 9400: 2.901643085479736\n",
      "\n",
      " This round's valence_loss=0.8039489388465881, arousal_loss=0.5868657827377319, emotion_loss=0.8847147226333618\n",
      "\n",
      "01_20_00:47:57 Seen so far: 300832 samples\n",
      "\n",
      "01_20_00:47:57 --- 1.7737634181976318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:47:59 Training loss at epoch 2 step 9410: 3.117186117172241\n",
      "\n",
      " This round's valence_loss=1.160032033920288, arousal_loss=1.1047931909561157, emotion_loss=1.0395578145980835\n",
      "\n",
      "01_20_00:47:59 Seen so far: 301152 samples\n",
      "\n",
      "01_20_00:47:59 --- 1.7206788063049316 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:01 Training loss at epoch 2 step 9420: 2.784657371044159\n",
      "\n",
      " This round's valence_loss=0.8999003767967224, arousal_loss=0.7100527286529541, emotion_loss=1.0688176155090332\n",
      "\n",
      "01_20_00:48:01 Seen so far: 301472 samples\n",
      "\n",
      "01_20_00:48:01 --- 1.8174452781677246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:02 Training loss at epoch 2 step 9430: 2.5535080313682554\n",
      "\n",
      " This round's valence_loss=0.8290518522262573, arousal_loss=0.7198536396026611, emotion_loss=1.1784104108810425\n",
      "\n",
      "01_20_00:48:02 Seen so far: 301792 samples\n",
      "\n",
      "01_20_00:48:02 --- 1.641120433807373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:04 Training loss at epoch 2 step 9440: 3.394171690940857\n",
      "\n",
      " This round's valence_loss=1.5808439254760742, arousal_loss=1.437873363494873, emotion_loss=1.2940387725830078\n",
      "\n",
      "01_20_00:48:04 Seen so far: 302112 samples\n",
      "\n",
      "01_20_00:48:04 --- 1.703528881072998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:06 Training loss at epoch 2 step 9450: 2.6343322515487673\n",
      "\n",
      " This round's valence_loss=1.0090105533599854, arousal_loss=0.8664803504943848, emotion_loss=0.8215111494064331\n",
      "\n",
      "01_20_00:48:06 Seen so far: 302432 samples\n",
      "\n",
      "01_20_00:48:06 --- 1.6666510105133057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:07 Training loss at epoch 2 step 9460: 3.129066061973572\n",
      "\n",
      " This round's valence_loss=0.9151368141174316, arousal_loss=0.6937360763549805, emotion_loss=0.9730042219161987\n",
      "\n",
      "01_20_00:48:07 Seen so far: 302752 samples\n",
      "\n",
      "01_20_00:48:07 --- 1.676241397857666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:09 Training loss at epoch 2 step 9470: 2.886249613761902\n",
      "\n",
      " This round's valence_loss=1.5836677551269531, arousal_loss=1.4361083507537842, emotion_loss=0.8192412257194519\n",
      "\n",
      "01_20_00:48:09 Seen so far: 303072 samples\n",
      "\n",
      "01_20_00:48:09 --- 1.7195756435394287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:11 Training loss at epoch 2 step 9480: 2.9160166501998903\n",
      "\n",
      " This round's valence_loss=0.8264999389648438, arousal_loss=0.7387921810150146, emotion_loss=0.8667625188827515\n",
      "\n",
      "01_20_00:48:11 Seen so far: 303392 samples\n",
      "\n",
      "01_20_00:48:11 --- 1.7052736282348633 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:12 Training loss at epoch 2 step 9490: 3.0815046310424803\n",
      "\n",
      " This round's valence_loss=0.8280808925628662, arousal_loss=0.6999992728233337, emotion_loss=0.8799514174461365\n",
      "\n",
      "01_20_00:48:12 Seen so far: 303712 samples\n",
      "\n",
      "01_20_00:48:12 --- 1.846057653427124 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:14 Training loss at epoch 2 step 9500: 3.00997576713562\n",
      "\n",
      " This round's valence_loss=1.4622610807418823, arousal_loss=1.373048186302185, emotion_loss=0.9870847463607788\n",
      "\n",
      "01_20_00:48:14 Seen so far: 304032 samples\n",
      "\n",
      "01_20_00:48:14 --- 1.775467872619629 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:16 Training loss at epoch 2 step 9510: 3.1261754751205446\n",
      "\n",
      " This round's valence_loss=1.1501237154006958, arousal_loss=1.0892488956451416, emotion_loss=0.8285385966300964\n",
      "\n",
      "01_20_00:48:16 Seen so far: 304352 samples\n",
      "\n",
      "01_20_00:48:16 --- 1.7247450351715088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:18 Training loss at epoch 2 step 9520: 3.017939591407776\n",
      "\n",
      " This round's valence_loss=1.2619764804840088, arousal_loss=1.0520977973937988, emotion_loss=0.665570855140686\n",
      "\n",
      "01_20_00:48:18 Seen so far: 304672 samples\n",
      "\n",
      "01_20_00:48:18 --- 1.7326271533966064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:19 Training loss at epoch 2 step 9530: 3.257004642486572\n",
      "\n",
      " This round's valence_loss=1.1173174381256104, arousal_loss=0.9483197927474976, emotion_loss=1.063025712966919\n",
      "\n",
      "01_20_00:48:19 Seen so far: 304992 samples\n",
      "\n",
      "01_20_00:48:19 --- 1.555537462234497 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:21 Training loss at epoch 2 step 9540: 3.1105983734130858\n",
      "\n",
      " This round's valence_loss=1.0776581764221191, arousal_loss=0.9517067074775696, emotion_loss=1.2115583419799805\n",
      "\n",
      "01_20_00:48:21 Seen so far: 305312 samples\n",
      "\n",
      "01_20_00:48:21 --- 1.8083100318908691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:23 Training loss at epoch 2 step 9550: 2.772827959060669\n",
      "\n",
      " This round's valence_loss=1.218719720840454, arousal_loss=1.100287675857544, emotion_loss=1.1125679016113281\n",
      "\n",
      "01_20_00:48:23 Seen so far: 305632 samples\n",
      "\n",
      "01_20_00:48:23 --- 1.726440191268921 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:25 Training loss at epoch 2 step 9560: 2.9887640714645385\n",
      "\n",
      " This round's valence_loss=0.44804444909095764, arousal_loss=0.3337128460407257, emotion_loss=1.1264662742614746\n",
      "\n",
      "01_20_00:48:25 Seen so far: 305952 samples\n",
      "\n",
      "01_20_00:48:25 --- 1.6990625858306885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:26 Training loss at epoch 2 step 9570: 3.364692044258118\n",
      "\n",
      " This round's valence_loss=1.1455705165863037, arousal_loss=0.9407922029495239, emotion_loss=1.3134044408798218\n",
      "\n",
      "01_20_00:48:26 Seen so far: 306272 samples\n",
      "\n",
      "01_20_00:48:26 --- 1.8609702587127686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:28 Training loss at epoch 2 step 9580: 2.855174255371094\n",
      "\n",
      " This round's valence_loss=0.7386380434036255, arousal_loss=0.5513829588890076, emotion_loss=0.9488471746444702\n",
      "\n",
      "01_20_00:48:28 Seen so far: 306592 samples\n",
      "\n",
      "01_20_00:48:28 --- 1.8372440338134766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:30 Training loss at epoch 2 step 9590: 2.8340059518814087\n",
      "\n",
      " This round's valence_loss=0.7708278894424438, arousal_loss=0.5705001354217529, emotion_loss=0.9327660202980042\n",
      "\n",
      "01_20_00:48:30 Seen so far: 306912 samples\n",
      "\n",
      "01_20_00:48:30 --- 2.0853774547576904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:32 Training loss at epoch 2 step 9600: 2.9322503089904783\n",
      "\n",
      " This round's valence_loss=1.5509086847305298, arousal_loss=1.4512172937393188, emotion_loss=0.9590333700180054\n",
      "\n",
      "01_20_00:48:32 Seen so far: 307232 samples\n",
      "\n",
      "01_20_00:48:32 --- 1.6633875370025635 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:34 Training loss at epoch 2 step 9610: 2.9819550633430483\n",
      "\n",
      " This round's valence_loss=1.2304208278656006, arousal_loss=1.1014232635498047, emotion_loss=0.8280584812164307\n",
      "\n",
      "01_20_00:48:34 Seen so far: 307552 samples\n",
      "\n",
      "01_20_00:48:34 --- 1.865863561630249 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:36 Training loss at epoch 2 step 9620: 3.1371399402618407\n",
      "\n",
      " This round's valence_loss=1.2122246026992798, arousal_loss=1.1616020202636719, emotion_loss=0.9990558624267578\n",
      "\n",
      "01_20_00:48:36 Seen so far: 307872 samples\n",
      "\n",
      "01_20_00:48:36 --- 1.8511731624603271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:38 Training loss at epoch 2 step 9630: 2.9786909341812136\n",
      "\n",
      " This round's valence_loss=1.6157382726669312, arousal_loss=1.436964511871338, emotion_loss=0.5566979646682739\n",
      "\n",
      "01_20_00:48:38 Seen so far: 308192 samples\n",
      "\n",
      "01_20_00:48:38 --- 2.0671398639678955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:39 Training loss at epoch 2 step 9640: 2.6263787031173704\n",
      "\n",
      " This round's valence_loss=0.7251689434051514, arousal_loss=0.6042811870574951, emotion_loss=1.0397956371307373\n",
      "\n",
      "01_20_00:48:39 Seen so far: 308512 samples\n",
      "\n",
      "01_20_00:48:39 --- 1.7057750225067139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:41 Training loss at epoch 2 step 9650: 3.2832759380340577\n",
      "\n",
      " This round's valence_loss=1.1944644451141357, arousal_loss=1.0744290351867676, emotion_loss=1.1565475463867188\n",
      "\n",
      "01_20_00:48:41 Seen so far: 308832 samples\n",
      "\n",
      "01_20_00:48:41 --- 1.818781852722168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:43 Training loss at epoch 2 step 9660: 2.867452931404114\n",
      "\n",
      " This round's valence_loss=0.9602516889572144, arousal_loss=0.7174274921417236, emotion_loss=0.6914053559303284\n",
      "\n",
      "01_20_00:48:43 Seen so far: 309152 samples\n",
      "\n",
      "01_20_00:48:43 --- 1.726067304611206 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:45 Training loss at epoch 2 step 9670: 2.4591867208480833\n",
      "\n",
      " This round's valence_loss=0.7380746603012085, arousal_loss=0.6307094693183899, emotion_loss=0.9386290907859802\n",
      "\n",
      "01_20_00:48:45 Seen so far: 309472 samples\n",
      "\n",
      "01_20_00:48:45 --- 1.7452020645141602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:46 Training loss at epoch 2 step 9680: 2.9163665056228636\n",
      "\n",
      " This round's valence_loss=0.9516969919204712, arousal_loss=0.8046078681945801, emotion_loss=1.1244779825210571\n",
      "\n",
      "01_20_00:48:46 Seen so far: 309792 samples\n",
      "\n",
      "01_20_00:48:46 --- 1.756676435470581 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:48 Training loss at epoch 2 step 9690: 3.388966965675354\n",
      "\n",
      " This round's valence_loss=0.7310367822647095, arousal_loss=0.5503569841384888, emotion_loss=1.026908040046692\n",
      "\n",
      "01_20_00:48:48 Seen so far: 310112 samples\n",
      "\n",
      "01_20_00:48:48 --- 1.8235805034637451 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:50 Training loss at epoch 2 step 9700: 3.042195677757263\n",
      "\n",
      " This round's valence_loss=0.8087913393974304, arousal_loss=0.6022382378578186, emotion_loss=0.81055748462677\n",
      "\n",
      "01_20_00:48:50 Seen so far: 310432 samples\n",
      "\n",
      "01_20_00:48:50 --- 1.599937915802002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:52 Training loss at epoch 2 step 9710: 2.607096004486084\n",
      "\n",
      " This round's valence_loss=1.1578927040100098, arousal_loss=0.9049252271652222, emotion_loss=0.7133561372756958\n",
      "\n",
      "01_20_00:48:52 Seen so far: 310752 samples\n",
      "\n",
      "01_20_00:48:52 --- 1.7801635265350342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:53 Training loss at epoch 2 step 9720: 3.038161063194275\n",
      "\n",
      " This round's valence_loss=0.9809858798980713, arousal_loss=0.8748023509979248, emotion_loss=1.3914393186569214\n",
      "\n",
      "01_20_00:48:53 Seen so far: 311072 samples\n",
      "\n",
      "01_20_00:48:53 --- 1.6943674087524414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:55 Training loss at epoch 2 step 9730: 2.8580528497695923\n",
      "\n",
      " This round's valence_loss=0.9251857995986938, arousal_loss=0.7899794578552246, emotion_loss=0.8429620265960693\n",
      "\n",
      "01_20_00:48:55 Seen so far: 311392 samples\n",
      "\n",
      "01_20_00:48:55 --- 1.717097282409668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:57 Training loss at epoch 2 step 9740: 3.029573583602905\n",
      "\n",
      " This round's valence_loss=0.8113584518432617, arousal_loss=0.7177850008010864, emotion_loss=1.124742865562439\n",
      "\n",
      "01_20_00:48:57 Seen so far: 311712 samples\n",
      "\n",
      "01_20_00:48:57 --- 1.7201874256134033 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:48:59 Training loss at epoch 2 step 9750: 3.1180383443832396\n",
      "\n",
      " This round's valence_loss=1.1937737464904785, arousal_loss=0.9545893669128418, emotion_loss=0.4760013222694397\n",
      "\n",
      "01_20_00:48:59 Seen so far: 312032 samples\n",
      "\n",
      "01_20_00:48:59 --- 1.852222204208374 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:00 Training loss at epoch 2 step 9760: 3.0650113582611085\n",
      "\n",
      " This round's valence_loss=1.3568165302276611, arousal_loss=1.2549030780792236, emotion_loss=0.9666568040847778\n",
      "\n",
      "01_20_00:49:00 Seen so far: 312352 samples\n",
      "\n",
      "01_20_00:49:00 --- 1.8109264373779297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:02 Training loss at epoch 2 step 9770: 2.674850511550903\n",
      "\n",
      " This round's valence_loss=0.6444586515426636, arousal_loss=0.4545478820800781, emotion_loss=0.8870140314102173\n",
      "\n",
      "01_20_00:49:02 Seen so far: 312672 samples\n",
      "\n",
      "01_20_00:49:02 --- 1.7758359909057617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:04 Training loss at epoch 2 step 9780: 2.7839069604873656\n",
      "\n",
      " This round's valence_loss=0.4971882104873657, arousal_loss=0.3645707070827484, emotion_loss=0.8224745392799377\n",
      "\n",
      "01_20_00:49:04 Seen so far: 312992 samples\n",
      "\n",
      "01_20_00:49:04 --- 1.8176648616790771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:06 Training loss at epoch 2 step 9790: 2.8832542538642882\n",
      "\n",
      " This round's valence_loss=1.0085757970809937, arousal_loss=0.8352935314178467, emotion_loss=0.9912574291229248\n",
      "\n",
      "01_20_00:49:06 Seen so far: 313312 samples\n",
      "\n",
      "01_20_00:49:06 --- 1.8946342468261719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:08 Training loss at epoch 2 step 9800: 3.207703971862793\n",
      "\n",
      " This round's valence_loss=1.1215863227844238, arousal_loss=0.9664026498794556, emotion_loss=0.9855761528015137\n",
      "\n",
      "01_20_00:49:08 Seen so far: 313632 samples\n",
      "\n",
      "01_20_00:49:08 --- 1.7741978168487549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:10 Training loss at epoch 2 step 9810: 2.938372349739075\n",
      "\n",
      " This round's valence_loss=1.7012766599655151, arousal_loss=1.571202278137207, emotion_loss=1.0232149362564087\n",
      "\n",
      "01_20_00:49:10 Seen so far: 313952 samples\n",
      "\n",
      "01_20_00:49:10 --- 1.8075168132781982 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:11 Training loss at epoch 2 step 9820: 2.857843446731567\n",
      "\n",
      " This round's valence_loss=0.8985142111778259, arousal_loss=0.796582043170929, emotion_loss=0.8360989093780518\n",
      "\n",
      "01_20_00:49:11 Seen so far: 314272 samples\n",
      "\n",
      "01_20_00:49:11 --- 1.7997667789459229 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:13 Training loss at epoch 2 step 9830: 2.758723723888397\n",
      "\n",
      " This round's valence_loss=1.2014228105545044, arousal_loss=1.1091341972351074, emotion_loss=0.8402096033096313\n",
      "\n",
      "01_20_00:49:13 Seen so far: 314592 samples\n",
      "\n",
      "01_20_00:49:13 --- 1.8329746723175049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:15 Training loss at epoch 2 step 9840: 3.035107135772705\n",
      "\n",
      " This round's valence_loss=1.8593108654022217, arousal_loss=1.817947268486023, emotion_loss=1.2884795665740967\n",
      "\n",
      "01_20_00:49:15 Seen so far: 314912 samples\n",
      "\n",
      "01_20_00:49:15 --- 1.6676890850067139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:17 Training loss at epoch 2 step 9850: 2.958786118030548\n",
      "\n",
      " This round's valence_loss=0.7091008424758911, arousal_loss=0.598605751991272, emotion_loss=0.9406507015228271\n",
      "\n",
      "01_20_00:49:17 Seen so far: 315232 samples\n",
      "\n",
      "01_20_00:49:17 --- 1.727813959121704 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:18 Training loss at epoch 2 step 9860: 2.982368898391724\n",
      "\n",
      " This round's valence_loss=0.8774311542510986, arousal_loss=0.7225797772407532, emotion_loss=1.0248451232910156\n",
      "\n",
      "01_20_00:49:18 Seen so far: 315552 samples\n",
      "\n",
      "01_20_00:49:18 --- 1.8465049266815186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:20 Training loss at epoch 2 step 9870: 2.991026520729065\n",
      "\n",
      " This round's valence_loss=0.9544201493263245, arousal_loss=0.6773872971534729, emotion_loss=0.7616094350814819\n",
      "\n",
      "01_20_00:49:20 Seen so far: 315872 samples\n",
      "\n",
      "01_20_00:49:20 --- 1.7913894653320312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:22 Training loss at epoch 2 step 9880: 2.926194453239441\n",
      "\n",
      " This round's valence_loss=0.6626308560371399, arousal_loss=0.6393932104110718, emotion_loss=1.190217137336731\n",
      "\n",
      "01_20_00:49:22 Seen so far: 316192 samples\n",
      "\n",
      "01_20_00:49:22 --- 1.5166969299316406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:24 Training loss at epoch 2 step 9890: 3.1771015167236327\n",
      "\n",
      " This round's valence_loss=0.9338278770446777, arousal_loss=0.8624157905578613, emotion_loss=0.8001763820648193\n",
      "\n",
      "01_20_00:49:24 Seen so far: 316512 samples\n",
      "\n",
      "01_20_00:49:24 --- 1.7804007530212402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:25 Training loss at epoch 2 step 9900: 2.7901880979537963\n",
      "\n",
      " This round's valence_loss=0.8602901697158813, arousal_loss=0.7775551676750183, emotion_loss=0.8040804862976074\n",
      "\n",
      "01_20_00:49:25 Seen so far: 316832 samples\n",
      "\n",
      "01_20_00:49:25 --- 1.9090211391448975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:27 Training loss at epoch 2 step 9910: 3.1389279842376707\n",
      "\n",
      " This round's valence_loss=1.5803325176239014, arousal_loss=1.4765970706939697, emotion_loss=0.8599575757980347\n",
      "\n",
      "01_20_00:49:27 Seen so far: 317152 samples\n",
      "\n",
      "01_20_00:49:27 --- 1.7630839347839355 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:29 Training loss at epoch 2 step 9920: 3.133977699279785\n",
      "\n",
      " This round's valence_loss=1.6160321235656738, arousal_loss=1.441007375717163, emotion_loss=0.8511862754821777\n",
      "\n",
      "01_20_00:49:29 Seen so far: 317472 samples\n",
      "\n",
      "01_20_00:49:29 --- 1.6343908309936523 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:31 Training loss at epoch 2 step 9930: 3.109656739234924\n",
      "\n",
      " This round's valence_loss=1.2558705806732178, arousal_loss=1.0870033502578735, emotion_loss=0.68524169921875\n",
      "\n",
      "01_20_00:49:31 Seen so far: 317792 samples\n",
      "\n",
      "01_20_00:49:31 --- 1.720710039138794 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:32 Training loss at epoch 2 step 9940: 3.114356827735901\n",
      "\n",
      " This round's valence_loss=1.2864952087402344, arousal_loss=1.2125508785247803, emotion_loss=0.7887811660766602\n",
      "\n",
      "01_20_00:49:32 Seen so far: 318112 samples\n",
      "\n",
      "01_20_00:49:32 --- 1.7668144702911377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:34 Training loss at epoch 2 step 9950: 2.931351625919342\n",
      "\n",
      " This round's valence_loss=1.337838888168335, arousal_loss=1.199912190437317, emotion_loss=0.8219479918479919\n",
      "\n",
      "01_20_00:49:34 Seen so far: 318432 samples\n",
      "\n",
      "01_20_00:49:34 --- 1.8217976093292236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:36 Training loss at epoch 2 step 9960: 3.3160551309585573\n",
      "\n",
      " This round's valence_loss=1.323789119720459, arousal_loss=1.1678671836853027, emotion_loss=1.0658526420593262\n",
      "\n",
      "01_20_00:49:36 Seen so far: 318752 samples\n",
      "\n",
      "01_20_00:49:36 --- 1.984877347946167 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:38 Training loss at epoch 2 step 9970: 2.7509033203125\n",
      "\n",
      " This round's valence_loss=0.9962896108627319, arousal_loss=0.8374276161193848, emotion_loss=0.8841246962547302\n",
      "\n",
      "01_20_00:49:38 Seen so far: 319072 samples\n",
      "\n",
      "01_20_00:49:38 --- 1.6807448863983154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:40 Training loss at epoch 2 step 9980: 3.0056624174118043\n",
      "\n",
      " This round's valence_loss=1.2359967231750488, arousal_loss=1.090221643447876, emotion_loss=1.2229145765304565\n",
      "\n",
      "01_20_00:49:40 Seen so far: 319392 samples\n",
      "\n",
      "01_20_00:49:40 --- 1.8237996101379395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:41 Training loss at epoch 2 step 9990: 2.9426204204559325\n",
      "\n",
      " This round's valence_loss=1.1680312156677246, arousal_loss=1.112746238708496, emotion_loss=1.080864429473877\n",
      "\n",
      "01_20_00:49:41 Seen so far: 319712 samples\n",
      "\n",
      "01_20_00:49:41 --- 1.7269983291625977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:43 Training loss at epoch 2 step 10000: 3.009947955608368\n",
      "\n",
      " This round's valence_loss=1.1021263599395752, arousal_loss=0.9891842007637024, emotion_loss=1.11729896068573\n",
      "\n",
      "01_20_00:49:43 Seen so far: 320032 samples\n",
      "\n",
      "01_20_00:49:43 --- 1.8368282318115234 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:45 Training loss at epoch 2 step 10010: 3.0192286491394045\n",
      "\n",
      " This round's valence_loss=1.812272310256958, arousal_loss=1.662636399269104, emotion_loss=1.0939387083053589\n",
      "\n",
      "01_20_00:49:45 Seen so far: 320352 samples\n",
      "\n",
      "01_20_00:49:45 --- 1.7888877391815186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:47 Training loss at epoch 2 step 10020: 3.1752890586853026\n",
      "\n",
      " This round's valence_loss=0.8513047695159912, arousal_loss=0.7560440301895142, emotion_loss=1.0191318988800049\n",
      "\n",
      "01_20_00:49:47 Seen so far: 320672 samples\n",
      "\n",
      "01_20_00:49:47 --- 1.7748708724975586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:49 Training loss at epoch 2 step 10030: 3.0307907819747926\n",
      "\n",
      " This round's valence_loss=1.4522343873977661, arousal_loss=1.3324288129806519, emotion_loss=1.0435301065444946\n",
      "\n",
      "01_20_00:49:49 Seen so far: 320992 samples\n",
      "\n",
      "01_20_00:49:49 --- 1.9685697555541992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:51 Training loss at epoch 2 step 10040: 2.8496219158172607\n",
      "\n",
      " This round's valence_loss=0.7028321623802185, arousal_loss=0.6017329692840576, emotion_loss=0.8230146765708923\n",
      "\n",
      "01_20_00:49:51 Seen so far: 321312 samples\n",
      "\n",
      "01_20_00:49:51 --- 1.7950739860534668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:52 Training loss at epoch 2 step 10050: 3.0151678919792175\n",
      "\n",
      " This round's valence_loss=0.530988335609436, arousal_loss=0.35159289836883545, emotion_loss=1.374833583831787\n",
      "\n",
      "01_20_00:49:52 Seen so far: 321632 samples\n",
      "\n",
      "01_20_00:49:52 --- 1.6998183727264404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:54 Training loss at epoch 2 step 10060: 3.226620006561279\n",
      "\n",
      " This round's valence_loss=1.1310644149780273, arousal_loss=0.9681140184402466, emotion_loss=1.1375293731689453\n",
      "\n",
      "01_20_00:49:54 Seen so far: 321952 samples\n",
      "\n",
      "01_20_00:49:54 --- 1.7300288677215576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:56 Training loss at epoch 2 step 10070: 3.0060054779052736\n",
      "\n",
      " This round's valence_loss=1.1048082113265991, arousal_loss=0.959320604801178, emotion_loss=0.8096204996109009\n",
      "\n",
      "01_20_00:49:56 Seen so far: 322272 samples\n",
      "\n",
      "01_20_00:49:56 --- 1.8429434299468994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:58 Training loss at epoch 2 step 10080: 3.0612449169158937\n",
      "\n",
      " This round's valence_loss=1.3077163696289062, arousal_loss=1.1717767715454102, emotion_loss=0.6198264360427856\n",
      "\n",
      "01_20_00:49:58 Seen so far: 322592 samples\n",
      "\n",
      "01_20_00:49:58 --- 1.807469129562378 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:49:59 Training loss at epoch 2 step 10090: 2.934554433822632\n",
      "\n",
      " This round's valence_loss=1.3245257139205933, arousal_loss=1.0825040340423584, emotion_loss=1.1552739143371582\n",
      "\n",
      "01_20_00:49:59 Seen so far: 322912 samples\n",
      "\n",
      "01_20_00:49:59 --- 1.7033593654632568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:01 Training loss at epoch 2 step 10100: 2.889305901527405\n",
      "\n",
      " This round's valence_loss=1.0193376541137695, arousal_loss=0.8662370443344116, emotion_loss=0.9704523086547852\n",
      "\n",
      "01_20_00:50:01 Seen so far: 323232 samples\n",
      "\n",
      "01_20_00:50:01 --- 1.7799043655395508 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:03 Training loss at epoch 2 step 10110: 2.7501046657562256\n",
      "\n",
      " This round's valence_loss=0.7242754101753235, arousal_loss=0.6265510320663452, emotion_loss=0.9077358245849609\n",
      "\n",
      "01_20_00:50:03 Seen so far: 323552 samples\n",
      "\n",
      "01_20_00:50:03 --- 1.9468817710876465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:05 Training loss at epoch 2 step 10120: 3.234325981140137\n",
      "\n",
      " This round's valence_loss=1.2017138004302979, arousal_loss=0.9196413159370422, emotion_loss=0.9550783634185791\n",
      "\n",
      "01_20_00:50:05 Seen so far: 323872 samples\n",
      "\n",
      "01_20_00:50:05 --- 1.8498775959014893 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:07 Training loss at epoch 2 step 10130: 2.8635966777801514\n",
      "\n",
      " This round's valence_loss=0.951064944267273, arousal_loss=0.8498642444610596, emotion_loss=0.8272799849510193\n",
      "\n",
      "01_20_00:50:07 Seen so far: 324192 samples\n",
      "\n",
      "01_20_00:50:07 --- 1.7436773777008057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:09 Training loss at epoch 2 step 10140: 3.049978184700012\n",
      "\n",
      " This round's valence_loss=1.8193740844726562, arousal_loss=1.660042643547058, emotion_loss=0.7481266856193542\n",
      "\n",
      "01_20_00:50:09 Seen so far: 324512 samples\n",
      "\n",
      "01_20_00:50:09 --- 1.8804144859313965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:10 Training loss at epoch 2 step 10150: 3.105989098548889\n",
      "\n",
      " This round's valence_loss=1.005455732345581, arousal_loss=0.8416234254837036, emotion_loss=0.8234360218048096\n",
      "\n",
      "01_20_00:50:10 Seen so far: 324832 samples\n",
      "\n",
      "01_20_00:50:10 --- 1.8894896507263184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:12 Training loss at epoch 2 step 10160: 2.8342010021209716\n",
      "\n",
      " This round's valence_loss=0.9404889941215515, arousal_loss=0.8621615171432495, emotion_loss=1.241905927658081\n",
      "\n",
      "01_20_00:50:12 Seen so far: 325152 samples\n",
      "\n",
      "01_20_00:50:12 --- 1.8243968486785889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:14 Training loss at epoch 2 step 10170: 3.146656107902527\n",
      "\n",
      " This round's valence_loss=1.3265738487243652, arousal_loss=1.1861063241958618, emotion_loss=0.7602008581161499\n",
      "\n",
      "01_20_00:50:14 Seen so far: 325472 samples\n",
      "\n",
      "01_20_00:50:14 --- 1.8439579010009766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:16 Training loss at epoch 2 step 10180: 2.7326870441436766\n",
      "\n",
      " This round's valence_loss=1.0341081619262695, arousal_loss=0.9513165950775146, emotion_loss=1.2764818668365479\n",
      "\n",
      "01_20_00:50:16 Seen so far: 325792 samples\n",
      "\n",
      "01_20_00:50:16 --- 1.8084170818328857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:18 Training loss at epoch 2 step 10190: 2.8853435039520265\n",
      "\n",
      " This round's valence_loss=1.0759849548339844, arousal_loss=0.9469993114471436, emotion_loss=1.0522488355636597\n",
      "\n",
      "01_20_00:50:18 Seen so far: 326112 samples\n",
      "\n",
      "01_20_00:50:18 --- 1.6837811470031738 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:19 Training loss at epoch 2 step 10200: 3.246426248550415\n",
      "\n",
      " This round's valence_loss=1.1470787525177002, arousal_loss=0.9499474167823792, emotion_loss=1.0042283535003662\n",
      "\n",
      "01_20_00:50:19 Seen so far: 326432 samples\n",
      "\n",
      "01_20_00:50:19 --- 1.8972866535186768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:21 Training loss at epoch 2 step 10210: 3.1988982915878297\n",
      "\n",
      " This round's valence_loss=0.9608950614929199, arousal_loss=0.8705207705497742, emotion_loss=1.125632882118225\n",
      "\n",
      "01_20_00:50:21 Seen so far: 326752 samples\n",
      "\n",
      "01_20_00:50:21 --- 1.9947621822357178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:23 Training loss at epoch 2 step 10220: 2.7848384857177733\n",
      "\n",
      " This round's valence_loss=0.8316691517829895, arousal_loss=0.6985241174697876, emotion_loss=1.0415626764297485\n",
      "\n",
      "01_20_00:50:23 Seen so far: 327072 samples\n",
      "\n",
      "01_20_00:50:23 --- 1.8541462421417236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:25 Training loss at epoch 2 step 10230: 2.822010946273804\n",
      "\n",
      " This round's valence_loss=1.0005638599395752, arousal_loss=0.8573207259178162, emotion_loss=1.3057124614715576\n",
      "\n",
      "01_20_00:50:25 Seen so far: 327392 samples\n",
      "\n",
      "01_20_00:50:25 --- 1.6326284408569336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:27 Training loss at epoch 2 step 10240: 3.26396062374115\n",
      "\n",
      " This round's valence_loss=1.3542479276657104, arousal_loss=1.180340051651001, emotion_loss=0.8087257146835327\n",
      "\n",
      "01_20_00:50:27 Seen so far: 327712 samples\n",
      "\n",
      "01_20_00:50:27 --- 1.6628949642181396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:28 Training loss at epoch 2 step 10250: 2.7879300355911254\n",
      "\n",
      " This round's valence_loss=1.0862836837768555, arousal_loss=1.0014419555664062, emotion_loss=1.0108332633972168\n",
      "\n",
      "01_20_00:50:28 Seen so far: 328032 samples\n",
      "\n",
      "01_20_00:50:28 --- 1.7929890155792236 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:30 Training loss at epoch 2 step 10260: 3.314095401763916\n",
      "\n",
      " This round's valence_loss=1.1558200120925903, arousal_loss=1.0948283672332764, emotion_loss=0.8203310966491699\n",
      "\n",
      "01_20_00:50:30 Seen so far: 328352 samples\n",
      "\n",
      "01_20_00:50:30 --- 1.7157363891601562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:32 Training loss at epoch 2 step 10270: 2.897110652923584\n",
      "\n",
      " This round's valence_loss=0.9750373959541321, arousal_loss=0.6823438405990601, emotion_loss=0.5764105319976807\n",
      "\n",
      "01_20_00:50:32 Seen so far: 328672 samples\n",
      "\n",
      "01_20_00:50:32 --- 1.6217091083526611 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:33 Training loss at epoch 2 step 10280: 2.8091267347335815\n",
      "\n",
      " This round's valence_loss=1.0595608949661255, arousal_loss=0.9444363713264465, emotion_loss=1.0371177196502686\n",
      "\n",
      "01_20_00:50:33 Seen so far: 328992 samples\n",
      "\n",
      "01_20_00:50:33 --- 1.6459758281707764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:35 Training loss at epoch 2 step 10290: 2.811233699321747\n",
      "\n",
      " This round's valence_loss=0.8418257236480713, arousal_loss=0.724310040473938, emotion_loss=0.6925675868988037\n",
      "\n",
      "01_20_00:50:35 Seen so far: 329312 samples\n",
      "\n",
      "01_20_00:50:35 --- 1.8066377639770508 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:37 Training loss at epoch 2 step 10300: 2.981842541694641\n",
      "\n",
      " This round's valence_loss=1.4504722356796265, arousal_loss=1.350406527519226, emotion_loss=1.2444640398025513\n",
      "\n",
      "01_20_00:50:37 Seen so far: 329632 samples\n",
      "\n",
      "01_20_00:50:37 --- 1.6865403652191162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:38 Training loss at epoch 2 step 10310: 3.0749017238616942\n",
      "\n",
      " This round's valence_loss=1.1009160280227661, arousal_loss=0.9540895223617554, emotion_loss=1.0292880535125732\n",
      "\n",
      "01_20_00:50:38 Seen so far: 329952 samples\n",
      "\n",
      "01_20_00:50:38 --- 1.614673137664795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:40 Training loss at epoch 2 step 10320: 2.922561764717102\n",
      "\n",
      " This round's valence_loss=0.6716649532318115, arousal_loss=0.4583849310874939, emotion_loss=0.9101133346557617\n",
      "\n",
      "01_20_00:50:40 Seen so far: 330272 samples\n",
      "\n",
      "01_20_00:50:40 --- 1.7248780727386475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:42 Training loss at epoch 2 step 10330: 2.78259072303772\n",
      "\n",
      " This round's valence_loss=0.8452883958816528, arousal_loss=0.7217996120452881, emotion_loss=0.9569467306137085\n",
      "\n",
      "01_20_00:50:42 Seen so far: 330592 samples\n",
      "\n",
      "01_20_00:50:42 --- 1.8569962978363037 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:44 Training loss at epoch 2 step 10340: 2.971786046028137\n",
      "\n",
      " This round's valence_loss=1.1005408763885498, arousal_loss=0.9216271638870239, emotion_loss=0.9137698411941528\n",
      "\n",
      "01_20_00:50:44 Seen so far: 330912 samples\n",
      "\n",
      "01_20_00:50:44 --- 1.6917989253997803 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:46 Training loss at epoch 2 step 10350: 3.0881934642791746\n",
      "\n",
      " This round's valence_loss=1.2990591526031494, arousal_loss=1.183013916015625, emotion_loss=1.1619293689727783\n",
      "\n",
      "01_20_00:50:46 Seen so far: 331232 samples\n",
      "\n",
      "01_20_00:50:46 --- 1.8218157291412354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:47 Training loss at epoch 2 step 10360: 2.76713490486145\n",
      "\n",
      " This round's valence_loss=0.6658414006233215, arousal_loss=0.522568941116333, emotion_loss=1.0535858869552612\n",
      "\n",
      "01_20_00:50:47 Seen so far: 331552 samples\n",
      "\n",
      "01_20_00:50:47 --- 1.6364552974700928 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:49 Training loss at epoch 2 step 10370: 2.313032364845276\n",
      "\n",
      " This round's valence_loss=0.5196207761764526, arousal_loss=0.3720209002494812, emotion_loss=1.2565380334854126\n",
      "\n",
      "01_20_00:50:49 Seen so far: 331872 samples\n",
      "\n",
      "01_20_00:50:49 --- 1.7804875373840332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:51 Training loss at epoch 2 step 10380: 2.8114104986190798\n",
      "\n",
      " This round's valence_loss=1.2006934881210327, arousal_loss=1.090952754020691, emotion_loss=0.5804373621940613\n",
      "\n",
      "01_20_00:50:51 Seen so far: 332192 samples\n",
      "\n",
      "01_20_00:50:51 --- 1.743969440460205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:53 Training loss at epoch 2 step 10390: 2.921299600601196\n",
      "\n",
      " This round's valence_loss=1.0246806144714355, arousal_loss=0.8128019571304321, emotion_loss=1.0461676120758057\n",
      "\n",
      "01_20_00:50:53 Seen so far: 332512 samples\n",
      "\n",
      "01_20_00:50:53 --- 1.9908607006072998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:54 Training loss at epoch 2 step 10400: 2.876396131515503\n",
      "\n",
      " This round's valence_loss=1.6302330493927002, arousal_loss=1.5833189487457275, emotion_loss=1.044179081916809\n",
      "\n",
      "01_20_00:50:54 Seen so far: 332832 samples\n",
      "\n",
      "01_20_00:50:54 --- 1.705596923828125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:56 Training loss at epoch 2 step 10410: 2.7432299852371216\n",
      "\n",
      " This round's valence_loss=1.5401887893676758, arousal_loss=1.4159327745437622, emotion_loss=0.6402539014816284\n",
      "\n",
      "01_20_00:50:56 Seen so far: 333152 samples\n",
      "\n",
      "01_20_00:50:56 --- 1.750746726989746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:50:58 Training loss at epoch 2 step 10420: 3.024658751487732\n",
      "\n",
      " This round's valence_loss=0.8700719475746155, arousal_loss=0.7638977766036987, emotion_loss=0.987843930721283\n",
      "\n",
      "01_20_00:50:58 Seen so far: 333472 samples\n",
      "\n",
      "01_20_00:50:58 --- 1.6251139640808105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:00 Training loss at epoch 2 step 10430: 3.1670989990234375\n",
      "\n",
      " This round's valence_loss=1.4240961074829102, arousal_loss=1.3467820882797241, emotion_loss=1.038922667503357\n",
      "\n",
      "01_20_00:51:00 Seen so far: 333792 samples\n",
      "\n",
      "01_20_00:51:00 --- 2.0180840492248535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:02 Training loss at epoch 2 step 10440: 3.082396125793457\n",
      "\n",
      " This round's valence_loss=1.6774351596832275, arousal_loss=1.4686188697814941, emotion_loss=1.1847279071807861\n",
      "\n",
      "01_20_00:51:02 Seen so far: 334112 samples\n",
      "\n",
      "01_20_00:51:02 --- 1.682760238647461 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:03 Training loss at epoch 2 step 10450: 3.097344756126404\n",
      "\n",
      " This round's valence_loss=0.9015816450119019, arousal_loss=0.7094101309776306, emotion_loss=0.9865274429321289\n",
      "\n",
      "01_20_00:51:03 Seen so far: 334432 samples\n",
      "\n",
      "01_20_00:51:03 --- 1.672044038772583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:05 Training loss at epoch 2 step 10460: 3.1134608507156374\n",
      "\n",
      " This round's valence_loss=0.7852360606193542, arousal_loss=0.5718114972114563, emotion_loss=0.8149659633636475\n",
      "\n",
      "01_20_00:51:05 Seen so far: 334752 samples\n",
      "\n",
      "01_20_00:51:05 --- 1.9460303783416748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:07 Training loss at epoch 2 step 10470: 2.9913657903671265\n",
      "\n",
      " This round's valence_loss=1.4492712020874023, arousal_loss=1.341876745223999, emotion_loss=1.0492035150527954\n",
      "\n",
      "01_20_00:51:07 Seen so far: 335072 samples\n",
      "\n",
      "01_20_00:51:07 --- 1.7623157501220703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:09 Training loss at epoch 2 step 10480: 3.133704090118408\n",
      "\n",
      " This round's valence_loss=1.3611903190612793, arousal_loss=1.185713291168213, emotion_loss=0.9906132221221924\n",
      "\n",
      "01_20_00:51:09 Seen so far: 335392 samples\n",
      "\n",
      "01_20_00:51:09 --- 1.751755714416504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:11 Training loss at epoch 2 step 10490: 2.974429488182068\n",
      "\n",
      " This round's valence_loss=0.7046473622322083, arousal_loss=0.600560188293457, emotion_loss=1.1837252378463745\n",
      "\n",
      "01_20_00:51:11 Seen so far: 335712 samples\n",
      "\n",
      "01_20_00:51:11 --- 1.9076383113861084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:12 Training loss at epoch 2 step 10500: 2.8159724950790403\n",
      "\n",
      " This round's valence_loss=0.7540478706359863, arousal_loss=0.6455159187316895, emotion_loss=1.427799940109253\n",
      "\n",
      "01_20_00:51:12 Seen so far: 336032 samples\n",
      "\n",
      "01_20_00:51:12 --- 1.7618143558502197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:14 Training loss at epoch 2 step 10510: 3.4686077356338503\n",
      "\n",
      " This round's valence_loss=0.8172996044158936, arousal_loss=0.6822368502616882, emotion_loss=1.0383061170578003\n",
      "\n",
      "01_20_00:51:14 Seen so far: 336352 samples\n",
      "\n",
      "01_20_00:51:14 --- 1.8454711437225342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:16 Training loss at epoch 2 step 10520: 2.879429888725281\n",
      "\n",
      " This round's valence_loss=1.2328883409500122, arousal_loss=1.075208067893982, emotion_loss=1.035783290863037\n",
      "\n",
      "01_20_00:51:16 Seen so far: 336672 samples\n",
      "\n",
      "01_20_00:51:16 --- 1.6298503875732422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:18 Training loss at epoch 2 step 10530: 3.3323452949523924\n",
      "\n",
      " This round's valence_loss=1.0760366916656494, arousal_loss=1.0082347393035889, emotion_loss=0.8337815999984741\n",
      "\n",
      "01_20_00:51:18 Seen so far: 336992 samples\n",
      "\n",
      "01_20_00:51:18 --- 1.9248721599578857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:19 Training loss at epoch 2 step 10540: 2.8187458753585815\n",
      "\n",
      " This round's valence_loss=1.1144530773162842, arousal_loss=0.9518873691558838, emotion_loss=1.1478369235992432\n",
      "\n",
      "01_20_00:51:19 Seen so far: 337312 samples\n",
      "\n",
      "01_20_00:51:19 --- 1.6193559169769287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:21 Training loss at epoch 2 step 10550: 3.09315505027771\n",
      "\n",
      " This round's valence_loss=0.873038113117218, arousal_loss=0.7314073443412781, emotion_loss=0.6393721103668213\n",
      "\n",
      "01_20_00:51:21 Seen so far: 337632 samples\n",
      "\n",
      "01_20_00:51:21 --- 1.825693130493164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:23 Training loss at epoch 2 step 10560: 3.4527404069900514\n",
      "\n",
      " This round's valence_loss=0.9680230617523193, arousal_loss=0.8502609133720398, emotion_loss=1.0642433166503906\n",
      "\n",
      "01_20_00:51:23 Seen so far: 337952 samples\n",
      "\n",
      "01_20_00:51:23 --- 1.6561763286590576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:24 Training loss at epoch 2 step 10570: 2.8481102108955385\n",
      "\n",
      " This round's valence_loss=0.8504490852355957, arousal_loss=0.6232789754867554, emotion_loss=1.2986901998519897\n",
      "\n",
      "01_20_00:51:24 Seen so far: 338272 samples\n",
      "\n",
      "01_20_00:51:24 --- 1.6466476917266846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:26 Training loss at epoch 2 step 10580: 3.192891502380371\n",
      "\n",
      " This round's valence_loss=1.1185901165008545, arousal_loss=0.9898862838745117, emotion_loss=0.6492956876754761\n",
      "\n",
      "01_20_00:51:26 Seen so far: 338592 samples\n",
      "\n",
      "01_20_00:51:26 --- 1.6594758033752441 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:28 Training loss at epoch 2 step 10590: 2.9362528324127197\n",
      "\n",
      " This round's valence_loss=1.4641872644424438, arousal_loss=1.369110107421875, emotion_loss=1.1729404926300049\n",
      "\n",
      "01_20_00:51:28 Seen so far: 338912 samples\n",
      "\n",
      "01_20_00:51:28 --- 1.791931390762329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:30 Training loss at epoch 2 step 10600: 2.7016130805015566\n",
      "\n",
      " This round's valence_loss=0.8589540719985962, arousal_loss=0.6807800531387329, emotion_loss=0.7976700067520142\n",
      "\n",
      "01_20_00:51:30 Seen so far: 339232 samples\n",
      "\n",
      "01_20_00:51:30 --- 1.6231567859649658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:31 Training loss at epoch 2 step 10610: 2.8634541988372804\n",
      "\n",
      " This round's valence_loss=0.9945900440216064, arousal_loss=0.7890689373016357, emotion_loss=0.96149742603302\n",
      "\n",
      "01_20_00:51:31 Seen so far: 339552 samples\n",
      "\n",
      "01_20_00:51:31 --- 1.6523752212524414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:33 Training loss at epoch 2 step 10620: 2.861338186264038\n",
      "\n",
      " This round's valence_loss=0.9945093393325806, arousal_loss=0.8505730628967285, emotion_loss=0.522205650806427\n",
      "\n",
      "01_20_00:51:33 Seen so far: 339872 samples\n",
      "\n",
      "01_20_00:51:33 --- 1.6973340511322021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:35 Training loss at epoch 2 step 10630: 3.1682498812675477\n",
      "\n",
      " This round's valence_loss=1.0015519857406616, arousal_loss=0.9092687368392944, emotion_loss=1.1819227933883667\n",
      "\n",
      "01_20_00:51:35 Seen so far: 340192 samples\n",
      "\n",
      "01_20_00:51:35 --- 1.783397912979126 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:37 Training loss at epoch 2 step 10640: 3.2334083318710327\n",
      "\n",
      " This round's valence_loss=1.7790218591690063, arousal_loss=1.674074649810791, emotion_loss=0.7865755558013916\n",
      "\n",
      "01_20_00:51:37 Seen so far: 340512 samples\n",
      "\n",
      "01_20_00:51:37 --- 1.9113807678222656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:38 Training loss at epoch 2 step 10650: 2.8835121393203735\n",
      "\n",
      " This round's valence_loss=0.8003628849983215, arousal_loss=0.738419771194458, emotion_loss=0.8011934757232666\n",
      "\n",
      "01_20_00:51:38 Seen so far: 340832 samples\n",
      "\n",
      "01_20_00:51:38 --- 1.709216594696045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:40 Training loss at epoch 2 step 10660: 2.9271169185638426\n",
      "\n",
      " This round's valence_loss=0.5365562438964844, arousal_loss=0.3666040301322937, emotion_loss=1.0124989748001099\n",
      "\n",
      "01_20_00:51:40 Seen so far: 341152 samples\n",
      "\n",
      "01_20_00:51:40 --- 2.0565080642700195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:42 Training loss at epoch 2 step 10670: 2.8223347902297973\n",
      "\n",
      " This round's valence_loss=1.2666202783584595, arousal_loss=1.1041650772094727, emotion_loss=0.7386151552200317\n",
      "\n",
      "01_20_00:51:42 Seen so far: 341472 samples\n",
      "\n",
      "01_20_00:51:42 --- 1.6272938251495361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:44 Training loss at epoch 2 step 10680: 3.309481310844421\n",
      "\n",
      " This round's valence_loss=0.8545664548873901, arousal_loss=0.6242938041687012, emotion_loss=0.8667291402816772\n",
      "\n",
      "01_20_00:51:44 Seen so far: 341792 samples\n",
      "\n",
      "01_20_00:51:44 --- 1.7462737560272217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:46 Training loss at epoch 2 step 10690: 3.1415788650512697\n",
      "\n",
      " This round's valence_loss=0.9651832580566406, arousal_loss=0.7399336099624634, emotion_loss=0.727163553237915\n",
      "\n",
      "01_20_00:51:46 Seen so far: 342112 samples\n",
      "\n",
      "01_20_00:51:46 --- 1.8451995849609375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:47 Training loss at epoch 2 step 10700: 3.0532597303390503\n",
      "\n",
      " This round's valence_loss=1.0638420581817627, arousal_loss=0.9769503474235535, emotion_loss=1.081197738647461\n",
      "\n",
      "01_20_00:51:47 Seen so far: 342432 samples\n",
      "\n",
      "01_20_00:51:47 --- 1.7232754230499268 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:49 Training loss at epoch 2 step 10710: 3.0745795011520385\n",
      "\n",
      " This round's valence_loss=0.8710612654685974, arousal_loss=0.690895676612854, emotion_loss=0.936672031879425\n",
      "\n",
      "01_20_00:51:49 Seen so far: 342752 samples\n",
      "\n",
      "01_20_00:51:49 --- 1.6689691543579102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:51 Training loss at epoch 2 step 10720: 2.8752193689346313\n",
      "\n",
      " This round's valence_loss=1.0054471492767334, arousal_loss=0.7971839308738708, emotion_loss=0.9313893914222717\n",
      "\n",
      "01_20_00:51:51 Seen so far: 343072 samples\n",
      "\n",
      "01_20_00:51:51 --- 1.837372064590454 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:53 Training loss at epoch 2 step 10730: 2.878806674480438\n",
      "\n",
      " This round's valence_loss=1.2454856634140015, arousal_loss=1.067053198814392, emotion_loss=0.9655359983444214\n",
      "\n",
      "01_20_00:51:53 Seen so far: 343392 samples\n",
      "\n",
      "01_20_00:51:53 --- 1.811856985092163 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:54 Training loss at epoch 2 step 10740: 2.857667589187622\n",
      "\n",
      " This round's valence_loss=1.0649782419204712, arousal_loss=0.9794633984565735, emotion_loss=0.6948261260986328\n",
      "\n",
      "01_20_00:51:54 Seen so far: 343712 samples\n",
      "\n",
      "01_20_00:51:54 --- 1.5182437896728516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:56 Training loss at epoch 2 step 10750: 3.2840227603912355\n",
      "\n",
      " This round's valence_loss=1.0034414529800415, arousal_loss=0.8543592691421509, emotion_loss=0.7992009520530701\n",
      "\n",
      "01_20_00:51:56 Seen so far: 344032 samples\n",
      "\n",
      "01_20_00:51:56 --- 1.6549179553985596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:58 Training loss at epoch 2 step 10760: 3.0432604551315308\n",
      "\n",
      " This round's valence_loss=0.9960795640945435, arousal_loss=0.8500293493270874, emotion_loss=0.9789999127388\n",
      "\n",
      "01_20_00:51:58 Seen so far: 344352 samples\n",
      "\n",
      "01_20_00:51:58 --- 1.7246408462524414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:51:59 Training loss at epoch 2 step 10770: 3.0633379459381103\n",
      "\n",
      " This round's valence_loss=1.2380530834197998, arousal_loss=1.0973457098007202, emotion_loss=0.8286556601524353\n",
      "\n",
      "01_20_00:51:59 Seen so far: 344672 samples\n",
      "\n",
      "01_20_00:51:59 --- 1.8654906749725342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:01 Training loss at epoch 2 step 10780: 2.7816580533981323\n",
      "\n",
      " This round's valence_loss=0.7028176784515381, arousal_loss=0.5106625556945801, emotion_loss=0.5530264377593994\n",
      "\n",
      "01_20_00:52:01 Seen so far: 344992 samples\n",
      "\n",
      "01_20_00:52:01 --- 1.7016589641571045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:03 Training loss at epoch 2 step 10790: 3.143301796913147\n",
      "\n",
      " This round's valence_loss=0.9320181608200073, arousal_loss=0.85658860206604, emotion_loss=1.1121362447738647\n",
      "\n",
      "01_20_00:52:03 Seen so far: 345312 samples\n",
      "\n",
      "01_20_00:52:03 --- 1.745764970779419 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:05 Training loss at epoch 2 step 10800: 2.9426627159118652\n",
      "\n",
      " This round's valence_loss=1.003605842590332, arousal_loss=0.827608048915863, emotion_loss=0.8186557292938232\n",
      "\n",
      "01_20_00:52:05 Seen so far: 345632 samples\n",
      "\n",
      "01_20_00:52:05 --- 1.857398509979248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:06 Training loss at epoch 2 step 10810: 3.1932345628738403\n",
      "\n",
      " This round's valence_loss=0.9451953172683716, arousal_loss=0.7975289821624756, emotion_loss=0.9097126722335815\n",
      "\n",
      "01_20_00:52:06 Seen so far: 345952 samples\n",
      "\n",
      "01_20_00:52:06 --- 1.7536466121673584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:08 Training loss at epoch 2 step 10820: 2.97888662815094\n",
      "\n",
      " This round's valence_loss=1.1437199115753174, arousal_loss=0.9259782433509827, emotion_loss=0.5479298830032349\n",
      "\n",
      "01_20_00:52:08 Seen so far: 346272 samples\n",
      "\n",
      "01_20_00:52:08 --- 1.7211542129516602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:10 Training loss at epoch 2 step 10830: 3.3986654043197633\n",
      "\n",
      " This round's valence_loss=1.5812993049621582, arousal_loss=1.4461772441864014, emotion_loss=1.0519566535949707\n",
      "\n",
      "01_20_00:52:10 Seen so far: 346592 samples\n",
      "\n",
      "01_20_00:52:10 --- 1.881223440170288 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:12 Training loss at epoch 2 step 10840: 3.207897925376892\n",
      "\n",
      " This round's valence_loss=1.492152214050293, arousal_loss=1.2928967475891113, emotion_loss=0.7786952257156372\n",
      "\n",
      "01_20_00:52:12 Seen so far: 346912 samples\n",
      "\n",
      "01_20_00:52:12 --- 1.7970576286315918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:14 Training loss at epoch 2 step 10850: 3.1110921144485473\n",
      "\n",
      " This round's valence_loss=1.0198379755020142, arousal_loss=0.7934284210205078, emotion_loss=0.5898007750511169\n",
      "\n",
      "01_20_00:52:14 Seen so far: 347232 samples\n",
      "\n",
      "01_20_00:52:14 --- 1.6590168476104736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:15 Training loss at epoch 2 step 10860: 2.762118136882782\n",
      "\n",
      " This round's valence_loss=0.4815309941768646, arousal_loss=0.40069735050201416, emotion_loss=0.9916611909866333\n",
      "\n",
      "01_20_00:52:15 Seen so far: 347552 samples\n",
      "\n",
      "01_20_00:52:15 --- 1.962996006011963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:17 Training loss at epoch 2 step 10870: 2.860808765888214\n",
      "\n",
      " This round's valence_loss=0.8138002157211304, arousal_loss=0.6740021705627441, emotion_loss=0.8751043081283569\n",
      "\n",
      "01_20_00:52:17 Seen so far: 347872 samples\n",
      "\n",
      "01_20_00:52:17 --- 1.802300214767456 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:19 Training loss at epoch 2 step 10880: 2.848175883293152\n",
      "\n",
      " This round's valence_loss=1.3270514011383057, arousal_loss=1.2550239562988281, emotion_loss=0.8177752494812012\n",
      "\n",
      "01_20_00:52:19 Seen so far: 348192 samples\n",
      "\n",
      "01_20_00:52:19 --- 1.5725464820861816 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:21 Training loss at epoch 2 step 10890: 2.8744895219802857\n",
      "\n",
      " This round's valence_loss=0.8655552864074707, arousal_loss=0.6830295324325562, emotion_loss=0.8337944746017456\n",
      "\n",
      "01_20_00:52:21 Seen so far: 348512 samples\n",
      "\n",
      "01_20_00:52:21 --- 1.6990985870361328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:22 Training loss at epoch 2 step 10900: 2.748676300048828\n",
      "\n",
      " This round's valence_loss=0.5926178097724915, arousal_loss=0.3708777129650116, emotion_loss=0.7827804684638977\n",
      "\n",
      "01_20_00:52:22 Seen so far: 348832 samples\n",
      "\n",
      "01_20_00:52:22 --- 1.7961170673370361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:24 Training loss at epoch 2 step 10910: 3.051499080657959\n",
      "\n",
      " This round's valence_loss=1.2154937982559204, arousal_loss=1.080077886581421, emotion_loss=1.1386216878890991\n",
      "\n",
      "01_20_00:52:24 Seen so far: 349152 samples\n",
      "\n",
      "01_20_00:52:24 --- 1.9235148429870605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:26 Training loss at epoch 2 step 10920: 3.1690686702728272\n",
      "\n",
      " This round's valence_loss=1.4279356002807617, arousal_loss=1.4035253524780273, emotion_loss=0.8540414571762085\n",
      "\n",
      "01_20_00:52:26 Seen so far: 349472 samples\n",
      "\n",
      "01_20_00:52:26 --- 1.7003324031829834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:28 Training loss at epoch 2 step 10930: 3.1816081762313844\n",
      "\n",
      " This round's valence_loss=1.0546391010284424, arousal_loss=0.8275748491287231, emotion_loss=0.649060845375061\n",
      "\n",
      "01_20_00:52:28 Seen so far: 349792 samples\n",
      "\n",
      "01_20_00:52:28 --- 1.7489638328552246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:30 Training loss at epoch 2 step 10940: 2.8955768585205077\n",
      "\n",
      " This round's valence_loss=0.6480280160903931, arousal_loss=0.5289521813392639, emotion_loss=1.2544667720794678\n",
      "\n",
      "01_20_00:52:30 Seen so far: 350112 samples\n",
      "\n",
      "01_20_00:52:30 --- 2.0410492420196533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:32 Training loss at epoch 2 step 10950: 2.7287621021270754\n",
      "\n",
      " This round's valence_loss=1.2999603748321533, arousal_loss=1.2460830211639404, emotion_loss=1.1421079635620117\n",
      "\n",
      "01_20_00:52:32 Seen so far: 350432 samples\n",
      "\n",
      "01_20_00:52:32 --- 1.7440009117126465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:33 Training loss at epoch 2 step 10960: 3.0280641078948975\n",
      "\n",
      " This round's valence_loss=0.6944184899330139, arousal_loss=0.6048375368118286, emotion_loss=0.9844586253166199\n",
      "\n",
      "01_20_00:52:33 Seen so far: 350752 samples\n",
      "\n",
      "01_20_00:52:33 --- 1.7911736965179443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:35 Training loss at epoch 2 step 10970: 2.7045121669769285\n",
      "\n",
      " This round's valence_loss=0.9563312530517578, arousal_loss=0.8003115653991699, emotion_loss=1.1167004108428955\n",
      "\n",
      "01_20_00:52:35 Seen so far: 351072 samples\n",
      "\n",
      "01_20_00:52:35 --- 1.5808310508728027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:37 Training loss at epoch 2 step 10980: 3.1316335201263428\n",
      "\n",
      " This round's valence_loss=1.0693172216415405, arousal_loss=0.9755470752716064, emotion_loss=1.089470386505127\n",
      "\n",
      "01_20_00:52:37 Seen so far: 351392 samples\n",
      "\n",
      "01_20_00:52:37 --- 1.7886252403259277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:38 Training loss at epoch 2 step 10990: 2.96552894115448\n",
      "\n",
      " This round's valence_loss=0.8093613386154175, arousal_loss=0.5553700923919678, emotion_loss=0.8549347519874573\n",
      "\n",
      "01_20_00:52:38 Seen so far: 351712 samples\n",
      "\n",
      "01_20_00:52:38 --- 1.635577917098999 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:40 Training loss at epoch 2 step 11000: 2.7245115518569945\n",
      "\n",
      " This round's valence_loss=0.9775689244270325, arousal_loss=0.9149265289306641, emotion_loss=0.8756116032600403\n",
      "\n",
      "01_20_00:52:40 Seen so far: 352032 samples\n",
      "\n",
      "01_20_00:52:40 --- 1.8480370044708252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:42 Training loss at epoch 2 step 11010: 2.847259283065796\n",
      "\n",
      " This round's valence_loss=1.057438611984253, arousal_loss=0.9510852694511414, emotion_loss=0.8796234130859375\n",
      "\n",
      "01_20_00:52:42 Seen so far: 352352 samples\n",
      "\n",
      "01_20_00:52:42 --- 1.8793416023254395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:44 Training loss at epoch 2 step 11020: 2.6327285885810854\n",
      "\n",
      " This round's valence_loss=0.8675134181976318, arousal_loss=0.8613783717155457, emotion_loss=1.1073405742645264\n",
      "\n",
      "01_20_00:52:44 Seen so far: 352672 samples\n",
      "\n",
      "01_20_00:52:44 --- 1.8019309043884277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:45 Training loss at epoch 2 step 11030: 2.843317222595215\n",
      "\n",
      " This round's valence_loss=1.2907423973083496, arousal_loss=1.2013823986053467, emotion_loss=0.8362845182418823\n",
      "\n",
      "01_20_00:52:45 Seen so far: 352992 samples\n",
      "\n",
      "01_20_00:52:45 --- 1.671724557876587 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:47 Training loss at epoch 2 step 11040: 2.936302065849304\n",
      "\n",
      " This round's valence_loss=1.4804620742797852, arousal_loss=1.3044319152832031, emotion_loss=1.0184623003005981\n",
      "\n",
      "01_20_00:52:47 Seen so far: 353312 samples\n",
      "\n",
      "01_20_00:52:47 --- 1.6733531951904297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:49 Training loss at epoch 2 step 11050: 3.0137698888778686\n",
      "\n",
      " This round's valence_loss=0.8303574919700623, arousal_loss=0.7894605994224548, emotion_loss=1.2700754404067993\n",
      "\n",
      "01_20_00:52:49 Seen so far: 353632 samples\n",
      "\n",
      "01_20_00:52:49 --- 1.6782960891723633 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:51 Training loss at epoch 2 step 11060: 2.765475130081177\n",
      "\n",
      " This round's valence_loss=1.3604897260665894, arousal_loss=1.2143492698669434, emotion_loss=0.7998374700546265\n",
      "\n",
      "01_20_00:52:51 Seen so far: 353952 samples\n",
      "\n",
      "01_20_00:52:51 --- 1.7669520378112793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:52 Training loss at epoch 2 step 11070: 2.79013729095459\n",
      "\n",
      " This round's valence_loss=1.2348525524139404, arousal_loss=1.1079691648483276, emotion_loss=0.8960299491882324\n",
      "\n",
      "01_20_00:52:52 Seen so far: 354272 samples\n",
      "\n",
      "01_20_00:52:52 --- 1.7160794734954834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:54 Training loss at epoch 2 step 11080: 2.972177529335022\n",
      "\n",
      " This round's valence_loss=1.1554639339447021, arousal_loss=1.1428241729736328, emotion_loss=1.1998491287231445\n",
      "\n",
      "01_20_00:52:54 Seen so far: 354592 samples\n",
      "\n",
      "01_20_00:52:54 --- 2.0103988647460938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:56 Training loss at epoch 2 step 11090: 2.8184983015060423\n",
      "\n",
      " This round's valence_loss=0.5865978598594666, arousal_loss=0.45869922637939453, emotion_loss=1.0779008865356445\n",
      "\n",
      "01_20_00:52:56 Seen so far: 354912 samples\n",
      "\n",
      "01_20_00:52:56 --- 1.5732429027557373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:52:58 Training loss at epoch 2 step 11100: 2.7435290575027467\n",
      "\n",
      " This round's valence_loss=1.3388320207595825, arousal_loss=1.1425334215164185, emotion_loss=0.6997630596160889\n",
      "\n",
      "01_20_00:52:58 Seen so far: 355232 samples\n",
      "\n",
      "01_20_00:52:58 --- 2.000196933746338 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:00 Training loss at epoch 2 step 11110: 2.8012431621551515\n",
      "\n",
      " This round's valence_loss=1.0361976623535156, arousal_loss=0.8489023447036743, emotion_loss=1.3962818384170532\n",
      "\n",
      "01_20_00:53:00 Seen so far: 355552 samples\n",
      "\n",
      "01_20_00:53:00 --- 1.6992294788360596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:01 Training loss at epoch 2 step 11120: 2.8675817966461183\n",
      "\n",
      " This round's valence_loss=0.5585426688194275, arousal_loss=0.5053060054779053, emotion_loss=0.8548005223274231\n",
      "\n",
      "01_20_00:53:01 Seen so far: 355872 samples\n",
      "\n",
      "01_20_00:53:01 --- 1.721597671508789 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:03 Training loss at epoch 2 step 11130: 3.106100392341614\n",
      "\n",
      " This round's valence_loss=0.9996404647827148, arousal_loss=0.8489264845848083, emotion_loss=1.2960476875305176\n",
      "\n",
      "01_20_00:53:03 Seen so far: 356192 samples\n",
      "\n",
      "01_20_00:53:03 --- 1.9529139995574951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:05 Training loss at epoch 2 step 11140: 3.161864733695984\n",
      "\n",
      " This round's valence_loss=0.7969387769699097, arousal_loss=0.6691591739654541, emotion_loss=0.7024729251861572\n",
      "\n",
      "01_20_00:53:05 Seen so far: 356512 samples\n",
      "\n",
      "01_20_00:53:05 --- 1.6841895580291748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:07 Training loss at epoch 2 step 11150: 2.651888918876648\n",
      "\n",
      " This round's valence_loss=0.9271759986877441, arousal_loss=0.6791282892227173, emotion_loss=0.7208184003829956\n",
      "\n",
      "01_20_00:53:07 Seen so far: 356832 samples\n",
      "\n",
      "01_20_00:53:07 --- 1.7789156436920166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:08 Training loss at epoch 2 step 11160: 3.0010607957839968\n",
      "\n",
      " This round's valence_loss=1.115441918373108, arousal_loss=0.9401165246963501, emotion_loss=0.8473615646362305\n",
      "\n",
      "01_20_00:53:08 Seen so far: 357152 samples\n",
      "\n",
      "01_20_00:53:08 --- 1.6997716426849365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:10 Training loss at epoch 2 step 11170: 3.1322813987731934\n",
      "\n",
      " This round's valence_loss=1.0121443271636963, arousal_loss=0.855826735496521, emotion_loss=1.098508596420288\n",
      "\n",
      "01_20_00:53:10 Seen so far: 357472 samples\n",
      "\n",
      "01_20_00:53:10 --- 1.8858704566955566 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:12 Training loss at epoch 2 step 11180: 3.061175060272217\n",
      "\n",
      " This round's valence_loss=1.2460923194885254, arousal_loss=1.1050870418548584, emotion_loss=1.2551953792572021\n",
      "\n",
      "01_20_00:53:12 Seen so far: 357792 samples\n",
      "\n",
      "01_20_00:53:12 --- 1.613481044769287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:14 Training loss at epoch 2 step 11190: 3.087782120704651\n",
      "\n",
      " This round's valence_loss=1.1904515027999878, arousal_loss=0.9537171721458435, emotion_loss=0.9859288334846497\n",
      "\n",
      "01_20_00:53:14 Seen so far: 358112 samples\n",
      "\n",
      "01_20_00:53:14 --- 1.9424464702606201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:16 Training loss at epoch 2 step 11200: 2.941580867767334\n",
      "\n",
      " This round's valence_loss=1.1215198040008545, arousal_loss=0.9463787078857422, emotion_loss=1.1397054195404053\n",
      "\n",
      "01_20_00:53:16 Seen so far: 358432 samples\n",
      "\n",
      "01_20_00:53:16 --- 1.7413787841796875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:18 Training loss at epoch 2 step 11210: 2.763374555110931\n",
      "\n",
      " This round's valence_loss=1.332220196723938, arousal_loss=1.2174646854400635, emotion_loss=1.0965708494186401\n",
      "\n",
      "01_20_00:53:18 Seen so far: 358752 samples\n",
      "\n",
      "01_20_00:53:18 --- 1.91448974609375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:19 Training loss at epoch 2 step 11220: 3.2220572233200073\n",
      "\n",
      " This round's valence_loss=0.9556717872619629, arousal_loss=0.7043343782424927, emotion_loss=0.9736348390579224\n",
      "\n",
      "01_20_00:53:19 Seen so far: 359072 samples\n",
      "\n",
      "01_20_00:53:19 --- 1.6587858200073242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:21 Training loss at epoch 2 step 11230: 3.1876742362976076\n",
      "\n",
      " This round's valence_loss=1.3659095764160156, arousal_loss=1.2673351764678955, emotion_loss=0.9787756204605103\n",
      "\n",
      "01_20_00:53:21 Seen so far: 359392 samples\n",
      "\n",
      "01_20_00:53:21 --- 1.6888022422790527 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:23 Training loss at epoch 2 step 11240: 3.1502121686935425\n",
      "\n",
      " This round's valence_loss=0.9441922307014465, arousal_loss=0.923676609992981, emotion_loss=0.7865821123123169\n",
      "\n",
      "01_20_00:53:23 Seen so far: 359712 samples\n",
      "\n",
      "01_20_00:53:23 --- 1.8954644203186035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:24 Training loss at epoch 2 step 11250: 2.8625460982322695\n",
      "\n",
      " This round's valence_loss=0.8045399188995361, arousal_loss=0.756431519985199, emotion_loss=1.022147297859192\n",
      "\n",
      "01_20_00:53:24 Seen so far: 360032 samples\n",
      "\n",
      "01_20_00:53:24 --- 1.6607654094696045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:26 Training loss at epoch 2 step 11260: 3.3184457063674926\n",
      "\n",
      " This round's valence_loss=1.4555549621582031, arousal_loss=1.3282139301300049, emotion_loss=1.0454449653625488\n",
      "\n",
      "01_20_00:53:26 Seen so far: 360352 samples\n",
      "\n",
      "01_20_00:53:26 --- 1.743910312652588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:28 Training loss at epoch 2 step 11270: 2.859016013145447\n",
      "\n",
      " This round's valence_loss=0.683547854423523, arousal_loss=0.6883805990219116, emotion_loss=1.158797264099121\n",
      "\n",
      "01_20_00:53:28 Seen so far: 360672 samples\n",
      "\n",
      "01_20_00:53:28 --- 1.7371904850006104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:30 Training loss at epoch 2 step 11280: 2.7004170775413514\n",
      "\n",
      " This round's valence_loss=1.546460747718811, arousal_loss=1.442591667175293, emotion_loss=0.9699170589447021\n",
      "\n",
      "01_20_00:53:30 Seen so far: 360992 samples\n",
      "\n",
      "01_20_00:53:30 --- 1.6773242950439453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:31 Training loss at epoch 2 step 11290: 2.9098628997802733\n",
      "\n",
      " This round's valence_loss=0.8274353742599487, arousal_loss=0.7049557566642761, emotion_loss=1.1591684818267822\n",
      "\n",
      "01_20_00:53:31 Seen so far: 361312 samples\n",
      "\n",
      "01_20_00:53:31 --- 1.723083257675171 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:33 Training loss at epoch 2 step 11300: 2.817959451675415\n",
      "\n",
      " This round's valence_loss=0.6136665940284729, arousal_loss=0.504839301109314, emotion_loss=1.015560507774353\n",
      "\n",
      "01_20_00:53:33 Seen so far: 361632 samples\n",
      "\n",
      "01_20_00:53:33 --- 1.8545935153961182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:35 Training loss at epoch 2 step 11310: 2.960328531265259\n",
      "\n",
      " This round's valence_loss=0.8130170106887817, arousal_loss=0.7597478032112122, emotion_loss=0.7606922388076782\n",
      "\n",
      "01_20_00:53:35 Seen so far: 361952 samples\n",
      "\n",
      "01_20_00:53:35 --- 1.9217078685760498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:37 Training loss at epoch 2 step 11320: 3.2831763505935667\n",
      "\n",
      " This round's valence_loss=1.2301409244537354, arousal_loss=1.0398544073104858, emotion_loss=0.6273474097251892\n",
      "\n",
      "01_20_00:53:37 Seen so far: 362272 samples\n",
      "\n",
      "01_20_00:53:37 --- 1.6822350025177002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:38 Training loss at epoch 2 step 11330: 3.0046218395233155\n",
      "\n",
      " This round's valence_loss=0.9265048503875732, arousal_loss=0.7381287813186646, emotion_loss=0.9309477806091309\n",
      "\n",
      "01_20_00:53:38 Seen so far: 362592 samples\n",
      "\n",
      "01_20_00:53:38 --- 1.6960768699645996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:40 Training loss at epoch 2 step 11340: 2.539410376548767\n",
      "\n",
      " This round's valence_loss=0.7011013627052307, arousal_loss=0.558288037776947, emotion_loss=1.070038080215454\n",
      "\n",
      "01_20_00:53:40 Seen so far: 362912 samples\n",
      "\n",
      "01_20_00:53:40 --- 1.7394392490386963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:42 Training loss at epoch 2 step 11350: 2.8808872222900392\n",
      "\n",
      " This round's valence_loss=1.3551793098449707, arousal_loss=1.0485594272613525, emotion_loss=0.9339497685432434\n",
      "\n",
      "01_20_00:53:42 Seen so far: 363232 samples\n",
      "\n",
      "01_20_00:53:42 --- 1.781555414199829 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:44 Training loss at epoch 2 step 11360: 2.466547358036041\n",
      "\n",
      " This round's valence_loss=0.8345999717712402, arousal_loss=0.5349562764167786, emotion_loss=0.7335563898086548\n",
      "\n",
      "01_20_00:53:44 Seen so far: 363552 samples\n",
      "\n",
      "01_20_00:53:44 --- 1.6604712009429932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:45 Training loss at epoch 2 step 11370: 3.3034526348114013\n",
      "\n",
      " This round's valence_loss=1.693404197692871, arousal_loss=1.6063807010650635, emotion_loss=1.254456877708435\n",
      "\n",
      "01_20_00:53:45 Seen so far: 363872 samples\n",
      "\n",
      "01_20_00:53:45 --- 1.709012746810913 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:47 Training loss at epoch 2 step 11380: 3.0533297777175905\n",
      "\n",
      " This round's valence_loss=1.14247727394104, arousal_loss=0.9566484689712524, emotion_loss=0.753665566444397\n",
      "\n",
      "01_20_00:53:47 Seen so far: 364192 samples\n",
      "\n",
      "01_20_00:53:47 --- 1.8042514324188232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:49 Training loss at epoch 2 step 11390: 2.9188747882843016\n",
      "\n",
      " This round's valence_loss=1.112684726715088, arousal_loss=0.9855659604072571, emotion_loss=0.9431339502334595\n",
      "\n",
      "01_20_00:53:49 Seen so far: 364512 samples\n",
      "\n",
      "01_20_00:53:49 --- 1.6912577152252197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:51 Training loss at epoch 2 step 11400: 2.8869645476341246\n",
      "\n",
      " This round's valence_loss=1.1214962005615234, arousal_loss=0.9422388076782227, emotion_loss=0.9556702375411987\n",
      "\n",
      "01_20_00:53:51 Seen so far: 364832 samples\n",
      "\n",
      "01_20_00:53:51 --- 2.030101776123047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:53 Training loss at epoch 2 step 11410: 3.0370457768440247\n",
      "\n",
      " This round's valence_loss=0.3388742208480835, arousal_loss=0.1586306095123291, emotion_loss=1.1381266117095947\n",
      "\n",
      "01_20_00:53:53 Seen so far: 365152 samples\n",
      "\n",
      "01_20_00:53:53 --- 1.8480803966522217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:54 Training loss at epoch 2 step 11420: 3.2682094097137453\n",
      "\n",
      " This round's valence_loss=1.3437178134918213, arousal_loss=1.179905891418457, emotion_loss=1.0383319854736328\n",
      "\n",
      "01_20_00:53:54 Seen so far: 365472 samples\n",
      "\n",
      "01_20_00:53:54 --- 1.6471290588378906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:56 Training loss at epoch 2 step 11430: 3.091592526435852\n",
      "\n",
      " This round's valence_loss=1.1431810855865479, arousal_loss=0.9256840944290161, emotion_loss=1.1768479347229004\n",
      "\n",
      "01_20_00:53:56 Seen so far: 365792 samples\n",
      "\n",
      "01_20_00:53:56 --- 1.9042637348175049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:53:58 Training loss at epoch 2 step 11440: 2.8389362573623655\n",
      "\n",
      " This round's valence_loss=1.0826029777526855, arousal_loss=0.9307519793510437, emotion_loss=0.9870567917823792\n",
      "\n",
      "01_20_00:53:58 Seen so far: 366112 samples\n",
      "\n",
      "01_20_00:53:58 --- 1.7722766399383545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:00 Training loss at epoch 2 step 11450: 2.7715940475463867\n",
      "\n",
      " This round's valence_loss=1.2906620502471924, arousal_loss=1.1803793907165527, emotion_loss=0.8041052222251892\n",
      "\n",
      "01_20_00:54:00 Seen so far: 366432 samples\n",
      "\n",
      "01_20_00:54:00 --- 1.8034954071044922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:02 Training loss at epoch 2 step 11460: 3.124696207046509\n",
      "\n",
      " This round's valence_loss=1.2671260833740234, arousal_loss=1.2011466026306152, emotion_loss=0.4690181612968445\n",
      "\n",
      "01_20_00:54:02 Seen so far: 366752 samples\n",
      "\n",
      "01_20_00:54:02 --- 1.7354154586791992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:03 Training loss at epoch 2 step 11470: 2.935961103439331\n",
      "\n",
      " This round's valence_loss=1.1724448204040527, arousal_loss=1.117243766784668, emotion_loss=0.8974176645278931\n",
      "\n",
      "01_20_00:54:03 Seen so far: 367072 samples\n",
      "\n",
      "01_20_00:54:03 --- 1.7532377243041992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:05 Training loss at epoch 2 step 11480: 3.0001885652542115\n",
      "\n",
      " This round's valence_loss=1.2026519775390625, arousal_loss=1.105882167816162, emotion_loss=0.9198576211929321\n",
      "\n",
      "01_20_00:54:05 Seen so far: 367392 samples\n",
      "\n",
      "01_20_00:54:05 --- 1.807523488998413 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:07 Training loss at epoch 2 step 11490: 3.5352242469787596\n",
      "\n",
      " This round's valence_loss=1.188326358795166, arousal_loss=1.111568808555603, emotion_loss=1.1470993757247925\n",
      "\n",
      "01_20_00:54:07 Seen so far: 367712 samples\n",
      "\n",
      "01_20_00:54:07 --- 1.776555061340332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:09 Training loss at epoch 2 step 11500: 2.85338933467865\n",
      "\n",
      " This round's valence_loss=0.8581173419952393, arousal_loss=0.725793719291687, emotion_loss=0.8970580697059631\n",
      "\n",
      "01_20_00:54:09 Seen so far: 368032 samples\n",
      "\n",
      "01_20_00:54:09 --- 1.8582940101623535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:11 Training loss at epoch 2 step 11510: 3.2083957195281982\n",
      "\n",
      " This round's valence_loss=1.6078081130981445, arousal_loss=1.439589023590088, emotion_loss=1.1621158123016357\n",
      "\n",
      "01_20_00:54:11 Seen so far: 368352 samples\n",
      "\n",
      "01_20_00:54:11 --- 1.7255218029022217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:12 Training loss at epoch 2 step 11520: 3.2271864652633666\n",
      "\n",
      " This round's valence_loss=1.1388823986053467, arousal_loss=0.9313490390777588, emotion_loss=0.9008381366729736\n",
      "\n",
      "01_20_00:54:12 Seen so far: 368672 samples\n",
      "\n",
      "01_20_00:54:12 --- 1.8858835697174072 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:14 Training loss at epoch 2 step 11530: 2.8140587329864504\n",
      "\n",
      " This round's valence_loss=1.3017586469650269, arousal_loss=1.2021411657333374, emotion_loss=0.8639438152313232\n",
      "\n",
      "01_20_00:54:14 Seen so far: 368992 samples\n",
      "\n",
      "01_20_00:54:14 --- 2.04923939704895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:16 Training loss at epoch 2 step 11540: 2.829450273513794\n",
      "\n",
      " This round's valence_loss=1.2722580432891846, arousal_loss=1.1081502437591553, emotion_loss=1.033996820449829\n",
      "\n",
      "01_20_00:54:16 Seen so far: 369312 samples\n",
      "\n",
      "01_20_00:54:16 --- 1.8906691074371338 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:18 Training loss at epoch 2 step 11550: 2.8328577041625977\n",
      "\n",
      " This round's valence_loss=0.7322028875350952, arousal_loss=0.6714528799057007, emotion_loss=0.9696105718612671\n",
      "\n",
      "01_20_00:54:18 Seen so far: 369632 samples\n",
      "\n",
      "01_20_00:54:18 --- 1.7584588527679443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:20 Training loss at epoch 2 step 11560: 3.115502214431763\n",
      "\n",
      " This round's valence_loss=0.9781773686408997, arousal_loss=0.8340147137641907, emotion_loss=0.820550262928009\n",
      "\n",
      "01_20_00:54:20 Seen so far: 369952 samples\n",
      "\n",
      "01_20_00:54:20 --- 1.7339835166931152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:22 Training loss at epoch 2 step 11570: 3.0761650085449217\n",
      "\n",
      " This round's valence_loss=1.0058739185333252, arousal_loss=0.8753455877304077, emotion_loss=1.0625033378601074\n",
      "\n",
      "01_20_00:54:22 Seen so far: 370272 samples\n",
      "\n",
      "01_20_00:54:22 --- 1.930068016052246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:23 Training loss at epoch 2 step 11580: 2.9210678339004517\n",
      "\n",
      " This round's valence_loss=1.4991912841796875, arousal_loss=1.324462652206421, emotion_loss=0.9597892761230469\n",
      "\n",
      "01_20_00:54:23 Seen so far: 370592 samples\n",
      "\n",
      "01_20_00:54:23 --- 1.6879591941833496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:25 Training loss at epoch 2 step 11590: 2.965398383140564\n",
      "\n",
      " This round's valence_loss=0.746830940246582, arousal_loss=0.6250479817390442, emotion_loss=0.8440621495246887\n",
      "\n",
      "01_20_00:54:25 Seen so far: 370912 samples\n",
      "\n",
      "01_20_00:54:25 --- 1.731274127960205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:27 Training loss at epoch 2 step 11600: 2.9234738111495973\n",
      "\n",
      " This round's valence_loss=1.2006064653396606, arousal_loss=1.1013857126235962, emotion_loss=1.0874676704406738\n",
      "\n",
      "01_20_00:54:27 Seen so far: 371232 samples\n",
      "\n",
      "01_20_00:54:27 --- 1.9804844856262207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:29 Training loss at epoch 2 step 11610: 2.7477773785591126\n",
      "\n",
      " This round's valence_loss=0.9449163675308228, arousal_loss=0.8005135655403137, emotion_loss=0.6918181777000427\n",
      "\n",
      "01_20_00:54:29 Seen so far: 371552 samples\n",
      "\n",
      "01_20_00:54:29 --- 1.7266747951507568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:31 Training loss at epoch 2 step 11620: 3.072634291648865\n",
      "\n",
      " This round's valence_loss=1.2746765613555908, arousal_loss=1.2051280736923218, emotion_loss=0.887678861618042\n",
      "\n",
      "01_20_00:54:31 Seen so far: 371872 samples\n",
      "\n",
      "01_20_00:54:31 --- 1.9225125312805176 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:33 Training loss at epoch 2 step 11630: 3.2613556146621705\n",
      "\n",
      " This round's valence_loss=1.4266853332519531, arousal_loss=1.3301044702529907, emotion_loss=0.9700656533241272\n",
      "\n",
      "01_20_00:54:33 Seen so far: 372192 samples\n",
      "\n",
      "01_20_00:54:33 --- 1.6636240482330322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:34 Training loss at epoch 2 step 11640: 2.8762301445007323\n",
      "\n",
      " This round's valence_loss=1.0892491340637207, arousal_loss=0.9771944284439087, emotion_loss=0.8706357479095459\n",
      "\n",
      "01_20_00:54:34 Seen so far: 372512 samples\n",
      "\n",
      "01_20_00:54:34 --- 1.8071584701538086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:36 Training loss at epoch 2 step 11650: 3.0899572134017945\n",
      "\n",
      " This round's valence_loss=0.912866473197937, arousal_loss=0.8981657028198242, emotion_loss=1.2223961353302002\n",
      "\n",
      "01_20_00:54:36 Seen so far: 372832 samples\n",
      "\n",
      "01_20_00:54:36 --- 1.717968463897705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:38 Training loss at epoch 2 step 11660: 3.2617671489715576\n",
      "\n",
      " This round's valence_loss=1.8188955783843994, arousal_loss=1.6540558338165283, emotion_loss=0.7509418725967407\n",
      "\n",
      "01_20_00:54:38 Seen so far: 373152 samples\n",
      "\n",
      "01_20_00:54:38 --- 1.735344648361206 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:39 Training loss at epoch 2 step 11670: 3.151242971420288\n",
      "\n",
      " This round's valence_loss=1.035236120223999, arousal_loss=0.8657447099685669, emotion_loss=0.6408803462982178\n",
      "\n",
      "01_20_00:54:39 Seen so far: 373472 samples\n",
      "\n",
      "01_20_00:54:39 --- 1.683241605758667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:41 Training loss at epoch 2 step 11680: 2.9799251556396484\n",
      "\n",
      " This round's valence_loss=1.3652092218399048, arousal_loss=1.203598976135254, emotion_loss=1.073965072631836\n",
      "\n",
      "01_20_00:54:41 Seen so far: 373792 samples\n",
      "\n",
      "01_20_00:54:41 --- 1.8530035018920898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:43 Training loss at epoch 2 step 11690: 3.2705259799957274\n",
      "\n",
      " This round's valence_loss=1.015129566192627, arousal_loss=0.8305995464324951, emotion_loss=0.846591591835022\n",
      "\n",
      "01_20_00:54:43 Seen so far: 374112 samples\n",
      "\n",
      "01_20_00:54:43 --- 1.8147227764129639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:45 Training loss at epoch 2 step 11700: 2.8523751497268677\n",
      "\n",
      " This round's valence_loss=0.8000304698944092, arousal_loss=0.6998135447502136, emotion_loss=1.3238797187805176\n",
      "\n",
      "01_20_00:54:45 Seen so far: 374432 samples\n",
      "\n",
      "01_20_00:54:45 --- 1.6730942726135254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:46 Training loss at epoch 2 step 11710: 3.2569183588027952\n",
      "\n",
      " This round's valence_loss=1.2106761932373047, arousal_loss=1.1246249675750732, emotion_loss=1.196354627609253\n",
      "\n",
      "01_20_00:54:46 Seen so far: 374752 samples\n",
      "\n",
      "01_20_00:54:46 --- 1.6894371509552002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:48 Training loss at epoch 2 step 11720: 3.0570189237594603\n",
      "\n",
      " This round's valence_loss=0.7970572710037231, arousal_loss=0.804146409034729, emotion_loss=1.2565088272094727\n",
      "\n",
      "01_20_00:54:48 Seen so far: 375072 samples\n",
      "\n",
      "01_20_00:54:48 --- 1.885103702545166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:50 Training loss at epoch 2 step 11730: 2.4633565664291384\n",
      "\n",
      " This round's valence_loss=0.6255711317062378, arousal_loss=0.45653823018074036, emotion_loss=0.9890987873077393\n",
      "\n",
      "01_20_00:54:50 Seen so far: 375392 samples\n",
      "\n",
      "01_20_00:54:50 --- 1.9369134902954102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:52 Training loss at epoch 2 step 11740: 2.995582342147827\n",
      "\n",
      " This round's valence_loss=1.2310662269592285, arousal_loss=1.0959789752960205, emotion_loss=1.2301924228668213\n",
      "\n",
      "01_20_00:54:52 Seen so far: 375712 samples\n",
      "\n",
      "01_20_00:54:52 --- 1.7972867488861084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:54 Training loss at epoch 2 step 11750: 3.0223083019256594\n",
      "\n",
      " This round's valence_loss=1.0381028652191162, arousal_loss=0.8365864753723145, emotion_loss=0.6405513286590576\n",
      "\n",
      "01_20_00:54:54 Seen so far: 376032 samples\n",
      "\n",
      "01_20_00:54:54 --- 1.9534001350402832 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:56 Training loss at epoch 2 step 11760: 2.6611481428146364\n",
      "\n",
      " This round's valence_loss=1.1473511457443237, arousal_loss=0.9465128779411316, emotion_loss=0.3640815317630768\n",
      "\n",
      "01_20_00:54:56 Seen so far: 376352 samples\n",
      "\n",
      "01_20_00:54:56 --- 1.9486074447631836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:54:58 Training loss at epoch 2 step 11770: 2.990199875831604\n",
      "\n",
      " This round's valence_loss=1.0225021839141846, arousal_loss=0.776877760887146, emotion_loss=0.8993315696716309\n",
      "\n",
      "01_20_00:54:58 Seen so far: 376672 samples\n",
      "\n",
      "01_20_00:54:58 --- 1.7751219272613525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:00 Training loss at epoch 2 step 11780: 2.5663572669029238\n",
      "\n",
      " This round's valence_loss=1.1122963428497314, arousal_loss=0.9512429237365723, emotion_loss=0.8459619283676147\n",
      "\n",
      "01_20_00:55:00 Seen so far: 376992 samples\n",
      "\n",
      "01_20_00:55:00 --- 1.9062364101409912 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:02 Training loss at epoch 2 step 11790: 3.0920284509658815\n",
      "\n",
      " This round's valence_loss=1.4442846775054932, arousal_loss=1.309619665145874, emotion_loss=1.179389476776123\n",
      "\n",
      "01_20_00:55:02 Seen so far: 377312 samples\n",
      "\n",
      "01_20_00:55:02 --- 1.8507933616638184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:03 Training loss at epoch 2 step 11800: 2.849385380744934\n",
      "\n",
      " This round's valence_loss=0.9512032270431519, arousal_loss=0.828544020652771, emotion_loss=0.9713137149810791\n",
      "\n",
      "01_20_00:55:03 Seen so far: 377632 samples\n",
      "\n",
      "01_20_00:55:03 --- 1.7577838897705078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:05 Training loss at epoch 2 step 11810: 2.7902416229248046\n",
      "\n",
      " This round's valence_loss=0.7551736831665039, arousal_loss=0.5491578578948975, emotion_loss=0.583777904510498\n",
      "\n",
      "01_20_00:55:05 Seen so far: 377952 samples\n",
      "\n",
      "01_20_00:55:05 --- 1.8825459480285645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:07 Training loss at epoch 2 step 11820: 3.0489598751068114\n",
      "\n",
      " This round's valence_loss=1.452136754989624, arousal_loss=1.3292205333709717, emotion_loss=0.9463748931884766\n",
      "\n",
      "01_20_00:55:07 Seen so far: 378272 samples\n",
      "\n",
      "01_20_00:55:07 --- 1.656635046005249 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:09 Training loss at epoch 2 step 11830: 2.8811684370040895\n",
      "\n",
      " This round's valence_loss=1.4245765209197998, arousal_loss=1.3039813041687012, emotion_loss=1.2183021306991577\n",
      "\n",
      "01_20_00:55:09 Seen so far: 378592 samples\n",
      "\n",
      "01_20_00:55:09 --- 1.7613322734832764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:10 Training loss at epoch 2 step 11840: 3.282179093360901\n",
      "\n",
      " This round's valence_loss=0.7990838885307312, arousal_loss=0.7047597169876099, emotion_loss=0.732698380947113\n",
      "\n",
      "01_20_00:55:10 Seen so far: 378912 samples\n",
      "\n",
      "01_20_00:55:10 --- 1.801408052444458 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:12 Training loss at epoch 2 step 11850: 3.3719451665878295\n",
      "\n",
      " This round's valence_loss=1.2046270370483398, arousal_loss=0.9567395448684692, emotion_loss=0.828837513923645\n",
      "\n",
      "01_20_00:55:12 Seen so far: 379232 samples\n",
      "\n",
      "01_20_00:55:12 --- 1.5976276397705078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:14 Training loss at epoch 2 step 11860: 3.0961953163146974\n",
      "\n",
      " This round's valence_loss=1.4243278503417969, arousal_loss=1.3091516494750977, emotion_loss=0.9798585772514343\n",
      "\n",
      "01_20_00:55:14 Seen so far: 379552 samples\n",
      "\n",
      "01_20_00:55:14 --- 1.8875720500946045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:16 Training loss at epoch 2 step 11870: 2.784649395942688\n",
      "\n",
      " This round's valence_loss=0.6511809229850769, arousal_loss=0.6241159439086914, emotion_loss=0.9828565120697021\n",
      "\n",
      "01_20_00:55:16 Seen so far: 379872 samples\n",
      "\n",
      "01_20_00:55:16 --- 1.7049665451049805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:17 Training loss at epoch 2 step 11880: 2.905922508239746\n",
      "\n",
      " This round's valence_loss=1.0648075342178345, arousal_loss=0.9958236217498779, emotion_loss=1.1253784894943237\n",
      "\n",
      "01_20_00:55:17 Seen so far: 380192 samples\n",
      "\n",
      "01_20_00:55:17 --- 1.7682297229766846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:19 Training loss at epoch 2 step 11890: 3.0952856063842775\n",
      "\n",
      " This round's valence_loss=1.1057846546173096, arousal_loss=1.0215095281600952, emotion_loss=0.909473180770874\n",
      "\n",
      "01_20_00:55:19 Seen so far: 380512 samples\n",
      "\n",
      "01_20_00:55:19 --- 1.6900241374969482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:21 Training loss at epoch 2 step 11900: 2.804606866836548\n",
      "\n",
      " This round's valence_loss=0.7435808181762695, arousal_loss=0.563724160194397, emotion_loss=0.7024304866790771\n",
      "\n",
      "01_20_00:55:21 Seen so far: 380832 samples\n",
      "\n",
      "01_20_00:55:21 --- 1.6935749053955078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:23 Training loss at epoch 2 step 11910: 3.0077107667922975\n",
      "\n",
      " This round's valence_loss=1.5059560537338257, arousal_loss=1.2842166423797607, emotion_loss=0.6275343298912048\n",
      "\n",
      "01_20_00:55:23 Seen so far: 381152 samples\n",
      "\n",
      "01_20_00:55:23 --- 1.9572882652282715 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:25 Training loss at epoch 2 step 11920: 2.8662944555282595\n",
      "\n",
      " This round's valence_loss=1.0625038146972656, arousal_loss=0.9860831499099731, emotion_loss=0.6695897579193115\n",
      "\n",
      "01_20_00:55:25 Seen so far: 381472 samples\n",
      "\n",
      "01_20_00:55:25 --- 1.9745848178863525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:26 Training loss at epoch 2 step 11930: 3.0661510229110718\n",
      "\n",
      " This round's valence_loss=0.955584704875946, arousal_loss=0.8574466109275818, emotion_loss=0.8417147397994995\n",
      "\n",
      "01_20_00:55:26 Seen so far: 381792 samples\n",
      "\n",
      "01_20_00:55:26 --- 1.6707098484039307 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:28 Training loss at epoch 2 step 11940: 2.865439939498901\n",
      "\n",
      " This round's valence_loss=1.5933985710144043, arousal_loss=1.4628374576568604, emotion_loss=0.9337736964225769\n",
      "\n",
      "01_20_00:55:28 Seen so far: 382112 samples\n",
      "\n",
      "01_20_00:55:28 --- 1.769838571548462 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:30 Training loss at epoch 2 step 11950: 3.2543800830841065\n",
      "\n",
      " This round's valence_loss=1.2632519006729126, arousal_loss=1.1689891815185547, emotion_loss=1.0902129411697388\n",
      "\n",
      "01_20_00:55:30 Seen so far: 382432 samples\n",
      "\n",
      "01_20_00:55:30 --- 1.7724676132202148 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:32 Training loss at epoch 2 step 11960: 2.942939043045044\n",
      "\n",
      " This round's valence_loss=1.283125877380371, arousal_loss=1.0761948823928833, emotion_loss=0.7150875329971313\n",
      "\n",
      "01_20_00:55:32 Seen so far: 382752 samples\n",
      "\n",
      "01_20_00:55:32 --- 2.148622751235962 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:34 Training loss at epoch 2 step 11970: 3.0196179866790773\n",
      "\n",
      " This round's valence_loss=0.5995616912841797, arousal_loss=0.5054816603660583, emotion_loss=1.0297062397003174\n",
      "\n",
      "01_20_00:55:34 Seen so far: 383072 samples\n",
      "\n",
      "01_20_00:55:34 --- 1.8143165111541748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:36 Training loss at epoch 2 step 11980: 2.81239800453186\n",
      "\n",
      " This round's valence_loss=1.095754861831665, arousal_loss=0.9619119167327881, emotion_loss=1.1702477931976318\n",
      "\n",
      "01_20_00:55:36 Seen so far: 383392 samples\n",
      "\n",
      "01_20_00:55:36 --- 1.876934289932251 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:37 Training loss at epoch 2 step 11990: 3.094882273674011\n",
      "\n",
      " This round's valence_loss=1.0481853485107422, arousal_loss=0.9405885338783264, emotion_loss=0.7499306797981262\n",
      "\n",
      "01_20_00:55:37 Seen so far: 383712 samples\n",
      "\n",
      "01_20_00:55:37 --- 1.6551012992858887 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:39 Training loss at epoch 2 step 12000: 2.69977685213089\n",
      "\n",
      " This round's valence_loss=1.0486770868301392, arousal_loss=0.8011130094528198, emotion_loss=0.8284028768539429\n",
      "\n",
      "01_20_00:55:39 Seen so far: 384032 samples\n",
      "\n",
      "01_20_00:55:39 --- 1.7618041038513184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:41 Training loss at epoch 2 step 12010: 3.0805133104324343\n",
      "\n",
      " This round's valence_loss=1.152750015258789, arousal_loss=1.0971299409866333, emotion_loss=0.9396456480026245\n",
      "\n",
      "01_20_00:55:41 Seen so far: 384352 samples\n",
      "\n",
      "01_20_00:55:41 --- 1.7375829219818115 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:43 Training loss at epoch 2 step 12020: 3.0571306705474854\n",
      "\n",
      " This round's valence_loss=0.8992877006530762, arousal_loss=0.7021563053131104, emotion_loss=0.955630898475647\n",
      "\n",
      "01_20_00:55:43 Seen so far: 384672 samples\n",
      "\n",
      "01_20_00:55:43 --- 1.7581861019134521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:45 Training loss at epoch 2 step 12030: 2.973578929901123\n",
      "\n",
      " This round's valence_loss=1.1226451396942139, arousal_loss=0.9412280917167664, emotion_loss=0.6093564033508301\n",
      "\n",
      "01_20_00:55:45 Seen so far: 384992 samples\n",
      "\n",
      "01_20_00:55:45 --- 1.9618966579437256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:46 Training loss at epoch 2 step 12040: 2.536411428451538\n",
      "\n",
      " This round's valence_loss=1.3241016864776611, arousal_loss=1.2712509632110596, emotion_loss=1.1901776790618896\n",
      "\n",
      "01_20_00:55:46 Seen so far: 385312 samples\n",
      "\n",
      "01_20_00:55:46 --- 1.854576826095581 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:48 Training loss at epoch 2 step 12050: 2.7526410818099976\n",
      "\n",
      " This round's valence_loss=0.9214745759963989, arousal_loss=0.7069333791732788, emotion_loss=0.8919776678085327\n",
      "\n",
      "01_20_00:55:48 Seen so far: 385632 samples\n",
      "\n",
      "01_20_00:55:48 --- 1.7674047946929932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:50 Training loss at epoch 2 step 12060: 3.273580479621887\n",
      "\n",
      " This round's valence_loss=1.3338398933410645, arousal_loss=1.2022666931152344, emotion_loss=1.1541866064071655\n",
      "\n",
      "01_20_00:55:50 Seen so far: 385952 samples\n",
      "\n",
      "01_20_00:55:50 --- 1.7059657573699951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:52 Training loss at epoch 2 step 12070: 2.912115287780762\n",
      "\n",
      " This round's valence_loss=1.0867559909820557, arousal_loss=0.9340940713882446, emotion_loss=0.8465334177017212\n",
      "\n",
      "01_20_00:55:52 Seen so far: 386272 samples\n",
      "\n",
      "01_20_00:55:52 --- 1.826979637145996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:54 Training loss at epoch 2 step 12080: 3.1911970376968384\n",
      "\n",
      " This round's valence_loss=0.8988394737243652, arousal_loss=0.5631074905395508, emotion_loss=1.3545019626617432\n",
      "\n",
      "01_20_00:55:54 Seen so far: 386592 samples\n",
      "\n",
      "01_20_00:55:54 --- 1.745408535003662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:55 Training loss at epoch 2 step 12090: 3.1452459573745726\n",
      "\n",
      " This round's valence_loss=1.4391493797302246, arousal_loss=1.3395037651062012, emotion_loss=1.136120319366455\n",
      "\n",
      "01_20_00:55:55 Seen so far: 386912 samples\n",
      "\n",
      "01_20_00:55:55 --- 1.6170427799224854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:57 Training loss at epoch 2 step 12100: 2.966623568534851\n",
      "\n",
      " This round's valence_loss=0.7740360498428345, arousal_loss=0.577306866645813, emotion_loss=0.9191339612007141\n",
      "\n",
      "01_20_00:55:57 Seen so far: 387232 samples\n",
      "\n",
      "01_20_00:55:57 --- 1.7362048625946045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:55:59 Training loss at epoch 2 step 12110: 2.9666898012161256\n",
      "\n",
      " This round's valence_loss=1.2746765613555908, arousal_loss=1.0482878684997559, emotion_loss=0.837244987487793\n",
      "\n",
      "01_20_00:55:59 Seen so far: 387552 samples\n",
      "\n",
      "01_20_00:55:59 --- 1.7107505798339844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:00 Training loss at epoch 2 step 12120: 2.9763286113739014\n",
      "\n",
      " This round's valence_loss=1.533402681350708, arousal_loss=1.479196310043335, emotion_loss=1.0071558952331543\n",
      "\n",
      "01_20_00:56:00 Seen so far: 387872 samples\n",
      "\n",
      "01_20_00:56:00 --- 1.7391595840454102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:02 Training loss at epoch 2 step 12130: 2.911132335662842\n",
      "\n",
      " This round's valence_loss=1.121585726737976, arousal_loss=0.9657142162322998, emotion_loss=1.076094388961792\n",
      "\n",
      "01_20_00:56:02 Seen so far: 388192 samples\n",
      "\n",
      "01_20_00:56:02 --- 1.7837913036346436 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:04 Training loss at epoch 2 step 12140: 2.90813148021698\n",
      "\n",
      " This round's valence_loss=1.075944185256958, arousal_loss=0.9640159606933594, emotion_loss=1.2542005777359009\n",
      "\n",
      "01_20_00:56:04 Seen so far: 388512 samples\n",
      "\n",
      "01_20_00:56:04 --- 1.7774426937103271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:06 Training loss at epoch 2 step 12150: 2.8001392245292664\n",
      "\n",
      " This round's valence_loss=1.5163339376449585, arousal_loss=1.3245437145233154, emotion_loss=0.6331310272216797\n",
      "\n",
      "01_20_00:56:06 Seen so far: 388832 samples\n",
      "\n",
      "01_20_00:56:06 --- 1.9110643863677979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:08 Training loss at epoch 2 step 12160: 3.3141434669494627\n",
      "\n",
      " This round's valence_loss=1.7864453792572021, arousal_loss=1.548179030418396, emotion_loss=0.8044008016586304\n",
      "\n",
      "01_20_00:56:08 Seen so far: 389152 samples\n",
      "\n",
      "01_20_00:56:08 --- 1.8489151000976562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:09 Training loss at epoch 2 step 12170: 2.879811668395996\n",
      "\n",
      " This round's valence_loss=0.7657749652862549, arousal_loss=0.5819672346115112, emotion_loss=0.8771729469299316\n",
      "\n",
      "01_20_00:56:09 Seen so far: 389472 samples\n",
      "\n",
      "01_20_00:56:09 --- 1.7437236309051514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:11 Training loss at epoch 2 step 12180: 2.779651379585266\n",
      "\n",
      " This round's valence_loss=0.9753713607788086, arousal_loss=0.8110411167144775, emotion_loss=0.4613204002380371\n",
      "\n",
      "01_20_00:56:11 Seen so far: 389792 samples\n",
      "\n",
      "01_20_00:56:11 --- 1.622986078262329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:13 Training loss at epoch 2 step 12190: 3.028855288028717\n",
      "\n",
      " This round's valence_loss=0.8689931035041809, arousal_loss=0.6893060803413391, emotion_loss=0.7406543493270874\n",
      "\n",
      "01_20_00:56:13 Seen so far: 390112 samples\n",
      "\n",
      "01_20_00:56:13 --- 2.137857675552368 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:15 Training loss at epoch 2 step 12200: 3.035539174079895\n",
      "\n",
      " This round's valence_loss=1.1234838962554932, arousal_loss=0.9413367509841919, emotion_loss=1.0361895561218262\n",
      "\n",
      "01_20_00:56:15 Seen so far: 390432 samples\n",
      "\n",
      "01_20_00:56:15 --- 1.7350273132324219 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:17 Training loss at epoch 2 step 12210: 2.6681490659713747\n",
      "\n",
      " This round's valence_loss=0.7166074514389038, arousal_loss=0.5946694612503052, emotion_loss=1.0072141885757446\n",
      "\n",
      "01_20_00:56:17 Seen so far: 390752 samples\n",
      "\n",
      "01_20_00:56:17 --- 1.8409278392791748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:18 Training loss at epoch 2 step 12220: 3.350247931480408\n",
      "\n",
      " This round's valence_loss=1.0647985935211182, arousal_loss=0.8626210689544678, emotion_loss=0.6666957139968872\n",
      "\n",
      "01_20_00:56:18 Seen so far: 391072 samples\n",
      "\n",
      "01_20_00:56:18 --- 1.5307528972625732 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:20 Training loss at epoch 2 step 12230: 2.9668029069900514\n",
      "\n",
      " This round's valence_loss=0.9471095204353333, arousal_loss=0.7979880571365356, emotion_loss=0.761493980884552\n",
      "\n",
      "01_20_00:56:20 Seen so far: 391392 samples\n",
      "\n",
      "01_20_00:56:20 --- 1.7430243492126465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:22 Training loss at epoch 2 step 12240: 2.9273617029190064\n",
      "\n",
      " This round's valence_loss=1.2671291828155518, arousal_loss=1.0985219478607178, emotion_loss=0.9347901344299316\n",
      "\n",
      "01_20_00:56:22 Seen so far: 391712 samples\n",
      "\n",
      "01_20_00:56:22 --- 1.745469331741333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:23 Training loss at epoch 2 step 12250: 3.137945365905762\n",
      "\n",
      " This round's valence_loss=1.5039831399917603, arousal_loss=1.268634557723999, emotion_loss=0.9554060697555542\n",
      "\n",
      "01_20_00:56:23 Seen so far: 392032 samples\n",
      "\n",
      "01_20_00:56:23 --- 1.5857248306274414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:25 Training loss at epoch 2 step 12260: 3.4480257749557497\n",
      "\n",
      " This round's valence_loss=1.4981133937835693, arousal_loss=1.3226525783538818, emotion_loss=0.9455372095108032\n",
      "\n",
      "01_20_00:56:25 Seen so far: 392352 samples\n",
      "\n",
      "01_20_00:56:25 --- 1.9247894287109375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:27 Training loss at epoch 2 step 12270: 2.679516649246216\n",
      "\n",
      " This round's valence_loss=0.8571341037750244, arousal_loss=0.7218387722969055, emotion_loss=0.8957477807998657\n",
      "\n",
      "01_20_00:56:27 Seen so far: 392672 samples\n",
      "\n",
      "01_20_00:56:27 --- 2.1680750846862793 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:29 Training loss at epoch 2 step 12280: 2.9296195983886717\n",
      "\n",
      " This round's valence_loss=0.8895734548568726, arousal_loss=0.6914982795715332, emotion_loss=0.9166528582572937\n",
      "\n",
      "01_20_00:56:29 Seen so far: 392992 samples\n",
      "\n",
      "01_20_00:56:29 --- 1.816094160079956 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:31 Training loss at epoch 2 step 12290: 3.2492801666259767\n",
      "\n",
      " This round's valence_loss=1.068521499633789, arousal_loss=0.9449875354766846, emotion_loss=0.7266095280647278\n",
      "\n",
      "01_20_00:56:31 Seen so far: 393312 samples\n",
      "\n",
      "01_20_00:56:31 --- 1.6855778694152832 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:33 Training loss at epoch 2 step 12300: 2.7416393518447877\n",
      "\n",
      " This round's valence_loss=1.207314133644104, arousal_loss=1.0685782432556152, emotion_loss=1.0869617462158203\n",
      "\n",
      "01_20_00:56:33 Seen so far: 393632 samples\n",
      "\n",
      "01_20_00:56:33 --- 1.8050591945648193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:34 Training loss at epoch 2 step 12310: 2.896390438079834\n",
      "\n",
      " This round's valence_loss=1.0053224563598633, arousal_loss=0.8328408002853394, emotion_loss=0.8007433414459229\n",
      "\n",
      "01_20_00:56:34 Seen so far: 393952 samples\n",
      "\n",
      "01_20_00:56:34 --- 1.6991372108459473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:36 Training loss at epoch 2 step 12320: 2.745147442817688\n",
      "\n",
      " This round's valence_loss=0.9072065949440002, arousal_loss=0.7154924869537354, emotion_loss=0.9945399761199951\n",
      "\n",
      "01_20_00:56:36 Seen so far: 394272 samples\n",
      "\n",
      "01_20_00:56:36 --- 1.7148973941802979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:38 Training loss at epoch 2 step 12330: 3.1387189388275147\n",
      "\n",
      " This round's valence_loss=1.5377933979034424, arousal_loss=1.31089186668396, emotion_loss=1.1735446453094482\n",
      "\n",
      "01_20_00:56:38 Seen so far: 394592 samples\n",
      "\n",
      "01_20_00:56:38 --- 1.708554983139038 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:40 Training loss at epoch 2 step 12340: 3.1654608249664307\n",
      "\n",
      " This round's valence_loss=0.9687765836715698, arousal_loss=0.8331153392791748, emotion_loss=1.0789356231689453\n",
      "\n",
      "01_20_00:56:40 Seen so far: 394912 samples\n",
      "\n",
      "01_20_00:56:40 --- 1.7419672012329102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:41 Training loss at epoch 2 step 12350: 3.313365626335144\n",
      "\n",
      " This round's valence_loss=1.73868989944458, arousal_loss=1.7324763536453247, emotion_loss=1.2433809041976929\n",
      "\n",
      "01_20_00:56:41 Seen so far: 395232 samples\n",
      "\n",
      "01_20_00:56:41 --- 1.749194860458374 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:43 Training loss at epoch 2 step 12360: 2.9907472252845766\n",
      "\n",
      " This round's valence_loss=0.6684005260467529, arousal_loss=0.461922824382782, emotion_loss=0.8651045560836792\n",
      "\n",
      "01_20_00:56:43 Seen so far: 395552 samples\n",
      "\n",
      "01_20_00:56:43 --- 1.8665571212768555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:45 Training loss at epoch 2 step 12370: 2.887768816947937\n",
      "\n",
      " This round's valence_loss=0.4834028482437134, arousal_loss=0.37781822681427, emotion_loss=0.6947238445281982\n",
      "\n",
      "01_20_00:56:45 Seen so far: 395872 samples\n",
      "\n",
      "01_20_00:56:45 --- 1.9358601570129395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:47 Training loss at epoch 2 step 12380: 2.993837904930115\n",
      "\n",
      " This round's valence_loss=0.7255170941352844, arousal_loss=0.6070961356163025, emotion_loss=0.9746475219726562\n",
      "\n",
      "01_20_00:56:47 Seen so far: 396192 samples\n",
      "\n",
      "01_20_00:56:47 --- 1.8283672332763672 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:49 Training loss at epoch 2 step 12390: 2.9473817586898803\n",
      "\n",
      " This round's valence_loss=1.1390187740325928, arousal_loss=0.9690345525741577, emotion_loss=1.097029685974121\n",
      "\n",
      "01_20_00:56:49 Seen so far: 396512 samples\n",
      "\n",
      "01_20_00:56:49 --- 1.743194341659546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:51 Training loss at epoch 2 step 12400: 2.832151198387146\n",
      "\n",
      " This round's valence_loss=1.23213791847229, arousal_loss=1.0494599342346191, emotion_loss=0.892707347869873\n",
      "\n",
      "01_20_00:56:51 Seen so far: 396832 samples\n",
      "\n",
      "01_20_00:56:51 --- 1.8138761520385742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:52 Training loss at epoch 2 step 12410: 2.995788097381592\n",
      "\n",
      " This round's valence_loss=1.0909481048583984, arousal_loss=0.9637270569801331, emotion_loss=1.2207798957824707\n",
      "\n",
      "01_20_00:56:52 Seen so far: 397152 samples\n",
      "\n",
      "01_20_00:56:52 --- 1.8504273891448975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:54 Training loss at epoch 2 step 12420: 2.855812931060791\n",
      "\n",
      " This round's valence_loss=0.6621809601783752, arousal_loss=0.48947566747665405, emotion_loss=0.9204083681106567\n",
      "\n",
      "01_20_00:56:54 Seen so far: 397472 samples\n",
      "\n",
      "01_20_00:56:54 --- 1.5587716102600098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:56 Training loss at epoch 2 step 12430: 2.8569474697113035\n",
      "\n",
      " This round's valence_loss=1.1231378316879272, arousal_loss=0.9391456246376038, emotion_loss=1.088631272315979\n",
      "\n",
      "01_20_00:56:56 Seen so far: 397792 samples\n",
      "\n",
      "01_20_00:56:56 --- 1.7552986145019531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:58 Training loss at epoch 2 step 12440: 2.5914780139923095\n",
      "\n",
      " This round's valence_loss=1.432161569595337, arousal_loss=1.3512271642684937, emotion_loss=0.824114978313446\n",
      "\n",
      "01_20_00:56:58 Seen so far: 398112 samples\n",
      "\n",
      "01_20_00:56:58 --- 1.8365809917449951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:56:59 Training loss at epoch 2 step 12450: 3.1289020776748657\n",
      "\n",
      " This round's valence_loss=1.3586820363998413, arousal_loss=1.2411398887634277, emotion_loss=0.9611241817474365\n",
      "\n",
      "01_20_00:56:59 Seen so far: 398432 samples\n",
      "\n",
      "01_20_00:56:59 --- 1.7714288234710693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:01 Training loss at epoch 2 step 12460: 2.9617241621017456\n",
      "\n",
      " This round's valence_loss=0.7994893789291382, arousal_loss=0.7298901081085205, emotion_loss=0.8150596618652344\n",
      "\n",
      "01_20_00:57:01 Seen so far: 398752 samples\n",
      "\n",
      "01_20_00:57:01 --- 1.9360296726226807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:03 Training loss at epoch 2 step 12470: 3.025605821609497\n",
      "\n",
      " This round's valence_loss=1.1502478122711182, arousal_loss=0.9318298697471619, emotion_loss=1.0522289276123047\n",
      "\n",
      "01_20_00:57:03 Seen so far: 399072 samples\n",
      "\n",
      "01_20_00:57:03 --- 1.7289671897888184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:05 Training loss at epoch 2 step 12480: 3.181579661369324\n",
      "\n",
      " This round's valence_loss=0.7412561178207397, arousal_loss=0.5886902809143066, emotion_loss=1.0072203874588013\n",
      "\n",
      "01_20_00:57:05 Seen so far: 399392 samples\n",
      "\n",
      "01_20_00:57:05 --- 1.7724740505218506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:06 Training loss at epoch 2 step 12490: 3.4529788970947264\n",
      "\n",
      " This round's valence_loss=1.4964911937713623, arousal_loss=1.279887080192566, emotion_loss=0.6507101058959961\n",
      "\n",
      "01_20_00:57:06 Seen so far: 399712 samples\n",
      "\n",
      "01_20_00:57:06 --- 1.7337727546691895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:08 Training loss at epoch 2 step 12500: 3.1783082723617553\n",
      "\n",
      " This round's valence_loss=1.2336392402648926, arousal_loss=1.1122848987579346, emotion_loss=1.0190458297729492\n",
      "\n",
      "01_20_00:57:08 Seen so far: 400032 samples\n",
      "\n",
      "01_20_00:57:08 --- 1.7154815196990967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:10 Training loss at epoch 2 step 12510: 2.969362187385559\n",
      "\n",
      " This round's valence_loss=1.5172057151794434, arousal_loss=1.332892656326294, emotion_loss=1.0783054828643799\n",
      "\n",
      "01_20_00:57:10 Seen so far: 400352 samples\n",
      "\n",
      "01_20_00:57:10 --- 1.697798490524292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:12 Training loss at epoch 2 step 12520: 2.6160444617271423\n",
      "\n",
      " This round's valence_loss=0.8571240901947021, arousal_loss=0.6862449645996094, emotion_loss=0.9050416350364685\n",
      "\n",
      "01_20_00:57:12 Seen so far: 400672 samples\n",
      "\n",
      "01_20_00:57:12 --- 1.8389856815338135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:13 Training loss at epoch 2 step 12530: 3.0898205995559693\n",
      "\n",
      " This round's valence_loss=0.8974952101707458, arousal_loss=0.8321139216423035, emotion_loss=1.0747038125991821\n",
      "\n",
      "01_20_00:57:13 Seen so far: 400992 samples\n",
      "\n",
      "01_20_00:57:13 --- 1.680884838104248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:15 Training loss at epoch 2 step 12540: 2.9930330753326415\n",
      "\n",
      " This round's valence_loss=1.1002063751220703, arousal_loss=0.9241111278533936, emotion_loss=0.7834312915802002\n",
      "\n",
      "01_20_00:57:15 Seen so far: 401312 samples\n",
      "\n",
      "01_20_00:57:15 --- 1.7823288440704346 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:17 Training loss at epoch 2 step 12550: 2.886401629447937\n",
      "\n",
      " This round's valence_loss=1.4414637088775635, arousal_loss=1.4012908935546875, emotion_loss=1.04594886302948\n",
      "\n",
      "01_20_00:57:17 Seen so far: 401632 samples\n",
      "\n",
      "01_20_00:57:17 --- 1.7859678268432617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:19 Training loss at epoch 2 step 12560: 2.8483160972595214\n",
      "\n",
      " This round's valence_loss=1.5528273582458496, arousal_loss=1.4449121952056885, emotion_loss=0.9562616348266602\n",
      "\n",
      "01_20_00:57:19 Seen so far: 401952 samples\n",
      "\n",
      "01_20_00:57:19 --- 1.7980446815490723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:21 Training loss at epoch 2 step 12570: 2.9727861046791078\n",
      "\n",
      " This round's valence_loss=1.0991854667663574, arousal_loss=0.9987396001815796, emotion_loss=1.2643040418624878\n",
      "\n",
      "01_20_00:57:21 Seen so far: 402272 samples\n",
      "\n",
      "01_20_00:57:21 --- 1.8102943897247314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:22 Training loss at epoch 2 step 12580: 2.8842031002044677\n",
      "\n",
      " This round's valence_loss=0.7289060354232788, arousal_loss=0.6254415512084961, emotion_loss=1.0497791767120361\n",
      "\n",
      "01_20_00:57:22 Seen so far: 402592 samples\n",
      "\n",
      "01_20_00:57:22 --- 1.8275032043457031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:24 Training loss at epoch 2 step 12590: 3.157015013694763\n",
      "\n",
      " This round's valence_loss=0.837769627571106, arousal_loss=0.743121862411499, emotion_loss=1.123990535736084\n",
      "\n",
      "01_20_00:57:24 Seen so far: 402912 samples\n",
      "\n",
      "01_20_00:57:24 --- 1.6081879138946533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:26 Training loss at epoch 2 step 12600: 3.098930525779724\n",
      "\n",
      " This round's valence_loss=0.679735541343689, arousal_loss=0.4347628355026245, emotion_loss=0.8631090521812439\n",
      "\n",
      "01_20_00:57:26 Seen so far: 403232 samples\n",
      "\n",
      "01_20_00:57:26 --- 1.6459307670593262 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:27 Training loss at epoch 2 step 12610: 3.0743881464004517\n",
      "\n",
      " This round's valence_loss=1.1744129657745361, arousal_loss=1.080757975578308, emotion_loss=0.7683987021446228\n",
      "\n",
      "01_20_00:57:27 Seen so far: 403552 samples\n",
      "\n",
      "01_20_00:57:27 --- 1.7269597053527832 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:29 Training loss at epoch 2 step 12620: 2.829552936553955\n",
      "\n",
      " This round's valence_loss=1.2309634685516357, arousal_loss=1.0786455869674683, emotion_loss=1.1334127187728882\n",
      "\n",
      "01_20_00:57:29 Seen so far: 403872 samples\n",
      "\n",
      "01_20_00:57:29 --- 1.727351188659668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:31 Training loss at epoch 2 step 12630: 2.868827724456787\n",
      "\n",
      " This round's valence_loss=1.3388817310333252, arousal_loss=1.181950330734253, emotion_loss=0.9031518697738647\n",
      "\n",
      "01_20_00:57:31 Seen so far: 404192 samples\n",
      "\n",
      "01_20_00:57:31 --- 1.788011074066162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:33 Training loss at epoch 2 step 12640: 2.8855923652648925\n",
      "\n",
      " This round's valence_loss=1.0722476243972778, arousal_loss=0.9593716859817505, emotion_loss=0.6859186291694641\n",
      "\n",
      "01_20_00:57:33 Seen so far: 404512 samples\n",
      "\n",
      "01_20_00:57:33 --- 1.7515294551849365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:34 Training loss at epoch 2 step 12650: 3.153463935852051\n",
      "\n",
      " This round's valence_loss=1.4053288698196411, arousal_loss=1.3357203006744385, emotion_loss=0.7306550145149231\n",
      "\n",
      "01_20_00:57:34 Seen so far: 404832 samples\n",
      "\n",
      "01_20_00:57:34 --- 1.7329990863800049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:36 Training loss at epoch 2 step 12660: 2.960497570037842\n",
      "\n",
      " This round's valence_loss=1.4903864860534668, arousal_loss=1.3517696857452393, emotion_loss=0.7491852045059204\n",
      "\n",
      "01_20_00:57:36 Seen so far: 405152 samples\n",
      "\n",
      "01_20_00:57:36 --- 1.9533178806304932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:38 Training loss at epoch 2 step 12670: 2.9387027740478517\n",
      "\n",
      " This round's valence_loss=1.3290596008300781, arousal_loss=1.2020851373672485, emotion_loss=0.6004127264022827\n",
      "\n",
      "01_20_00:57:38 Seen so far: 405472 samples\n",
      "\n",
      "01_20_00:57:38 --- 1.7664732933044434 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:40 Training loss at epoch 2 step 12680: 2.987063455581665\n",
      "\n",
      " This round's valence_loss=1.1930173635482788, arousal_loss=1.1178789138793945, emotion_loss=0.9911478757858276\n",
      "\n",
      "01_20_00:57:40 Seen so far: 405792 samples\n",
      "\n",
      "01_20_00:57:40 --- 1.9039275646209717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:42 Training loss at epoch 2 step 12690: 3.1390705823898317\n",
      "\n",
      " This round's valence_loss=1.0450483560562134, arousal_loss=1.0220770835876465, emotion_loss=0.9598919153213501\n",
      "\n",
      "01_20_00:57:42 Seen so far: 406112 samples\n",
      "\n",
      "01_20_00:57:42 --- 1.8891634941101074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:44 Training loss at epoch 2 step 12700: 2.848586320877075\n",
      "\n",
      " This round's valence_loss=1.2250559329986572, arousal_loss=1.074905514717102, emotion_loss=1.1551189422607422\n",
      "\n",
      "01_20_00:57:44 Seen so far: 406432 samples\n",
      "\n",
      "01_20_00:57:44 --- 1.9315996170043945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:55 Training loss at epoch 3 step 0: 3.109637641906738\n",
      "\n",
      " This round's valence_loss=1.7539684772491455, arousal_loss=1.6943268775939941, emotion_loss=1.0982062816619873\n",
      "\n",
      "01_20_00:57:55 Seen so far: 32 samples\n",
      "\n",
      "01_20_00:57:55 --- 11.412224769592285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:57 Training loss at epoch 3 step 10: 2.894595813751221\n",
      "\n",
      " This round's valence_loss=0.7429714202880859, arousal_loss=0.5690258741378784, emotion_loss=0.6056053042411804\n",
      "\n",
      "01_20_00:57:57 Seen so far: 352 samples\n",
      "\n",
      "01_20_00:57:57 --- 1.9859521389007568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:57:59 Training loss at epoch 3 step 20: 3.072278952598572\n",
      "\n",
      " This round's valence_loss=1.1344971656799316, arousal_loss=0.979147732257843, emotion_loss=0.7038300037384033\n",
      "\n",
      "01_20_00:57:59 Seen so far: 672 samples\n",
      "\n",
      "01_20_00:57:59 --- 1.8891527652740479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:01 Training loss at epoch 3 step 30: 3.096239948272705\n",
      "\n",
      " This round's valence_loss=1.1073822975158691, arousal_loss=0.9587273001670837, emotion_loss=1.0915149450302124\n",
      "\n",
      "01_20_00:58:01 Seen so far: 992 samples\n",
      "\n",
      "01_20_00:58:01 --- 1.7841148376464844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:03 Training loss at epoch 3 step 40: 3.161713433265686\n",
      "\n",
      " This round's valence_loss=0.9624417424201965, arousal_loss=0.8512842655181885, emotion_loss=1.1985834836959839\n",
      "\n",
      "01_20_00:58:03 Seen so far: 1312 samples\n",
      "\n",
      "01_20_00:58:03 --- 1.9222681522369385 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:05 Training loss at epoch 3 step 50: 2.802024722099304\n",
      "\n",
      " This round's valence_loss=1.338747501373291, arousal_loss=1.217984914779663, emotion_loss=0.9314091205596924\n",
      "\n",
      "01_20_00:58:05 Seen so far: 1632 samples\n",
      "\n",
      "01_20_00:58:05 --- 1.809607982635498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:06 Training loss at epoch 3 step 60: 3.007946228981018\n",
      "\n",
      " This round's valence_loss=0.9459389448165894, arousal_loss=0.8681762218475342, emotion_loss=0.8430238962173462\n",
      "\n",
      "01_20_00:58:06 Seen so far: 1952 samples\n",
      "\n",
      "01_20_00:58:06 --- 1.8402085304260254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:08 Training loss at epoch 3 step 70: 2.6619892477989198\n",
      "\n",
      " This round's valence_loss=0.5911442041397095, arousal_loss=0.3467450439929962, emotion_loss=0.7863399982452393\n",
      "\n",
      "01_20_00:58:08 Seen so far: 2272 samples\n",
      "\n",
      "01_20_00:58:08 --- 1.7731904983520508 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:10 Training loss at epoch 3 step 80: 3.188665497303009\n",
      "\n",
      " This round's valence_loss=1.80056631565094, arousal_loss=1.7186017036437988, emotion_loss=0.8633315563201904\n",
      "\n",
      "01_20_00:58:10 Seen so far: 2592 samples\n",
      "\n",
      "01_20_00:58:10 --- 1.8450286388397217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:12 Training loss at epoch 3 step 90: 2.758747029304504\n",
      "\n",
      " This round's valence_loss=1.3198822736740112, arousal_loss=1.1760468482971191, emotion_loss=0.7174853086471558\n",
      "\n",
      "01_20_00:58:12 Seen so far: 2912 samples\n",
      "\n",
      "01_20_00:58:12 --- 1.6696653366088867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:14 Training loss at epoch 3 step 100: 2.9293665409088137\n",
      "\n",
      " This round's valence_loss=0.5946910381317139, arousal_loss=0.48823094367980957, emotion_loss=1.0017327070236206\n",
      "\n",
      "01_20_00:58:14 Seen so far: 3232 samples\n",
      "\n",
      "01_20_00:58:14 --- 1.762193202972412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:15 Training loss at epoch 3 step 110: 3.1268325090408324\n",
      "\n",
      " This round's valence_loss=1.2453818321228027, arousal_loss=1.0914642810821533, emotion_loss=0.9912120699882507\n",
      "\n",
      "01_20_00:58:15 Seen so far: 3552 samples\n",
      "\n",
      "01_20_00:58:15 --- 1.8481314182281494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:17 Training loss at epoch 3 step 120: 3.0747796535491942\n",
      "\n",
      " This round's valence_loss=1.0683540105819702, arousal_loss=0.9767191410064697, emotion_loss=1.527231216430664\n",
      "\n",
      "01_20_00:58:17 Seen so far: 3872 samples\n",
      "\n",
      "01_20_00:58:17 --- 1.7857017517089844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:19 Training loss at epoch 3 step 130: 2.8563244342803955\n",
      "\n",
      " This round's valence_loss=0.5926175713539124, arousal_loss=0.34391093254089355, emotion_loss=0.9523143172264099\n",
      "\n",
      "01_20_00:58:19 Seen so far: 4192 samples\n",
      "\n",
      "01_20_00:58:19 --- 1.6025984287261963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:21 Training loss at epoch 3 step 140: 3.0879534482955933\n",
      "\n",
      " This round's valence_loss=1.3393096923828125, arousal_loss=1.229905366897583, emotion_loss=0.9466661214828491\n",
      "\n",
      "01_20_00:58:21 Seen so far: 4512 samples\n",
      "\n",
      "01_20_00:58:21 --- 1.9639053344726562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:22 Training loss at epoch 3 step 150: 2.876823592185974\n",
      "\n",
      " This round's valence_loss=0.836531400680542, arousal_loss=0.7143419981002808, emotion_loss=0.8837789297103882\n",
      "\n",
      "01_20_00:58:22 Seen so far: 4832 samples\n",
      "\n",
      "01_20_00:58:22 --- 1.7451841831207275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:24 Training loss at epoch 3 step 160: 2.883258843421936\n",
      "\n",
      " This round's valence_loss=1.0153260231018066, arousal_loss=0.9035463929176331, emotion_loss=1.0698975324630737\n",
      "\n",
      "01_20_00:58:24 Seen so far: 5152 samples\n",
      "\n",
      "01_20_00:58:24 --- 1.8797836303710938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:26 Training loss at epoch 3 step 170: 3.139083647727966\n",
      "\n",
      " This round's valence_loss=1.3626376390457153, arousal_loss=1.2096035480499268, emotion_loss=0.8980783820152283\n",
      "\n",
      "01_20_00:58:26 Seen so far: 5472 samples\n",
      "\n",
      "01_20_00:58:26 --- 1.785506010055542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:28 Training loss at epoch 3 step 180: 3.0556601524353026\n",
      "\n",
      " This round's valence_loss=1.0766661167144775, arousal_loss=0.9615427255630493, emotion_loss=1.0336710214614868\n",
      "\n",
      "01_20_00:58:28 Seen so far: 5792 samples\n",
      "\n",
      "01_20_00:58:28 --- 1.7110815048217773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:30 Training loss at epoch 3 step 190: 2.9990851163864134\n",
      "\n",
      " This round's valence_loss=1.1655902862548828, arousal_loss=0.9568901062011719, emotion_loss=0.5819016695022583\n",
      "\n",
      "01_20_00:58:30 Seen so far: 6112 samples\n",
      "\n",
      "01_20_00:58:30 --- 1.9227104187011719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:32 Training loss at epoch 3 step 200: 2.8319077491760254\n",
      "\n",
      " This round's valence_loss=0.966942548751831, arousal_loss=0.848299503326416, emotion_loss=1.1582636833190918\n",
      "\n",
      "01_20_00:58:32 Seen so far: 6432 samples\n",
      "\n",
      "01_20_00:58:32 --- 1.7293689250946045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:33 Training loss at epoch 3 step 210: 3.0271334886550902\n",
      "\n",
      " This round's valence_loss=1.2303824424743652, arousal_loss=1.1033194065093994, emotion_loss=0.9736169576644897\n",
      "\n",
      "01_20_00:58:33 Seen so far: 6752 samples\n",
      "\n",
      "01_20_00:58:33 --- 1.6713206768035889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:35 Training loss at epoch 3 step 220: 2.6239121675491335\n",
      "\n",
      " This round's valence_loss=0.4893447160720825, arousal_loss=0.33275407552719116, emotion_loss=0.6762718558311462\n",
      "\n",
      "01_20_00:58:35 Seen so far: 7072 samples\n",
      "\n",
      "01_20_00:58:35 --- 1.780151605606079 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:37 Training loss at epoch 3 step 230: 2.843456816673279\n",
      "\n",
      " This round's valence_loss=0.9184495806694031, arousal_loss=0.6808057427406311, emotion_loss=0.5846002101898193\n",
      "\n",
      "01_20_00:58:37 Seen so far: 7392 samples\n",
      "\n",
      "01_20_00:58:37 --- 1.8266446590423584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:38 Training loss at epoch 3 step 240: 2.931254816055298\n",
      "\n",
      " This round's valence_loss=1.1500320434570312, arousal_loss=0.969250500202179, emotion_loss=0.8316329717636108\n",
      "\n",
      "01_20_00:58:38 Seen so far: 7712 samples\n",
      "\n",
      "01_20_00:58:38 --- 1.686377763748169 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:40 Training loss at epoch 3 step 250: 3.1398454904556274\n",
      "\n",
      " This round's valence_loss=1.324167013168335, arousal_loss=1.259169101715088, emotion_loss=1.1103007793426514\n",
      "\n",
      "01_20_00:58:40 Seen so far: 8032 samples\n",
      "\n",
      "01_20_00:58:40 --- 1.7435317039489746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:42 Training loss at epoch 3 step 260: 2.949770927429199\n",
      "\n",
      " This round's valence_loss=0.9508993029594421, arousal_loss=0.8615962266921997, emotion_loss=0.9408531188964844\n",
      "\n",
      "01_20_00:58:42 Seen so far: 8352 samples\n",
      "\n",
      "01_20_00:58:42 --- 1.7322547435760498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:44 Training loss at epoch 3 step 270: 3.0128878712654115\n",
      "\n",
      " This round's valence_loss=1.7648577690124512, arousal_loss=1.6534264087677002, emotion_loss=0.9431872367858887\n",
      "\n",
      "01_20_00:58:44 Seen so far: 8672 samples\n",
      "\n",
      "01_20_00:58:44 --- 1.6331255435943604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:45 Training loss at epoch 3 step 280: 2.9304941654205323\n",
      "\n",
      " This round's valence_loss=1.0167293548583984, arousal_loss=0.8277156352996826, emotion_loss=0.8302747011184692\n",
      "\n",
      "01_20_00:58:45 Seen so far: 8992 samples\n",
      "\n",
      "01_20_00:58:45 --- 1.680769681930542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:47 Training loss at epoch 3 step 290: 2.981023573875427\n",
      "\n",
      " This round's valence_loss=1.07288658618927, arousal_loss=1.013096570968628, emotion_loss=0.9460806250572205\n",
      "\n",
      "01_20_00:58:47 Seen so far: 9312 samples\n",
      "\n",
      "01_20_00:58:47 --- 1.838294267654419 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:49 Training loss at epoch 3 step 300: 2.860767388343811\n",
      "\n",
      " This round's valence_loss=1.111993432044983, arousal_loss=0.9801469445228577, emotion_loss=0.8954707384109497\n",
      "\n",
      "01_20_00:58:49 Seen so far: 9632 samples\n",
      "\n",
      "01_20_00:58:49 --- 1.9321112632751465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:51 Training loss at epoch 3 step 310: 2.9582485914230348\n",
      "\n",
      " This round's valence_loss=0.9450437426567078, arousal_loss=0.8165735602378845, emotion_loss=0.7247716784477234\n",
      "\n",
      "01_20_00:58:51 Seen so far: 9952 samples\n",
      "\n",
      "01_20_00:58:51 --- 1.7448196411132812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:53 Training loss at epoch 3 step 320: 3.0535775899887083\n",
      "\n",
      " This round's valence_loss=0.8341436982154846, arousal_loss=0.6941229701042175, emotion_loss=0.7499083280563354\n",
      "\n",
      "01_20_00:58:53 Seen so far: 10272 samples\n",
      "\n",
      "01_20_00:58:53 --- 1.8410186767578125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:54 Training loss at epoch 3 step 330: 2.874555063247681\n",
      "\n",
      " This round's valence_loss=0.9919847249984741, arousal_loss=0.7934256792068481, emotion_loss=0.9483731389045715\n",
      "\n",
      "01_20_00:58:54 Seen so far: 10592 samples\n",
      "\n",
      "01_20_00:58:54 --- 1.7402312755584717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:56 Training loss at epoch 3 step 340: 3.0549750328063965\n",
      "\n",
      " This round's valence_loss=1.2597695589065552, arousal_loss=1.0651419162750244, emotion_loss=0.9631873369216919\n",
      "\n",
      "01_20_00:58:56 Seen so far: 10912 samples\n",
      "\n",
      "01_20_00:58:56 --- 1.7873389720916748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:58:58 Training loss at epoch 3 step 350: 2.8895018339157104\n",
      "\n",
      " This round's valence_loss=1.3003190755844116, arousal_loss=1.2097212076187134, emotion_loss=1.0553500652313232\n",
      "\n",
      "01_20_00:58:58 Seen so far: 11232 samples\n",
      "\n",
      "01_20_00:58:58 --- 1.725898265838623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:00 Training loss at epoch 3 step 360: 3.3330721855163574\n",
      "\n",
      " This round's valence_loss=1.0920770168304443, arousal_loss=1.0118271112442017, emotion_loss=1.0885159969329834\n",
      "\n",
      "01_20_00:59:00 Seen so far: 11552 samples\n",
      "\n",
      "01_20_00:59:00 --- 1.6592886447906494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:01 Training loss at epoch 3 step 370: 3.0764333963394166\n",
      "\n",
      " This round's valence_loss=1.3585052490234375, arousal_loss=1.2288494110107422, emotion_loss=0.8990088105201721\n",
      "\n",
      "01_20_00:59:01 Seen so far: 11872 samples\n",
      "\n",
      "01_20_00:59:01 --- 1.8521602153778076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:03 Training loss at epoch 3 step 380: 3.174005556106567\n",
      "\n",
      " This round's valence_loss=1.1265443563461304, arousal_loss=0.9340628981590271, emotion_loss=1.0253716707229614\n",
      "\n",
      "01_20_00:59:03 Seen so far: 12192 samples\n",
      "\n",
      "01_20_00:59:03 --- 1.7713699340820312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:05 Training loss at epoch 3 step 390: 3.0600209474563598\n",
      "\n",
      " This round's valence_loss=1.1653964519500732, arousal_loss=0.9798347353935242, emotion_loss=1.097192645072937\n",
      "\n",
      "01_20_00:59:05 Seen so far: 12512 samples\n",
      "\n",
      "01_20_00:59:05 --- 1.6876966953277588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:07 Training loss at epoch 3 step 400: 2.7297343730926515\n",
      "\n",
      " This round's valence_loss=1.004611611366272, arousal_loss=0.8791506886482239, emotion_loss=0.6065489053726196\n",
      "\n",
      "01_20_00:59:07 Seen so far: 12832 samples\n",
      "\n",
      "01_20_00:59:07 --- 1.7023792266845703 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:08 Training loss at epoch 3 step 410: 2.979866790771484\n",
      "\n",
      " This round's valence_loss=1.2399457693099976, arousal_loss=1.087191104888916, emotion_loss=1.11946439743042\n",
      "\n",
      "01_20_00:59:08 Seen so far: 13152 samples\n",
      "\n",
      "01_20_00:59:08 --- 1.7788844108581543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:10 Training loss at epoch 3 step 420: 3.338277530670166\n",
      "\n",
      " This round's valence_loss=1.109292984008789, arousal_loss=0.932716429233551, emotion_loss=0.8958046436309814\n",
      "\n",
      "01_20_00:59:10 Seen so far: 13472 samples\n",
      "\n",
      "01_20_00:59:10 --- 1.8037254810333252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:12 Training loss at epoch 3 step 430: 2.7348111152648924\n",
      "\n",
      " This round's valence_loss=0.7453902959823608, arousal_loss=0.5786693096160889, emotion_loss=1.3941669464111328\n",
      "\n",
      "01_20_00:59:12 Seen so far: 13792 samples\n",
      "\n",
      "01_20_00:59:12 --- 1.7583062648773193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:14 Training loss at epoch 3 step 440: 2.840169358253479\n",
      "\n",
      " This round's valence_loss=0.4360049068927765, arousal_loss=0.2356070578098297, emotion_loss=0.6218135356903076\n",
      "\n",
      "01_20_00:59:14 Seen so far: 14112 samples\n",
      "\n",
      "01_20_00:59:14 --- 1.7286708354949951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:15 Training loss at epoch 3 step 450: 3.149498450756073\n",
      "\n",
      " This round's valence_loss=1.3742797374725342, arousal_loss=1.2662605047225952, emotion_loss=1.4696694612503052\n",
      "\n",
      "01_20_00:59:15 Seen so far: 14432 samples\n",
      "\n",
      "01_20_00:59:15 --- 1.6893603801727295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:17 Training loss at epoch 3 step 460: 3.182372283935547\n",
      "\n",
      " This round's valence_loss=1.0632827281951904, arousal_loss=0.9509072303771973, emotion_loss=0.7740902900695801\n",
      "\n",
      "01_20_00:59:17 Seen so far: 14752 samples\n",
      "\n",
      "01_20_00:59:17 --- 1.632509469985962 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:19 Training loss at epoch 3 step 470: 3.2483246088027955\n",
      "\n",
      " This round's valence_loss=1.2098796367645264, arousal_loss=1.071061134338379, emotion_loss=0.8814550638198853\n",
      "\n",
      "01_20_00:59:19 Seen so far: 15072 samples\n",
      "\n",
      "01_20_00:59:19 --- 1.6852569580078125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:20 Training loss at epoch 3 step 480: 2.908710813522339\n",
      "\n",
      " This round's valence_loss=0.8347904086112976, arousal_loss=0.7791740894317627, emotion_loss=1.4035711288452148\n",
      "\n",
      "01_20_00:59:20 Seen so far: 15392 samples\n",
      "\n",
      "01_20_00:59:20 --- 1.7577569484710693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:22 Training loss at epoch 3 step 490: 2.6981417179107665\n",
      "\n",
      " This round's valence_loss=1.0060367584228516, arousal_loss=0.8046543598175049, emotion_loss=0.9662227034568787\n",
      "\n",
      "01_20_00:59:22 Seen so far: 15712 samples\n",
      "\n",
      "01_20_00:59:22 --- 1.6495389938354492 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:24 Training loss at epoch 3 step 500: 3.16380832195282\n",
      "\n",
      " This round's valence_loss=0.7779747247695923, arousal_loss=0.5993068218231201, emotion_loss=0.933246374130249\n",
      "\n",
      "01_20_00:59:24 Seen so far: 16032 samples\n",
      "\n",
      "01_20_00:59:24 --- 1.9754438400268555 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:26 Training loss at epoch 3 step 510: 3.2081257104873657\n",
      "\n",
      " This round's valence_loss=1.5050244331359863, arousal_loss=1.3385009765625, emotion_loss=0.8950621485710144\n",
      "\n",
      "01_20_00:59:26 Seen so far: 16352 samples\n",
      "\n",
      "01_20_00:59:26 --- 1.8252449035644531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:28 Training loss at epoch 3 step 520: 3.02248752117157\n",
      "\n",
      " This round's valence_loss=1.0155115127563477, arousal_loss=0.8208214044570923, emotion_loss=0.6920955181121826\n",
      "\n",
      "01_20_00:59:28 Seen so far: 16672 samples\n",
      "\n",
      "01_20_00:59:28 --- 1.7667276859283447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:29 Training loss at epoch 3 step 530: 2.8703773021698\n",
      "\n",
      " This round's valence_loss=0.850508987903595, arousal_loss=0.7264036536216736, emotion_loss=1.3354697227478027\n",
      "\n",
      "01_20_00:59:29 Seen so far: 16992 samples\n",
      "\n",
      "01_20_00:59:29 --- 1.7926273345947266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:31 Training loss at epoch 3 step 540: 3.229505181312561\n",
      "\n",
      " This round's valence_loss=1.1357240676879883, arousal_loss=0.9941638112068176, emotion_loss=0.9304119944572449\n",
      "\n",
      "01_20_00:59:31 Seen so far: 17312 samples\n",
      "\n",
      "01_20_00:59:31 --- 1.778172254562378 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:33 Training loss at epoch 3 step 550: 3.176950526237488\n",
      "\n",
      " This round's valence_loss=0.7350518703460693, arousal_loss=0.6081938147544861, emotion_loss=1.032038927078247\n",
      "\n",
      "01_20_00:59:33 Seen so far: 17632 samples\n",
      "\n",
      "01_20_00:59:33 --- 1.941704511642456 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:35 Training loss at epoch 3 step 560: 2.7082046270370483\n",
      "\n",
      " This round's valence_loss=0.9069108963012695, arousal_loss=0.7541540265083313, emotion_loss=0.5822544693946838\n",
      "\n",
      "01_20_00:59:35 Seen so far: 17952 samples\n",
      "\n",
      "01_20_00:59:35 --- 1.8489799499511719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:37 Training loss at epoch 3 step 570: 2.740933585166931\n",
      "\n",
      " This round's valence_loss=0.8720820546150208, arousal_loss=0.6867931485176086, emotion_loss=0.8812333345413208\n",
      "\n",
      "01_20_00:59:37 Seen so far: 18272 samples\n",
      "\n",
      "01_20_00:59:37 --- 1.711742877960205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:38 Training loss at epoch 3 step 580: 2.884454584121704\n",
      "\n",
      " This round's valence_loss=1.2703050374984741, arousal_loss=1.1271750926971436, emotion_loss=1.1589677333831787\n",
      "\n",
      "01_20_00:59:38 Seen so far: 18592 samples\n",
      "\n",
      "01_20_00:59:38 --- 1.792365312576294 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:40 Training loss at epoch 3 step 590: 2.8994198083877563\n",
      "\n",
      " This round's valence_loss=1.220383644104004, arousal_loss=1.0662070512771606, emotion_loss=0.9977141618728638\n",
      "\n",
      "01_20_00:59:40 Seen so far: 18912 samples\n",
      "\n",
      "01_20_00:59:40 --- 1.8153917789459229 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:42 Training loss at epoch 3 step 600: 2.932784366607666\n",
      "\n",
      " This round's valence_loss=1.1717848777770996, arousal_loss=1.0904314517974854, emotion_loss=1.0339045524597168\n",
      "\n",
      "01_20_00:59:42 Seen so far: 19232 samples\n",
      "\n",
      "01_20_00:59:42 --- 1.6642227172851562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:44 Training loss at epoch 3 step 610: 3.157654678821564\n",
      "\n",
      " This round's valence_loss=0.7342380285263062, arousal_loss=0.6363842487335205, emotion_loss=1.0333993434906006\n",
      "\n",
      "01_20_00:59:44 Seen so far: 19552 samples\n",
      "\n",
      "01_20_00:59:44 --- 1.7998998165130615 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:46 Training loss at epoch 3 step 620: 2.895456075668335\n",
      "\n",
      " This round's valence_loss=1.002777099609375, arousal_loss=0.9482898116111755, emotion_loss=1.1418198347091675\n",
      "\n",
      "01_20_00:59:46 Seen so far: 19872 samples\n",
      "\n",
      "01_20_00:59:46 --- 1.7874691486358643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:47 Training loss at epoch 3 step 630: 3.0080459833145143\n",
      "\n",
      " This round's valence_loss=1.5402460098266602, arousal_loss=1.4522650241851807, emotion_loss=1.0279877185821533\n",
      "\n",
      "01_20_00:59:47 Seen so far: 20192 samples\n",
      "\n",
      "01_20_00:59:47 --- 1.5843110084533691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:49 Training loss at epoch 3 step 640: 2.8396679520606996\n",
      "\n",
      " This round's valence_loss=0.7066348791122437, arousal_loss=0.494148850440979, emotion_loss=1.3946495056152344\n",
      "\n",
      "01_20_00:59:49 Seen so far: 20512 samples\n",
      "\n",
      "01_20_00:59:49 --- 1.753096103668213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:51 Training loss at epoch 3 step 650: 3.169372630119324\n",
      "\n",
      " This round's valence_loss=0.8844655752182007, arousal_loss=0.7300659418106079, emotion_loss=1.062793493270874\n",
      "\n",
      "01_20_00:59:51 Seen so far: 20832 samples\n",
      "\n",
      "01_20_00:59:51 --- 1.7131249904632568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:52 Training loss at epoch 3 step 660: 2.8796406745910645\n",
      "\n",
      " This round's valence_loss=1.0480525493621826, arousal_loss=0.9556803703308105, emotion_loss=0.8199615478515625\n",
      "\n",
      "01_20_00:59:52 Seen so far: 21152 samples\n",
      "\n",
      "01_20_00:59:52 --- 1.7384533882141113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:54 Training loss at epoch 3 step 670: 3.1101707458496093\n",
      "\n",
      " This round's valence_loss=1.1383925676345825, arousal_loss=1.1354875564575195, emotion_loss=1.0780428647994995\n",
      "\n",
      "01_20_00:59:54 Seen so far: 21472 samples\n",
      "\n",
      "01_20_00:59:54 --- 1.700145959854126 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:56 Training loss at epoch 3 step 680: 3.1000468254089357\n",
      "\n",
      " This round's valence_loss=0.839248776435852, arousal_loss=0.770017147064209, emotion_loss=1.2559740543365479\n",
      "\n",
      "01_20_00:59:56 Seen so far: 21792 samples\n",
      "\n",
      "01_20_00:59:56 --- 1.9701037406921387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:58 Training loss at epoch 3 step 690: 3.1800851106643675\n",
      "\n",
      " This round's valence_loss=1.3347363471984863, arousal_loss=1.25882887840271, emotion_loss=0.756923258304596\n",
      "\n",
      "01_20_00:59:58 Seen so far: 22112 samples\n",
      "\n",
      "01_20_00:59:58 --- 1.6820385456085205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_00:59:59 Training loss at epoch 3 step 700: 2.940566825866699\n",
      "\n",
      " This round's valence_loss=0.6409071683883667, arousal_loss=0.45189327001571655, emotion_loss=1.016052007675171\n",
      "\n",
      "01_20_00:59:59 Seen so far: 22432 samples\n",
      "\n",
      "01_20_00:59:59 --- 1.669281244277954 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:01 Training loss at epoch 3 step 710: 2.6591269850730894\n",
      "\n",
      " This round's valence_loss=1.4894561767578125, arousal_loss=1.3420708179473877, emotion_loss=1.0632948875427246\n",
      "\n",
      "01_20_01:00:01 Seen so far: 22752 samples\n",
      "\n",
      "01_20_01:00:01 --- 1.7139005661010742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:03 Training loss at epoch 3 step 720: 3.0524001121520996\n",
      "\n",
      " This round's valence_loss=1.1886484622955322, arousal_loss=1.181114912033081, emotion_loss=0.8711106181144714\n",
      "\n",
      "01_20_01:00:03 Seen so far: 23072 samples\n",
      "\n",
      "01_20_01:00:03 --- 1.7145428657531738 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:05 Training loss at epoch 3 step 730: 2.8881888151168824\n",
      "\n",
      " This round's valence_loss=0.8807951807975769, arousal_loss=0.7622933387756348, emotion_loss=0.7987074851989746\n",
      "\n",
      "01_20_01:00:05 Seen so far: 23392 samples\n",
      "\n",
      "01_20_01:00:05 --- 1.9607460498809814 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:07 Training loss at epoch 3 step 740: 3.104219973087311\n",
      "\n",
      " This round's valence_loss=1.2542262077331543, arousal_loss=1.2291593551635742, emotion_loss=0.6244074106216431\n",
      "\n",
      "01_20_01:00:07 Seen so far: 23712 samples\n",
      "\n",
      "01_20_01:00:07 --- 2.0728302001953125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:09 Training loss at epoch 3 step 750: 3.1018794775009155\n",
      "\n",
      " This round's valence_loss=1.1954203844070435, arousal_loss=1.0856964588165283, emotion_loss=0.8521328568458557\n",
      "\n",
      "01_20_01:00:09 Seen so far: 24032 samples\n",
      "\n",
      "01_20_01:00:09 --- 1.7163453102111816 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:10 Training loss at epoch 3 step 760: 3.1097108840942385\n",
      "\n",
      " This round's valence_loss=0.7480183839797974, arousal_loss=0.5930464267730713, emotion_loss=1.0902535915374756\n",
      "\n",
      "01_20_01:00:10 Seen so far: 24352 samples\n",
      "\n",
      "01_20_01:00:10 --- 1.8499400615692139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:12 Training loss at epoch 3 step 770: 3.2148082494735717\n",
      "\n",
      " This round's valence_loss=0.977156937122345, arousal_loss=0.846412181854248, emotion_loss=1.012193202972412\n",
      "\n",
      "01_20_01:00:12 Seen so far: 24672 samples\n",
      "\n",
      "01_20_01:00:12 --- 1.8014299869537354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:14 Training loss at epoch 3 step 780: 2.857893133163452\n",
      "\n",
      " This round's valence_loss=1.1065301895141602, arousal_loss=0.9953925609588623, emotion_loss=0.8651759624481201\n",
      "\n",
      "01_20_01:00:14 Seen so far: 24992 samples\n",
      "\n",
      "01_20_01:00:14 --- 1.8083884716033936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:16 Training loss at epoch 3 step 790: 2.907808518409729\n",
      "\n",
      " This round's valence_loss=1.1658718585968018, arousal_loss=0.9553090333938599, emotion_loss=0.9483739137649536\n",
      "\n",
      "01_20_01:00:16 Seen so far: 25312 samples\n",
      "\n",
      "01_20_01:00:16 --- 1.728025197982788 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:17 Training loss at epoch 3 step 800: 3.3747496128082277\n",
      "\n",
      " This round's valence_loss=1.3610789775848389, arousal_loss=1.1549955606460571, emotion_loss=0.8266383409500122\n",
      "\n",
      "01_20_01:00:17 Seen so far: 25632 samples\n",
      "\n",
      "01_20_01:00:17 --- 1.6795084476470947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:19 Training loss at epoch 3 step 810: 2.9707589387893676\n",
      "\n",
      " This round's valence_loss=1.2318872213363647, arousal_loss=1.1151481866836548, emotion_loss=0.8608580827713013\n",
      "\n",
      "01_20_01:00:19 Seen so far: 25952 samples\n",
      "\n",
      "01_20_01:00:19 --- 1.6967473030090332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:21 Training loss at epoch 3 step 820: 2.965856647491455\n",
      "\n",
      " This round's valence_loss=0.737139105796814, arousal_loss=0.601632833480835, emotion_loss=0.7904723882675171\n",
      "\n",
      "01_20_01:00:21 Seen so far: 26272 samples\n",
      "\n",
      "01_20_01:00:21 --- 1.685849905014038 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:23 Training loss at epoch 3 step 830: 3.087136483192444\n",
      "\n",
      " This round's valence_loss=1.0975942611694336, arousal_loss=0.9979872703552246, emotion_loss=1.0690205097198486\n",
      "\n",
      "01_20_01:00:23 Seen so far: 26592 samples\n",
      "\n",
      "01_20_01:00:23 --- 1.8547122478485107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:24 Training loss at epoch 3 step 840: 2.7776811718940735\n",
      "\n",
      " This round's valence_loss=1.3109608888626099, arousal_loss=1.2290761470794678, emotion_loss=1.3136450052261353\n",
      "\n",
      "01_20_01:00:24 Seen so far: 26912 samples\n",
      "\n",
      "01_20_01:00:24 --- 1.6994431018829346 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:26 Training loss at epoch 3 step 850: 3.0049846172332764\n",
      "\n",
      " This round's valence_loss=1.1354739665985107, arousal_loss=0.9332587122917175, emotion_loss=1.2961945533752441\n",
      "\n",
      "01_20_01:00:26 Seen so far: 27232 samples\n",
      "\n",
      "01_20_01:00:26 --- 1.8164687156677246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:28 Training loss at epoch 3 step 860: 2.808108758926392\n",
      "\n",
      " This round's valence_loss=0.8030532002449036, arousal_loss=0.6266831159591675, emotion_loss=0.9774115681648254\n",
      "\n",
      "01_20_01:00:28 Seen so far: 27552 samples\n",
      "\n",
      "01_20_01:00:28 --- 1.8316197395324707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:30 Training loss at epoch 3 step 870: 2.868749904632568\n",
      "\n",
      " This round's valence_loss=1.316835880279541, arousal_loss=1.2257354259490967, emotion_loss=1.259222149848938\n",
      "\n",
      "01_20_01:00:30 Seen so far: 27872 samples\n",
      "\n",
      "01_20_01:00:30 --- 2.010357141494751 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:32 Training loss at epoch 3 step 880: 3.2120338916778564\n",
      "\n",
      " This round's valence_loss=1.0331177711486816, arousal_loss=0.8372766375541687, emotion_loss=0.7658166289329529\n",
      "\n",
      "01_20_01:00:32 Seen so far: 28192 samples\n",
      "\n",
      "01_20_01:00:32 --- 1.8628015518188477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:34 Training loss at epoch 3 step 890: 3.408139705657959\n",
      "\n",
      " This round's valence_loss=0.7502084374427795, arousal_loss=0.6302956342697144, emotion_loss=1.060584306716919\n",
      "\n",
      "01_20_01:00:34 Seen so far: 28512 samples\n",
      "\n",
      "01_20_01:00:34 --- 1.6627302169799805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:35 Training loss at epoch 3 step 900: 2.777823638916016\n",
      "\n",
      " This round's valence_loss=0.8050506114959717, arousal_loss=0.5599730014801025, emotion_loss=0.8920406699180603\n",
      "\n",
      "01_20_01:00:35 Seen so far: 28832 samples\n",
      "\n",
      "01_20_01:00:35 --- 1.7813546657562256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:37 Training loss at epoch 3 step 910: 3.15300567150116\n",
      "\n",
      " This round's valence_loss=1.6609272956848145, arousal_loss=1.5633257627487183, emotion_loss=1.1333223581314087\n",
      "\n",
      "01_20_01:00:37 Seen so far: 29152 samples\n",
      "\n",
      "01_20_01:00:37 --- 1.7090301513671875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:39 Training loss at epoch 3 step 920: 3.405566120147705\n",
      "\n",
      " This round's valence_loss=1.2355016469955444, arousal_loss=1.074601173400879, emotion_loss=0.9071291089057922\n",
      "\n",
      "01_20_01:00:39 Seen so far: 29472 samples\n",
      "\n",
      "01_20_01:00:39 --- 1.8324756622314453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:41 Training loss at epoch 3 step 930: 2.9432923793792725\n",
      "\n",
      " This round's valence_loss=0.9643332362174988, arousal_loss=0.8640770316123962, emotion_loss=1.1437788009643555\n",
      "\n",
      "01_20_01:00:41 Seen so far: 29792 samples\n",
      "\n",
      "01_20_01:00:41 --- 1.8247647285461426 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:43 Training loss at epoch 3 step 940: 3.1397892951965334\n",
      "\n",
      " This round's valence_loss=1.4754319190979004, arousal_loss=1.3542345762252808, emotion_loss=0.6902289390563965\n",
      "\n",
      "01_20_01:00:43 Seen so far: 30112 samples\n",
      "\n",
      "01_20_01:00:43 --- 1.9601924419403076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:44 Training loss at epoch 3 step 950: 3.1135730862617494\n",
      "\n",
      " This round's valence_loss=1.1472423076629639, arousal_loss=0.9347426295280457, emotion_loss=0.7870278358459473\n",
      "\n",
      "01_20_01:00:44 Seen so far: 30432 samples\n",
      "\n",
      "01_20_01:00:44 --- 1.6937110424041748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:46 Training loss at epoch 3 step 960: 2.9171369075775146\n",
      "\n",
      " This round's valence_loss=1.3223912715911865, arousal_loss=1.2439165115356445, emotion_loss=0.9132241606712341\n",
      "\n",
      "01_20_01:00:46 Seen so far: 30752 samples\n",
      "\n",
      "01_20_01:00:46 --- 1.764122724533081 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:48 Training loss at epoch 3 step 970: 3.049915838241577\n",
      "\n",
      " This round's valence_loss=1.224217176437378, arousal_loss=1.0303568840026855, emotion_loss=0.9918264150619507\n",
      "\n",
      "01_20_01:00:48 Seen so far: 31072 samples\n",
      "\n",
      "01_20_01:00:48 --- 1.836881399154663 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:50 Training loss at epoch 3 step 980: 2.932947850227356\n",
      "\n",
      " This round's valence_loss=1.0302585363388062, arousal_loss=0.9925239682197571, emotion_loss=1.27213716506958\n",
      "\n",
      "01_20_01:00:50 Seen so far: 31392 samples\n",
      "\n",
      "01_20_01:00:50 --- 1.6747045516967773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:51 Training loss at epoch 3 step 990: 2.735604763031006\n",
      "\n",
      " This round's valence_loss=0.49643874168395996, arousal_loss=0.3295527696609497, emotion_loss=0.9127475023269653\n",
      "\n",
      "01_20_01:00:51 Seen so far: 31712 samples\n",
      "\n",
      "01_20_01:00:51 --- 1.878739833831787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:53 Training loss at epoch 3 step 1000: 2.7313748598098755\n",
      "\n",
      " This round's valence_loss=0.8489371538162231, arousal_loss=0.7031822204589844, emotion_loss=0.5698680877685547\n",
      "\n",
      "01_20_01:00:53 Seen so far: 32032 samples\n",
      "\n",
      "01_20_01:00:53 --- 1.8870348930358887 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:55 Training loss at epoch 3 step 1010: 2.9525175213813784\n",
      "\n",
      " This round's valence_loss=0.9952669739723206, arousal_loss=0.8164219260215759, emotion_loss=0.7434543967247009\n",
      "\n",
      "01_20_01:00:55 Seen so far: 32352 samples\n",
      "\n",
      "01_20_01:00:55 --- 2.0260934829711914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:57 Training loss at epoch 3 step 1020: 2.883442735671997\n",
      "\n",
      " This round's valence_loss=1.394733190536499, arousal_loss=1.184859275817871, emotion_loss=1.146170973777771\n",
      "\n",
      "01_20_01:00:57 Seen so far: 32672 samples\n",
      "\n",
      "01_20_01:00:57 --- 1.677927017211914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:00:59 Training loss at epoch 3 step 1030: 2.7874269247055055\n",
      "\n",
      " This round's valence_loss=0.4762905240058899, arousal_loss=0.36420154571533203, emotion_loss=1.0707266330718994\n",
      "\n",
      "01_20_01:00:59 Seen so far: 32992 samples\n",
      "\n",
      "01_20_01:00:59 --- 1.929412603378296 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:01 Training loss at epoch 3 step 1040: 3.0462687253952025\n",
      "\n",
      " This round's valence_loss=0.8615630269050598, arousal_loss=0.7148599624633789, emotion_loss=0.7073737978935242\n",
      "\n",
      "01_20_01:01:01 Seen so far: 33312 samples\n",
      "\n",
      "01_20_01:01:01 --- 1.756251573562622 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:02 Training loss at epoch 3 step 1050: 2.969640588760376\n",
      "\n",
      " This round's valence_loss=1.406670093536377, arousal_loss=1.3524185419082642, emotion_loss=1.0054192543029785\n",
      "\n",
      "01_20_01:01:02 Seen so far: 33632 samples\n",
      "\n",
      "01_20_01:01:02 --- 1.6943295001983643 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:04 Training loss at epoch 3 step 1060: 3.266038346290588\n",
      "\n",
      " This round's valence_loss=1.2119343280792236, arousal_loss=1.0608117580413818, emotion_loss=0.8299641013145447\n",
      "\n",
      "01_20_01:01:04 Seen so far: 33952 samples\n",
      "\n",
      "01_20_01:01:04 --- 1.8280985355377197 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:06 Training loss at epoch 3 step 1070: 2.8220335841178894\n",
      "\n",
      " This round's valence_loss=1.5071964263916016, arousal_loss=1.3245201110839844, emotion_loss=0.8522498607635498\n",
      "\n",
      "01_20_01:01:06 Seen so far: 34272 samples\n",
      "\n",
      "01_20_01:01:06 --- 1.9211328029632568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:08 Training loss at epoch 3 step 1080: 2.8958733558654783\n",
      "\n",
      " This round's valence_loss=1.1387994289398193, arousal_loss=0.7763691544532776, emotion_loss=0.453526109457016\n",
      "\n",
      "01_20_01:01:08 Seen so far: 34592 samples\n",
      "\n",
      "01_20_01:01:08 --- 2.050903797149658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:10 Training loss at epoch 3 step 1090: 3.022154355049133\n",
      "\n",
      " This round's valence_loss=1.1763660907745361, arousal_loss=1.0440049171447754, emotion_loss=0.8582409620285034\n",
      "\n",
      "01_20_01:01:10 Seen so far: 34912 samples\n",
      "\n",
      "01_20_01:01:10 --- 1.6957061290740967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:12 Training loss at epoch 3 step 1100: 3.3596236228942873\n",
      "\n",
      " This round's valence_loss=0.9360333681106567, arousal_loss=0.7244106531143188, emotion_loss=1.0897141695022583\n",
      "\n",
      "01_20_01:01:12 Seen so far: 35232 samples\n",
      "\n",
      "01_20_01:01:12 --- 1.8295655250549316 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:14 Training loss at epoch 3 step 1110: 2.649903106689453\n",
      "\n",
      " This round's valence_loss=0.8552442789077759, arousal_loss=0.699416995048523, emotion_loss=0.6814203262329102\n",
      "\n",
      "01_20_01:01:14 Seen so far: 35552 samples\n",
      "\n",
      "01_20_01:01:14 --- 1.7763056755065918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:15 Training loss at epoch 3 step 1120: 2.9699836134910584\n",
      "\n",
      " This round's valence_loss=1.4070184230804443, arousal_loss=1.3102846145629883, emotion_loss=1.187809944152832\n",
      "\n",
      "01_20_01:01:15 Seen so far: 35872 samples\n",
      "\n",
      "01_20_01:01:15 --- 1.633622407913208 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:17 Training loss at epoch 3 step 1130: 2.9045064449310303\n",
      "\n",
      " This round's valence_loss=1.0579005479812622, arousal_loss=0.9394291639328003, emotion_loss=1.373474359512329\n",
      "\n",
      "01_20_01:01:17 Seen so far: 36192 samples\n",
      "\n",
      "01_20_01:01:17 --- 2.092538595199585 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:19 Training loss at epoch 3 step 1140: 3.038652312755585\n",
      "\n",
      " This round's valence_loss=1.2508916854858398, arousal_loss=1.071911334991455, emotion_loss=0.7627798318862915\n",
      "\n",
      "01_20_01:01:19 Seen so far: 36512 samples\n",
      "\n",
      "01_20_01:01:19 --- 1.8333022594451904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:21 Training loss at epoch 3 step 1150: 2.6248351097106934\n",
      "\n",
      " This round's valence_loss=1.1128454208374023, arousal_loss=0.9754297733306885, emotion_loss=0.8396576642990112\n",
      "\n",
      "01_20_01:01:21 Seen so far: 36832 samples\n",
      "\n",
      "01_20_01:01:21 --- 1.703768253326416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:23 Training loss at epoch 3 step 1160: 2.919568347930908\n",
      "\n",
      " This round's valence_loss=0.7325602769851685, arousal_loss=0.6193910241127014, emotion_loss=1.052708387374878\n",
      "\n",
      "01_20_01:01:23 Seen so far: 37152 samples\n",
      "\n",
      "01_20_01:01:23 --- 1.716984748840332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:24 Training loss at epoch 3 step 1170: 2.8722830295562742\n",
      "\n",
      " This round's valence_loss=1.2271231412887573, arousal_loss=1.108469843864441, emotion_loss=0.764265775680542\n",
      "\n",
      "01_20_01:01:24 Seen so far: 37472 samples\n",
      "\n",
      "01_20_01:01:24 --- 1.705017328262329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:26 Training loss at epoch 3 step 1180: 2.928667187690735\n",
      "\n",
      " This round's valence_loss=0.8957022428512573, arousal_loss=0.6780955791473389, emotion_loss=0.6660261154174805\n",
      "\n",
      "01_20_01:01:26 Seen so far: 37792 samples\n",
      "\n",
      "01_20_01:01:26 --- 1.7126374244689941 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:28 Training loss at epoch 3 step 1190: 2.798154664039612\n",
      "\n",
      " This round's valence_loss=1.339874505996704, arousal_loss=1.189304232597351, emotion_loss=0.687472403049469\n",
      "\n",
      "01_20_01:01:28 Seen so far: 38112 samples\n",
      "\n",
      "01_20_01:01:28 --- 1.699065923690796 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:30 Training loss at epoch 3 step 1200: 2.731302499771118\n",
      "\n",
      " This round's valence_loss=0.7163516283035278, arousal_loss=0.6701270341873169, emotion_loss=0.7598646283149719\n",
      "\n",
      "01_20_01:01:30 Seen so far: 38432 samples\n",
      "\n",
      "01_20_01:01:30 --- 1.876434087753296 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:31 Training loss at epoch 3 step 1210: 2.823081135749817\n",
      "\n",
      " This round's valence_loss=0.8854055404663086, arousal_loss=0.7265478372573853, emotion_loss=0.7680525779724121\n",
      "\n",
      "01_20_01:01:31 Seen so far: 38752 samples\n",
      "\n",
      "01_20_01:01:31 --- 1.867384672164917 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:33 Training loss at epoch 3 step 1220: 2.8915634155273438\n",
      "\n",
      " This round's valence_loss=0.9880396127700806, arousal_loss=0.8338885307312012, emotion_loss=0.8779904842376709\n",
      "\n",
      "01_20_01:01:33 Seen so far: 39072 samples\n",
      "\n",
      "01_20_01:01:33 --- 1.709826946258545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:35 Training loss at epoch 3 step 1230: 3.033052158355713\n",
      "\n",
      " This round's valence_loss=0.8413805961608887, arousal_loss=0.7367721796035767, emotion_loss=0.8712745308876038\n",
      "\n",
      "01_20_01:01:35 Seen so far: 39392 samples\n",
      "\n",
      "01_20_01:01:35 --- 1.805570125579834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:37 Training loss at epoch 3 step 1240: 3.0119348049163817\n",
      "\n",
      " This round's valence_loss=1.1489136219024658, arousal_loss=0.9762871265411377, emotion_loss=1.0761722326278687\n",
      "\n",
      "01_20_01:01:37 Seen so far: 39712 samples\n",
      "\n",
      "01_20_01:01:37 --- 1.8816277980804443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:39 Training loss at epoch 3 step 1250: 3.1884119272232057\n",
      "\n",
      " This round's valence_loss=1.4430696964263916, arousal_loss=1.185025930404663, emotion_loss=0.7642712593078613\n",
      "\n",
      "01_20_01:01:39 Seen so far: 40032 samples\n",
      "\n",
      "01_20_01:01:39 --- 1.9317090511322021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:41 Training loss at epoch 3 step 1260: 3.1859573841094972\n",
      "\n",
      " This round's valence_loss=1.0570120811462402, arousal_loss=0.9941667318344116, emotion_loss=1.0344877243041992\n",
      "\n",
      "01_20_01:01:41 Seen so far: 40352 samples\n",
      "\n",
      "01_20_01:01:41 --- 1.8396415710449219 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:42 Training loss at epoch 3 step 1270: 3.008432388305664\n",
      "\n",
      " This round's valence_loss=0.9050910472869873, arousal_loss=0.6718552708625793, emotion_loss=0.9623479843139648\n",
      "\n",
      "01_20_01:01:42 Seen so far: 40672 samples\n",
      "\n",
      "01_20_01:01:42 --- 1.7157340049743652 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:44 Training loss at epoch 3 step 1280: 2.7305285692214967\n",
      "\n",
      " This round's valence_loss=0.7451062202453613, arousal_loss=0.6133602857589722, emotion_loss=1.0422046184539795\n",
      "\n",
      "01_20_01:01:44 Seen so far: 40992 samples\n",
      "\n",
      "01_20_01:01:44 --- 1.7696661949157715 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:46 Training loss at epoch 3 step 1290: 2.8573474168777464\n",
      "\n",
      " This round's valence_loss=0.6194247007369995, arousal_loss=0.5977632403373718, emotion_loss=1.0796842575073242\n",
      "\n",
      "01_20_01:01:46 Seen so far: 41312 samples\n",
      "\n",
      "01_20_01:01:46 --- 1.7752711772918701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:48 Training loss at epoch 3 step 1300: 3.184956741333008\n",
      "\n",
      " This round's valence_loss=1.251121997833252, arousal_loss=1.0670337677001953, emotion_loss=0.966323733329773\n",
      "\n",
      "01_20_01:01:48 Seen so far: 41632 samples\n",
      "\n",
      "01_20_01:01:48 --- 1.8042421340942383 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:49 Training loss at epoch 3 step 1310: 2.8815215826034546\n",
      "\n",
      " This round's valence_loss=1.244920253753662, arousal_loss=1.0523672103881836, emotion_loss=0.9124541282653809\n",
      "\n",
      "01_20_01:01:49 Seen so far: 41952 samples\n",
      "\n",
      "01_20_01:01:49 --- 1.6789863109588623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:51 Training loss at epoch 3 step 1320: 2.9890211701393126\n",
      "\n",
      " This round's valence_loss=1.5899531841278076, arousal_loss=1.430611252784729, emotion_loss=0.8051771521568298\n",
      "\n",
      "01_20_01:01:51 Seen so far: 42272 samples\n",
      "\n",
      "01_20_01:01:51 --- 1.7621698379516602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:53 Training loss at epoch 3 step 1330: 3.2471933603286742\n",
      "\n",
      " This round's valence_loss=0.9314165711402893, arousal_loss=0.7119085788726807, emotion_loss=0.6862250566482544\n",
      "\n",
      "01_20_01:01:53 Seen so far: 42592 samples\n",
      "\n",
      "01_20_01:01:53 --- 1.93050217628479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:55 Training loss at epoch 3 step 1340: 3.124534320831299\n",
      "\n",
      " This round's valence_loss=1.1648006439208984, arousal_loss=1.109956979751587, emotion_loss=1.137622356414795\n",
      "\n",
      "01_20_01:01:55 Seen so far: 42912 samples\n",
      "\n",
      "01_20_01:01:55 --- 1.9012327194213867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:57 Training loss at epoch 3 step 1350: 3.2337934255599974\n",
      "\n",
      " This round's valence_loss=1.0839972496032715, arousal_loss=0.9837780594825745, emotion_loss=0.8235498666763306\n",
      "\n",
      "01_20_01:01:57 Seen so far: 43232 samples\n",
      "\n",
      "01_20_01:01:57 --- 1.797698974609375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:01:59 Training loss at epoch 3 step 1360: 3.1552044630050657\n",
      "\n",
      " This round's valence_loss=0.8641135692596436, arousal_loss=0.7127274870872498, emotion_loss=1.1124498844146729\n",
      "\n",
      "01_20_01:01:59 Seen so far: 43552 samples\n",
      "\n",
      "01_20_01:01:59 --- 1.8684368133544922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:00 Training loss at epoch 3 step 1370: 2.683810293674469\n",
      "\n",
      " This round's valence_loss=0.5662755966186523, arousal_loss=0.32924020290374756, emotion_loss=0.8120414614677429\n",
      "\n",
      "01_20_01:02:00 Seen so far: 43872 samples\n",
      "\n",
      "01_20_01:02:00 --- 1.6291561126708984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:02 Training loss at epoch 3 step 1380: 2.9565696716308594\n",
      "\n",
      " This round's valence_loss=1.5707701444625854, arousal_loss=1.4500068426132202, emotion_loss=0.9491482973098755\n",
      "\n",
      "01_20_01:02:02 Seen so far: 44192 samples\n",
      "\n",
      "01_20_01:02:02 --- 1.8423182964324951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:04 Training loss at epoch 3 step 1390: 2.9454721927642824\n",
      "\n",
      " This round's valence_loss=0.997948169708252, arousal_loss=0.8039196729660034, emotion_loss=0.8336503505706787\n",
      "\n",
      "01_20_01:02:04 Seen so far: 44512 samples\n",
      "\n",
      "01_20_01:02:04 --- 1.9474499225616455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:06 Training loss at epoch 3 step 1400: 3.1093116283416746\n",
      "\n",
      " This round's valence_loss=1.8256711959838867, arousal_loss=1.6598763465881348, emotion_loss=0.7018889784812927\n",
      "\n",
      "01_20_01:02:06 Seen so far: 44832 samples\n",
      "\n",
      "01_20_01:02:06 --- 1.7424125671386719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:07 Training loss at epoch 3 step 1410: 2.763291037082672\n",
      "\n",
      " This round's valence_loss=0.9895296096801758, arousal_loss=0.8920562267303467, emotion_loss=0.6029152870178223\n",
      "\n",
      "01_20_01:02:07 Seen so far: 45152 samples\n",
      "\n",
      "01_20_01:02:07 --- 1.6977436542510986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:09 Training loss at epoch 3 step 1420: 2.9218663454055784\n",
      "\n",
      " This round's valence_loss=1.5706815719604492, arousal_loss=1.446435809135437, emotion_loss=1.1189203262329102\n",
      "\n",
      "01_20_01:02:09 Seen so far: 45472 samples\n",
      "\n",
      "01_20_01:02:09 --- 1.8417181968688965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:11 Training loss at epoch 3 step 1430: 3.111772084236145\n",
      "\n",
      " This round's valence_loss=1.3636891841888428, arousal_loss=1.222335696220398, emotion_loss=1.111735463142395\n",
      "\n",
      "01_20_01:02:11 Seen so far: 45792 samples\n",
      "\n",
      "01_20_01:02:11 --- 1.8117101192474365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:13 Training loss at epoch 3 step 1440: 3.116690182685852\n",
      "\n",
      " This round's valence_loss=1.2399258613586426, arousal_loss=1.059822916984558, emotion_loss=0.8780105113983154\n",
      "\n",
      "01_20_01:02:13 Seen so far: 46112 samples\n",
      "\n",
      "01_20_01:02:13 --- 1.8175246715545654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:15 Training loss at epoch 3 step 1450: 3.1348713397979737\n",
      "\n",
      " This round's valence_loss=1.0649875402450562, arousal_loss=0.9703958034515381, emotion_loss=0.8942263722419739\n",
      "\n",
      "01_20_01:02:15 Seen so far: 46432 samples\n",
      "\n",
      "01_20_01:02:15 --- 1.7285232543945312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:17 Training loss at epoch 3 step 1460: 3.2359225273132326\n",
      "\n",
      " This round's valence_loss=1.030785322189331, arousal_loss=0.9545203447341919, emotion_loss=0.9350347518920898\n",
      "\n",
      "01_20_01:02:17 Seen so far: 46752 samples\n",
      "\n",
      "01_20_01:02:17 --- 1.8866758346557617 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:18 Training loss at epoch 3 step 1470: 2.8280195355415345\n",
      "\n",
      " This round's valence_loss=0.7042739391326904, arousal_loss=0.44206422567367554, emotion_loss=0.5796829462051392\n",
      "\n",
      "01_20_01:02:18 Seen so far: 47072 samples\n",
      "\n",
      "01_20_01:02:18 --- 1.770857334136963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:20 Training loss at epoch 3 step 1480: 3.0953518390655517\n",
      "\n",
      " This round's valence_loss=1.122431993484497, arousal_loss=0.9382256865501404, emotion_loss=0.7180397510528564\n",
      "\n",
      "01_20_01:02:20 Seen so far: 47392 samples\n",
      "\n",
      "01_20_01:02:20 --- 1.702232837677002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:22 Training loss at epoch 3 step 1490: 3.023534154891968\n",
      "\n",
      " This round's valence_loss=0.5618497133255005, arousal_loss=0.4838443100452423, emotion_loss=0.9743080139160156\n",
      "\n",
      "01_20_01:02:22 Seen so far: 47712 samples\n",
      "\n",
      "01_20_01:02:22 --- 1.7309136390686035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:24 Training loss at epoch 3 step 1500: 2.7518633127212526\n",
      "\n",
      " This round's valence_loss=1.1931746006011963, arousal_loss=1.0593260526657104, emotion_loss=1.137789011001587\n",
      "\n",
      "01_20_01:02:24 Seen so far: 48032 samples\n",
      "\n",
      "01_20_01:02:24 --- 1.9002070426940918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:25 Training loss at epoch 3 step 1510: 2.8398061752319337\n",
      "\n",
      " This round's valence_loss=1.2145060300827026, arousal_loss=1.0692273378372192, emotion_loss=0.8728325366973877\n",
      "\n",
      "01_20_01:02:25 Seen so far: 48352 samples\n",
      "\n",
      "01_20_01:02:25 --- 1.612658977508545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:27 Training loss at epoch 3 step 1520: 3.1959172248840333\n",
      "\n",
      " This round's valence_loss=1.337430477142334, arousal_loss=1.1726500988006592, emotion_loss=0.8066517114639282\n",
      "\n",
      "01_20_01:02:27 Seen so far: 48672 samples\n",
      "\n",
      "01_20_01:02:27 --- 1.710864782333374 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:29 Training loss at epoch 3 step 1530: 3.0407111644744873\n",
      "\n",
      " This round's valence_loss=0.9964185953140259, arousal_loss=0.8717966079711914, emotion_loss=1.3744311332702637\n",
      "\n",
      "01_20_01:02:29 Seen so far: 48992 samples\n",
      "\n",
      "01_20_01:02:29 --- 1.9977209568023682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:31 Training loss at epoch 3 step 1540: 3.0582226276397706\n",
      "\n",
      " This round's valence_loss=1.218310832977295, arousal_loss=1.124422311782837, emotion_loss=1.0550248622894287\n",
      "\n",
      "01_20_01:02:31 Seen so far: 49312 samples\n",
      "\n",
      "01_20_01:02:31 --- 1.9805142879486084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:33 Training loss at epoch 3 step 1550: 2.890627455711365\n",
      "\n",
      " This round's valence_loss=1.1631375551223755, arousal_loss=1.1156421899795532, emotion_loss=0.9341059327125549\n",
      "\n",
      "01_20_01:02:33 Seen so far: 49632 samples\n",
      "\n",
      "01_20_01:02:33 --- 1.8038225173950195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:34 Training loss at epoch 3 step 1560: 2.8344634532928468\n",
      "\n",
      " This round's valence_loss=1.3081855773925781, arousal_loss=1.1839280128479004, emotion_loss=1.1810157299041748\n",
      "\n",
      "01_20_01:02:34 Seen so far: 49952 samples\n",
      "\n",
      "01_20_01:02:34 --- 1.6939902305603027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:36 Training loss at epoch 3 step 1570: 2.9880895376205445\n",
      "\n",
      " This round's valence_loss=0.9608890414237976, arousal_loss=0.8876069784164429, emotion_loss=1.2415741682052612\n",
      "\n",
      "01_20_01:02:36 Seen so far: 50272 samples\n",
      "\n",
      "01_20_01:02:36 --- 1.6806697845458984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:38 Training loss at epoch 3 step 1580: 2.8209482431411743\n",
      "\n",
      " This round's valence_loss=1.5995781421661377, arousal_loss=1.4292831420898438, emotion_loss=1.0792094469070435\n",
      "\n",
      "01_20_01:02:38 Seen so far: 50592 samples\n",
      "\n",
      "01_20_01:02:38 --- 1.9244697093963623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:40 Training loss at epoch 3 step 1590: 2.73685108423233\n",
      "\n",
      " This round's valence_loss=0.7765405178070068, arousal_loss=0.5623162388801575, emotion_loss=0.5012210607528687\n",
      "\n",
      "01_20_01:02:40 Seen so far: 50912 samples\n",
      "\n",
      "01_20_01:02:40 --- 1.630800724029541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:41 Training loss at epoch 3 step 1600: 2.9833478927612305\n",
      "\n",
      " This round's valence_loss=1.2825044393539429, arousal_loss=1.194847822189331, emotion_loss=1.0370548963546753\n",
      "\n",
      "01_20_01:02:41 Seen so far: 51232 samples\n",
      "\n",
      "01_20_01:02:41 --- 1.7560744285583496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:43 Training loss at epoch 3 step 1610: 2.8752502679824827\n",
      "\n",
      " This round's valence_loss=1.1514912843704224, arousal_loss=0.9229540228843689, emotion_loss=0.8899449110031128\n",
      "\n",
      "01_20_01:02:43 Seen so far: 51552 samples\n",
      "\n",
      "01_20_01:02:43 --- 1.7730169296264648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:45 Training loss at epoch 3 step 1620: 2.818332147598267\n",
      "\n",
      " This round's valence_loss=0.8007561564445496, arousal_loss=0.5517393350601196, emotion_loss=0.7949926853179932\n",
      "\n",
      "01_20_01:02:45 Seen so far: 51872 samples\n",
      "\n",
      "01_20_01:02:45 --- 1.6459040641784668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:47 Training loss at epoch 3 step 1630: 3.148664402961731\n",
      "\n",
      " This round's valence_loss=0.860364556312561, arousal_loss=0.7090697884559631, emotion_loss=0.5993349552154541\n",
      "\n",
      "01_20_01:02:47 Seen so far: 52192 samples\n",
      "\n",
      "01_20_01:02:47 --- 1.8124072551727295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:48 Training loss at epoch 3 step 1640: 2.860495924949646\n",
      "\n",
      " This round's valence_loss=0.9631129503250122, arousal_loss=0.8678950667381287, emotion_loss=1.1233808994293213\n",
      "\n",
      "01_20_01:02:48 Seen so far: 52512 samples\n",
      "\n",
      "01_20_01:02:48 --- 1.8023531436920166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:50 Training loss at epoch 3 step 1650: 2.692099189758301\n",
      "\n",
      " This round's valence_loss=0.9566158056259155, arousal_loss=0.8800468444824219, emotion_loss=0.9964263439178467\n",
      "\n",
      "01_20_01:02:50 Seen so far: 52832 samples\n",
      "\n",
      "01_20_01:02:50 --- 1.8511722087860107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:52 Training loss at epoch 3 step 1660: 3.0799480199813845\n",
      "\n",
      " This round's valence_loss=1.3307008743286133, arousal_loss=1.2150664329528809, emotion_loss=1.0332491397857666\n",
      "\n",
      "01_20_01:02:52 Seen so far: 53152 samples\n",
      "\n",
      "01_20_01:02:52 --- 1.7247388362884521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:54 Training loss at epoch 3 step 1670: 3.095616102218628\n",
      "\n",
      " This round's valence_loss=0.9043524265289307, arousal_loss=0.689100980758667, emotion_loss=0.7337096333503723\n",
      "\n",
      "01_20_01:02:54 Seen so far: 53472 samples\n",
      "\n",
      "01_20_01:02:54 --- 1.7153372764587402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:56 Training loss at epoch 3 step 1680: 2.7728520154953005\n",
      "\n",
      " This round's valence_loss=0.8072769641876221, arousal_loss=0.6283348798751831, emotion_loss=0.7227383852005005\n",
      "\n",
      "01_20_01:02:56 Seen so far: 53792 samples\n",
      "\n",
      "01_20_01:02:56 --- 1.8995392322540283 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:57 Training loss at epoch 3 step 1690: 2.779798436164856\n",
      "\n",
      " This round's valence_loss=0.6892303228378296, arousal_loss=0.50285804271698, emotion_loss=0.7795211672782898\n",
      "\n",
      "01_20_01:02:57 Seen so far: 54112 samples\n",
      "\n",
      "01_20_01:02:57 --- 1.6069090366363525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:02:59 Training loss at epoch 3 step 1700: 2.9246018171310424\n",
      "\n",
      " This round's valence_loss=1.090592861175537, arousal_loss=0.9376468658447266, emotion_loss=0.8641422986984253\n",
      "\n",
      "01_20_01:02:59 Seen so far: 54432 samples\n",
      "\n",
      "01_20_01:02:59 --- 1.8220772743225098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:01 Training loss at epoch 3 step 1710: 2.893944525718689\n",
      "\n",
      " This round's valence_loss=0.9169303178787231, arousal_loss=0.7322444915771484, emotion_loss=0.803764820098877\n",
      "\n",
      "01_20_01:03:01 Seen so far: 54752 samples\n",
      "\n",
      "01_20_01:03:01 --- 1.6707990169525146 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:02 Training loss at epoch 3 step 1720: 3.4546640396118162\n",
      "\n",
      " This round's valence_loss=1.0604491233825684, arousal_loss=0.9586216807365417, emotion_loss=0.8402990698814392\n",
      "\n",
      "01_20_01:03:02 Seen so far: 55072 samples\n",
      "\n",
      "01_20_01:03:02 --- 1.6651971340179443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:04 Training loss at epoch 3 step 1730: 3.161312770843506\n",
      "\n",
      " This round's valence_loss=1.3603092432022095, arousal_loss=1.1871821880340576, emotion_loss=1.0294029712677002\n",
      "\n",
      "01_20_01:03:04 Seen so far: 55392 samples\n",
      "\n",
      "01_20_01:03:04 --- 1.7265355587005615 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:06 Training loss at epoch 3 step 1740: 3.078888177871704\n",
      "\n",
      " This round's valence_loss=0.9645341634750366, arousal_loss=0.8182506561279297, emotion_loss=0.7189776301383972\n",
      "\n",
      "01_20_01:03:06 Seen so far: 55712 samples\n",
      "\n",
      "01_20_01:03:06 --- 1.8338472843170166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:08 Training loss at epoch 3 step 1750: 2.8122130393981934\n",
      "\n",
      " This round's valence_loss=1.1185595989227295, arousal_loss=0.9606866836547852, emotion_loss=1.0455124378204346\n",
      "\n",
      "01_20_01:03:08 Seen so far: 56032 samples\n",
      "\n",
      "01_20_01:03:08 --- 1.6595449447631836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:09 Training loss at epoch 3 step 1760: 2.9758914947509765\n",
      "\n",
      " This round's valence_loss=0.9107879400253296, arousal_loss=0.8665538430213928, emotion_loss=0.8753777146339417\n",
      "\n",
      "01_20_01:03:09 Seen so far: 56352 samples\n",
      "\n",
      "01_20_01:03:09 --- 1.8064498901367188 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:11 Training loss at epoch 3 step 1770: 2.607925999164581\n",
      "\n",
      " This round's valence_loss=1.103759527206421, arousal_loss=1.0130667686462402, emotion_loss=1.359613060951233\n",
      "\n",
      "01_20_01:03:11 Seen so far: 56672 samples\n",
      "\n",
      "01_20_01:03:11 --- 1.7910902500152588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:13 Training loss at epoch 3 step 1780: 2.8964024424552917\n",
      "\n",
      " This round's valence_loss=0.9280838966369629, arousal_loss=0.8268301486968994, emotion_loss=0.7595154047012329\n",
      "\n",
      "01_20_01:03:13 Seen so far: 56992 samples\n",
      "\n",
      "01_20_01:03:13 --- 1.662487506866455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:15 Training loss at epoch 3 step 1790: 2.8987915992736815\n",
      "\n",
      " This round's valence_loss=0.9840822815895081, arousal_loss=0.8523181080818176, emotion_loss=0.8466198444366455\n",
      "\n",
      "01_20_01:03:15 Seen so far: 57312 samples\n",
      "\n",
      "01_20_01:03:15 --- 1.8100883960723877 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:17 Training loss at epoch 3 step 1800: 3.2296098947525023\n",
      "\n",
      " This round's valence_loss=1.0188921689987183, arousal_loss=0.8310674428939819, emotion_loss=0.8446308374404907\n",
      "\n",
      "01_20_01:03:17 Seen so far: 57632 samples\n",
      "\n",
      "01_20_01:03:17 --- 1.8620529174804688 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:18 Training loss at epoch 3 step 1810: 2.9781110167503355\n",
      "\n",
      " This round's valence_loss=1.2525116205215454, arousal_loss=1.1292409896850586, emotion_loss=0.8622100353240967\n",
      "\n",
      "01_20_01:03:18 Seen so far: 57952 samples\n",
      "\n",
      "01_20_01:03:18 --- 1.8554883003234863 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:20 Training loss at epoch 3 step 1820: 2.656855583190918\n",
      "\n",
      " This round's valence_loss=0.8503749370574951, arousal_loss=0.7284255027770996, emotion_loss=0.8971998691558838\n",
      "\n",
      "01_20_01:03:20 Seen so far: 58272 samples\n",
      "\n",
      "01_20_01:03:20 --- 1.6549327373504639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:22 Training loss at epoch 3 step 1830: 3.1772961616516113\n",
      "\n",
      " This round's valence_loss=0.7965445518493652, arousal_loss=0.7002357840538025, emotion_loss=1.3872535228729248\n",
      "\n",
      "01_20_01:03:22 Seen so far: 58592 samples\n",
      "\n",
      "01_20_01:03:22 --- 1.811391830444336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:24 Training loss at epoch 3 step 1840: 3.1130337953567504\n",
      "\n",
      " This round's valence_loss=1.1035468578338623, arousal_loss=0.9630221724510193, emotion_loss=0.7927892208099365\n",
      "\n",
      "01_20_01:03:24 Seen so far: 58912 samples\n",
      "\n",
      "01_20_01:03:24 --- 1.6780426502227783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:25 Training loss at epoch 3 step 1850: 3.2609476327896116\n",
      "\n",
      " This round's valence_loss=1.230701208114624, arousal_loss=1.1074838638305664, emotion_loss=0.8101184964179993\n",
      "\n",
      "01_20_01:03:25 Seen so far: 59232 samples\n",
      "\n",
      "01_20_01:03:25 --- 1.852696180343628 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:27 Training loss at epoch 3 step 1860: 2.8909107446670532\n",
      "\n",
      " This round's valence_loss=0.8741722106933594, arousal_loss=0.6958204507827759, emotion_loss=0.930014431476593\n",
      "\n",
      "01_20_01:03:27 Seen so far: 59552 samples\n",
      "\n",
      "01_20_01:03:27 --- 1.6089231967926025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:29 Training loss at epoch 3 step 1870: 2.93354914188385\n",
      "\n",
      " This round's valence_loss=1.6561847925186157, arousal_loss=1.588858723640442, emotion_loss=1.0330491065979004\n",
      "\n",
      "01_20_01:03:29 Seen so far: 59872 samples\n",
      "\n",
      "01_20_01:03:29 --- 1.6540863513946533 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:30 Training loss at epoch 3 step 1880: 3.00193567276001\n",
      "\n",
      " This round's valence_loss=1.0604435205459595, arousal_loss=0.9956976175308228, emotion_loss=0.916751503944397\n",
      "\n",
      "01_20_01:03:30 Seen so far: 60192 samples\n",
      "\n",
      "01_20_01:03:30 --- 1.8065946102142334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:32 Training loss at epoch 3 step 1890: 3.0402738094329833\n",
      "\n",
      " This round's valence_loss=1.3398340940475464, arousal_loss=1.223043441772461, emotion_loss=1.019347071647644\n",
      "\n",
      "01_20_01:03:32 Seen so far: 60512 samples\n",
      "\n",
      "01_20_01:03:32 --- 1.6372897624969482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:34 Training loss at epoch 3 step 1900: 2.8936296701431274\n",
      "\n",
      " This round's valence_loss=1.2925529479980469, arousal_loss=1.2086232900619507, emotion_loss=0.8262665271759033\n",
      "\n",
      "01_20_01:03:34 Seen so far: 60832 samples\n",
      "\n",
      "01_20_01:03:34 --- 1.5647742748260498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:36 Training loss at epoch 3 step 1910: 3.081825518608093\n",
      "\n",
      " This round's valence_loss=0.7960860729217529, arousal_loss=0.5823496580123901, emotion_loss=0.7306133508682251\n",
      "\n",
      "01_20_01:03:36 Seen so far: 61152 samples\n",
      "\n",
      "01_20_01:03:36 --- 1.842670202255249 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:37 Training loss at epoch 3 step 1920: 2.8426831722259522\n",
      "\n",
      " This round's valence_loss=1.5539205074310303, arousal_loss=1.4737532138824463, emotion_loss=1.3208788633346558\n",
      "\n",
      "01_20_01:03:37 Seen so far: 61472 samples\n",
      "\n",
      "01_20_01:03:37 --- 1.5932912826538086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:39 Training loss at epoch 3 step 1930: 2.8520668268203737\n",
      "\n",
      " This round's valence_loss=0.8793516159057617, arousal_loss=0.709883451461792, emotion_loss=1.0932164192199707\n",
      "\n",
      "01_20_01:03:39 Seen so far: 61792 samples\n",
      "\n",
      "01_20_01:03:39 --- 1.9217815399169922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:41 Training loss at epoch 3 step 1940: 2.9600890636444093\n",
      "\n",
      " This round's valence_loss=1.1753003597259521, arousal_loss=0.9608701467514038, emotion_loss=0.9792837500572205\n",
      "\n",
      "01_20_01:03:41 Seen so far: 62112 samples\n",
      "\n",
      "01_20_01:03:41 --- 1.7326276302337646 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:43 Training loss at epoch 3 step 1950: 2.9677690982818605\n",
      "\n",
      " This round's valence_loss=1.236625075340271, arousal_loss=1.0929481983184814, emotion_loss=1.1717040538787842\n",
      "\n",
      "01_20_01:03:43 Seen so far: 62432 samples\n",
      "\n",
      "01_20_01:03:43 --- 1.8384935855865479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:44 Training loss at epoch 3 step 1960: 3.0870354890823366\n",
      "\n",
      " This round's valence_loss=0.8217818737030029, arousal_loss=0.6125272512435913, emotion_loss=1.022068738937378\n",
      "\n",
      "01_20_01:03:44 Seen so far: 62752 samples\n",
      "\n",
      "01_20_01:03:44 --- 1.7306501865386963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:46 Training loss at epoch 3 step 1970: 2.958327865600586\n",
      "\n",
      " This round's valence_loss=1.1879520416259766, arousal_loss=1.0779495239257812, emotion_loss=0.7080105543136597\n",
      "\n",
      "01_20_01:03:46 Seen so far: 63072 samples\n",
      "\n",
      "01_20_01:03:46 --- 1.8334014415740967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:48 Training loss at epoch 3 step 1980: 2.7681567668914795\n",
      "\n",
      " This round's valence_loss=1.0661442279815674, arousal_loss=0.9802840948104858, emotion_loss=0.9362679719924927\n",
      "\n",
      "01_20_01:03:48 Seen so far: 63392 samples\n",
      "\n",
      "01_20_01:03:48 --- 1.7084476947784424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:50 Training loss at epoch 3 step 1990: 3.216490292549133\n",
      "\n",
      " This round's valence_loss=1.7048723697662354, arousal_loss=1.5576772689819336, emotion_loss=1.0122734308242798\n",
      "\n",
      "01_20_01:03:50 Seen so far: 63712 samples\n",
      "\n",
      "01_20_01:03:50 --- 1.8212151527404785 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:52 Training loss at epoch 3 step 2000: 3.2272927284240724\n",
      "\n",
      " This round's valence_loss=1.7082825899124146, arousal_loss=1.5404739379882812, emotion_loss=0.7979865670204163\n",
      "\n",
      "01_20_01:03:52 Seen so far: 64032 samples\n",
      "\n",
      "01_20_01:03:52 --- 1.8501594066619873 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:53 Training loss at epoch 3 step 2010: 3.266052222251892\n",
      "\n",
      " This round's valence_loss=1.405134677886963, arousal_loss=1.319005012512207, emotion_loss=1.0675292015075684\n",
      "\n",
      "01_20_01:03:53 Seen so far: 64352 samples\n",
      "\n",
      "01_20_01:03:53 --- 1.758073329925537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:55 Training loss at epoch 3 step 2020: 2.6887266755104067\n",
      "\n",
      " This round's valence_loss=1.0876065492630005, arousal_loss=0.9370527267456055, emotion_loss=0.7979992032051086\n",
      "\n",
      "01_20_01:03:55 Seen so far: 64672 samples\n",
      "\n",
      "01_20_01:03:55 --- 1.7515432834625244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:57 Training loss at epoch 3 step 2030: 2.927068603038788\n",
      "\n",
      " This round's valence_loss=0.8241870999336243, arousal_loss=0.6034934520721436, emotion_loss=0.7221903800964355\n",
      "\n",
      "01_20_01:03:57 Seen so far: 64992 samples\n",
      "\n",
      "01_20_01:03:57 --- 2.0082383155822754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:03:59 Training loss at epoch 3 step 2040: 2.963497185707092\n",
      "\n",
      " This round's valence_loss=0.8520556688308716, arousal_loss=0.7179850339889526, emotion_loss=0.817585825920105\n",
      "\n",
      "01_20_01:03:59 Seen so far: 65312 samples\n",
      "\n",
      "01_20_01:03:59 --- 1.865760326385498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:01 Training loss at epoch 3 step 2050: 2.7689687967300416\n",
      "\n",
      " This round's valence_loss=0.9525829553604126, arousal_loss=0.8597463369369507, emotion_loss=0.6148238182067871\n",
      "\n",
      "01_20_01:04:01 Seen so far: 65632 samples\n",
      "\n",
      "01_20_01:04:01 --- 1.9379334449768066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:03 Training loss at epoch 3 step 2060: 2.7018441915512086\n",
      "\n",
      " This round's valence_loss=1.1258783340454102, arousal_loss=0.9182624220848083, emotion_loss=1.1697673797607422\n",
      "\n",
      "01_20_01:04:03 Seen so far: 65952 samples\n",
      "\n",
      "01_20_01:04:03 --- 1.76393723487854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:04 Training loss at epoch 3 step 2070: 3.2095873832702635\n",
      "\n",
      " This round's valence_loss=1.0651733875274658, arousal_loss=0.9833458662033081, emotion_loss=1.2882764339447021\n",
      "\n",
      "01_20_01:04:04 Seen so far: 66272 samples\n",
      "\n",
      "01_20_01:04:04 --- 1.626990795135498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:06 Training loss at epoch 3 step 2080: 3.2068557024002073\n",
      "\n",
      " This round's valence_loss=1.3122605085372925, arousal_loss=1.067878246307373, emotion_loss=0.9784150123596191\n",
      "\n",
      "01_20_01:04:06 Seen so far: 66592 samples\n",
      "\n",
      "01_20_01:04:06 --- 1.8896050453186035 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:08 Training loss at epoch 3 step 2090: 3.241939973831177\n",
      "\n",
      " This round's valence_loss=1.279012680053711, arousal_loss=1.053515911102295, emotion_loss=0.848195493221283\n",
      "\n",
      "01_20_01:04:08 Seen so far: 66912 samples\n",
      "\n",
      "01_20_01:04:08 --- 1.6296930313110352 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:09 Training loss at epoch 3 step 2100: 2.9981356143951414\n",
      "\n",
      " This round's valence_loss=0.6388223171234131, arousal_loss=0.5543167591094971, emotion_loss=1.1644413471221924\n",
      "\n",
      "01_20_01:04:09 Seen so far: 67232 samples\n",
      "\n",
      "01_20_01:04:09 --- 1.5649335384368896 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:11 Training loss at epoch 3 step 2110: 3.066127908229828\n",
      "\n",
      " This round's valence_loss=1.4583934545516968, arousal_loss=1.3345786333084106, emotion_loss=1.17109215259552\n",
      "\n",
      "01_20_01:04:11 Seen so far: 67552 samples\n",
      "\n",
      "01_20_01:04:11 --- 1.7765724658966064 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:13 Training loss at epoch 3 step 2120: 3.0741450548172\n",
      "\n",
      " This round's valence_loss=1.7855368852615356, arousal_loss=1.6884363889694214, emotion_loss=1.0296270847320557\n",
      "\n",
      "01_20_01:04:13 Seen so far: 67872 samples\n",
      "\n",
      "01_20_01:04:13 --- 1.7923831939697266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:15 Training loss at epoch 3 step 2130: 3.4643786430358885\n",
      "\n",
      " This round's valence_loss=0.7074614763259888, arousal_loss=0.6090859770774841, emotion_loss=1.2500722408294678\n",
      "\n",
      "01_20_01:04:15 Seen so far: 68192 samples\n",
      "\n",
      "01_20_01:04:15 --- 1.7987236976623535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:17 Training loss at epoch 3 step 2140: 3.492324638366699\n",
      "\n",
      " This round's valence_loss=1.0478720664978027, arousal_loss=0.8372759819030762, emotion_loss=1.3117139339447021\n",
      "\n",
      "01_20_01:04:17 Seen so far: 68512 samples\n",
      "\n",
      "01_20_01:04:17 --- 1.8202717304229736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:18 Training loss at epoch 3 step 2150: 3.185585355758667\n",
      "\n",
      " This round's valence_loss=1.4579576253890991, arousal_loss=1.3461799621582031, emotion_loss=0.9907751083374023\n",
      "\n",
      "01_20_01:04:18 Seen so far: 68832 samples\n",
      "\n",
      "01_20_01:04:18 --- 1.7860591411590576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:20 Training loss at epoch 3 step 2160: 3.0991687297821047\n",
      "\n",
      " This round's valence_loss=1.339940071105957, arousal_loss=1.1984297037124634, emotion_loss=1.0631682872772217\n",
      "\n",
      "01_20_01:04:20 Seen so far: 69152 samples\n",
      "\n",
      "01_20_01:04:20 --- 1.8104596138000488 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:22 Training loss at epoch 3 step 2170: 2.7799071788787844\n",
      "\n",
      " This round's valence_loss=1.0252727270126343, arousal_loss=0.825391411781311, emotion_loss=0.9249347448348999\n",
      "\n",
      "01_20_01:04:22 Seen so far: 69472 samples\n",
      "\n",
      "01_20_01:04:22 --- 1.653832197189331 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:24 Training loss at epoch 3 step 2180: 3.2019799947738647\n",
      "\n",
      " This round's valence_loss=1.4223589897155762, arousal_loss=1.3545809984207153, emotion_loss=1.054046392440796\n",
      "\n",
      "01_20_01:04:24 Seen so far: 69792 samples\n",
      "\n",
      "01_20_01:04:24 --- 1.76499342918396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:25 Training loss at epoch 3 step 2190: 2.924522042274475\n",
      "\n",
      " This round's valence_loss=0.9979508519172668, arousal_loss=0.8468139171600342, emotion_loss=0.5879767537117004\n",
      "\n",
      "01_20_01:04:25 Seen so far: 70112 samples\n",
      "\n",
      "01_20_01:04:25 --- 1.785883903503418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:27 Training loss at epoch 3 step 2200: 2.444531035423279\n",
      "\n",
      " This round's valence_loss=1.082348108291626, arousal_loss=0.9264154434204102, emotion_loss=0.8159106373786926\n",
      "\n",
      "01_20_01:04:27 Seen so far: 70432 samples\n",
      "\n",
      "01_20_01:04:27 --- 1.799185037612915 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:29 Training loss at epoch 3 step 2210: 2.9323471069335936\n",
      "\n",
      " This round's valence_loss=0.8723759055137634, arousal_loss=0.7277685403823853, emotion_loss=0.8142014741897583\n",
      "\n",
      "01_20_01:04:29 Seen so far: 70752 samples\n",
      "\n",
      "01_20_01:04:29 --- 1.8578472137451172 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:31 Training loss at epoch 3 step 2220: 2.9265452146530153\n",
      "\n",
      " This round's valence_loss=0.9852511882781982, arousal_loss=0.8811941146850586, emotion_loss=0.7336961030960083\n",
      "\n",
      "01_20_01:04:31 Seen so far: 71072 samples\n",
      "\n",
      "01_20_01:04:31 --- 1.8932123184204102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:33 Training loss at epoch 3 step 2230: 3.233155608177185\n",
      "\n",
      " This round's valence_loss=1.4605580568313599, arousal_loss=1.3930625915527344, emotion_loss=1.1322202682495117\n",
      "\n",
      "01_20_01:04:33 Seen so far: 71392 samples\n",
      "\n",
      "01_20_01:04:33 --- 1.7565135955810547 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:34 Training loss at epoch 3 step 2240: 2.733107566833496\n",
      "\n",
      " This round's valence_loss=0.575778603553772, arousal_loss=0.3376949727535248, emotion_loss=0.9548449516296387\n",
      "\n",
      "01_20_01:04:34 Seen so far: 71712 samples\n",
      "\n",
      "01_20_01:04:34 --- 1.8048865795135498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:36 Training loss at epoch 3 step 2250: 3.1613371849060057\n",
      "\n",
      " This round's valence_loss=0.8254150152206421, arousal_loss=0.742280125617981, emotion_loss=1.0540200471878052\n",
      "\n",
      "01_20_01:04:36 Seen so far: 72032 samples\n",
      "\n",
      "01_20_01:04:36 --- 1.9145607948303223 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:38 Training loss at epoch 3 step 2260: 2.8414138078689577\n",
      "\n",
      " This round's valence_loss=1.215151309967041, arousal_loss=1.134164571762085, emotion_loss=1.0394413471221924\n",
      "\n",
      "01_20_01:04:38 Seen so far: 72352 samples\n",
      "\n",
      "01_20_01:04:38 --- 1.8227267265319824 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:40 Training loss at epoch 3 step 2270: 3.0921902656555176\n",
      "\n",
      " This round's valence_loss=1.2704576253890991, arousal_loss=1.0717952251434326, emotion_loss=1.0543075799942017\n",
      "\n",
      "01_20_01:04:40 Seen so far: 72672 samples\n",
      "\n",
      "01_20_01:04:40 --- 1.8023757934570312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:42 Training loss at epoch 3 step 2280: 2.863592338562012\n",
      "\n",
      " This round's valence_loss=1.109771966934204, arousal_loss=0.9573956727981567, emotion_loss=0.971820592880249\n",
      "\n",
      "01_20_01:04:42 Seen so far: 72992 samples\n",
      "\n",
      "01_20_01:04:42 --- 1.875185251235962 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:44 Training loss at epoch 3 step 2290: 3.196980929374695\n",
      "\n",
      " This round's valence_loss=1.217966079711914, arousal_loss=1.1060729026794434, emotion_loss=1.1362757682800293\n",
      "\n",
      "01_20_01:04:44 Seen so far: 73312 samples\n",
      "\n",
      "01_20_01:04:44 --- 1.644601821899414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:45 Training loss at epoch 3 step 2300: 2.981263852119446\n",
      "\n",
      " This round's valence_loss=0.8381756544113159, arousal_loss=0.6864211559295654, emotion_loss=0.981522262096405\n",
      "\n",
      "01_20_01:04:45 Seen so far: 73632 samples\n",
      "\n",
      "01_20_01:04:45 --- 1.6596159934997559 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:47 Training loss at epoch 3 step 2310: 2.7156451463699343\n",
      "\n",
      " This round's valence_loss=1.2231481075286865, arousal_loss=1.1127614974975586, emotion_loss=0.7864438891410828\n",
      "\n",
      "01_20_01:04:47 Seen so far: 73952 samples\n",
      "\n",
      "01_20_01:04:47 --- 1.6811223030090332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:49 Training loss at epoch 3 step 2320: 2.7373969078063967\n",
      "\n",
      " This round's valence_loss=0.8674945831298828, arousal_loss=0.7253208756446838, emotion_loss=0.9233430624008179\n",
      "\n",
      "01_20_01:04:49 Seen so far: 74272 samples\n",
      "\n",
      "01_20_01:04:49 --- 1.8273181915283203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:50 Training loss at epoch 3 step 2330: 3.0612416505813598\n",
      "\n",
      " This round's valence_loss=0.9978936314582825, arousal_loss=0.8754889965057373, emotion_loss=0.8515865802764893\n",
      "\n",
      "01_20_01:04:50 Seen so far: 74592 samples\n",
      "\n",
      "01_20_01:04:50 --- 1.8152720928192139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:52 Training loss at epoch 3 step 2340: 3.1099002361297607\n",
      "\n",
      " This round's valence_loss=1.6290966272354126, arousal_loss=1.5660595893859863, emotion_loss=0.9098976850509644\n",
      "\n",
      "01_20_01:04:52 Seen so far: 74912 samples\n",
      "\n",
      "01_20_01:04:52 --- 1.8612024784088135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:54 Training loss at epoch 3 step 2350: 2.916488432884216\n",
      "\n",
      " This round's valence_loss=0.999356746673584, arousal_loss=0.8346723318099976, emotion_loss=0.6777672171592712\n",
      "\n",
      "01_20_01:04:54 Seen so far: 75232 samples\n",
      "\n",
      "01_20_01:04:54 --- 1.8050382137298584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:56 Training loss at epoch 3 step 2360: 3.048730421066284\n",
      "\n",
      " This round's valence_loss=1.3408222198486328, arousal_loss=1.2045618295669556, emotion_loss=1.169637680053711\n",
      "\n",
      "01_20_01:04:56 Seen so far: 75552 samples\n",
      "\n",
      "01_20_01:04:56 --- 1.6706254482269287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:58 Training loss at epoch 3 step 2370: 2.6817280530929564\n",
      "\n",
      " This round's valence_loss=0.5956448912620544, arousal_loss=0.33087727427482605, emotion_loss=0.582055926322937\n",
      "\n",
      "01_20_01:04:58 Seen so far: 75872 samples\n",
      "\n",
      "01_20_01:04:58 --- 1.816805124282837 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:04:59 Training loss at epoch 3 step 2380: 2.651810073852539\n",
      "\n",
      " This round's valence_loss=0.9670616984367371, arousal_loss=0.8002451658248901, emotion_loss=0.751556932926178\n",
      "\n",
      "01_20_01:04:59 Seen so far: 76192 samples\n",
      "\n",
      "01_20_01:04:59 --- 1.6710121631622314 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:01 Training loss at epoch 3 step 2390: 3.270414400100708\n",
      "\n",
      " This round's valence_loss=1.0921077728271484, arousal_loss=0.9598788619041443, emotion_loss=0.6079200506210327\n",
      "\n",
      "01_20_01:05:01 Seen so far: 76512 samples\n",
      "\n",
      "01_20_01:05:01 --- 1.6170825958251953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:03 Training loss at epoch 3 step 2400: 2.750781846046448\n",
      "\n",
      " This round's valence_loss=0.8727248311042786, arousal_loss=0.7575187683105469, emotion_loss=0.6532507538795471\n",
      "\n",
      "01_20_01:05:03 Seen so far: 76832 samples\n",
      "\n",
      "01_20_01:05:03 --- 1.8243005275726318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:05 Training loss at epoch 3 step 2410: 2.9276675939559937\n",
      "\n",
      " This round's valence_loss=0.985649824142456, arousal_loss=0.7915010452270508, emotion_loss=0.6570875644683838\n",
      "\n",
      "01_20_01:05:05 Seen so far: 77152 samples\n",
      "\n",
      "01_20_01:05:05 --- 1.7908790111541748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:06 Training loss at epoch 3 step 2420: 3.040202021598816\n",
      "\n",
      " This round's valence_loss=1.4243425130844116, arousal_loss=1.3213518857955933, emotion_loss=0.8458261489868164\n",
      "\n",
      "01_20_01:05:06 Seen so far: 77472 samples\n",
      "\n",
      "01_20_01:05:06 --- 1.9275445938110352 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:08 Training loss at epoch 3 step 2430: 3.216919469833374\n",
      "\n",
      " This round's valence_loss=1.2246677875518799, arousal_loss=1.099094033241272, emotion_loss=0.9568917751312256\n",
      "\n",
      "01_20_01:05:08 Seen so far: 77792 samples\n",
      "\n",
      "01_20_01:05:08 --- 1.6863367557525635 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:10 Training loss at epoch 3 step 2440: 3.030674958229065\n",
      "\n",
      " This round's valence_loss=0.9267838001251221, arousal_loss=0.8054611682891846, emotion_loss=1.200088381767273\n",
      "\n",
      "01_20_01:05:10 Seen so far: 78112 samples\n",
      "\n",
      "01_20_01:05:10 --- 1.680924654006958 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:12 Training loss at epoch 3 step 2450: 3.0031468629837037\n",
      "\n",
      " This round's valence_loss=0.8787206411361694, arousal_loss=0.7534475326538086, emotion_loss=1.0714635848999023\n",
      "\n",
      "01_20_01:05:12 Seen so far: 78432 samples\n",
      "\n",
      "01_20_01:05:12 --- 1.7612721920013428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:13 Training loss at epoch 3 step 2460: 2.9860116124153135\n",
      "\n",
      " This round's valence_loss=1.1185390949249268, arousal_loss=0.961675763130188, emotion_loss=1.1075308322906494\n",
      "\n",
      "01_20_01:05:13 Seen so far: 78752 samples\n",
      "\n",
      "01_20_01:05:13 --- 1.8310396671295166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:15 Training loss at epoch 3 step 2470: 3.028780150413513\n",
      "\n",
      " This round's valence_loss=0.9851983785629272, arousal_loss=0.8639041781425476, emotion_loss=1.0768630504608154\n",
      "\n",
      "01_20_01:05:15 Seen so far: 79072 samples\n",
      "\n",
      "01_20_01:05:15 --- 1.9480538368225098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:17 Training loss at epoch 3 step 2480: 2.915722918510437\n",
      "\n",
      " This round's valence_loss=0.9804379940032959, arousal_loss=0.8465484380722046, emotion_loss=0.8367396593093872\n",
      "\n",
      "01_20_01:05:17 Seen so far: 79392 samples\n",
      "\n",
      "01_20_01:05:17 --- 1.811915397644043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:19 Training loss at epoch 3 step 2490: 2.366890001296997\n",
      "\n",
      " This round's valence_loss=0.8789318203926086, arousal_loss=0.7096610069274902, emotion_loss=0.6124452352523804\n",
      "\n",
      "01_20_01:05:19 Seen so far: 79712 samples\n",
      "\n",
      "01_20_01:05:19 --- 1.7451343536376953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:21 Training loss at epoch 3 step 2500: 3.100473189353943\n",
      "\n",
      " This round's valence_loss=1.1594297885894775, arousal_loss=0.9064267873764038, emotion_loss=0.7948591709136963\n",
      "\n",
      "01_20_01:05:21 Seen so far: 80032 samples\n",
      "\n",
      "01_20_01:05:21 --- 1.6696736812591553 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:22 Training loss at epoch 3 step 2510: 3.304258608818054\n",
      "\n",
      " This round's valence_loss=1.121093988418579, arousal_loss=0.9602887630462646, emotion_loss=0.8700445294380188\n",
      "\n",
      "01_20_01:05:22 Seen so far: 80352 samples\n",
      "\n",
      "01_20_01:05:22 --- 1.687384843826294 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:24 Training loss at epoch 3 step 2520: 3.1593704223632812\n",
      "\n",
      " This round's valence_loss=1.324916958808899, arousal_loss=1.2291138172149658, emotion_loss=0.8966971039772034\n",
      "\n",
      "01_20_01:05:24 Seen so far: 80672 samples\n",
      "\n",
      "01_20_01:05:24 --- 1.7988073825836182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:26 Training loss at epoch 3 step 2530: 3.056791603565216\n",
      "\n",
      " This round's valence_loss=1.0183205604553223, arousal_loss=0.8098763227462769, emotion_loss=1.0838561058044434\n",
      "\n",
      "01_20_01:05:26 Seen so far: 80992 samples\n",
      "\n",
      "01_20_01:05:26 --- 1.774683952331543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:28 Training loss at epoch 3 step 2540: 3.0362005949020388\n",
      "\n",
      " This round's valence_loss=0.9907686710357666, arousal_loss=0.8440788984298706, emotion_loss=1.0030783414840698\n",
      "\n",
      "01_20_01:05:28 Seen so far: 81312 samples\n",
      "\n",
      "01_20_01:05:28 --- 1.7202982902526855 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:29 Training loss at epoch 3 step 2550: 3.0970200538635253\n",
      "\n",
      " This round's valence_loss=1.426289677619934, arousal_loss=1.305861473083496, emotion_loss=1.1646056175231934\n",
      "\n",
      "01_20_01:05:29 Seen so far: 81632 samples\n",
      "\n",
      "01_20_01:05:29 --- 1.7009484767913818 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:31 Training loss at epoch 3 step 2560: 2.8413774013519286\n",
      "\n",
      " This round's valence_loss=0.9324244856834412, arousal_loss=0.715389609336853, emotion_loss=0.9936858415603638\n",
      "\n",
      "01_20_01:05:31 Seen so far: 81952 samples\n",
      "\n",
      "01_20_01:05:31 --- 1.7328064441680908 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:33 Training loss at epoch 3 step 2570: 2.983930468559265\n",
      "\n",
      " This round's valence_loss=0.8015464544296265, arousal_loss=0.6312922239303589, emotion_loss=0.9673380851745605\n",
      "\n",
      "01_20_01:05:33 Seen so far: 82272 samples\n",
      "\n",
      "01_20_01:05:33 --- 1.7633228302001953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:34 Training loss at epoch 3 step 2580: 2.6581074953079225\n",
      "\n",
      " This round's valence_loss=1.591928482055664, arousal_loss=1.4397331476211548, emotion_loss=0.6790164113044739\n",
      "\n",
      "01_20_01:05:34 Seen so far: 82592 samples\n",
      "\n",
      "01_20_01:05:34 --- 1.6363248825073242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:36 Training loss at epoch 3 step 2590: 3.00141499042511\n",
      "\n",
      " This round's valence_loss=0.8997273445129395, arousal_loss=0.6703604459762573, emotion_loss=0.5252948999404907\n",
      "\n",
      "01_20_01:05:36 Seen so far: 82912 samples\n",
      "\n",
      "01_20_01:05:36 --- 1.7182791233062744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:38 Training loss at epoch 3 step 2600: 2.8466192722320556\n",
      "\n",
      " This round's valence_loss=0.5268923044204712, arousal_loss=0.33925506472587585, emotion_loss=0.9691539406776428\n",
      "\n",
      "01_20_01:05:38 Seen so far: 83232 samples\n",
      "\n",
      "01_20_01:05:38 --- 1.9455983638763428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:40 Training loss at epoch 3 step 2610: 2.8843629598617553\n",
      "\n",
      " This round's valence_loss=1.0635838508605957, arousal_loss=0.939427375793457, emotion_loss=0.9440219402313232\n",
      "\n",
      "01_20_01:05:40 Seen so far: 83552 samples\n",
      "\n",
      "01_20_01:05:40 --- 1.6007308959960938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:41 Training loss at epoch 3 step 2620: 3.4326034069061278\n",
      "\n",
      " This round's valence_loss=1.4979074001312256, arousal_loss=1.3363251686096191, emotion_loss=0.9622592926025391\n",
      "\n",
      "01_20_01:05:41 Seen so far: 83872 samples\n",
      "\n",
      "01_20_01:05:41 --- 1.7748382091522217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:43 Training loss at epoch 3 step 2630: 2.7577114582061766\n",
      "\n",
      " This round's valence_loss=1.1252110004425049, arousal_loss=0.999800443649292, emotion_loss=1.047001838684082\n",
      "\n",
      "01_20_01:05:43 Seen so far: 84192 samples\n",
      "\n",
      "01_20_01:05:43 --- 1.7979049682617188 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:45 Training loss at epoch 3 step 2640: 2.992634725570679\n",
      "\n",
      " This round's valence_loss=1.0521056652069092, arousal_loss=0.8322290778160095, emotion_loss=0.6805904507637024\n",
      "\n",
      "01_20_01:05:45 Seen so far: 84512 samples\n",
      "\n",
      "01_20_01:05:45 --- 1.8913238048553467 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:47 Training loss at epoch 3 step 2650: 2.8497922897338865\n",
      "\n",
      " This round's valence_loss=0.869102954864502, arousal_loss=0.6824907064437866, emotion_loss=1.0331677198410034\n",
      "\n",
      "01_20_01:05:47 Seen so far: 84832 samples\n",
      "\n",
      "01_20_01:05:47 --- 1.833920955657959 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:49 Training loss at epoch 3 step 2660: 2.9638399124145507\n",
      "\n",
      " This round's valence_loss=1.147049903869629, arousal_loss=0.9345941543579102, emotion_loss=0.8435362577438354\n",
      "\n",
      "01_20_01:05:49 Seen so far: 85152 samples\n",
      "\n",
      "01_20_01:05:49 --- 1.8515839576721191 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:51 Training loss at epoch 3 step 2670: 3.0989981174468992\n",
      "\n",
      " This round's valence_loss=1.0071768760681152, arousal_loss=0.6891552805900574, emotion_loss=0.7680562734603882\n",
      "\n",
      "01_20_01:05:51 Seen so far: 85472 samples\n",
      "\n",
      "01_20_01:05:51 --- 1.7709753513336182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:52 Training loss at epoch 3 step 2680: 3.039344644546509\n",
      "\n",
      " This round's valence_loss=1.227150321006775, arousal_loss=1.0514912605285645, emotion_loss=0.7813047170639038\n",
      "\n",
      "01_20_01:05:52 Seen so far: 85792 samples\n",
      "\n",
      "01_20_01:05:52 --- 1.7145788669586182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:54 Training loss at epoch 3 step 2690: 2.8387133121490478\n",
      "\n",
      " This round's valence_loss=1.2534064054489136, arousal_loss=1.0465166568756104, emotion_loss=0.7555326223373413\n",
      "\n",
      "01_20_01:05:54 Seen so far: 86112 samples\n",
      "\n",
      "01_20_01:05:54 --- 1.6992990970611572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:56 Training loss at epoch 3 step 2700: 3.10070264339447\n",
      "\n",
      " This round's valence_loss=0.9257116913795471, arousal_loss=0.8283832669258118, emotion_loss=0.9472206830978394\n",
      "\n",
      "01_20_01:05:56 Seen so far: 86432 samples\n",
      "\n",
      "01_20_01:05:56 --- 1.669039249420166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:57 Training loss at epoch 3 step 2710: 3.295121741294861\n",
      "\n",
      " This round's valence_loss=1.3499518632888794, arousal_loss=1.2067022323608398, emotion_loss=0.8459357023239136\n",
      "\n",
      "01_20_01:05:57 Seen so far: 86752 samples\n",
      "\n",
      "01_20_01:05:57 --- 1.629472255706787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:05:59 Training loss at epoch 3 step 2720: 2.8815072536468507\n",
      "\n",
      " This round's valence_loss=1.4439616203308105, arousal_loss=1.326634407043457, emotion_loss=0.6339903473854065\n",
      "\n",
      "01_20_01:05:59 Seen so far: 87072 samples\n",
      "\n",
      "01_20_01:05:59 --- 1.6910035610198975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:01 Training loss at epoch 3 step 2730: 3.032704544067383\n",
      "\n",
      " This round's valence_loss=0.8987765312194824, arousal_loss=0.8413440585136414, emotion_loss=1.0899935960769653\n",
      "\n",
      "01_20_01:06:01 Seen so far: 87392 samples\n",
      "\n",
      "01_20_01:06:01 --- 1.6103589534759521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:02 Training loss at epoch 3 step 2740: 3.0458322882652284\n",
      "\n",
      " This round's valence_loss=1.2881767749786377, arousal_loss=1.1754558086395264, emotion_loss=0.7979661822319031\n",
      "\n",
      "01_20_01:06:02 Seen so far: 87712 samples\n",
      "\n",
      "01_20_01:06:02 --- 1.7116146087646484 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:04 Training loss at epoch 3 step 2750: 3.3003029823303223\n",
      "\n",
      " This round's valence_loss=1.363625407218933, arousal_loss=1.1888689994812012, emotion_loss=1.061837077140808\n",
      "\n",
      "01_20_01:06:04 Seen so far: 88032 samples\n",
      "\n",
      "01_20_01:06:04 --- 1.8032200336456299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:06 Training loss at epoch 3 step 2760: 2.8693954706192017\n",
      "\n",
      " This round's valence_loss=1.164724588394165, arousal_loss=1.074446439743042, emotion_loss=0.9553805589675903\n",
      "\n",
      "01_20_01:06:06 Seen so far: 88352 samples\n",
      "\n",
      "01_20_01:06:06 --- 1.6946399211883545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:08 Training loss at epoch 3 step 2770: 3.0122634172439575\n",
      "\n",
      " This round's valence_loss=0.9693998694419861, arousal_loss=0.8065274953842163, emotion_loss=0.8217346668243408\n",
      "\n",
      "01_20_01:06:08 Seen so far: 88672 samples\n",
      "\n",
      "01_20_01:06:08 --- 1.7816808223724365 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:09 Training loss at epoch 3 step 2780: 2.9494055271148683\n",
      "\n",
      " This round's valence_loss=1.3534047603607178, arousal_loss=1.2209067344665527, emotion_loss=0.9332497715950012\n",
      "\n",
      "01_20_01:06:09 Seen so far: 88992 samples\n",
      "\n",
      "01_20_01:06:09 --- 1.8670337200164795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:11 Training loss at epoch 3 step 2790: 3.138566517829895\n",
      "\n",
      " This round's valence_loss=1.1916718482971191, arousal_loss=1.1121063232421875, emotion_loss=0.8692435026168823\n",
      "\n",
      "01_20_01:06:11 Seen so far: 89312 samples\n",
      "\n",
      "01_20_01:06:11 --- 1.8881902694702148 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:13 Training loss at epoch 3 step 2800: 3.022659993171692\n",
      "\n",
      " This round's valence_loss=1.1783865690231323, arousal_loss=1.0862727165222168, emotion_loss=0.9711019396781921\n",
      "\n",
      "01_20_01:06:13 Seen so far: 89632 samples\n",
      "\n",
      "01_20_01:06:13 --- 1.7311348915100098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:15 Training loss at epoch 3 step 2810: 2.9237385749816895\n",
      "\n",
      " This round's valence_loss=1.2654420137405396, arousal_loss=1.0724384784698486, emotion_loss=0.7616884708404541\n",
      "\n",
      "01_20_01:06:15 Seen so far: 89952 samples\n",
      "\n",
      "01_20_01:06:15 --- 1.8967115879058838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:17 Training loss at epoch 3 step 2820: 2.711681771278381\n",
      "\n",
      " This round's valence_loss=0.43862271308898926, arousal_loss=0.36934447288513184, emotion_loss=0.9916080832481384\n",
      "\n",
      "01_20_01:06:17 Seen so far: 90272 samples\n",
      "\n",
      "01_20_01:06:17 --- 1.9050111770629883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:19 Training loss at epoch 3 step 2830: 3.1581989169120788\n",
      "\n",
      " This round's valence_loss=1.6424179077148438, arousal_loss=1.464745044708252, emotion_loss=0.9997751712799072\n",
      "\n",
      "01_20_01:06:19 Seen so far: 90592 samples\n",
      "\n",
      "01_20_01:06:19 --- 1.596221923828125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:20 Training loss at epoch 3 step 2840: 2.8136371850967405\n",
      "\n",
      " This round's valence_loss=1.094321846961975, arousal_loss=0.9583117961883545, emotion_loss=0.7216895818710327\n",
      "\n",
      "01_20_01:06:20 Seen so far: 90912 samples\n",
      "\n",
      "01_20_01:06:20 --- 1.6481828689575195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:22 Training loss at epoch 3 step 2850: 3.0774516820907594\n",
      "\n",
      " This round's valence_loss=0.7962300777435303, arousal_loss=0.5729670524597168, emotion_loss=0.8345608711242676\n",
      "\n",
      "01_20_01:06:22 Seen so far: 91232 samples\n",
      "\n",
      "01_20_01:06:22 --- 1.8225674629211426 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:24 Training loss at epoch 3 step 2860: 3.051396894454956\n",
      "\n",
      " This round's valence_loss=1.1142148971557617, arousal_loss=1.019054651260376, emotion_loss=1.085763931274414\n",
      "\n",
      "01_20_01:06:24 Seen so far: 91552 samples\n",
      "\n",
      "01_20_01:06:24 --- 1.635221004486084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:25 Training loss at epoch 3 step 2870: 3.0028472423553465\n",
      "\n",
      " This round's valence_loss=1.3884289264678955, arousal_loss=1.3401880264282227, emotion_loss=0.9447624683380127\n",
      "\n",
      "01_20_01:06:25 Seen so far: 91872 samples\n",
      "\n",
      "01_20_01:06:25 --- 1.7909059524536133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:27 Training loss at epoch 3 step 2880: 3.4104129552841185\n",
      "\n",
      " This round's valence_loss=1.4222676753997803, arousal_loss=1.3492069244384766, emotion_loss=1.0377259254455566\n",
      "\n",
      "01_20_01:06:27 Seen so far: 92192 samples\n",
      "\n",
      "01_20_01:06:27 --- 1.7147815227508545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:29 Training loss at epoch 3 step 2890: 3.0015650272369383\n",
      "\n",
      " This round's valence_loss=1.564676284790039, arousal_loss=1.4881904125213623, emotion_loss=1.1314432621002197\n",
      "\n",
      "01_20_01:06:29 Seen so far: 92512 samples\n",
      "\n",
      "01_20_01:06:29 --- 1.887786865234375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:31 Training loss at epoch 3 step 2900: 2.899957466125488\n",
      "\n",
      " This round's valence_loss=1.4258410930633545, arousal_loss=1.3201792240142822, emotion_loss=1.0784302949905396\n",
      "\n",
      "01_20_01:06:31 Seen so far: 92832 samples\n",
      "\n",
      "01_20_01:06:31 --- 1.932802677154541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:33 Training loss at epoch 3 step 2910: 3.1593746185302733\n",
      "\n",
      " This round's valence_loss=1.3096108436584473, arousal_loss=1.2343165874481201, emotion_loss=0.8977808952331543\n",
      "\n",
      "01_20_01:06:33 Seen so far: 93152 samples\n",
      "\n",
      "01_20_01:06:33 --- 1.9171168804168701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:35 Training loss at epoch 3 step 2920: 2.807302916049957\n",
      "\n",
      " This round's valence_loss=1.66550612449646, arousal_loss=1.5797593593597412, emotion_loss=0.7048448324203491\n",
      "\n",
      "01_20_01:06:35 Seen so far: 93472 samples\n",
      "\n",
      "01_20_01:06:35 --- 2.1144673824310303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:37 Training loss at epoch 3 step 2930: 3.1287440776824953\n",
      "\n",
      " This round's valence_loss=1.150391697883606, arousal_loss=1.1105213165283203, emotion_loss=1.0506726503372192\n",
      "\n",
      "01_20_01:06:37 Seen so far: 93792 samples\n",
      "\n",
      "01_20_01:06:37 --- 1.6641771793365479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:39 Training loss at epoch 3 step 2940: 2.5964452981948853\n",
      "\n",
      " This round's valence_loss=1.1148579120635986, arousal_loss=0.9627895355224609, emotion_loss=0.8238677978515625\n",
      "\n",
      "01_20_01:06:39 Seen so far: 94112 samples\n",
      "\n",
      "01_20_01:06:39 --- 1.992964267730713 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:40 Training loss at epoch 3 step 2950: 3.0956681966781616\n",
      "\n",
      " This round's valence_loss=1.2444357872009277, arousal_loss=1.0878195762634277, emotion_loss=0.8554551601409912\n",
      "\n",
      "01_20_01:06:40 Seen so far: 94432 samples\n",
      "\n",
      "01_20_01:06:40 --- 1.7896544933319092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:42 Training loss at epoch 3 step 2960: 3.289898085594177\n",
      "\n",
      " This round's valence_loss=1.5151445865631104, arousal_loss=1.4782211780548096, emotion_loss=0.9902525544166565\n",
      "\n",
      "01_20_01:06:42 Seen so far: 94752 samples\n",
      "\n",
      "01_20_01:06:42 --- 1.711745262145996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:44 Training loss at epoch 3 step 2970: 3.1789490222930907\n",
      "\n",
      " This round's valence_loss=1.0274901390075684, arousal_loss=0.8459392786026001, emotion_loss=0.9857660531997681\n",
      "\n",
      "01_20_01:06:44 Seen so far: 95072 samples\n",
      "\n",
      "01_20_01:06:44 --- 1.6580753326416016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:46 Training loss at epoch 3 step 2980: 3.065174174308777\n",
      "\n",
      " This round's valence_loss=1.457567811012268, arousal_loss=1.316215991973877, emotion_loss=0.8535066843032837\n",
      "\n",
      "01_20_01:06:46 Seen so far: 95392 samples\n",
      "\n",
      "01_20_01:06:46 --- 1.7323503494262695 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:47 Training loss at epoch 3 step 2990: 2.7935595989227293\n",
      "\n",
      " This round's valence_loss=1.094567060470581, arousal_loss=0.9630953073501587, emotion_loss=1.0350035429000854\n",
      "\n",
      "01_20_01:06:47 Seen so far: 95712 samples\n",
      "\n",
      "01_20_01:06:47 --- 1.644479513168335 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:49 Training loss at epoch 3 step 3000: 2.8967832565307616\n",
      "\n",
      " This round's valence_loss=0.8719125390052795, arousal_loss=0.6792266964912415, emotion_loss=0.9109631180763245\n",
      "\n",
      "01_20_01:06:49 Seen so far: 96032 samples\n",
      "\n",
      "01_20_01:06:49 --- 1.804077386856079 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:51 Training loss at epoch 3 step 3010: 2.9866361379623414\n",
      "\n",
      " This round's valence_loss=1.0730385780334473, arousal_loss=0.9766761660575867, emotion_loss=0.894098162651062\n",
      "\n",
      "01_20_01:06:51 Seen so far: 96352 samples\n",
      "\n",
      "01_20_01:06:51 --- 1.7371585369110107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:53 Training loss at epoch 3 step 3020: 2.744724464416504\n",
      "\n",
      " This round's valence_loss=1.2253365516662598, arousal_loss=1.0822687149047852, emotion_loss=0.9026256799697876\n",
      "\n",
      "01_20_01:06:53 Seen so far: 96672 samples\n",
      "\n",
      "01_20_01:06:53 --- 1.9191467761993408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:54 Training loss at epoch 3 step 3030: 3.1693057775497437\n",
      "\n",
      " This round's valence_loss=1.4598239660263062, arousal_loss=1.3066058158874512, emotion_loss=0.9144001603126526\n",
      "\n",
      "01_20_01:06:54 Seen so far: 96992 samples\n",
      "\n",
      "01_20_01:06:54 --- 1.6543359756469727 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:56 Training loss at epoch 3 step 3040: 2.8587257981300356\n",
      "\n",
      " This round's valence_loss=1.0960663557052612, arousal_loss=0.961819589138031, emotion_loss=1.1975274085998535\n",
      "\n",
      "01_20_01:06:56 Seen so far: 97312 samples\n",
      "\n",
      "01_20_01:06:56 --- 1.6263573169708252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:58 Training loss at epoch 3 step 3050: 3.0724485874176026\n",
      "\n",
      " This round's valence_loss=1.0357258319854736, arousal_loss=0.8199722766876221, emotion_loss=1.009136438369751\n",
      "\n",
      "01_20_01:06:58 Seen so far: 97632 samples\n",
      "\n",
      "01_20_01:06:58 --- 1.7452383041381836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:06:59 Training loss at epoch 3 step 3060: 2.8836325883865355\n",
      "\n",
      " This round's valence_loss=1.0492191314697266, arousal_loss=0.961898684501648, emotion_loss=1.030570387840271\n",
      "\n",
      "01_20_01:06:59 Seen so far: 97952 samples\n",
      "\n",
      "01_20_01:06:59 --- 1.7196192741394043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:01 Training loss at epoch 3 step 3070: 3.121746563911438\n",
      "\n",
      " This round's valence_loss=0.8242461681365967, arousal_loss=0.7095069885253906, emotion_loss=0.9151724576950073\n",
      "\n",
      "01_20_01:07:01 Seen so far: 98272 samples\n",
      "\n",
      "01_20_01:07:01 --- 1.7584142684936523 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:03 Training loss at epoch 3 step 3080: 2.9893188953399656\n",
      "\n",
      " This round's valence_loss=1.090293049812317, arousal_loss=1.0127935409545898, emotion_loss=0.7762293815612793\n",
      "\n",
      "01_20_01:07:03 Seen so far: 98592 samples\n",
      "\n",
      "01_20_01:07:03 --- 1.8544504642486572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:05 Training loss at epoch 3 step 3090: 3.007023334503174\n",
      "\n",
      " This round's valence_loss=1.55414879322052, arousal_loss=1.4631578922271729, emotion_loss=0.8098445534706116\n",
      "\n",
      "01_20_01:07:05 Seen so far: 98912 samples\n",
      "\n",
      "01_20_01:07:05 --- 1.8122084140777588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:07 Training loss at epoch 3 step 3100: 2.904593801498413\n",
      "\n",
      " This round's valence_loss=0.8290891647338867, arousal_loss=0.6966521739959717, emotion_loss=0.7891852855682373\n",
      "\n",
      "01_20_01:07:07 Seen so far: 99232 samples\n",
      "\n",
      "01_20_01:07:07 --- 1.9082846641540527 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:08 Training loss at epoch 3 step 3110: 2.9384869813919066\n",
      "\n",
      " This round's valence_loss=0.9577715396881104, arousal_loss=0.8463289737701416, emotion_loss=0.8921539783477783\n",
      "\n",
      "01_20_01:07:08 Seen so far: 99552 samples\n",
      "\n",
      "01_20_01:07:08 --- 1.697361707687378 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:10 Training loss at epoch 3 step 3120: 3.239447546005249\n",
      "\n",
      " This round's valence_loss=1.483919620513916, arousal_loss=1.280442476272583, emotion_loss=0.7217363715171814\n",
      "\n",
      "01_20_01:07:10 Seen so far: 99872 samples\n",
      "\n",
      "01_20_01:07:10 --- 1.8020215034484863 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:12 Training loss at epoch 3 step 3130: 3.168860673904419\n",
      "\n",
      " This round's valence_loss=1.1305993795394897, arousal_loss=0.9509800672531128, emotion_loss=1.0664677619934082\n",
      "\n",
      "01_20_01:07:12 Seen so far: 100192 samples\n",
      "\n",
      "01_20_01:07:12 --- 1.6036467552185059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:13 Training loss at epoch 3 step 3140: 2.962796688079834\n",
      "\n",
      " This round's valence_loss=1.099405288696289, arousal_loss=0.984096109867096, emotion_loss=0.9182770848274231\n",
      "\n",
      "01_20_01:07:13 Seen so far: 100512 samples\n",
      "\n",
      "01_20_01:07:13 --- 1.6223692893981934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:15 Training loss at epoch 3 step 3150: 3.1074399948120117\n",
      "\n",
      " This round's valence_loss=1.102808952331543, arousal_loss=0.985954999923706, emotion_loss=1.125070333480835\n",
      "\n",
      "01_20_01:07:15 Seen so far: 100832 samples\n",
      "\n",
      "01_20_01:07:15 --- 1.6768591403961182 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:17 Training loss at epoch 3 step 3160: 2.772017705440521\n",
      "\n",
      " This round's valence_loss=1.166556477546692, arousal_loss=0.9736519455909729, emotion_loss=1.151801586151123\n",
      "\n",
      "01_20_01:07:17 Seen so far: 101152 samples\n",
      "\n",
      "01_20_01:07:17 --- 1.7016973495483398 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:18 Training loss at epoch 3 step 3170: 3.1038361549377442\n",
      "\n",
      " This round's valence_loss=0.8498975038528442, arousal_loss=0.7065664529800415, emotion_loss=1.1221849918365479\n",
      "\n",
      "01_20_01:07:18 Seen so far: 101472 samples\n",
      "\n",
      "01_20_01:07:18 --- 1.643777847290039 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:20 Training loss at epoch 3 step 3180: 2.9040332555770876\n",
      "\n",
      " This round's valence_loss=0.6647636890411377, arousal_loss=0.44457781314849854, emotion_loss=1.049100399017334\n",
      "\n",
      "01_20_01:07:20 Seen so far: 101792 samples\n",
      "\n",
      "01_20_01:07:20 --- 1.7254645824432373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:22 Training loss at epoch 3 step 3190: 2.9290674448013307\n",
      "\n",
      " This round's valence_loss=0.9631680250167847, arousal_loss=0.8566492795944214, emotion_loss=0.9815080761909485\n",
      "\n",
      "01_20_01:07:22 Seen so far: 102112 samples\n",
      "\n",
      "01_20_01:07:22 --- 1.7334363460540771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:24 Training loss at epoch 3 step 3200: 3.2605180144309998\n",
      "\n",
      " This round's valence_loss=1.4079993963241577, arousal_loss=1.3150922060012817, emotion_loss=0.843356192111969\n",
      "\n",
      "01_20_01:07:24 Seen so far: 102432 samples\n",
      "\n",
      "01_20_01:07:24 --- 1.783557415008545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:25 Training loss at epoch 3 step 3210: 3.4518105506896974\n",
      "\n",
      " This round's valence_loss=1.1980416774749756, arousal_loss=0.9588513374328613, emotion_loss=0.6213614344596863\n",
      "\n",
      "01_20_01:07:25 Seen so far: 102752 samples\n",
      "\n",
      "01_20_01:07:25 --- 1.6885015964508057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:27 Training loss at epoch 3 step 3220: 3.1904901027679444\n",
      "\n",
      " This round's valence_loss=1.4006624221801758, arousal_loss=1.3223421573638916, emotion_loss=1.243795394897461\n",
      "\n",
      "01_20_01:07:27 Seen so far: 103072 samples\n",
      "\n",
      "01_20_01:07:27 --- 1.8522367477416992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:29 Training loss at epoch 3 step 3230: 3.0267571449279784\n",
      "\n",
      " This round's valence_loss=1.1826659440994263, arousal_loss=0.9209067821502686, emotion_loss=0.7225613594055176\n",
      "\n",
      "01_20_01:07:29 Seen so far: 103392 samples\n",
      "\n",
      "01_20_01:07:29 --- 1.6864020824432373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:31 Training loss at epoch 3 step 3240: 3.1614300847053527\n",
      "\n",
      " This round's valence_loss=1.2003644704818726, arousal_loss=1.0947213172912598, emotion_loss=0.5816839933395386\n",
      "\n",
      "01_20_01:07:31 Seen so far: 103712 samples\n",
      "\n",
      "01_20_01:07:31 --- 1.7780086994171143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:32 Training loss at epoch 3 step 3250: 2.923973226547241\n",
      "\n",
      " This round's valence_loss=0.8636807203292847, arousal_loss=0.6917046308517456, emotion_loss=1.3191180229187012\n",
      "\n",
      "01_20_01:07:32 Seen so far: 104032 samples\n",
      "\n",
      "01_20_01:07:32 --- 1.772508144378662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:34 Training loss at epoch 3 step 3260: 3.0020660638809202\n",
      "\n",
      " This round's valence_loss=1.221129298210144, arousal_loss=1.0828304290771484, emotion_loss=0.8949843645095825\n",
      "\n",
      "01_20_01:07:34 Seen so far: 104352 samples\n",
      "\n",
      "01_20_01:07:34 --- 1.9256999492645264 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:36 Training loss at epoch 3 step 3270: 2.953268313407898\n",
      "\n",
      " This round's valence_loss=0.6972094774246216, arousal_loss=0.5959992408752441, emotion_loss=0.9071217775344849\n",
      "\n",
      "01_20_01:07:36 Seen so far: 104672 samples\n",
      "\n",
      "01_20_01:07:36 --- 1.9024507999420166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:38 Training loss at epoch 3 step 3280: 2.9409932851791383\n",
      "\n",
      " This round's valence_loss=1.1421101093292236, arousal_loss=0.9487043023109436, emotion_loss=0.9183998107910156\n",
      "\n",
      "01_20_01:07:38 Seen so far: 104992 samples\n",
      "\n",
      "01_20_01:07:38 --- 1.8484292030334473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:40 Training loss at epoch 3 step 3290: 2.9835236787796022\n",
      "\n",
      " This round's valence_loss=0.9354057312011719, arousal_loss=0.8839886784553528, emotion_loss=1.2287777662277222\n",
      "\n",
      "01_20_01:07:40 Seen so far: 105312 samples\n",
      "\n",
      "01_20_01:07:40 --- 1.7291250228881836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:42 Training loss at epoch 3 step 3300: 2.705800175666809\n",
      "\n",
      " This round's valence_loss=1.3325097560882568, arousal_loss=1.1620659828186035, emotion_loss=0.7494186162948608\n",
      "\n",
      "01_20_01:07:42 Seen so far: 105632 samples\n",
      "\n",
      "01_20_01:07:42 --- 1.6664361953735352 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:43 Training loss at epoch 3 step 3310: 2.8751686334609987\n",
      "\n",
      " This round's valence_loss=1.1262061595916748, arousal_loss=0.9944300651550293, emotion_loss=1.1132540702819824\n",
      "\n",
      "01_20_01:07:43 Seen so far: 105952 samples\n",
      "\n",
      "01_20_01:07:43 --- 1.6251723766326904 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:45 Training loss at epoch 3 step 3320: 3.333640718460083\n",
      "\n",
      " This round's valence_loss=1.344104528427124, arousal_loss=1.1949381828308105, emotion_loss=0.748782753944397\n",
      "\n",
      "01_20_01:07:45 Seen so far: 106272 samples\n",
      "\n",
      "01_20_01:07:45 --- 1.6826190948486328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:47 Training loss at epoch 3 step 3330: 2.8170594215393066\n",
      "\n",
      " This round's valence_loss=1.0379691123962402, arousal_loss=0.8325473070144653, emotion_loss=0.8182710409164429\n",
      "\n",
      "01_20_01:07:47 Seen so far: 106592 samples\n",
      "\n",
      "01_20_01:07:47 --- 1.751136064529419 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:48 Training loss at epoch 3 step 3340: 3.063470196723938\n",
      "\n",
      " This round's valence_loss=1.1651394367218018, arousal_loss=0.9653928279876709, emotion_loss=0.6546781063079834\n",
      "\n",
      "01_20_01:07:48 Seen so far: 106912 samples\n",
      "\n",
      "01_20_01:07:48 --- 1.8577370643615723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:50 Training loss at epoch 3 step 3350: 3.109912705421448\n",
      "\n",
      " This round's valence_loss=0.9820877909660339, arousal_loss=0.8906062841415405, emotion_loss=1.0818963050842285\n",
      "\n",
      "01_20_01:07:50 Seen so far: 107232 samples\n",
      "\n",
      "01_20_01:07:50 --- 1.6306533813476562 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:52 Training loss at epoch 3 step 3360: 2.9989665031433104\n",
      "\n",
      " This round's valence_loss=1.0591928958892822, arousal_loss=0.8606255054473877, emotion_loss=1.1171573400497437\n",
      "\n",
      "01_20_01:07:52 Seen so far: 107552 samples\n",
      "\n",
      "01_20_01:07:52 --- 1.7226641178131104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:54 Training loss at epoch 3 step 3370: 3.022789478302002\n",
      "\n",
      " This round's valence_loss=0.9641950130462646, arousal_loss=0.8761018514633179, emotion_loss=0.9216495752334595\n",
      "\n",
      "01_20_01:07:54 Seen so far: 107872 samples\n",
      "\n",
      "01_20_01:07:54 --- 1.885439395904541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:55 Training loss at epoch 3 step 3380: 2.714444613456726\n",
      "\n",
      " This round's valence_loss=0.9442135095596313, arousal_loss=0.8607497811317444, emotion_loss=1.0481765270233154\n",
      "\n",
      "01_20_01:07:55 Seen so far: 108192 samples\n",
      "\n",
      "01_20_01:07:55 --- 1.7851073741912842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:57 Training loss at epoch 3 step 3390: 2.906945753097534\n",
      "\n",
      " This round's valence_loss=0.6916017532348633, arousal_loss=0.46805596351623535, emotion_loss=1.017464280128479\n",
      "\n",
      "01_20_01:07:57 Seen so far: 108512 samples\n",
      "\n",
      "01_20_01:07:57 --- 1.7284095287322998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:07:59 Training loss at epoch 3 step 3400: 3.0002889394760133\n",
      "\n",
      " This round's valence_loss=1.3676388263702393, arousal_loss=1.2245053052902222, emotion_loss=1.2753698825836182\n",
      "\n",
      "01_20_01:07:59 Seen so far: 108832 samples\n",
      "\n",
      "01_20_01:07:59 --- 1.7509276866912842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:01 Training loss at epoch 3 step 3410: 3.3116783142089843\n",
      "\n",
      " This round's valence_loss=0.8054325580596924, arousal_loss=0.7086058855056763, emotion_loss=0.9366582632064819\n",
      "\n",
      "01_20_01:08:01 Seen so far: 109152 samples\n",
      "\n",
      "01_20_01:08:01 --- 1.7687761783599854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:03 Training loss at epoch 3 step 3420: 3.4846489667892455\n",
      "\n",
      " This round's valence_loss=1.6526051759719849, arousal_loss=1.525592565536499, emotion_loss=0.7855616807937622\n",
      "\n",
      "01_20_01:08:03 Seen so far: 109472 samples\n",
      "\n",
      "01_20_01:08:03 --- 1.917997121810913 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:04 Training loss at epoch 3 step 3430: 3.0299060106277467\n",
      "\n",
      " This round's valence_loss=1.58046555519104, arousal_loss=1.5854133367538452, emotion_loss=0.6165011525154114\n",
      "\n",
      "01_20_01:08:04 Seen so far: 109792 samples\n",
      "\n",
      "01_20_01:08:04 --- 1.7267847061157227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:06 Training loss at epoch 3 step 3440: 3.299126124382019\n",
      "\n",
      " This round's valence_loss=0.7610560655593872, arousal_loss=0.6521583795547485, emotion_loss=1.1953006982803345\n",
      "\n",
      "01_20_01:08:06 Seen so far: 110112 samples\n",
      "\n",
      "01_20_01:08:06 --- 1.724034309387207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:08 Training loss at epoch 3 step 3450: 3.2188108921051026\n",
      "\n",
      " This round's valence_loss=1.3707966804504395, arousal_loss=1.320136308670044, emotion_loss=1.2381203174591064\n",
      "\n",
      "01_20_01:08:08 Seen so far: 110432 samples\n",
      "\n",
      "01_20_01:08:08 --- 1.6384773254394531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:09 Training loss at epoch 3 step 3460: 3.2732745170593263\n",
      "\n",
      " This round's valence_loss=1.2978134155273438, arousal_loss=1.2026331424713135, emotion_loss=0.9718718528747559\n",
      "\n",
      "01_20_01:08:09 Seen so far: 110752 samples\n",
      "\n",
      "01_20_01:08:09 --- 1.7452945709228516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:11 Training loss at epoch 3 step 3470: 2.910592484474182\n",
      "\n",
      " This round's valence_loss=0.6779892444610596, arousal_loss=0.6142188310623169, emotion_loss=1.0050973892211914\n",
      "\n",
      "01_20_01:08:11 Seen so far: 111072 samples\n",
      "\n",
      "01_20_01:08:11 --- 1.720106601715088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:13 Training loss at epoch 3 step 3480: 3.03065345287323\n",
      "\n",
      " This round's valence_loss=0.9138835668563843, arousal_loss=0.864700198173523, emotion_loss=1.261578917503357\n",
      "\n",
      "01_20_01:08:13 Seen so far: 111392 samples\n",
      "\n",
      "01_20_01:08:13 --- 1.7988777160644531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:15 Training loss at epoch 3 step 3490: 2.718482732772827\n",
      "\n",
      " This round's valence_loss=0.923335075378418, arousal_loss=0.852368175983429, emotion_loss=0.9263495206832886\n",
      "\n",
      "01_20_01:08:15 Seen so far: 111712 samples\n",
      "\n",
      "01_20_01:08:15 --- 1.801814317703247 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:17 Training loss at epoch 3 step 3500: 2.7000418663024903\n",
      "\n",
      " This round's valence_loss=1.1459559202194214, arousal_loss=0.9932284355163574, emotion_loss=0.8908524513244629\n",
      "\n",
      "01_20_01:08:17 Seen so far: 112032 samples\n",
      "\n",
      "01_20_01:08:17 --- 1.7652428150177002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:18 Training loss at epoch 3 step 3510: 2.7864050388336183\n",
      "\n",
      " This round's valence_loss=0.7407422661781311, arousal_loss=0.6425954103469849, emotion_loss=1.054693341255188\n",
      "\n",
      "01_20_01:08:18 Seen so far: 112352 samples\n",
      "\n",
      "01_20_01:08:18 --- 1.633206844329834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:20 Training loss at epoch 3 step 3520: 3.423313283920288\n",
      "\n",
      " This round's valence_loss=1.1037499904632568, arousal_loss=0.9612123966217041, emotion_loss=0.9869273900985718\n",
      "\n",
      "01_20_01:08:20 Seen so far: 112672 samples\n",
      "\n",
      "01_20_01:08:20 --- 1.8648931980133057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:22 Training loss at epoch 3 step 3530: 2.7203755378723145\n",
      "\n",
      " This round's valence_loss=0.7557443380355835, arousal_loss=0.6326872110366821, emotion_loss=1.031886339187622\n",
      "\n",
      "01_20_01:08:22 Seen so far: 112992 samples\n",
      "\n",
      "01_20_01:08:22 --- 1.6554737091064453 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:24 Training loss at epoch 3 step 3540: 2.6428815722465515\n",
      "\n",
      " This round's valence_loss=0.8855302333831787, arousal_loss=0.669587254524231, emotion_loss=0.9850019812583923\n",
      "\n",
      "01_20_01:08:24 Seen so far: 113312 samples\n",
      "\n",
      "01_20_01:08:24 --- 1.8305647373199463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:26 Training loss at epoch 3 step 3550: 2.6101842284202577\n",
      "\n",
      " This round's valence_loss=0.7245835065841675, arousal_loss=0.6028679609298706, emotion_loss=0.7990020513534546\n",
      "\n",
      "01_20_01:08:26 Seen so far: 113632 samples\n",
      "\n",
      "01_20_01:08:26 --- 1.9917564392089844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:27 Training loss at epoch 3 step 3560: 3.4488240480422974\n",
      "\n",
      " This round's valence_loss=1.453498125076294, arousal_loss=1.2957217693328857, emotion_loss=0.9705157279968262\n",
      "\n",
      "01_20_01:08:27 Seen so far: 113952 samples\n",
      "\n",
      "01_20_01:08:27 --- 1.724578619003296 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:29 Training loss at epoch 3 step 3570: 2.9856364488601685\n",
      "\n",
      " This round's valence_loss=1.0162646770477295, arousal_loss=0.9357236623764038, emotion_loss=0.9337944388389587\n",
      "\n",
      "01_20_01:08:29 Seen so far: 114272 samples\n",
      "\n",
      "01_20_01:08:29 --- 1.7086265087127686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:31 Training loss at epoch 3 step 3580: 2.758053779602051\n",
      "\n",
      " This round's valence_loss=0.7699630260467529, arousal_loss=0.5844593048095703, emotion_loss=0.9393841028213501\n",
      "\n",
      "01_20_01:08:31 Seen so far: 114592 samples\n",
      "\n",
      "01_20_01:08:31 --- 1.9917044639587402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:33 Training loss at epoch 3 step 3590: 3.025078368186951\n",
      "\n",
      " This round's valence_loss=1.1329119205474854, arousal_loss=1.021936058998108, emotion_loss=0.9808981418609619\n",
      "\n",
      "01_20_01:08:33 Seen so far: 114912 samples\n",
      "\n",
      "01_20_01:08:33 --- 1.6179184913635254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:34 Training loss at epoch 3 step 3600: 3.498627018928528\n",
      "\n",
      " This round's valence_loss=1.6913721561431885, arousal_loss=1.5562251806259155, emotion_loss=0.6968502402305603\n",
      "\n",
      "01_20_01:08:34 Seen so far: 115232 samples\n",
      "\n",
      "01_20_01:08:34 --- 1.7630739212036133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:36 Training loss at epoch 3 step 3610: 3.0020477294921877\n",
      "\n",
      " This round's valence_loss=1.369708776473999, arousal_loss=1.3503737449645996, emotion_loss=1.1310198307037354\n",
      "\n",
      "01_20_01:08:36 Seen so far: 115552 samples\n",
      "\n",
      "01_20_01:08:36 --- 1.6355657577514648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:38 Training loss at epoch 3 step 3620: 2.94161034822464\n",
      "\n",
      " This round's valence_loss=0.5243399739265442, arousal_loss=0.3655950129032135, emotion_loss=0.8855427503585815\n",
      "\n",
      "01_20_01:08:38 Seen so far: 115872 samples\n",
      "\n",
      "01_20_01:08:38 --- 1.7967987060546875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:39 Training loss at epoch 3 step 3630: 3.1611025094985963\n",
      "\n",
      " This round's valence_loss=1.0843422412872314, arousal_loss=1.0041894912719727, emotion_loss=1.1757889986038208\n",
      "\n",
      "01_20_01:08:39 Seen so far: 116192 samples\n",
      "\n",
      "01_20_01:08:39 --- 1.6557674407958984 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:41 Training loss at epoch 3 step 3640: 2.917785906791687\n",
      "\n",
      " This round's valence_loss=0.6142675280570984, arousal_loss=0.4778779447078705, emotion_loss=0.9103268384933472\n",
      "\n",
      "01_20_01:08:41 Seen so far: 116512 samples\n",
      "\n",
      "01_20_01:08:41 --- 1.7102265357971191 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:43 Training loss at epoch 3 step 3650: 2.929555058479309\n",
      "\n",
      " This round's valence_loss=0.9585946798324585, arousal_loss=0.8373805284500122, emotion_loss=1.4334040880203247\n",
      "\n",
      "01_20_01:08:43 Seen so far: 116832 samples\n",
      "\n",
      "01_20_01:08:43 --- 1.6963181495666504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:45 Training loss at epoch 3 step 3660: 2.817488360404968\n",
      "\n",
      " This round's valence_loss=0.8506990671157837, arousal_loss=0.6868569254875183, emotion_loss=0.8210400342941284\n",
      "\n",
      "01_20_01:08:45 Seen so far: 117152 samples\n",
      "\n",
      "01_20_01:08:45 --- 1.8676507472991943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:46 Training loss at epoch 3 step 3670: 2.8123494267463682\n",
      "\n",
      " This round's valence_loss=0.6024335026741028, arousal_loss=0.4720383882522583, emotion_loss=1.1652898788452148\n",
      "\n",
      "01_20_01:08:46 Seen so far: 117472 samples\n",
      "\n",
      "01_20_01:08:46 --- 1.7347443103790283 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:48 Training loss at epoch 3 step 3680: 2.9644680261611938\n",
      "\n",
      " This round's valence_loss=1.0011142492294312, arousal_loss=0.9249637126922607, emotion_loss=0.9339067935943604\n",
      "\n",
      "01_20_01:08:48 Seen so far: 117792 samples\n",
      "\n",
      "01_20_01:08:48 --- 1.882988452911377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:50 Training loss at epoch 3 step 3690: 3.2090843677520753\n",
      "\n",
      " This round's valence_loss=1.552377462387085, arousal_loss=1.4651422500610352, emotion_loss=0.9121803641319275\n",
      "\n",
      "01_20_01:08:50 Seen so far: 118112 samples\n",
      "\n",
      "01_20_01:08:50 --- 1.6834146976470947 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:52 Training loss at epoch 3 step 3700: 2.931013321876526\n",
      "\n",
      " This round's valence_loss=1.2712082862854004, arousal_loss=1.0244439840316772, emotion_loss=0.6230733394622803\n",
      "\n",
      "01_20_01:08:52 Seen so far: 118432 samples\n",
      "\n",
      "01_20_01:08:52 --- 1.7912142276763916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:54 Training loss at epoch 3 step 3710: 3.1784546613693236\n",
      "\n",
      " This round's valence_loss=1.1479136943817139, arousal_loss=0.9354546666145325, emotion_loss=0.9055108428001404\n",
      "\n",
      "01_20_01:08:54 Seen so far: 118752 samples\n",
      "\n",
      "01_20_01:08:54 --- 1.8042242527008057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:55 Training loss at epoch 3 step 3720: 3.017250323295593\n",
      "\n",
      " This round's valence_loss=1.3174854516983032, arousal_loss=1.2403457164764404, emotion_loss=0.976865291595459\n",
      "\n",
      "01_20_01:08:55 Seen so far: 119072 samples\n",
      "\n",
      "01_20_01:08:55 --- 1.8165628910064697 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:57 Training loss at epoch 3 step 3730: 2.9776501417160035\n",
      "\n",
      " This round's valence_loss=0.956294596195221, arousal_loss=0.7185537815093994, emotion_loss=0.7249975204467773\n",
      "\n",
      "01_20_01:08:57 Seen so far: 119392 samples\n",
      "\n",
      "01_20_01:08:57 --- 1.723151683807373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:08:59 Training loss at epoch 3 step 3740: 2.9588452577590942\n",
      "\n",
      " This round's valence_loss=1.3671722412109375, arousal_loss=1.1499706506729126, emotion_loss=1.086064338684082\n",
      "\n",
      "01_20_01:08:59 Seen so far: 119712 samples\n",
      "\n",
      "01_20_01:08:59 --- 1.6129298210144043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:00 Training loss at epoch 3 step 3750: 2.810936379432678\n",
      "\n",
      " This round's valence_loss=0.8452872633934021, arousal_loss=0.6045727729797363, emotion_loss=1.002379298210144\n",
      "\n",
      "01_20_01:09:00 Seen so far: 120032 samples\n",
      "\n",
      "01_20_01:09:00 --- 1.6828982830047607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:02 Training loss at epoch 3 step 3760: 3.215302658081055\n",
      "\n",
      " This round's valence_loss=1.2119181156158447, arousal_loss=1.0819895267486572, emotion_loss=0.7825225591659546\n",
      "\n",
      "01_20_01:09:02 Seen so far: 120352 samples\n",
      "\n",
      "01_20_01:09:02 --- 1.8306512832641602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:04 Training loss at epoch 3 step 3770: 3.154852604866028\n",
      "\n",
      " This round's valence_loss=1.1851069927215576, arousal_loss=1.0494712591171265, emotion_loss=0.6533486843109131\n",
      "\n",
      "01_20_01:09:04 Seen so far: 120672 samples\n",
      "\n",
      "01_20_01:09:04 --- 1.726942777633667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:06 Training loss at epoch 3 step 3780: 3.176665425300598\n",
      "\n",
      " This round's valence_loss=1.1952065229415894, arousal_loss=1.0691732168197632, emotion_loss=0.7854084968566895\n",
      "\n",
      "01_20_01:09:06 Seen so far: 120992 samples\n",
      "\n",
      "01_20_01:09:06 --- 1.9678444862365723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:08 Training loss at epoch 3 step 3790: 2.768662714958191\n",
      "\n",
      " This round's valence_loss=0.8206110000610352, arousal_loss=0.7155110836029053, emotion_loss=1.0584367513656616\n",
      "\n",
      "01_20_01:09:08 Seen so far: 121312 samples\n",
      "\n",
      "01_20_01:09:08 --- 1.726078987121582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:09 Training loss at epoch 3 step 3800: 2.9325714707374573\n",
      "\n",
      " This round's valence_loss=1.3890379667282104, arousal_loss=1.160989761352539, emotion_loss=0.8444908261299133\n",
      "\n",
      "01_20_01:09:09 Seen so far: 121632 samples\n",
      "\n",
      "01_20_01:09:09 --- 1.7516913414001465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:11 Training loss at epoch 3 step 3810: 2.9621060848236085\n",
      "\n",
      " This round's valence_loss=0.6638442277908325, arousal_loss=0.5563898086547852, emotion_loss=1.2840896844863892\n",
      "\n",
      "01_20_01:09:11 Seen so far: 121952 samples\n",
      "\n",
      "01_20_01:09:11 --- 1.7727327346801758 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:13 Training loss at epoch 3 step 3820: 3.2998039960861205\n",
      "\n",
      " This round's valence_loss=1.180087685585022, arousal_loss=1.088170051574707, emotion_loss=0.8414475917816162\n",
      "\n",
      "01_20_01:09:13 Seen so far: 122272 samples\n",
      "\n",
      "01_20_01:09:13 --- 1.8833746910095215 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:15 Training loss at epoch 3 step 3830: 2.563760983943939\n",
      "\n",
      " This round's valence_loss=1.0929133892059326, arousal_loss=1.0209875106811523, emotion_loss=0.9999130368232727\n",
      "\n",
      "01_20_01:09:15 Seen so far: 122592 samples\n",
      "\n",
      "01_20_01:09:15 --- 1.7942283153533936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:17 Training loss at epoch 3 step 3840: 2.918246865272522\n",
      "\n",
      " This round's valence_loss=0.9255502223968506, arousal_loss=0.8769378662109375, emotion_loss=1.0761544704437256\n",
      "\n",
      "01_20_01:09:17 Seen so far: 122912 samples\n",
      "\n",
      "01_20_01:09:17 --- 1.7329115867614746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:18 Training loss at epoch 3 step 3850: 3.0617666244506836\n",
      "\n",
      " This round's valence_loss=1.205709457397461, arousal_loss=1.0995879173278809, emotion_loss=0.8694812059402466\n",
      "\n",
      "01_20_01:09:18 Seen so far: 123232 samples\n",
      "\n",
      "01_20_01:09:18 --- 1.6799066066741943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:20 Training loss at epoch 3 step 3860: 2.968222808837891\n",
      "\n",
      " This round's valence_loss=1.112658977508545, arousal_loss=0.9783347845077515, emotion_loss=0.9226645231246948\n",
      "\n",
      "01_20_01:09:20 Seen so far: 123552 samples\n",
      "\n",
      "01_20_01:09:20 --- 1.760594367980957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:22 Training loss at epoch 3 step 3870: 2.694785785675049\n",
      "\n",
      " This round's valence_loss=1.293046474456787, arousal_loss=1.276476263999939, emotion_loss=0.9928264021873474\n",
      "\n",
      "01_20_01:09:22 Seen so far: 123872 samples\n",
      "\n",
      "01_20_01:09:22 --- 1.7995047569274902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:24 Training loss at epoch 3 step 3880: 3.3058844089508055\n",
      "\n",
      " This round's valence_loss=1.0033745765686035, arousal_loss=0.8176424503326416, emotion_loss=0.9023191332817078\n",
      "\n",
      "01_20_01:09:24 Seen so far: 124192 samples\n",
      "\n",
      "01_20_01:09:24 --- 1.9175879955291748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:25 Training loss at epoch 3 step 3890: 2.8323593616485594\n",
      "\n",
      " This round's valence_loss=1.266160249710083, arousal_loss=1.1042068004608154, emotion_loss=1.2314093112945557\n",
      "\n",
      "01_20_01:09:25 Seen so far: 124512 samples\n",
      "\n",
      "01_20_01:09:25 --- 1.5942661762237549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:27 Training loss at epoch 3 step 3900: 2.979244065284729\n",
      "\n",
      " This round's valence_loss=1.3331242799758911, arousal_loss=1.2114232778549194, emotion_loss=0.8006269931793213\n",
      "\n",
      "01_20_01:09:27 Seen so far: 124832 samples\n",
      "\n",
      "01_20_01:09:27 --- 1.8401625156402588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:29 Training loss at epoch 3 step 3910: 3.069430112838745\n",
      "\n",
      " This round's valence_loss=1.4099242687225342, arousal_loss=1.3282852172851562, emotion_loss=1.0422028303146362\n",
      "\n",
      "01_20_01:09:29 Seen so far: 125152 samples\n",
      "\n",
      "01_20_01:09:29 --- 1.6574387550354004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:31 Training loss at epoch 3 step 3920: 3.1797595024108887\n",
      "\n",
      " This round's valence_loss=1.1990195512771606, arousal_loss=1.0882633924484253, emotion_loss=0.8929073214530945\n",
      "\n",
      "01_20_01:09:31 Seen so far: 125472 samples\n",
      "\n",
      "01_20_01:09:31 --- 1.825775146484375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:32 Training loss at epoch 3 step 3930: 2.93770592212677\n",
      "\n",
      " This round's valence_loss=1.0978248119354248, arousal_loss=0.9592192769050598, emotion_loss=0.9930166602134705\n",
      "\n",
      "01_20_01:09:32 Seen so far: 125792 samples\n",
      "\n",
      "01_20_01:09:32 --- 1.7030882835388184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:34 Training loss at epoch 3 step 3940: 3.3374165534973144\n",
      "\n",
      " This round's valence_loss=1.3408091068267822, arousal_loss=1.2060198783874512, emotion_loss=0.9286039471626282\n",
      "\n",
      "01_20_01:09:34 Seen so far: 126112 samples\n",
      "\n",
      "01_20_01:09:34 --- 1.802769660949707 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:36 Training loss at epoch 3 step 3950: 2.7839049100875854\n",
      "\n",
      " This round's valence_loss=0.9550613164901733, arousal_loss=0.8639576435089111, emotion_loss=1.1830253601074219\n",
      "\n",
      "01_20_01:09:36 Seen so far: 126432 samples\n",
      "\n",
      "01_20_01:09:36 --- 1.5758309364318848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:38 Training loss at epoch 3 step 3960: 2.7467045307159426\n",
      "\n",
      " This round's valence_loss=0.922167956829071, arousal_loss=0.8742914199829102, emotion_loss=1.2028820514678955\n",
      "\n",
      "01_20_01:09:38 Seen so far: 126752 samples\n",
      "\n",
      "01_20_01:09:38 --- 1.7794082164764404 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:39 Training loss at epoch 3 step 3970: 2.967115020751953\n",
      "\n",
      " This round's valence_loss=1.172802448272705, arousal_loss=1.087483525276184, emotion_loss=1.1943473815917969\n",
      "\n",
      "01_20_01:09:39 Seen so far: 127072 samples\n",
      "\n",
      "01_20_01:09:39 --- 1.645296573638916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:41 Training loss at epoch 3 step 3980: 2.965381717681885\n",
      "\n",
      " This round's valence_loss=1.3349618911743164, arousal_loss=1.1792852878570557, emotion_loss=1.041273593902588\n",
      "\n",
      "01_20_01:09:41 Seen so far: 127392 samples\n",
      "\n",
      "01_20_01:09:41 --- 1.6490237712860107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:42 Training loss at epoch 3 step 3990: 3.085650384426117\n",
      "\n",
      " This round's valence_loss=1.178297996520996, arousal_loss=1.0625789165496826, emotion_loss=1.007948398590088\n",
      "\n",
      "01_20_01:09:42 Seen so far: 127712 samples\n",
      "\n",
      "01_20_01:09:42 --- 1.5787978172302246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:44 Training loss at epoch 3 step 4000: 2.8100900888442992\n",
      "\n",
      " This round's valence_loss=1.5431510210037231, arousal_loss=1.4476405382156372, emotion_loss=0.8589218854904175\n",
      "\n",
      "01_20_01:09:44 Seen so far: 128032 samples\n",
      "\n",
      "01_20_01:09:44 --- 1.7388858795166016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:46 Training loss at epoch 3 step 4010: 2.97050678730011\n",
      "\n",
      " This round's valence_loss=1.735090970993042, arousal_loss=1.5622637271881104, emotion_loss=0.7081727981567383\n",
      "\n",
      "01_20_01:09:46 Seen so far: 128352 samples\n",
      "\n",
      "01_20_01:09:46 --- 1.7309246063232422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:48 Training loss at epoch 3 step 4020: 3.1681586503982544\n",
      "\n",
      " This round's valence_loss=1.0777404308319092, arousal_loss=0.9651971459388733, emotion_loss=1.1184974908828735\n",
      "\n",
      "01_20_01:09:48 Seen so far: 128672 samples\n",
      "\n",
      "01_20_01:09:48 --- 1.787123441696167 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:50 Training loss at epoch 3 step 4030: 2.7950299739837647\n",
      "\n",
      " This round's valence_loss=0.508929967880249, arousal_loss=0.34062454104423523, emotion_loss=0.9544885158538818\n",
      "\n",
      "01_20_01:09:50 Seen so far: 128992 samples\n",
      "\n",
      "01_20_01:09:50 --- 1.8248836994171143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:51 Training loss at epoch 3 step 4040: 2.748726654052734\n",
      "\n",
      " This round's valence_loss=1.0110085010528564, arousal_loss=0.877467930316925, emotion_loss=0.8949964046478271\n",
      "\n",
      "01_20_01:09:51 Seen so far: 129312 samples\n",
      "\n",
      "01_20_01:09:51 --- 1.8456659317016602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:53 Training loss at epoch 3 step 4050: 2.804833984375\n",
      "\n",
      " This round's valence_loss=0.9649875164031982, arousal_loss=0.8808819055557251, emotion_loss=0.8342938423156738\n",
      "\n",
      "01_20_01:09:53 Seen so far: 129632 samples\n",
      "\n",
      "01_20_01:09:53 --- 1.7694053649902344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:55 Training loss at epoch 3 step 4060: 3.2253151416778563\n",
      "\n",
      " This round's valence_loss=0.9315134286880493, arousal_loss=0.7052654027938843, emotion_loss=0.8606014251708984\n",
      "\n",
      "01_20_01:09:55 Seen so far: 129952 samples\n",
      "\n",
      "01_20_01:09:55 --- 1.8463711738586426 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:57 Training loss at epoch 3 step 4070: 2.7397067070007326\n",
      "\n",
      " This round's valence_loss=0.7928058505058289, arousal_loss=0.572115421295166, emotion_loss=0.7083486318588257\n",
      "\n",
      "01_20_01:09:57 Seen so far: 130272 samples\n",
      "\n",
      "01_20_01:09:57 --- 1.6999826431274414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:09:59 Training loss at epoch 3 step 4080: 3.0904116868972777\n",
      "\n",
      " This round's valence_loss=1.1495440006256104, arousal_loss=0.9589789509773254, emotion_loss=1.0150175094604492\n",
      "\n",
      "01_20_01:09:59 Seen so far: 130592 samples\n",
      "\n",
      "01_20_01:09:59 --- 1.8383688926696777 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:00 Training loss at epoch 3 step 4090: 2.9262542486190797\n",
      "\n",
      " This round's valence_loss=0.9586082696914673, arousal_loss=0.8563939332962036, emotion_loss=0.9186711311340332\n",
      "\n",
      "01_20_01:10:00 Seen so far: 130912 samples\n",
      "\n",
      "01_20_01:10:00 --- 1.7070844173431396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:02 Training loss at epoch 3 step 4100: 2.984064817428589\n",
      "\n",
      " This round's valence_loss=0.7603346109390259, arousal_loss=0.618539035320282, emotion_loss=0.8088556528091431\n",
      "\n",
      "01_20_01:10:02 Seen so far: 131232 samples\n",
      "\n",
      "01_20_01:10:02 --- 1.5802466869354248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:04 Training loss at epoch 3 step 4110: 2.93650084733963\n",
      "\n",
      " This round's valence_loss=1.3068265914916992, arousal_loss=1.1633775234222412, emotion_loss=0.889288604259491\n",
      "\n",
      "01_20_01:10:04 Seen so far: 131552 samples\n",
      "\n",
      "01_20_01:10:04 --- 1.8392534255981445 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:05 Training loss at epoch 3 step 4120: 3.0818699836730956\n",
      "\n",
      " This round's valence_loss=1.2816557884216309, arousal_loss=1.2490720748901367, emotion_loss=1.0125294923782349\n",
      "\n",
      "01_20_01:10:05 Seen so far: 131872 samples\n",
      "\n",
      "01_20_01:10:05 --- 1.6801445484161377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:07 Training loss at epoch 3 step 4130: 2.630423974990845\n",
      "\n",
      " This round's valence_loss=0.887043833732605, arousal_loss=0.7718726396560669, emotion_loss=0.7881734371185303\n",
      "\n",
      "01_20_01:10:07 Seen so far: 132192 samples\n",
      "\n",
      "01_20_01:10:07 --- 1.8276073932647705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:09 Training loss at epoch 3 step 4140: 3.270215630531311\n",
      "\n",
      " This round's valence_loss=1.3100013732910156, arousal_loss=1.2171224355697632, emotion_loss=0.8394153118133545\n",
      "\n",
      "01_20_01:10:09 Seen so far: 132512 samples\n",
      "\n",
      "01_20_01:10:09 --- 1.7287771701812744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:11 Training loss at epoch 3 step 4150: 3.2332820177078245\n",
      "\n",
      " This round's valence_loss=1.398810863494873, arousal_loss=1.3525354862213135, emotion_loss=0.6856592297554016\n",
      "\n",
      "01_20_01:10:11 Seen so far: 132832 samples\n",
      "\n",
      "01_20_01:10:11 --- 1.7595305442810059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:12 Training loss at epoch 3 step 4160: 2.8858368158340455\n",
      "\n",
      " This round's valence_loss=1.0785012245178223, arousal_loss=1.0072087049484253, emotion_loss=1.3303731679916382\n",
      "\n",
      "01_20_01:10:12 Seen so far: 133152 samples\n",
      "\n",
      "01_20_01:10:12 --- 1.7829742431640625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:14 Training loss at epoch 3 step 4170: 3.1060956716537476\n",
      "\n",
      " This round's valence_loss=1.2100849151611328, arousal_loss=1.0498892068862915, emotion_loss=1.0916553735733032\n",
      "\n",
      "01_20_01:10:14 Seen so far: 133472 samples\n",
      "\n",
      "01_20_01:10:14 --- 1.906764030456543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:16 Training loss at epoch 3 step 4180: 2.902081036567688\n",
      "\n",
      " This round's valence_loss=1.4231665134429932, arousal_loss=1.3048157691955566, emotion_loss=0.9802049994468689\n",
      "\n",
      "01_20_01:10:16 Seen so far: 133792 samples\n",
      "\n",
      "01_20_01:10:16 --- 1.8894550800323486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:18 Training loss at epoch 3 step 4190: 3.0621734619140626\n",
      "\n",
      " This round's valence_loss=0.8724948763847351, arousal_loss=0.7611957788467407, emotion_loss=1.0019993782043457\n",
      "\n",
      "01_20_01:10:18 Seen so far: 134112 samples\n",
      "\n",
      "01_20_01:10:18 --- 1.7559635639190674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:20 Training loss at epoch 3 step 4200: 3.0720723390579225\n",
      "\n",
      " This round's valence_loss=0.9375343322753906, arousal_loss=0.6755967140197754, emotion_loss=0.6715269684791565\n",
      "\n",
      "01_20_01:10:20 Seen so far: 134432 samples\n",
      "\n",
      "01_20_01:10:20 --- 1.668623447418213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:21 Training loss at epoch 3 step 4210: 2.8591222286224367\n",
      "\n",
      " This round's valence_loss=1.046324372291565, arousal_loss=0.819638192653656, emotion_loss=0.8479337692260742\n",
      "\n",
      "01_20_01:10:21 Seen so far: 134752 samples\n",
      "\n",
      "01_20_01:10:21 --- 1.6612613201141357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:23 Training loss at epoch 3 step 4220: 2.9202606678009033\n",
      "\n",
      " This round's valence_loss=0.7281713485717773, arousal_loss=0.6329096555709839, emotion_loss=1.0076361894607544\n",
      "\n",
      "01_20_01:10:23 Seen so far: 135072 samples\n",
      "\n",
      "01_20_01:10:23 --- 1.808727741241455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:25 Training loss at epoch 3 step 4230: 3.206215667724609\n",
      "\n",
      " This round's valence_loss=1.1455979347229004, arousal_loss=0.9456734657287598, emotion_loss=1.2598978281021118\n",
      "\n",
      "01_20_01:10:25 Seen so far: 135392 samples\n",
      "\n",
      "01_20_01:10:25 --- 1.651853322982788 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:26 Training loss at epoch 3 step 4240: 2.92010418176651\n",
      "\n",
      " This round's valence_loss=0.721298098564148, arousal_loss=0.45549753308296204, emotion_loss=1.0288807153701782\n",
      "\n",
      "01_20_01:10:26 Seen so far: 135712 samples\n",
      "\n",
      "01_20_01:10:26 --- 1.695141315460205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:28 Training loss at epoch 3 step 4250: 3.2401859521865846\n",
      "\n",
      " This round's valence_loss=0.895825207233429, arousal_loss=0.8237786293029785, emotion_loss=1.2010083198547363\n",
      "\n",
      "01_20_01:10:28 Seen so far: 136032 samples\n",
      "\n",
      "01_20_01:10:28 --- 1.7345435619354248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:30 Training loss at epoch 3 step 4260: 3.073150062561035\n",
      "\n",
      " This round's valence_loss=1.444812297821045, arousal_loss=1.2807137966156006, emotion_loss=1.0095407962799072\n",
      "\n",
      "01_20_01:10:30 Seen so far: 136352 samples\n",
      "\n",
      "01_20_01:10:30 --- 1.7844576835632324 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:32 Training loss at epoch 3 step 4270: 3.200992059707642\n",
      "\n",
      " This round's valence_loss=1.0256664752960205, arousal_loss=0.8785088658332825, emotion_loss=1.0063233375549316\n",
      "\n",
      "01_20_01:10:32 Seen so far: 136672 samples\n",
      "\n",
      "01_20_01:10:32 --- 1.7972776889801025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:34 Training loss at epoch 3 step 4280: 2.9826086521148683\n",
      "\n",
      " This round's valence_loss=1.3794398307800293, arousal_loss=1.2190452814102173, emotion_loss=0.6575770378112793\n",
      "\n",
      "01_20_01:10:34 Seen so far: 136992 samples\n",
      "\n",
      "01_20_01:10:34 --- 1.7395694255828857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:35 Training loss at epoch 3 step 4290: 3.378712272644043\n",
      "\n",
      " This round's valence_loss=1.064096212387085, arousal_loss=0.9743266105651855, emotion_loss=1.3375952243804932\n",
      "\n",
      "01_20_01:10:35 Seen so far: 137312 samples\n",
      "\n",
      "01_20_01:10:35 --- 1.7520642280578613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:37 Training loss at epoch 3 step 4300: 3.0920711040496824\n",
      "\n",
      " This round's valence_loss=1.2014071941375732, arousal_loss=1.0806353092193604, emotion_loss=0.9725757241249084\n",
      "\n",
      "01_20_01:10:37 Seen so far: 137632 samples\n",
      "\n",
      "01_20_01:10:37 --- 1.717433214187622 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:39 Training loss at epoch 3 step 4310: 2.8202147245407105\n",
      "\n",
      " This round's valence_loss=1.0083932876586914, arousal_loss=0.8259249329566956, emotion_loss=0.7608453035354614\n",
      "\n",
      "01_20_01:10:39 Seen so far: 137952 samples\n",
      "\n",
      "01_20_01:10:39 --- 1.7724509239196777 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:41 Training loss at epoch 3 step 4320: 2.9826422929763794\n",
      "\n",
      " This round's valence_loss=1.801651954650879, arousal_loss=1.717490792274475, emotion_loss=0.7954515814781189\n",
      "\n",
      "01_20_01:10:41 Seen so far: 138272 samples\n",
      "\n",
      "01_20_01:10:41 --- 1.767991304397583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:42 Training loss at epoch 3 step 4330: 2.9696687698364257\n",
      "\n",
      " This round's valence_loss=1.085457682609558, arousal_loss=0.9771479368209839, emotion_loss=1.057080864906311\n",
      "\n",
      "01_20_01:10:42 Seen so far: 138592 samples\n",
      "\n",
      "01_20_01:10:42 --- 1.7843725681304932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:44 Training loss at epoch 3 step 4340: 3.2435784339904785\n",
      "\n",
      " This round's valence_loss=1.4670085906982422, arousal_loss=1.2959113121032715, emotion_loss=0.630538821220398\n",
      "\n",
      "01_20_01:10:44 Seen so far: 138912 samples\n",
      "\n",
      "01_20_01:10:44 --- 1.8579509258270264 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:46 Training loss at epoch 3 step 4350: 3.0011111974716185\n",
      "\n",
      " This round's valence_loss=1.080721139907837, arousal_loss=1.031381607055664, emotion_loss=0.9680303335189819\n",
      "\n",
      "01_20_01:10:46 Seen so far: 139232 samples\n",
      "\n",
      "01_20_01:10:46 --- 1.7562155723571777 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:48 Training loss at epoch 3 step 4360: 2.968921422958374\n",
      "\n",
      " This round's valence_loss=1.2130579948425293, arousal_loss=1.0611921548843384, emotion_loss=1.0634762048721313\n",
      "\n",
      "01_20_01:10:48 Seen so far: 139552 samples\n",
      "\n",
      "01_20_01:10:48 --- 1.8405239582061768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:50 Training loss at epoch 3 step 4370: 2.9354026317596436\n",
      "\n",
      " This round's valence_loss=0.6522828340530396, arousal_loss=0.5234061479568481, emotion_loss=1.1880953311920166\n",
      "\n",
      "01_20_01:10:50 Seen so far: 139872 samples\n",
      "\n",
      "01_20_01:10:50 --- 1.7788219451904297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:51 Training loss at epoch 3 step 4380: 3.439348840713501\n",
      "\n",
      " This round's valence_loss=1.0952439308166504, arousal_loss=0.9122004508972168, emotion_loss=1.3439775705337524\n",
      "\n",
      "01_20_01:10:51 Seen so far: 140192 samples\n",
      "\n",
      "01_20_01:10:51 --- 1.6165287494659424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:53 Training loss at epoch 3 step 4390: 3.2498721837997437\n",
      "\n",
      " This round's valence_loss=0.9603169560432434, arousal_loss=0.720367431640625, emotion_loss=0.907879114151001\n",
      "\n",
      "01_20_01:10:53 Seen so far: 140512 samples\n",
      "\n",
      "01_20_01:10:53 --- 1.8251655101776123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:55 Training loss at epoch 3 step 4400: 2.8740071058273315\n",
      "\n",
      " This round's valence_loss=1.6809788942337036, arousal_loss=1.5415749549865723, emotion_loss=1.0781036615371704\n",
      "\n",
      "01_20_01:10:55 Seen so far: 140832 samples\n",
      "\n",
      "01_20_01:10:55 --- 1.7253668308258057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:56 Training loss at epoch 3 step 4410: 2.797657346725464\n",
      "\n",
      " This round's valence_loss=0.787787914276123, arousal_loss=0.6116058230400085, emotion_loss=1.1028225421905518\n",
      "\n",
      "01_20_01:10:56 Seen so far: 141152 samples\n",
      "\n",
      "01_20_01:10:56 --- 1.6696345806121826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:10:58 Training loss at epoch 3 step 4420: 2.877433156967163\n",
      "\n",
      " This round's valence_loss=1.1769376993179321, arousal_loss=1.0621912479400635, emotion_loss=1.0181453227996826\n",
      "\n",
      "01_20_01:10:58 Seen so far: 141472 samples\n",
      "\n",
      "01_20_01:10:58 --- 1.7069904804229736 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:00 Training loss at epoch 3 step 4430: 3.370633053779602\n",
      "\n",
      " This round's valence_loss=1.3022183179855347, arousal_loss=1.1729092597961426, emotion_loss=1.133522868156433\n",
      "\n",
      "01_20_01:11:00 Seen so far: 141792 samples\n",
      "\n",
      "01_20_01:11:00 --- 1.6599371433258057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:02 Training loss at epoch 3 step 4440: 2.872763967514038\n",
      "\n",
      " This round's valence_loss=1.2286945581436157, arousal_loss=1.0992581844329834, emotion_loss=0.9485874176025391\n",
      "\n",
      "01_20_01:11:02 Seen so far: 142112 samples\n",
      "\n",
      "01_20_01:11:02 --- 1.874772548675537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:03 Training loss at epoch 3 step 4450: 3.061917757987976\n",
      "\n",
      " This round's valence_loss=0.9648407697677612, arousal_loss=0.8060786724090576, emotion_loss=0.8551228642463684\n",
      "\n",
      "01_20_01:11:03 Seen so far: 142432 samples\n",
      "\n",
      "01_20_01:11:03 --- 1.8049609661102295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:05 Training loss at epoch 3 step 4460: 3.2528982520103455\n",
      "\n",
      " This round's valence_loss=1.8022565841674805, arousal_loss=1.6556549072265625, emotion_loss=0.8873065114021301\n",
      "\n",
      "01_20_01:11:05 Seen so far: 142752 samples\n",
      "\n",
      "01_20_01:11:05 --- 1.7126359939575195 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:07 Training loss at epoch 3 step 4470: 2.6954096078872682\n",
      "\n",
      " This round's valence_loss=0.8734460473060608, arousal_loss=0.7387769222259521, emotion_loss=0.6496812701225281\n",
      "\n",
      "01_20_01:11:07 Seen so far: 143072 samples\n",
      "\n",
      "01_20_01:11:07 --- 1.5991957187652588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:08 Training loss at epoch 3 step 4480: 2.757018494606018\n",
      "\n",
      " This round's valence_loss=1.2000337839126587, arousal_loss=1.1116611957550049, emotion_loss=0.9134502410888672\n",
      "\n",
      "01_20_01:11:08 Seen so far: 143392 samples\n",
      "\n",
      "01_20_01:11:08 --- 1.6204314231872559 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:10 Training loss at epoch 3 step 4490: 2.9979378938674928\n",
      "\n",
      " This round's valence_loss=0.9727523326873779, arousal_loss=0.7949780225753784, emotion_loss=0.6764949560165405\n",
      "\n",
      "01_20_01:11:10 Seen so far: 143712 samples\n",
      "\n",
      "01_20_01:11:10 --- 1.6877639293670654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:12 Training loss at epoch 3 step 4500: 2.6219646453857424\n",
      "\n",
      " This round's valence_loss=1.1289161443710327, arousal_loss=0.9835985898971558, emotion_loss=0.7757362127304077\n",
      "\n",
      "01_20_01:11:12 Seen so far: 144032 samples\n",
      "\n",
      "01_20_01:11:12 --- 1.7271111011505127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:14 Training loss at epoch 3 step 4510: 3.039041209220886\n",
      "\n",
      " This round's valence_loss=1.0190839767456055, arousal_loss=0.8296876549720764, emotion_loss=0.908128023147583\n",
      "\n",
      "01_20_01:11:14 Seen so far: 144352 samples\n",
      "\n",
      "01_20_01:11:14 --- 1.9881250858306885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:16 Training loss at epoch 3 step 4520: 2.8793891429901124\n",
      "\n",
      " This round's valence_loss=1.1057720184326172, arousal_loss=0.9882063865661621, emotion_loss=0.8198210000991821\n",
      "\n",
      "01_20_01:11:16 Seen so far: 144672 samples\n",
      "\n",
      "01_20_01:11:16 --- 2.0016729831695557 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:18 Training loss at epoch 3 step 4530: 2.6928792119026186\n",
      "\n",
      " This round's valence_loss=0.8569461107254028, arousal_loss=0.5838440656661987, emotion_loss=0.7655668258666992\n",
      "\n",
      "01_20_01:11:18 Seen so far: 144992 samples\n",
      "\n",
      "01_20_01:11:18 --- 1.7792973518371582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:20 Training loss at epoch 3 step 4540: 3.176323938369751\n",
      "\n",
      " This round's valence_loss=0.7537254691123962, arousal_loss=0.5900993943214417, emotion_loss=0.931082010269165\n",
      "\n",
      "01_20_01:11:20 Seen so far: 145312 samples\n",
      "\n",
      "01_20_01:11:20 --- 1.9988913536071777 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:21 Training loss at epoch 3 step 4550: 2.901049184799194\n",
      "\n",
      " This round's valence_loss=1.2925885915756226, arousal_loss=1.0828871726989746, emotion_loss=0.9267439246177673\n",
      "\n",
      "01_20_01:11:21 Seen so far: 145632 samples\n",
      "\n",
      "01_20_01:11:21 --- 1.8601667881011963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:23 Training loss at epoch 3 step 4560: 2.7075740933418273\n",
      "\n",
      " This round's valence_loss=0.6441623568534851, arousal_loss=0.4961443543434143, emotion_loss=0.8264447450637817\n",
      "\n",
      "01_20_01:11:23 Seen so far: 145952 samples\n",
      "\n",
      "01_20_01:11:23 --- 1.6731367111206055 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:25 Training loss at epoch 3 step 4570: 2.754105806350708\n",
      "\n",
      " This round's valence_loss=1.1354939937591553, arousal_loss=0.9906478524208069, emotion_loss=0.8782187104225159\n",
      "\n",
      "01_20_01:11:25 Seen so far: 146272 samples\n",
      "\n",
      "01_20_01:11:25 --- 1.7217438220977783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:27 Training loss at epoch 3 step 4580: 2.7372127056121824\n",
      "\n",
      " This round's valence_loss=0.7753570079803467, arousal_loss=0.7403758764266968, emotion_loss=1.0820958614349365\n",
      "\n",
      "01_20_01:11:27 Seen so far: 146592 samples\n",
      "\n",
      "01_20_01:11:27 --- 1.7114241123199463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:28 Training loss at epoch 3 step 4590: 2.793865275382996\n",
      "\n",
      " This round's valence_loss=1.6386032104492188, arousal_loss=1.4364714622497559, emotion_loss=0.6222609281539917\n",
      "\n",
      "01_20_01:11:28 Seen so far: 146912 samples\n",
      "\n",
      "01_20_01:11:28 --- 1.542855978012085 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:30 Training loss at epoch 3 step 4600: 2.929516625404358\n",
      "\n",
      " This round's valence_loss=1.0268282890319824, arousal_loss=0.8251188397407532, emotion_loss=1.0177369117736816\n",
      "\n",
      "01_20_01:11:30 Seen so far: 147232 samples\n",
      "\n",
      "01_20_01:11:30 --- 1.7712981700897217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:32 Training loss at epoch 3 step 4610: 2.6928985118865967\n",
      "\n",
      " This round's valence_loss=0.6044666767120361, arousal_loss=0.3216578960418701, emotion_loss=0.625410258769989\n",
      "\n",
      "01_20_01:11:32 Seen so far: 147552 samples\n",
      "\n",
      "01_20_01:11:32 --- 1.7476963996887207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:33 Training loss at epoch 3 step 4620: 2.72392543554306\n",
      "\n",
      " This round's valence_loss=0.6287988424301147, arousal_loss=0.428018182516098, emotion_loss=0.8283164501190186\n",
      "\n",
      "01_20_01:11:33 Seen so far: 147872 samples\n",
      "\n",
      "01_20_01:11:33 --- 1.7279319763183594 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:35 Training loss at epoch 3 step 4630: 3.0899304866790773\n",
      "\n",
      " This round's valence_loss=1.5246169567108154, arousal_loss=1.4193689823150635, emotion_loss=0.9720346927642822\n",
      "\n",
      "01_20_01:11:35 Seen so far: 148192 samples\n",
      "\n",
      "01_20_01:11:35 --- 1.6952834129333496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:37 Training loss at epoch 3 step 4640: 3.138010859489441\n",
      "\n",
      " This round's valence_loss=1.3838099241256714, arousal_loss=1.3615643978118896, emotion_loss=0.8970497250556946\n",
      "\n",
      "01_20_01:11:37 Seen so far: 148512 samples\n",
      "\n",
      "01_20_01:11:37 --- 2.0144059658050537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:39 Training loss at epoch 3 step 4650: 2.776387429237366\n",
      "\n",
      " This round's valence_loss=1.0885522365570068, arousal_loss=0.9450455904006958, emotion_loss=1.022056221961975\n",
      "\n",
      "01_20_01:11:39 Seen so far: 148832 samples\n",
      "\n",
      "01_20_01:11:39 --- 1.9602329730987549 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:41 Training loss at epoch 3 step 4660: 2.933932197093964\n",
      "\n",
      " This round's valence_loss=1.3264007568359375, arousal_loss=1.2044117450714111, emotion_loss=1.0490666627883911\n",
      "\n",
      "01_20_01:11:41 Seen so far: 149152 samples\n",
      "\n",
      "01_20_01:11:41 --- 1.9200873374938965 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:43 Training loss at epoch 3 step 4670: 2.90051326751709\n",
      "\n",
      " This round's valence_loss=1.0570478439331055, arousal_loss=0.9845099449157715, emotion_loss=1.1570024490356445\n",
      "\n",
      "01_20_01:11:43 Seen so far: 149472 samples\n",
      "\n",
      "01_20_01:11:43 --- 1.884110927581787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:45 Training loss at epoch 3 step 4680: 3.1812116861343385\n",
      "\n",
      " This round's valence_loss=0.8534337878227234, arousal_loss=0.7262868881225586, emotion_loss=0.7894929647445679\n",
      "\n",
      "01_20_01:11:45 Seen so far: 149792 samples\n",
      "\n",
      "01_20_01:11:45 --- 1.852860450744629 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:46 Training loss at epoch 3 step 4690: 2.9927747011184693\n",
      "\n",
      " This round's valence_loss=0.7414344549179077, arousal_loss=0.5952026844024658, emotion_loss=0.9323269128799438\n",
      "\n",
      "01_20_01:11:46 Seen so far: 150112 samples\n",
      "\n",
      "01_20_01:11:46 --- 1.7228772640228271 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:48 Training loss at epoch 3 step 4700: 2.778878164291382\n",
      "\n",
      " This round's valence_loss=1.247589349746704, arousal_loss=1.0716898441314697, emotion_loss=0.7749413847923279\n",
      "\n",
      "01_20_01:11:48 Seen so far: 150432 samples\n",
      "\n",
      "01_20_01:11:48 --- 1.7158007621765137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:50 Training loss at epoch 3 step 4710: 3.198459601402283\n",
      "\n",
      " This round's valence_loss=0.8626827001571655, arousal_loss=0.6685362458229065, emotion_loss=0.8830873370170593\n",
      "\n",
      "01_20_01:11:50 Seen so far: 150752 samples\n",
      "\n",
      "01_20_01:11:50 --- 1.6844232082366943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:52 Training loss at epoch 3 step 4720: 3.0403133630752563\n",
      "\n",
      " This round's valence_loss=0.8986983299255371, arousal_loss=0.8350108861923218, emotion_loss=1.0976675748825073\n",
      "\n",
      "01_20_01:11:52 Seen so far: 151072 samples\n",
      "\n",
      "01_20_01:11:52 --- 1.834956407546997 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:53 Training loss at epoch 3 step 4730: 2.954957127571106\n",
      "\n",
      " This round's valence_loss=0.8237432837486267, arousal_loss=0.7535851001739502, emotion_loss=1.2840993404388428\n",
      "\n",
      "01_20_01:11:53 Seen so far: 151392 samples\n",
      "\n",
      "01_20_01:11:53 --- 1.7011346817016602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:55 Training loss at epoch 3 step 4740: 2.8500051736831664\n",
      "\n",
      " This round's valence_loss=1.3156917095184326, arousal_loss=1.255426049232483, emotion_loss=0.6627453565597534\n",
      "\n",
      "01_20_01:11:55 Seen so far: 151712 samples\n",
      "\n",
      "01_20_01:11:55 --- 1.6419916152954102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:57 Training loss at epoch 3 step 4750: 3.10182044506073\n",
      "\n",
      " This round's valence_loss=1.0478925704956055, arousal_loss=1.0093237161636353, emotion_loss=1.0864908695220947\n",
      "\n",
      "01_20_01:11:57 Seen so far: 152032 samples\n",
      "\n",
      "01_20_01:11:57 --- 1.6850745677947998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:11:58 Training loss at epoch 3 step 4760: 3.376778745651245\n",
      "\n",
      " This round's valence_loss=1.2284679412841797, arousal_loss=1.0774481296539307, emotion_loss=0.8712916970252991\n",
      "\n",
      "01_20_01:11:58 Seen so far: 152352 samples\n",
      "\n",
      "01_20_01:11:58 --- 1.8217298984527588 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:00 Training loss at epoch 3 step 4770: 3.0573918342590334\n",
      "\n",
      " This round's valence_loss=1.1197562217712402, arousal_loss=0.9617918729782104, emotion_loss=0.9894410967826843\n",
      "\n",
      "01_20_01:12:00 Seen so far: 152672 samples\n",
      "\n",
      "01_20_01:12:00 --- 1.673604965209961 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:02 Training loss at epoch 3 step 4780: 2.99671356678009\n",
      "\n",
      " This round's valence_loss=0.8253458738327026, arousal_loss=0.6641343832015991, emotion_loss=1.0060313940048218\n",
      "\n",
      "01_20_01:12:02 Seen so far: 152992 samples\n",
      "\n",
      "01_20_01:12:02 --- 1.7009820938110352 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:04 Training loss at epoch 3 step 4790: 3.3862166166305543\n",
      "\n",
      " This round's valence_loss=1.541895866394043, arousal_loss=1.4511699676513672, emotion_loss=0.7826480865478516\n",
      "\n",
      "01_20_01:12:04 Seen so far: 153312 samples\n",
      "\n",
      "01_20_01:12:04 --- 1.863210916519165 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:05 Training loss at epoch 3 step 4800: 2.9009940028190613\n",
      "\n",
      " This round's valence_loss=1.2748100757598877, arousal_loss=1.086031198501587, emotion_loss=0.7629493474960327\n",
      "\n",
      "01_20_01:12:05 Seen so far: 153632 samples\n",
      "\n",
      "01_20_01:12:05 --- 1.7531030178070068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:07 Training loss at epoch 3 step 4810: 3.099592554569244\n",
      "\n",
      " This round's valence_loss=0.9881594777107239, arousal_loss=0.8712584972381592, emotion_loss=1.130313515663147\n",
      "\n",
      "01_20_01:12:07 Seen so far: 153952 samples\n",
      "\n",
      "01_20_01:12:07 --- 1.7300963401794434 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:09 Training loss at epoch 3 step 4820: 2.956828761100769\n",
      "\n",
      " This round's valence_loss=1.0408378839492798, arousal_loss=0.8257502317428589, emotion_loss=0.9375561475753784\n",
      "\n",
      "01_20_01:12:09 Seen so far: 154272 samples\n",
      "\n",
      "01_20_01:12:09 --- 1.7312595844268799 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:11 Training loss at epoch 3 step 4830: 3.0514026641845704\n",
      "\n",
      " This round's valence_loss=1.467771053314209, arousal_loss=1.3485569953918457, emotion_loss=1.1301474571228027\n",
      "\n",
      "01_20_01:12:11 Seen so far: 154592 samples\n",
      "\n",
      "01_20_01:12:11 --- 1.764000415802002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:12 Training loss at epoch 3 step 4840: 2.9976633071899412\n",
      "\n",
      " This round's valence_loss=1.0166606903076172, arousal_loss=0.8815373182296753, emotion_loss=1.2651548385620117\n",
      "\n",
      "01_20_01:12:12 Seen so far: 154912 samples\n",
      "\n",
      "01_20_01:12:12 --- 1.7375757694244385 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:14 Training loss at epoch 3 step 4850: 2.9749024629592897\n",
      "\n",
      " This round's valence_loss=1.0652283430099487, arousal_loss=1.0025534629821777, emotion_loss=0.8527790307998657\n",
      "\n",
      "01_20_01:12:14 Seen so far: 155232 samples\n",
      "\n",
      "01_20_01:12:14 --- 1.807931900024414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:16 Training loss at epoch 3 step 4860: 2.9885437726974486\n",
      "\n",
      " This round's valence_loss=0.8888309001922607, arousal_loss=0.6988822221755981, emotion_loss=0.7252560257911682\n",
      "\n",
      "01_20_01:12:16 Seen so far: 155552 samples\n",
      "\n",
      "01_20_01:12:16 --- 1.7602462768554688 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:18 Training loss at epoch 3 step 4870: 2.8888802766799926\n",
      "\n",
      " This round's valence_loss=0.9751123189926147, arousal_loss=0.8797342777252197, emotion_loss=1.0430198907852173\n",
      "\n",
      "01_20_01:12:18 Seen so far: 155872 samples\n",
      "\n",
      "01_20_01:12:18 --- 2.03731632232666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:20 Training loss at epoch 3 step 4880: 2.637357807159424\n",
      "\n",
      " This round's valence_loss=1.0624420642852783, arousal_loss=1.0189586877822876, emotion_loss=0.966947078704834\n",
      "\n",
      "01_20_01:12:20 Seen so far: 156192 samples\n",
      "\n",
      "01_20_01:12:20 --- 1.9237914085388184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:22 Training loss at epoch 3 step 4890: 2.854820442199707\n",
      "\n",
      " This round's valence_loss=1.4286285638809204, arousal_loss=1.3424420356750488, emotion_loss=1.2167115211486816\n",
      "\n",
      "01_20_01:12:22 Seen so far: 156512 samples\n",
      "\n",
      "01_20_01:12:22 --- 1.6091744899749756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:23 Training loss at epoch 3 step 4900: 2.8923542976379393\n",
      "\n",
      " This round's valence_loss=0.6666409373283386, arousal_loss=0.5248704552650452, emotion_loss=0.851392388343811\n",
      "\n",
      "01_20_01:12:23 Seen so far: 156832 samples\n",
      "\n",
      "01_20_01:12:23 --- 1.8443090915679932 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:25 Training loss at epoch 3 step 4910: 3.200027620792389\n",
      "\n",
      " This round's valence_loss=0.6130762696266174, arousal_loss=0.49678850173950195, emotion_loss=0.8184422254562378\n",
      "\n",
      "01_20_01:12:25 Seen so far: 157152 samples\n",
      "\n",
      "01_20_01:12:25 --- 1.7834842205047607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:27 Training loss at epoch 3 step 4920: 3.1141380310058593\n",
      "\n",
      " This round's valence_loss=0.9742006063461304, arousal_loss=0.8739535212516785, emotion_loss=1.0517792701721191\n",
      "\n",
      "01_20_01:12:27 Seen so far: 157472 samples\n",
      "\n",
      "01_20_01:12:27 --- 1.8685925006866455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:29 Training loss at epoch 3 step 4930: 2.667426419258118\n",
      "\n",
      " This round's valence_loss=0.8719127774238586, arousal_loss=0.7548294067382812, emotion_loss=0.6322954893112183\n",
      "\n",
      "01_20_01:12:29 Seen so far: 157792 samples\n",
      "\n",
      "01_20_01:12:29 --- 1.9087958335876465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:31 Training loss at epoch 3 step 4940: 2.881561851501465\n",
      "\n",
      " This round's valence_loss=1.1059339046478271, arousal_loss=0.9940552711486816, emotion_loss=0.8775519132614136\n",
      "\n",
      "01_20_01:12:31 Seen so far: 158112 samples\n",
      "\n",
      "01_20_01:12:31 --- 1.7014379501342773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:33 Training loss at epoch 3 step 4950: 3.114278054237366\n",
      "\n",
      " This round's valence_loss=1.4745426177978516, arousal_loss=1.3511755466461182, emotion_loss=1.1157150268554688\n",
      "\n",
      "01_20_01:12:33 Seen so far: 158432 samples\n",
      "\n",
      "01_20_01:12:33 --- 1.8699989318847656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:34 Training loss at epoch 3 step 4960: 3.1402936697006227\n",
      "\n",
      " This round's valence_loss=1.2039523124694824, arousal_loss=1.117354393005371, emotion_loss=0.926607608795166\n",
      "\n",
      "01_20_01:12:34 Seen so far: 158752 samples\n",
      "\n",
      "01_20_01:12:34 --- 1.7568700313568115 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:36 Training loss at epoch 3 step 4970: 2.589664840698242\n",
      "\n",
      " This round's valence_loss=1.2257038354873657, arousal_loss=1.094196081161499, emotion_loss=0.8795744180679321\n",
      "\n",
      "01_20_01:12:36 Seen so far: 159072 samples\n",
      "\n",
      "01_20_01:12:36 --- 1.8484852313995361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:38 Training loss at epoch 3 step 4980: 3.2274285554885864\n",
      "\n",
      " This round's valence_loss=1.766934871673584, arousal_loss=1.6693429946899414, emotion_loss=1.2211389541625977\n",
      "\n",
      "01_20_01:12:38 Seen so far: 159392 samples\n",
      "\n",
      "01_20_01:12:38 --- 1.8719937801361084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:40 Training loss at epoch 3 step 4990: 2.7249898433685305\n",
      "\n",
      " This round's valence_loss=0.7595086693763733, arousal_loss=0.6022422909736633, emotion_loss=1.1168781518936157\n",
      "\n",
      "01_20_01:12:40 Seen so far: 159712 samples\n",
      "\n",
      "01_20_01:12:40 --- 1.7277584075927734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:41 Training loss at epoch 3 step 5000: 2.852127957344055\n",
      "\n",
      " This round's valence_loss=1.2151904106140137, arousal_loss=1.0666948556900024, emotion_loss=0.794391930103302\n",
      "\n",
      "01_20_01:12:41 Seen so far: 160032 samples\n",
      "\n",
      "01_20_01:12:41 --- 1.7260632514953613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:43 Training loss at epoch 3 step 5010: 2.938931667804718\n",
      "\n",
      " This round's valence_loss=1.2839891910552979, arousal_loss=1.1996841430664062, emotion_loss=1.2525866031646729\n",
      "\n",
      "01_20_01:12:43 Seen so far: 160352 samples\n",
      "\n",
      "01_20_01:12:43 --- 1.6223106384277344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:45 Training loss at epoch 3 step 5020: 2.9116471290588377\n",
      "\n",
      " This round's valence_loss=1.124018669128418, arousal_loss=0.9777383208274841, emotion_loss=1.0172995328903198\n",
      "\n",
      "01_20_01:12:45 Seen so far: 160672 samples\n",
      "\n",
      "01_20_01:12:45 --- 1.8347694873809814 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:47 Training loss at epoch 3 step 5030: 3.057141399383545\n",
      "\n",
      " This round's valence_loss=1.2017464637756348, arousal_loss=1.104707956314087, emotion_loss=1.2530367374420166\n",
      "\n",
      "01_20_01:12:47 Seen so far: 160992 samples\n",
      "\n",
      "01_20_01:12:47 --- 1.7950856685638428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:48 Training loss at epoch 3 step 5040: 3.0519387483596803\n",
      "\n",
      " This round's valence_loss=1.065848469734192, arousal_loss=0.8330521583557129, emotion_loss=0.6930624842643738\n",
      "\n",
      "01_20_01:12:48 Seen so far: 161312 samples\n",
      "\n",
      "01_20_01:12:48 --- 1.6591541767120361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:50 Training loss at epoch 3 step 5050: 3.052739715576172\n",
      "\n",
      " This round's valence_loss=1.1941087245941162, arousal_loss=1.0030900239944458, emotion_loss=0.975896954536438\n",
      "\n",
      "01_20_01:12:50 Seen so far: 161632 samples\n",
      "\n",
      "01_20_01:12:50 --- 1.6976866722106934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:52 Training loss at epoch 3 step 5060: 2.92847900390625\n",
      "\n",
      " This round's valence_loss=0.9689487218856812, arousal_loss=0.8366521596908569, emotion_loss=0.7245553731918335\n",
      "\n",
      "01_20_01:12:52 Seen so far: 161952 samples\n",
      "\n",
      "01_20_01:12:52 --- 1.693917989730835 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:53 Training loss at epoch 3 step 5070: 3.131575012207031\n",
      "\n",
      " This round's valence_loss=0.9336348176002502, arousal_loss=0.8778775930404663, emotion_loss=1.2329614162445068\n",
      "\n",
      "01_20_01:12:53 Seen so far: 162272 samples\n",
      "\n",
      "01_20_01:12:53 --- 1.6643426418304443 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:55 Training loss at epoch 3 step 5080: 2.9851274251937867\n",
      "\n",
      " This round's valence_loss=0.7467840909957886, arousal_loss=0.6643074750900269, emotion_loss=1.1509826183319092\n",
      "\n",
      "01_20_01:12:55 Seen so far: 162592 samples\n",
      "\n",
      "01_20_01:12:55 --- 1.6207399368286133 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:57 Training loss at epoch 3 step 5090: 2.825840711593628\n",
      "\n",
      " This round's valence_loss=1.1066792011260986, arousal_loss=0.996428370475769, emotion_loss=0.7690131664276123\n",
      "\n",
      "01_20_01:12:57 Seen so far: 162912 samples\n",
      "\n",
      "01_20_01:12:57 --- 1.8279194831848145 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:12:59 Training loss at epoch 3 step 5100: 3.255755376815796\n",
      "\n",
      " This round's valence_loss=1.6403192281723022, arousal_loss=1.5711910724639893, emotion_loss=1.4374032020568848\n",
      "\n",
      "01_20_01:12:59 Seen so far: 163232 samples\n",
      "\n",
      "01_20_01:12:59 --- 1.775707483291626 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:01 Training loss at epoch 3 step 5110: 3.4018978118896483\n",
      "\n",
      " This round's valence_loss=1.9711260795593262, arousal_loss=1.9675254821777344, emotion_loss=1.254837989807129\n",
      "\n",
      "01_20_01:13:01 Seen so far: 163552 samples\n",
      "\n",
      "01_20_01:13:01 --- 1.8578643798828125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:02 Training loss at epoch 3 step 5120: 2.668285775184631\n",
      "\n",
      " This round's valence_loss=0.9367261528968811, arousal_loss=0.7334664463996887, emotion_loss=0.7870502471923828\n",
      "\n",
      "01_20_01:13:02 Seen so far: 163872 samples\n",
      "\n",
      "01_20_01:13:02 --- 1.731379508972168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:04 Training loss at epoch 3 step 5130: 3.241931200027466\n",
      "\n",
      " This round's valence_loss=1.5499651432037354, arousal_loss=1.3419418334960938, emotion_loss=0.8868725299835205\n",
      "\n",
      "01_20_01:13:04 Seen so far: 164192 samples\n",
      "\n",
      "01_20_01:13:04 --- 1.7304608821868896 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:06 Training loss at epoch 3 step 5140: 3.0795989274978637\n",
      "\n",
      " This round's valence_loss=1.2721540927886963, arousal_loss=1.066277265548706, emotion_loss=0.8337095379829407\n",
      "\n",
      "01_20_01:13:06 Seen so far: 164512 samples\n",
      "\n",
      "01_20_01:13:06 --- 1.8271167278289795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:08 Training loss at epoch 3 step 5150: 2.9718968868255615\n",
      "\n",
      " This round's valence_loss=1.2011996507644653, arousal_loss=1.101468801498413, emotion_loss=1.0407438278198242\n",
      "\n",
      "01_20_01:13:08 Seen so far: 164832 samples\n",
      "\n",
      "01_20_01:13:08 --- 1.7313830852508545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:09 Training loss at epoch 3 step 5160: 3.171362280845642\n",
      "\n",
      " This round's valence_loss=1.2499215602874756, arousal_loss=1.0860955715179443, emotion_loss=0.8631501793861389\n",
      "\n",
      "01_20_01:13:09 Seen so far: 165152 samples\n",
      "\n",
      "01_20_01:13:09 --- 1.8165414333343506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:11 Training loss at epoch 3 step 5170: 3.152718424797058\n",
      "\n",
      " This round's valence_loss=1.1850160360336304, arousal_loss=1.0564136505126953, emotion_loss=0.86717289686203\n",
      "\n",
      "01_20_01:13:11 Seen so far: 165472 samples\n",
      "\n",
      "01_20_01:13:11 --- 1.9675679206848145 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:13 Training loss at epoch 3 step 5180: 3.0134519577026366\n",
      "\n",
      " This round's valence_loss=1.3485232591629028, arousal_loss=1.2078510522842407, emotion_loss=0.7816664576530457\n",
      "\n",
      "01_20_01:13:13 Seen so far: 165792 samples\n",
      "\n",
      "01_20_01:13:13 --- 1.8466925621032715 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:15 Training loss at epoch 3 step 5190: 3.2178420782089234\n",
      "\n",
      " This round's valence_loss=1.2615660429000854, arousal_loss=1.1141853332519531, emotion_loss=0.9738497734069824\n",
      "\n",
      "01_20_01:13:15 Seen so far: 166112 samples\n",
      "\n",
      "01_20_01:13:15 --- 1.7750575542449951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:17 Training loss at epoch 3 step 5200: 2.7666513681411744\n",
      "\n",
      " This round's valence_loss=0.9459614753723145, arousal_loss=0.8121267557144165, emotion_loss=0.8769751787185669\n",
      "\n",
      "01_20_01:13:17 Seen so far: 166432 samples\n",
      "\n",
      "01_20_01:13:17 --- 1.6288158893585205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:18 Training loss at epoch 3 step 5210: 3.131601619720459\n",
      "\n",
      " This round's valence_loss=0.739995539188385, arousal_loss=0.6087427139282227, emotion_loss=0.9500236511230469\n",
      "\n",
      "01_20_01:13:18 Seen so far: 166752 samples\n",
      "\n",
      "01_20_01:13:18 --- 1.7649822235107422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:20 Training loss at epoch 3 step 5220: 3.069195008277893\n",
      "\n",
      " This round's valence_loss=0.9888312816619873, arousal_loss=0.8568787574768066, emotion_loss=0.7888190150260925\n",
      "\n",
      "01_20_01:13:20 Seen so far: 167072 samples\n",
      "\n",
      "01_20_01:13:20 --- 1.6993553638458252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:22 Training loss at epoch 3 step 5230: 3.320116138458252\n",
      "\n",
      " This round's valence_loss=0.6449097394943237, arousal_loss=0.4924313426017761, emotion_loss=0.6214392185211182\n",
      "\n",
      "01_20_01:13:22 Seen so far: 167392 samples\n",
      "\n",
      "01_20_01:13:22 --- 1.6579084396362305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:23 Training loss at epoch 3 step 5240: 3.1484715700149537\n",
      "\n",
      " This round's valence_loss=1.5665885210037231, arousal_loss=1.4731197357177734, emotion_loss=1.1106529235839844\n",
      "\n",
      "01_20_01:13:23 Seen so far: 167712 samples\n",
      "\n",
      "01_20_01:13:23 --- 1.7091078758239746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:25 Training loss at epoch 3 step 5250: 2.852997612953186\n",
      "\n",
      " This round's valence_loss=0.5217858552932739, arousal_loss=0.36429351568222046, emotion_loss=0.7922985553741455\n",
      "\n",
      "01_20_01:13:25 Seen so far: 168032 samples\n",
      "\n",
      "01_20_01:13:25 --- 1.9806368350982666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:27 Training loss at epoch 3 step 5260: 2.9222923040390016\n",
      "\n",
      " This round's valence_loss=1.520989179611206, arousal_loss=1.3334835767745972, emotion_loss=0.9350191354751587\n",
      "\n",
      "01_20_01:13:27 Seen so far: 168352 samples\n",
      "\n",
      "01_20_01:13:27 --- 1.933774709701538 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:29 Training loss at epoch 3 step 5270: 2.902283263206482\n",
      "\n",
      " This round's valence_loss=0.6806813478469849, arousal_loss=0.4646499752998352, emotion_loss=1.0774052143096924\n",
      "\n",
      "01_20_01:13:29 Seen so far: 168672 samples\n",
      "\n",
      "01_20_01:13:29 --- 1.8239858150482178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:31 Training loss at epoch 3 step 5280: 2.9919523000717163\n",
      "\n",
      " This round's valence_loss=1.007645845413208, arousal_loss=0.8852095603942871, emotion_loss=1.2984389066696167\n",
      "\n",
      "01_20_01:13:31 Seen so far: 168992 samples\n",
      "\n",
      "01_20_01:13:31 --- 1.9502811431884766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:33 Training loss at epoch 3 step 5290: 3.010556173324585\n",
      "\n",
      " This round's valence_loss=1.222475290298462, arousal_loss=1.0651086568832397, emotion_loss=0.9380978345870972\n",
      "\n",
      "01_20_01:13:33 Seen so far: 169312 samples\n",
      "\n",
      "01_20_01:13:33 --- 1.7758769989013672 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:35 Training loss at epoch 3 step 5300: 2.7790051460266114\n",
      "\n",
      " This round's valence_loss=1.337216854095459, arousal_loss=1.2010282278060913, emotion_loss=1.028875470161438\n",
      "\n",
      "01_20_01:13:35 Seen so far: 169632 samples\n",
      "\n",
      "01_20_01:13:35 --- 1.8669462203979492 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:37 Training loss at epoch 3 step 5310: 2.659048008918762\n",
      "\n",
      " This round's valence_loss=0.7989053726196289, arousal_loss=0.7256718873977661, emotion_loss=0.8683179020881653\n",
      "\n",
      "01_20_01:13:37 Seen so far: 169952 samples\n",
      "\n",
      "01_20_01:13:37 --- 1.7730908393859863 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:38 Training loss at epoch 3 step 5320: 2.9100839138031005\n",
      "\n",
      " This round's valence_loss=0.7589148879051208, arousal_loss=0.5861866474151611, emotion_loss=0.8818644285202026\n",
      "\n",
      "01_20_01:13:38 Seen so far: 170272 samples\n",
      "\n",
      "01_20_01:13:38 --- 1.6796505451202393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:40 Training loss at epoch 3 step 5330: 3.5470353841781614\n",
      "\n",
      " This round's valence_loss=0.8756057024002075, arousal_loss=0.7498701810836792, emotion_loss=1.151342749595642\n",
      "\n",
      "01_20_01:13:40 Seen so far: 170592 samples\n",
      "\n",
      "01_20_01:13:40 --- 1.6283738613128662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:41 Training loss at epoch 3 step 5340: 2.9370334148406982\n",
      "\n",
      " This round's valence_loss=0.8167895078659058, arousal_loss=0.5549215078353882, emotion_loss=0.7899694442749023\n",
      "\n",
      "01_20_01:13:41 Seen so far: 170912 samples\n",
      "\n",
      "01_20_01:13:41 --- 1.5368807315826416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:43 Training loss at epoch 3 step 5350: 2.6656550645828245\n",
      "\n",
      " This round's valence_loss=0.8320499658584595, arousal_loss=0.7220880389213562, emotion_loss=0.8751941919326782\n",
      "\n",
      "01_20_01:13:43 Seen so far: 171232 samples\n",
      "\n",
      "01_20_01:13:43 --- 1.7145729064941406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:45 Training loss at epoch 3 step 5360: 2.9081783294677734\n",
      "\n",
      " This round's valence_loss=0.8739084005355835, arousal_loss=0.7219936847686768, emotion_loss=0.9534319639205933\n",
      "\n",
      "01_20_01:13:45 Seen so far: 171552 samples\n",
      "\n",
      "01_20_01:13:45 --- 1.821382761001587 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:47 Training loss at epoch 3 step 5370: 2.727127695083618\n",
      "\n",
      " This round's valence_loss=0.9670925736427307, arousal_loss=0.7964158058166504, emotion_loss=0.8257237672805786\n",
      "\n",
      "01_20_01:13:47 Seen so far: 171872 samples\n",
      "\n",
      "01_20_01:13:47 --- 1.828416347503662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:48 Training loss at epoch 3 step 5380: 2.9464279651641845\n",
      "\n",
      " This round's valence_loss=0.7723633050918579, arousal_loss=0.594355583190918, emotion_loss=0.9099262356758118\n",
      "\n",
      "01_20_01:13:48 Seen so far: 172192 samples\n",
      "\n",
      "01_20_01:13:48 --- 1.6427502632141113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:50 Training loss at epoch 3 step 5390: 3.1326828718185427\n",
      "\n",
      " This round's valence_loss=1.7583959102630615, arousal_loss=1.6564658880233765, emotion_loss=1.1796895265579224\n",
      "\n",
      "01_20_01:13:50 Seen so far: 172512 samples\n",
      "\n",
      "01_20_01:13:50 --- 1.806039810180664 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:52 Training loss at epoch 3 step 5400: 2.797416031360626\n",
      "\n",
      " This round's valence_loss=0.8584855794906616, arousal_loss=0.7058035135269165, emotion_loss=0.9936781525611877\n",
      "\n",
      "01_20_01:13:52 Seen so far: 172832 samples\n",
      "\n",
      "01_20_01:13:52 --- 1.8201415538787842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:54 Training loss at epoch 3 step 5410: 2.9479328989982605\n",
      "\n",
      " This round's valence_loss=1.227278232574463, arousal_loss=1.1089882850646973, emotion_loss=1.214867353439331\n",
      "\n",
      "01_20_01:13:54 Seen so far: 173152 samples\n",
      "\n",
      "01_20_01:13:54 --- 1.7805061340332031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:56 Training loss at epoch 3 step 5420: 2.7987830877304076\n",
      "\n",
      " This round's valence_loss=1.6125550270080566, arousal_loss=1.451399564743042, emotion_loss=1.028350591659546\n",
      "\n",
      "01_20_01:13:56 Seen so far: 173472 samples\n",
      "\n",
      "01_20_01:13:56 --- 1.7378039360046387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:57 Training loss at epoch 3 step 5430: 2.6874944806098937\n",
      "\n",
      " This round's valence_loss=1.1146469116210938, arousal_loss=0.9635827541351318, emotion_loss=1.015427827835083\n",
      "\n",
      "01_20_01:13:57 Seen so far: 173792 samples\n",
      "\n",
      "01_20_01:13:57 --- 1.6148977279663086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:13:59 Training loss at epoch 3 step 5440: 2.6242645978927612\n",
      "\n",
      " This round's valence_loss=1.2333664894104004, arousal_loss=1.0515129566192627, emotion_loss=0.9253433346748352\n",
      "\n",
      "01_20_01:13:59 Seen so far: 174112 samples\n",
      "\n",
      "01_20_01:13:59 --- 1.6880238056182861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:01 Training loss at epoch 3 step 5450: 2.801744246482849\n",
      "\n",
      " This round's valence_loss=0.6219879984855652, arousal_loss=0.5406920909881592, emotion_loss=0.692446231842041\n",
      "\n",
      "01_20_01:14:01 Seen so far: 174432 samples\n",
      "\n",
      "01_20_01:14:01 --- 1.7720694541931152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:02 Training loss at epoch 3 step 5460: 2.793213200569153\n",
      "\n",
      " This round's valence_loss=0.659989595413208, arousal_loss=0.5267433524131775, emotion_loss=1.0111980438232422\n",
      "\n",
      "01_20_01:14:02 Seen so far: 174752 samples\n",
      "\n",
      "01_20_01:14:02 --- 1.7955284118652344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:04 Training loss at epoch 3 step 5470: 3.1324845790863036\n",
      "\n",
      " This round's valence_loss=1.4572019577026367, arousal_loss=1.3040218353271484, emotion_loss=0.7605165243148804\n",
      "\n",
      "01_20_01:14:04 Seen so far: 175072 samples\n",
      "\n",
      "01_20_01:14:04 --- 1.9762170314788818 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:06 Training loss at epoch 3 step 5480: 3.045327353477478\n",
      "\n",
      " This round's valence_loss=1.342698335647583, arousal_loss=1.2207562923431396, emotion_loss=1.1834009885787964\n",
      "\n",
      "01_20_01:14:06 Seen so far: 175392 samples\n",
      "\n",
      "01_20_01:14:06 --- 1.7456636428833008 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:08 Training loss at epoch 3 step 5490: 2.94927841424942\n",
      "\n",
      " This round's valence_loss=1.2432910203933716, arousal_loss=1.1271324157714844, emotion_loss=0.9876655340194702\n",
      "\n",
      "01_20_01:14:08 Seen so far: 175712 samples\n",
      "\n",
      "01_20_01:14:08 --- 1.8369295597076416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:10 Training loss at epoch 3 step 5500: 3.120230484008789\n",
      "\n",
      " This round's valence_loss=1.2825756072998047, arousal_loss=1.1808068752288818, emotion_loss=0.8313275575637817\n",
      "\n",
      "01_20_01:14:10 Seen so far: 176032 samples\n",
      "\n",
      "01_20_01:14:10 --- 2.026122570037842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:12 Training loss at epoch 3 step 5510: 2.6173710584640504\n",
      "\n",
      " This round's valence_loss=0.5235641002655029, arousal_loss=0.3374161720275879, emotion_loss=0.6827375292778015\n",
      "\n",
      "01_20_01:14:12 Seen so far: 176352 samples\n",
      "\n",
      "01_20_01:14:12 --- 1.940190315246582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:14 Training loss at epoch 3 step 5520: 2.7917882204055786\n",
      "\n",
      " This round's valence_loss=0.9486747980117798, arousal_loss=0.8399428129196167, emotion_loss=0.903032660484314\n",
      "\n",
      "01_20_01:14:14 Seen so far: 176672 samples\n",
      "\n",
      "01_20_01:14:14 --- 1.77718186378479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:15 Training loss at epoch 3 step 5530: 2.9812360048294066\n",
      "\n",
      " This round's valence_loss=1.1488301753997803, arousal_loss=0.9481163024902344, emotion_loss=0.8571167588233948\n",
      "\n",
      "01_20_01:14:15 Seen so far: 176992 samples\n",
      "\n",
      "01_20_01:14:15 --- 1.7507061958312988 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:17 Training loss at epoch 3 step 5540: 3.4046886920928956\n",
      "\n",
      " This round's valence_loss=1.2963200807571411, arousal_loss=1.2057628631591797, emotion_loss=1.0512784719467163\n",
      "\n",
      "01_20_01:14:17 Seen so far: 177312 samples\n",
      "\n",
      "01_20_01:14:17 --- 1.7363791465759277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:19 Training loss at epoch 3 step 5550: 3.029954218864441\n",
      "\n",
      " This round's valence_loss=1.2216527462005615, arousal_loss=1.099339485168457, emotion_loss=1.313709020614624\n",
      "\n",
      "01_20_01:14:19 Seen so far: 177632 samples\n",
      "\n",
      "01_20_01:14:19 --- 1.7467396259307861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:21 Training loss at epoch 3 step 5560: 2.9402530908584597\n",
      "\n",
      " This round's valence_loss=0.9766519069671631, arousal_loss=0.8530490398406982, emotion_loss=1.0302194356918335\n",
      "\n",
      "01_20_01:14:21 Seen so far: 177952 samples\n",
      "\n",
      "01_20_01:14:21 --- 1.8102989196777344 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:23 Training loss at epoch 3 step 5570: 3.224152851104736\n",
      "\n",
      " This round's valence_loss=0.8007473945617676, arousal_loss=0.7797970771789551, emotion_loss=0.9597926139831543\n",
      "\n",
      "01_20_01:14:23 Seen so far: 178272 samples\n",
      "\n",
      "01_20_01:14:23 --- 1.870880365371704 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:25 Training loss at epoch 3 step 5580: 3.247705006599426\n",
      "\n",
      " This round's valence_loss=1.2757539749145508, arousal_loss=1.1189467906951904, emotion_loss=0.5951767563819885\n",
      "\n",
      "01_20_01:14:25 Seen so far: 178592 samples\n",
      "\n",
      "01_20_01:14:25 --- 1.9031579494476318 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:26 Training loss at epoch 3 step 5590: 3.188944935798645\n",
      "\n",
      " This round's valence_loss=1.09669828414917, arousal_loss=0.9553486108779907, emotion_loss=0.9189090728759766\n",
      "\n",
      "01_20_01:14:26 Seen so far: 178912 samples\n",
      "\n",
      "01_20_01:14:26 --- 1.7684781551361084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:28 Training loss at epoch 3 step 5600: 2.9111794233322144\n",
      "\n",
      " This round's valence_loss=0.7935593128204346, arousal_loss=0.5868625044822693, emotion_loss=0.8380784392356873\n",
      "\n",
      "01_20_01:14:28 Seen so far: 179232 samples\n",
      "\n",
      "01_20_01:14:28 --- 1.6639745235443115 seconds for iter 10 step, each step have 32, so the model train with 320 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_20_01:14:30 Training loss at epoch 3 step 5610: 3.1895201206207275\n",
      "\n",
      " This round's valence_loss=1.6092058420181274, arousal_loss=1.4837310314178467, emotion_loss=1.172715425491333\n",
      "\n",
      "01_20_01:14:30 Seen so far: 179552 samples\n",
      "\n",
      "01_20_01:14:30 --- 1.8354322910308838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:32 Training loss at epoch 3 step 5620: 2.947439169883728\n",
      "\n",
      " This round's valence_loss=1.0561320781707764, arousal_loss=0.9906046390533447, emotion_loss=1.1102280616760254\n",
      "\n",
      "01_20_01:14:32 Seen so far: 179872 samples\n",
      "\n",
      "01_20_01:14:32 --- 1.7656316757202148 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:33 Training loss at epoch 3 step 5630: 3.3222716808319093\n",
      "\n",
      " This round's valence_loss=1.2032190561294556, arousal_loss=1.0835145711898804, emotion_loss=1.0543148517608643\n",
      "\n",
      "01_20_01:14:33 Seen so far: 180192 samples\n",
      "\n",
      "01_20_01:14:33 --- 1.7643802165985107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:35 Training loss at epoch 3 step 5640: 2.7582664012908937\n",
      "\n",
      " This round's valence_loss=1.0053095817565918, arousal_loss=0.9640210866928101, emotion_loss=0.7989848852157593\n",
      "\n",
      "01_20_01:14:35 Seen so far: 180512 samples\n",
      "\n",
      "01_20_01:14:35 --- 1.7301621437072754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:37 Training loss at epoch 3 step 5650: 3.164403772354126\n",
      "\n",
      " This round's valence_loss=1.1907135248184204, arousal_loss=1.1123952865600586, emotion_loss=1.4039890766143799\n",
      "\n",
      "01_20_01:14:37 Seen so far: 180832 samples\n",
      "\n",
      "01_20_01:14:37 --- 1.715386152267456 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:39 Training loss at epoch 3 step 5660: 2.766367328166962\n",
      "\n",
      " This round's valence_loss=1.0278555154800415, arousal_loss=0.8758278489112854, emotion_loss=0.8870453834533691\n",
      "\n",
      "01_20_01:14:39 Seen so far: 181152 samples\n",
      "\n",
      "01_20_01:14:39 --- 1.7670130729675293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:40 Training loss at epoch 3 step 5670: 3.5292553663253785\n",
      "\n",
      " This round's valence_loss=1.3788783550262451, arousal_loss=1.2375577688217163, emotion_loss=0.8750642538070679\n",
      "\n",
      "01_20_01:14:40 Seen so far: 181472 samples\n",
      "\n",
      "01_20_01:14:40 --- 1.6823089122772217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:42 Training loss at epoch 3 step 5680: 2.9122024297714235\n",
      "\n",
      " This round's valence_loss=1.456022024154663, arousal_loss=1.304978609085083, emotion_loss=0.8416954278945923\n",
      "\n",
      "01_20_01:14:42 Seen so far: 181792 samples\n",
      "\n",
      "01_20_01:14:42 --- 1.7315118312835693 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:44 Training loss at epoch 3 step 5690: 2.776258397102356\n",
      "\n",
      " This round's valence_loss=1.3097054958343506, arousal_loss=1.0215351581573486, emotion_loss=0.7916616201400757\n",
      "\n",
      "01_20_01:14:44 Seen so far: 182112 samples\n",
      "\n",
      "01_20_01:14:44 --- 1.7444355487823486 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:45 Training loss at epoch 3 step 5700: 3.370609927177429\n",
      "\n",
      " This round's valence_loss=0.7082966566085815, arousal_loss=0.6144224405288696, emotion_loss=1.100433111190796\n",
      "\n",
      "01_20_01:14:45 Seen so far: 182432 samples\n",
      "\n",
      "01_20_01:14:45 --- 1.7155072689056396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:47 Training loss at epoch 3 step 5710: 2.9143651485443116\n",
      "\n",
      " This round's valence_loss=1.1153416633605957, arousal_loss=0.979783296585083, emotion_loss=0.6049487590789795\n",
      "\n",
      "01_20_01:14:47 Seen so far: 182752 samples\n",
      "\n",
      "01_20_01:14:47 --- 1.7410836219787598 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:49 Training loss at epoch 3 step 5720: 3.0770682096481323\n",
      "\n",
      " This round's valence_loss=1.7768332958221436, arousal_loss=1.708325743675232, emotion_loss=1.0272072553634644\n",
      "\n",
      "01_20_01:14:49 Seen so far: 183072 samples\n",
      "\n",
      "01_20_01:14:49 --- 1.7066900730133057 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:51 Training loss at epoch 3 step 5730: 3.267299842834473\n",
      "\n",
      " This round's valence_loss=0.9842296838760376, arousal_loss=0.8725837469100952, emotion_loss=0.6410000324249268\n",
      "\n",
      "01_20_01:14:51 Seen so far: 183392 samples\n",
      "\n",
      "01_20_01:14:51 --- 1.8216593265533447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:52 Training loss at epoch 3 step 5740: 3.1759547710418703\n",
      "\n",
      " This round's valence_loss=1.1474133729934692, arousal_loss=0.9312155246734619, emotion_loss=0.8206874132156372\n",
      "\n",
      "01_20_01:14:52 Seen so far: 183712 samples\n",
      "\n",
      "01_20_01:14:52 --- 1.7321953773498535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:54 Training loss at epoch 3 step 5750: 3.0225255250930787\n",
      "\n",
      " This round's valence_loss=1.1965572834014893, arousal_loss=0.8970348834991455, emotion_loss=0.5962072610855103\n",
      "\n",
      "01_20_01:14:54 Seen so far: 184032 samples\n",
      "\n",
      "01_20_01:14:54 --- 1.6857314109802246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:56 Training loss at epoch 3 step 5760: 2.896363091468811\n",
      "\n",
      " This round's valence_loss=1.105388879776001, arousal_loss=0.9319415092468262, emotion_loss=0.9713070392608643\n",
      "\n",
      "01_20_01:14:56 Seen so far: 184352 samples\n",
      "\n",
      "01_20_01:14:56 --- 1.8010222911834717 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:58 Training loss at epoch 3 step 5770: 3.1565514087677\n",
      "\n",
      " This round's valence_loss=1.048506259918213, arousal_loss=1.0348622798919678, emotion_loss=1.3269057273864746\n",
      "\n",
      "01_20_01:14:58 Seen so far: 184672 samples\n",
      "\n",
      "01_20_01:14:58 --- 1.6947863101959229 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:14:59 Training loss at epoch 3 step 5780: 2.663240122795105\n",
      "\n",
      " This round's valence_loss=0.9776884317398071, arousal_loss=0.8500747680664062, emotion_loss=0.8789600133895874\n",
      "\n",
      "01_20_01:14:59 Seen so far: 184992 samples\n",
      "\n",
      "01_20_01:14:59 --- 1.833730936050415 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:01 Training loss at epoch 3 step 5790: 2.900725984573364\n",
      "\n",
      " This round's valence_loss=1.4739940166473389, arousal_loss=1.3113266229629517, emotion_loss=0.8018485307693481\n",
      "\n",
      "01_20_01:15:01 Seen so far: 185312 samples\n",
      "\n",
      "01_20_01:15:01 --- 1.7256982326507568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:03 Training loss at epoch 3 step 5800: 2.6185232996940613\n",
      "\n",
      " This round's valence_loss=1.0847759246826172, arousal_loss=0.952938437461853, emotion_loss=0.8889449834823608\n",
      "\n",
      "01_20_01:15:03 Seen so far: 185632 samples\n",
      "\n",
      "01_20_01:15:03 --- 1.6831910610198975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:05 Training loss at epoch 3 step 5810: 3.2321834325790406\n",
      "\n",
      " This round's valence_loss=1.21750009059906, arousal_loss=1.078474760055542, emotion_loss=1.0567631721496582\n",
      "\n",
      "01_20_01:15:05 Seen so far: 185952 samples\n",
      "\n",
      "01_20_01:15:05 --- 1.9466092586517334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:07 Training loss at epoch 3 step 5820: 3.074265241622925\n",
      "\n",
      " This round's valence_loss=1.4493743181228638, arousal_loss=1.350118637084961, emotion_loss=0.5599774122238159\n",
      "\n",
      "01_20_01:15:07 Seen so far: 186272 samples\n",
      "\n",
      "01_20_01:15:07 --- 1.8425934314727783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:08 Training loss at epoch 3 step 5830: 3.1506278038024904\n",
      "\n",
      " This round's valence_loss=1.3670814037322998, arousal_loss=1.1825087070465088, emotion_loss=0.9739402532577515\n",
      "\n",
      "01_20_01:15:08 Seen so far: 186592 samples\n",
      "\n",
      "01_20_01:15:08 --- 1.7528748512268066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:10 Training loss at epoch 3 step 5840: 2.7599484443664553\n",
      "\n",
      " This round's valence_loss=0.6140566468238831, arousal_loss=0.5248951315879822, emotion_loss=0.8055346012115479\n",
      "\n",
      "01_20_01:15:10 Seen so far: 186912 samples\n",
      "\n",
      "01_20_01:15:10 --- 1.7623329162597656 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:12 Training loss at epoch 3 step 5850: 2.9495052814483644\n",
      "\n",
      " This round's valence_loss=0.5850445032119751, arousal_loss=0.47836700081825256, emotion_loss=1.0590875148773193\n",
      "\n",
      "01_20_01:15:12 Seen so far: 187232 samples\n",
      "\n",
      "01_20_01:15:12 --- 1.777883768081665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:14 Training loss at epoch 3 step 5860: 3.0519349336624146\n",
      "\n",
      " This round's valence_loss=0.6442478895187378, arousal_loss=0.513023853302002, emotion_loss=1.196592092514038\n",
      "\n",
      "01_20_01:15:14 Seen so far: 187552 samples\n",
      "\n",
      "01_20_01:15:14 --- 1.693831205368042 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:15 Training loss at epoch 3 step 5870: 3.033937859535217\n",
      "\n",
      " This round's valence_loss=0.8804006576538086, arousal_loss=0.7352371215820312, emotion_loss=0.5664042234420776\n",
      "\n",
      "01_20_01:15:15 Seen so far: 187872 samples\n",
      "\n",
      "01_20_01:15:15 --- 1.6861448287963867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:17 Training loss at epoch 3 step 5880: 2.9373669624328613\n",
      "\n",
      " This round's valence_loss=0.8714745044708252, arousal_loss=0.7190871238708496, emotion_loss=0.7297799587249756\n",
      "\n",
      "01_20_01:15:17 Seen so far: 188192 samples\n",
      "\n",
      "01_20_01:15:17 --- 1.6743123531341553 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:19 Training loss at epoch 3 step 5890: 3.021419143676758\n",
      "\n",
      " This round's valence_loss=1.726806879043579, arousal_loss=1.600188970565796, emotion_loss=1.101341962814331\n",
      "\n",
      "01_20_01:15:19 Seen so far: 188512 samples\n",
      "\n",
      "01_20_01:15:19 --- 1.8458211421966553 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:21 Training loss at epoch 3 step 5900: 2.7829146146774293\n",
      "\n",
      " This round's valence_loss=0.8799424767494202, arousal_loss=0.7127773761749268, emotion_loss=0.6731424331665039\n",
      "\n",
      "01_20_01:15:21 Seen so far: 188832 samples\n",
      "\n",
      "01_20_01:15:21 --- 1.7437467575073242 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:22 Training loss at epoch 3 step 5910: 2.9166205644607546\n",
      "\n",
      " This round's valence_loss=0.9092665910720825, arousal_loss=0.7611993551254272, emotion_loss=0.6766179203987122\n",
      "\n",
      "01_20_01:15:22 Seen so far: 189152 samples\n",
      "\n",
      "01_20_01:15:22 --- 1.8014271259307861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:24 Training loss at epoch 3 step 5920: 3.044221210479736\n",
      "\n",
      " This round's valence_loss=1.308439016342163, arousal_loss=1.0822253227233887, emotion_loss=0.8627490997314453\n",
      "\n",
      "01_20_01:15:24 Seen so far: 189472 samples\n",
      "\n",
      "01_20_01:15:24 --- 1.836040735244751 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:26 Training loss at epoch 3 step 5930: 3.0353967428207396\n",
      "\n",
      " This round's valence_loss=1.4235780239105225, arousal_loss=1.3362174034118652, emotion_loss=1.02017080783844\n",
      "\n",
      "01_20_01:15:26 Seen so far: 189792 samples\n",
      "\n",
      "01_20_01:15:26 --- 1.7231595516204834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:28 Training loss at epoch 3 step 5940: 2.93037748336792\n",
      "\n",
      " This round's valence_loss=0.8490003347396851, arousal_loss=0.7185397148132324, emotion_loss=0.8691709637641907\n",
      "\n",
      "01_20_01:15:28 Seen so far: 190112 samples\n",
      "\n",
      "01_20_01:15:28 --- 1.7092359066009521 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:29 Training loss at epoch 3 step 5950: 2.8855770111083983\n",
      "\n",
      " This round's valence_loss=0.948677659034729, arousal_loss=0.8653428554534912, emotion_loss=1.1495612859725952\n",
      "\n",
      "01_20_01:15:29 Seen so far: 190432 samples\n",
      "\n",
      "01_20_01:15:29 --- 1.790553092956543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:31 Training loss at epoch 3 step 5960: 2.9130978345870973\n",
      "\n",
      " This round's valence_loss=0.9922906756401062, arousal_loss=0.8892070651054382, emotion_loss=0.9035344123840332\n",
      "\n",
      "01_20_01:15:31 Seen so far: 190752 samples\n",
      "\n",
      "01_20_01:15:31 --- 1.7852609157562256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:33 Training loss at epoch 3 step 5970: 3.222630226612091\n",
      "\n",
      " This round's valence_loss=1.1205703020095825, arousal_loss=0.9734575748443604, emotion_loss=1.0958425998687744\n",
      "\n",
      "01_20_01:15:33 Seen so far: 191072 samples\n",
      "\n",
      "01_20_01:15:33 --- 1.8166553974151611 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:35 Training loss at epoch 3 step 5980: 2.934095597267151\n",
      "\n",
      " This round's valence_loss=0.7102477550506592, arousal_loss=0.6992007493972778, emotion_loss=1.0855507850646973\n",
      "\n",
      "01_20_01:15:35 Seen so far: 191392 samples\n",
      "\n",
      "01_20_01:15:35 --- 1.8274884223937988 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:37 Training loss at epoch 3 step 5990: 2.736290228366852\n",
      "\n",
      " This round's valence_loss=0.5368856191635132, arousal_loss=0.423678994178772, emotion_loss=0.9374033808708191\n",
      "\n",
      "01_20_01:15:37 Seen so far: 191712 samples\n",
      "\n",
      "01_20_01:15:37 --- 1.7970483303070068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:38 Training loss at epoch 3 step 6000: 2.9331472754478454\n",
      "\n",
      " This round's valence_loss=0.9926135540008545, arousal_loss=0.8163489103317261, emotion_loss=0.8394092321395874\n",
      "\n",
      "01_20_01:15:38 Seen so far: 192032 samples\n",
      "\n",
      "01_20_01:15:38 --- 1.8296923637390137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:40 Training loss at epoch 3 step 6010: 3.225320243835449\n",
      "\n",
      " This round's valence_loss=1.4727108478546143, arousal_loss=1.363387107849121, emotion_loss=1.1589076519012451\n",
      "\n",
      "01_20_01:15:40 Seen so far: 192352 samples\n",
      "\n",
      "01_20_01:15:40 --- 1.735239028930664 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:42 Training loss at epoch 3 step 6020: 3.0876490592956545\n",
      "\n",
      " This round's valence_loss=1.2115767002105713, arousal_loss=0.9694955348968506, emotion_loss=0.8715735673904419\n",
      "\n",
      "01_20_01:15:42 Seen so far: 192672 samples\n",
      "\n",
      "01_20_01:15:42 --- 1.7219769954681396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:44 Training loss at epoch 3 step 6030: 3.143926572799683\n",
      "\n",
      " This round's valence_loss=1.1600114107131958, arousal_loss=1.1399462223052979, emotion_loss=1.0745410919189453\n",
      "\n",
      "01_20_01:15:44 Seen so far: 192992 samples\n",
      "\n",
      "01_20_01:15:44 --- 1.8634915351867676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:45 Training loss at epoch 3 step 6040: 2.781601881980896\n",
      "\n",
      " This round's valence_loss=1.4950252771377563, arousal_loss=1.3483127355575562, emotion_loss=0.8030039072036743\n",
      "\n",
      "01_20_01:15:45 Seen so far: 193312 samples\n",
      "\n",
      "01_20_01:15:45 --- 1.5774919986724854 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:47 Training loss at epoch 3 step 6050: 2.726818525791168\n",
      "\n",
      " This round's valence_loss=1.1320507526397705, arousal_loss=0.9545844793319702, emotion_loss=0.9104843139648438\n",
      "\n",
      "01_20_01:15:47 Seen so far: 193632 samples\n",
      "\n",
      "01_20_01:15:47 --- 1.9387493133544922 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:49 Training loss at epoch 3 step 6060: 3.3909331798553466\n",
      "\n",
      " This round's valence_loss=1.2235260009765625, arousal_loss=1.0706815719604492, emotion_loss=1.223839282989502\n",
      "\n",
      "01_20_01:15:49 Seen so far: 193952 samples\n",
      "\n",
      "01_20_01:15:49 --- 1.819244623184204 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:51 Training loss at epoch 3 step 6070: 2.804596555233002\n",
      "\n",
      " This round's valence_loss=0.6322380900382996, arousal_loss=0.4737684726715088, emotion_loss=0.8697513937950134\n",
      "\n",
      "01_20_01:15:51 Seen so far: 194272 samples\n",
      "\n",
      "01_20_01:15:51 --- 1.7363872528076172 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:53 Training loss at epoch 3 step 6080: 3.088574457168579\n",
      "\n",
      " This round's valence_loss=0.966019868850708, arousal_loss=0.8528448343276978, emotion_loss=0.9538254737854004\n",
      "\n",
      "01_20_01:15:53 Seen so far: 194592 samples\n",
      "\n",
      "01_20_01:15:53 --- 1.7138547897338867 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:54 Training loss at epoch 3 step 6090: 2.9101571559906008\n",
      "\n",
      " This round's valence_loss=0.7407644987106323, arousal_loss=0.46350735425949097, emotion_loss=0.6838507652282715\n",
      "\n",
      "01_20_01:15:54 Seen so far: 194912 samples\n",
      "\n",
      "01_20_01:15:54 --- 1.707664966583252 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:56 Training loss at epoch 3 step 6100: 2.8823075771331785\n",
      "\n",
      " This round's valence_loss=1.9206581115722656, arousal_loss=1.8175909519195557, emotion_loss=0.8390886783599854\n",
      "\n",
      "01_20_01:15:56 Seen so far: 195232 samples\n",
      "\n",
      "01_20_01:15:56 --- 1.789804458618164 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:15:58 Training loss at epoch 3 step 6110: 2.867370307445526\n",
      "\n",
      " This round's valence_loss=1.234424352645874, arousal_loss=1.02619206905365, emotion_loss=0.6139084100723267\n",
      "\n",
      "01_20_01:15:58 Seen so far: 195552 samples\n",
      "\n",
      "01_20_01:15:58 --- 1.805363416671753 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:00 Training loss at epoch 3 step 6120: 2.9881588935852053\n",
      "\n",
      " This round's valence_loss=1.3498649597167969, arousal_loss=1.2228237390518188, emotion_loss=0.6370396614074707\n",
      "\n",
      "01_20_01:16:00 Seen so far: 195872 samples\n",
      "\n",
      "01_20_01:16:00 --- 1.7243103981018066 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:01 Training loss at epoch 3 step 6130: 2.7582757234573365\n",
      "\n",
      " This round's valence_loss=0.9661973714828491, arousal_loss=0.6724783182144165, emotion_loss=0.7767242193222046\n",
      "\n",
      "01_20_01:16:01 Seen so far: 196192 samples\n",
      "\n",
      "01_20_01:16:01 --- 1.8596267700195312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:03 Training loss at epoch 3 step 6140: 2.760555863380432\n",
      "\n",
      " This round's valence_loss=1.3747432231903076, arousal_loss=1.223085880279541, emotion_loss=0.6336405873298645\n",
      "\n",
      "01_20_01:16:03 Seen so far: 196512 samples\n",
      "\n",
      "01_20_01:16:03 --- 1.7280921936035156 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:05 Training loss at epoch 3 step 6150: 2.9834280014038086\n",
      "\n",
      " This round's valence_loss=0.739578366279602, arousal_loss=0.6376842260360718, emotion_loss=1.041157841682434\n",
      "\n",
      "01_20_01:16:05 Seen so far: 196832 samples\n",
      "\n",
      "01_20_01:16:05 --- 1.7868728637695312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:07 Training loss at epoch 3 step 6160: 2.792354142665863\n",
      "\n",
      " This round's valence_loss=1.3389809131622314, arousal_loss=1.1793574094772339, emotion_loss=0.9335126280784607\n",
      "\n",
      "01_20_01:16:07 Seen so far: 197152 samples\n",
      "\n",
      "01_20_01:16:07 --- 1.8126716613769531 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:08 Training loss at epoch 3 step 6170: 2.9523953676223753\n",
      "\n",
      " This round's valence_loss=0.6856815814971924, arousal_loss=0.5934339761734009, emotion_loss=0.8463586568832397\n",
      "\n",
      "01_20_01:16:08 Seen so far: 197472 samples\n",
      "\n",
      "01_20_01:16:08 --- 1.5917415618896484 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:10 Training loss at epoch 3 step 6180: 2.9738348007202147\n",
      "\n",
      " This round's valence_loss=1.0880156755447388, arousal_loss=0.9837762117385864, emotion_loss=0.9657790660858154\n",
      "\n",
      "01_20_01:16:10 Seen so far: 197792 samples\n",
      "\n",
      "01_20_01:16:10 --- 1.7294402122497559 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:12 Training loss at epoch 3 step 6190: 2.890076780319214\n",
      "\n",
      " This round's valence_loss=1.2562175989151, arousal_loss=1.1044950485229492, emotion_loss=0.8361670970916748\n",
      "\n",
      "01_20_01:16:12 Seen so far: 198112 samples\n",
      "\n",
      "01_20_01:16:12 --- 1.8044893741607666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:14 Training loss at epoch 3 step 6200: 3.240322804450989\n",
      "\n",
      " This round's valence_loss=0.8829858899116516, arousal_loss=0.7428637742996216, emotion_loss=1.0154740810394287\n",
      "\n",
      "01_20_01:16:14 Seen so far: 198432 samples\n",
      "\n",
      "01_20_01:16:14 --- 1.883772611618042 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:16 Training loss at epoch 3 step 6210: 3.182786464691162\n",
      "\n",
      " This round's valence_loss=1.4408516883850098, arousal_loss=1.3505284786224365, emotion_loss=1.0075187683105469\n",
      "\n",
      "01_20_01:16:16 Seen so far: 198752 samples\n",
      "\n",
      "01_20_01:16:16 --- 1.82774019241333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:17 Training loss at epoch 3 step 6220: 3.3676361322402952\n",
      "\n",
      " This round's valence_loss=1.2119166851043701, arousal_loss=1.1059998273849487, emotion_loss=1.2224278450012207\n",
      "\n",
      "01_20_01:16:17 Seen so far: 199072 samples\n",
      "\n",
      "01_20_01:16:17 --- 1.6961965560913086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:19 Training loss at epoch 3 step 6230: 2.937996780872345\n",
      "\n",
      " This round's valence_loss=1.2493422031402588, arousal_loss=1.1168181896209717, emotion_loss=1.076120138168335\n",
      "\n",
      "01_20_01:16:19 Seen so far: 199392 samples\n",
      "\n",
      "01_20_01:16:19 --- 1.710369348526001 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:21 Training loss at epoch 3 step 6240: 3.255356693267822\n",
      "\n",
      " This round's valence_loss=0.7782652974128723, arousal_loss=0.5518879890441895, emotion_loss=0.9435559511184692\n",
      "\n",
      "01_20_01:16:21 Seen so far: 199712 samples\n",
      "\n",
      "01_20_01:16:21 --- 1.7867317199707031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:23 Training loss at epoch 3 step 6250: 3.1178534984588624\n",
      "\n",
      " This round's valence_loss=1.3768116235733032, arousal_loss=1.3134942054748535, emotion_loss=1.1672823429107666\n",
      "\n",
      "01_20_01:16:23 Seen so far: 200032 samples\n",
      "\n",
      "01_20_01:16:23 --- 1.8847944736480713 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:25 Training loss at epoch 3 step 6260: 2.954805278778076\n",
      "\n",
      " This round's valence_loss=0.880427360534668, arousal_loss=0.6750094890594482, emotion_loss=0.796249270439148\n",
      "\n",
      "01_20_01:16:25 Seen so far: 200352 samples\n",
      "\n",
      "01_20_01:16:25 --- 1.8666281700134277 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:26 Training loss at epoch 3 step 6270: 2.7559889793395995\n",
      "\n",
      " This round's valence_loss=0.7456249594688416, arousal_loss=0.5806745886802673, emotion_loss=0.6049299240112305\n",
      "\n",
      "01_20_01:16:26 Seen so far: 200672 samples\n",
      "\n",
      "01_20_01:16:26 --- 1.8757569789886475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:28 Training loss at epoch 3 step 6280: 2.703320574760437\n",
      "\n",
      " This round's valence_loss=1.159098744392395, arousal_loss=1.0931166410446167, emotion_loss=0.9154292345046997\n",
      "\n",
      "01_20_01:16:28 Seen so far: 200992 samples\n",
      "\n",
      "01_20_01:16:28 --- 1.856184482574463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:30 Training loss at epoch 3 step 6290: 2.8357850193977354\n",
      "\n",
      " This round's valence_loss=0.713316798210144, arousal_loss=0.6371884942054749, emotion_loss=1.1061654090881348\n",
      "\n",
      "01_20_01:16:30 Seen so far: 201312 samples\n",
      "\n",
      "01_20_01:16:30 --- 1.6695923805236816 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:32 Training loss at epoch 3 step 6300: 3.2247556686401366\n",
      "\n",
      " This round's valence_loss=1.2517619132995605, arousal_loss=1.0795402526855469, emotion_loss=0.8688236474990845\n",
      "\n",
      "01_20_01:16:32 Seen so far: 201632 samples\n",
      "\n",
      "01_20_01:16:32 --- 1.6884584426879883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:33 Training loss at epoch 3 step 6310: 2.8321983575820924\n",
      "\n",
      " This round's valence_loss=0.9850896596908569, arousal_loss=0.8779908418655396, emotion_loss=1.0754097700119019\n",
      "\n",
      "01_20_01:16:33 Seen so far: 201952 samples\n",
      "\n",
      "01_20_01:16:33 --- 1.7199792861938477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:35 Training loss at epoch 3 step 6320: 3.1211936235427857\n",
      "\n",
      " This round's valence_loss=0.9675894975662231, arousal_loss=0.8159434795379639, emotion_loss=0.8889347314834595\n",
      "\n",
      "01_20_01:16:35 Seen so far: 202272 samples\n",
      "\n",
      "01_20_01:16:35 --- 1.5694231986999512 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:37 Training loss at epoch 3 step 6330: 2.8060904502868653\n",
      "\n",
      " This round's valence_loss=1.2474486827850342, arousal_loss=1.063776969909668, emotion_loss=0.9970694780349731\n",
      "\n",
      "01_20_01:16:37 Seen so far: 202592 samples\n",
      "\n",
      "01_20_01:16:37 --- 1.7334678173065186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:39 Training loss at epoch 3 step 6340: 3.184009575843811\n",
      "\n",
      " This round's valence_loss=0.5982393026351929, arousal_loss=0.5338822603225708, emotion_loss=0.7415883541107178\n",
      "\n",
      "01_20_01:16:39 Seen so far: 202912 samples\n",
      "\n",
      "01_20_01:16:39 --- 1.9554288387298584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:40 Training loss at epoch 3 step 6350: 2.667014646530151\n",
      "\n",
      " This round's valence_loss=0.5829372406005859, arousal_loss=0.42835062742233276, emotion_loss=0.66660475730896\n",
      "\n",
      "01_20_01:16:40 Seen so far: 203232 samples\n",
      "\n",
      "01_20_01:16:40 --- 1.7861113548278809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:42 Training loss at epoch 3 step 6360: 2.809325361251831\n",
      "\n",
      " This round's valence_loss=0.9765802025794983, arousal_loss=0.8209205865859985, emotion_loss=0.7795544862747192\n",
      "\n",
      "01_20_01:16:42 Seen so far: 203552 samples\n",
      "\n",
      "01_20_01:16:42 --- 1.6457018852233887 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:44 Training loss at epoch 3 step 6370: 3.104872488975525\n",
      "\n",
      " This round's valence_loss=1.5593106746673584, arousal_loss=1.4352896213531494, emotion_loss=0.7197997570037842\n",
      "\n",
      "01_20_01:16:44 Seen so far: 203872 samples\n",
      "\n",
      "01_20_01:16:44 --- 1.735159158706665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:46 Training loss at epoch 3 step 6380: 3.064288115501404\n",
      "\n",
      " This round's valence_loss=0.9296976327896118, arousal_loss=0.8618361949920654, emotion_loss=1.1201586723327637\n",
      "\n",
      "01_20_01:16:46 Seen so far: 204192 samples\n",
      "\n",
      "01_20_01:16:46 --- 1.778738021850586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:47 Training loss at epoch 3 step 6390: 3.072233033180237\n",
      "\n",
      " This round's valence_loss=1.1281509399414062, arousal_loss=1.012422800064087, emotion_loss=0.9028278589248657\n",
      "\n",
      "01_20_01:16:47 Seen so far: 204512 samples\n",
      "\n",
      "01_20_01:16:47 --- 1.6508491039276123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:49 Training loss at epoch 3 step 6400: 3.244585084915161\n",
      "\n",
      " This round's valence_loss=0.8649893403053284, arousal_loss=0.7107956409454346, emotion_loss=1.1406097412109375\n",
      "\n",
      "01_20_01:16:49 Seen so far: 204832 samples\n",
      "\n",
      "01_20_01:16:49 --- 1.9621226787567139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:51 Training loss at epoch 3 step 6410: 2.911683428287506\n",
      "\n",
      " This round's valence_loss=1.4227113723754883, arousal_loss=1.3850326538085938, emotion_loss=0.9066925644874573\n",
      "\n",
      "01_20_01:16:51 Seen so far: 205152 samples\n",
      "\n",
      "01_20_01:16:51 --- 1.6807494163513184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:53 Training loss at epoch 3 step 6420: 3.0619219541549683\n",
      "\n",
      " This round's valence_loss=1.1254605054855347, arousal_loss=1.0295778512954712, emotion_loss=0.873121976852417\n",
      "\n",
      "01_20_01:16:53 Seen so far: 205472 samples\n",
      "\n",
      "01_20_01:16:53 --- 1.8784124851226807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:54 Training loss at epoch 3 step 6430: 2.842874526977539\n",
      "\n",
      " This round's valence_loss=1.3376855850219727, arousal_loss=1.2022993564605713, emotion_loss=0.8513052463531494\n",
      "\n",
      "01_20_01:16:54 Seen so far: 205792 samples\n",
      "\n",
      "01_20_01:16:54 --- 1.685438632965088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:56 Training loss at epoch 3 step 6440: 2.78023761510849\n",
      "\n",
      " This round's valence_loss=1.5004451274871826, arousal_loss=1.4755803346633911, emotion_loss=0.9779268503189087\n",
      "\n",
      "01_20_01:16:56 Seen so far: 206112 samples\n",
      "\n",
      "01_20_01:16:56 --- 1.6302766799926758 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:58 Training loss at epoch 3 step 6450: 3.1400288105010987\n",
      "\n",
      " This round's valence_loss=1.0550272464752197, arousal_loss=0.9710077047348022, emotion_loss=0.9595934152603149\n",
      "\n",
      "01_20_01:16:58 Seen so far: 206432 samples\n",
      "\n",
      "01_20_01:16:58 --- 1.725477695465088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:16:59 Training loss at epoch 3 step 6460: 2.894475245475769\n",
      "\n",
      " This round's valence_loss=0.8950108289718628, arousal_loss=0.6965152025222778, emotion_loss=0.8631733059883118\n",
      "\n",
      "01_20_01:16:59 Seen so far: 206752 samples\n",
      "\n",
      "01_20_01:16:59 --- 1.6477439403533936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:01 Training loss at epoch 3 step 6470: 3.043747329711914\n",
      "\n",
      " This round's valence_loss=1.0487221479415894, arousal_loss=0.9682028293609619, emotion_loss=0.9757009744644165\n",
      "\n",
      "01_20_01:17:01 Seen so far: 207072 samples\n",
      "\n",
      "01_20_01:17:01 --- 1.7935676574707031 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:03 Training loss at epoch 3 step 6480: 3.0015580892562865\n",
      "\n",
      " This round's valence_loss=0.8582133054733276, arousal_loss=0.712683916091919, emotion_loss=0.9209916591644287\n",
      "\n",
      "01_20_01:17:03 Seen so far: 207392 samples\n",
      "\n",
      "01_20_01:17:03 --- 1.7369861602783203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:05 Training loss at epoch 3 step 6490: 2.9325975656509398\n",
      "\n",
      " This round's valence_loss=1.3405499458312988, arousal_loss=1.1763801574707031, emotion_loss=0.8876948952674866\n",
      "\n",
      "01_20_01:17:05 Seen so far: 207712 samples\n",
      "\n",
      "01_20_01:17:05 --- 1.8830668926239014 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:07 Training loss at epoch 3 step 6500: 3.174112248420715\n",
      "\n",
      " This round's valence_loss=1.0910043716430664, arousal_loss=1.0018796920776367, emotion_loss=0.8815765380859375\n",
      "\n",
      "01_20_01:17:07 Seen so far: 208032 samples\n",
      "\n",
      "01_20_01:17:07 --- 1.722978115081787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:08 Training loss at epoch 3 step 6510: 2.7481851816177367\n",
      "\n",
      " This round's valence_loss=1.2743055820465088, arousal_loss=1.0853532552719116, emotion_loss=0.8235700130462646\n",
      "\n",
      "01_20_01:17:08 Seen so far: 208352 samples\n",
      "\n",
      "01_20_01:17:08 --- 1.8280303478240967 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:10 Training loss at epoch 3 step 6520: 2.857631969451904\n",
      "\n",
      " This round's valence_loss=0.9179377555847168, arousal_loss=0.7026064395904541, emotion_loss=0.7121957540512085\n",
      "\n",
      "01_20_01:17:10 Seen so far: 208672 samples\n",
      "\n",
      "01_20_01:17:10 --- 1.7036542892456055 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:12 Training loss at epoch 3 step 6530: 2.8032302856445312\n",
      "\n",
      " This round's valence_loss=0.8813794851303101, arousal_loss=0.70199054479599, emotion_loss=0.8124080896377563\n",
      "\n",
      "01_20_01:17:12 Seen so far: 208992 samples\n",
      "\n",
      "01_20_01:17:12 --- 2.0261449813842773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:14 Training loss at epoch 3 step 6540: 2.888517165184021\n",
      "\n",
      " This round's valence_loss=0.8856443166732788, arousal_loss=0.7170245051383972, emotion_loss=0.8036176562309265\n",
      "\n",
      "01_20_01:17:14 Seen so far: 209312 samples\n",
      "\n",
      "01_20_01:17:14 --- 1.77451753616333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:16 Training loss at epoch 3 step 6550: 2.848552680015564\n",
      "\n",
      " This round's valence_loss=0.8937969207763672, arousal_loss=0.6784942150115967, emotion_loss=0.7074436545372009\n",
      "\n",
      "01_20_01:17:16 Seen so far: 209632 samples\n",
      "\n",
      "01_20_01:17:16 --- 1.7151403427124023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:17 Training loss at epoch 3 step 6560: 2.8815250158309937\n",
      "\n",
      " This round's valence_loss=0.9826878905296326, arousal_loss=0.8432880640029907, emotion_loss=1.020190954208374\n",
      "\n",
      "01_20_01:17:17 Seen so far: 209952 samples\n",
      "\n",
      "01_20_01:17:17 --- 1.7798752784729004 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:19 Training loss at epoch 3 step 6570: 2.7993311166763304\n",
      "\n",
      " This round's valence_loss=0.994152843952179, arousal_loss=0.8245887756347656, emotion_loss=0.4461292624473572\n",
      "\n",
      "01_20_01:17:19 Seen so far: 210272 samples\n",
      "\n",
      "01_20_01:17:19 --- 1.8164548873901367 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:21 Training loss at epoch 3 step 6580: 2.855092692375183\n",
      "\n",
      " This round's valence_loss=0.9172379970550537, arousal_loss=0.855646014213562, emotion_loss=0.8872760534286499\n",
      "\n",
      "01_20_01:17:21 Seen so far: 210592 samples\n",
      "\n",
      "01_20_01:17:21 --- 1.7015395164489746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:23 Training loss at epoch 3 step 6590: 2.5068418383598328\n",
      "\n",
      " This round's valence_loss=0.7819298505783081, arousal_loss=0.6052889823913574, emotion_loss=0.9094148278236389\n",
      "\n",
      "01_20_01:17:23 Seen so far: 210912 samples\n",
      "\n",
      "01_20_01:17:23 --- 1.7806222438812256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:24 Training loss at epoch 3 step 6600: 2.9242818713188172\n",
      "\n",
      " This round's valence_loss=0.7993481159210205, arousal_loss=0.7043414115905762, emotion_loss=1.0074987411499023\n",
      "\n",
      "01_20_01:17:24 Seen so far: 211232 samples\n",
      "\n",
      "01_20_01:17:24 --- 1.5520060062408447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:26 Training loss at epoch 3 step 6610: 2.959773325920105\n",
      "\n",
      " This round's valence_loss=1.4617865085601807, arousal_loss=1.3452651500701904, emotion_loss=0.8940000534057617\n",
      "\n",
      "01_20_01:17:26 Seen so far: 211552 samples\n",
      "\n",
      "01_20_01:17:26 --- 1.9130170345306396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:28 Training loss at epoch 3 step 6620: 2.7998225569725035\n",
      "\n",
      " This round's valence_loss=1.3009743690490723, arousal_loss=1.2167811393737793, emotion_loss=0.9696992039680481\n",
      "\n",
      "01_20_01:17:28 Seen so far: 211872 samples\n",
      "\n",
      "01_20_01:17:28 --- 1.5824735164642334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:30 Training loss at epoch 3 step 6630: 2.854172945022583\n",
      "\n",
      " This round's valence_loss=1.3992466926574707, arousal_loss=1.234192132949829, emotion_loss=1.2097277641296387\n",
      "\n",
      "01_20_01:17:30 Seen so far: 212192 samples\n",
      "\n",
      "01_20_01:17:30 --- 2.027522325515747 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:32 Training loss at epoch 3 step 6640: 3.004725217819214\n",
      "\n",
      " This round's valence_loss=0.7333581447601318, arousal_loss=0.5659528970718384, emotion_loss=0.8000038862228394\n",
      "\n",
      "01_20_01:17:32 Seen so far: 212512 samples\n",
      "\n",
      "01_20_01:17:32 --- 1.9547643661499023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:34 Training loss at epoch 3 step 6650: 2.953612232208252\n",
      "\n",
      " This round's valence_loss=1.2969385385513306, arousal_loss=1.045356035232544, emotion_loss=1.0451419353485107\n",
      "\n",
      "01_20_01:17:34 Seen so far: 212832 samples\n",
      "\n",
      "01_20_01:17:34 --- 1.7688863277435303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:35 Training loss at epoch 3 step 6660: 3.2457439422607424\n",
      "\n",
      " This round's valence_loss=1.1890318393707275, arousal_loss=1.1507370471954346, emotion_loss=1.1469589471817017\n",
      "\n",
      "01_20_01:17:35 Seen so far: 213152 samples\n",
      "\n",
      "01_20_01:17:35 --- 1.721362829208374 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:37 Training loss at epoch 3 step 6670: 3.2989022493362428\n",
      "\n",
      " This round's valence_loss=1.1705517768859863, arousal_loss=1.077683448791504, emotion_loss=0.8780335783958435\n",
      "\n",
      "01_20_01:17:37 Seen so far: 213472 samples\n",
      "\n",
      "01_20_01:17:37 --- 1.6630492210388184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:39 Training loss at epoch 3 step 6680: 3.1060745477676392\n",
      "\n",
      " This round's valence_loss=0.6850916147232056, arousal_loss=0.6458861231803894, emotion_loss=1.413771629333496\n",
      "\n",
      "01_20_01:17:39 Seen so far: 213792 samples\n",
      "\n",
      "01_20_01:17:39 --- 1.9173362255096436 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:41 Training loss at epoch 3 step 6690: 2.9574084281921387\n",
      "\n",
      " This round's valence_loss=1.0212526321411133, arousal_loss=0.8728482723236084, emotion_loss=0.9088016748428345\n",
      "\n",
      "01_20_01:17:41 Seen so far: 214112 samples\n",
      "\n",
      "01_20_01:17:41 --- 1.7050845623016357 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:42 Training loss at epoch 3 step 6700: 3.2917909622192383\n",
      "\n",
      " This round's valence_loss=1.0612578392028809, arousal_loss=0.9507625699043274, emotion_loss=0.9151877164840698\n",
      "\n",
      "01_20_01:17:42 Seen so far: 214432 samples\n",
      "\n",
      "01_20_01:17:42 --- 1.6814918518066406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:44 Training loss at epoch 3 step 6710: 3.280406951904297\n",
      "\n",
      " This round's valence_loss=0.7604032158851624, arousal_loss=0.7912161350250244, emotion_loss=0.9719080924987793\n",
      "\n",
      "01_20_01:17:44 Seen so far: 214752 samples\n",
      "\n",
      "01_20_01:17:44 --- 1.9037084579467773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:46 Training loss at epoch 3 step 6720: 3.1744160413742066\n",
      "\n",
      " This round's valence_loss=0.8463186025619507, arousal_loss=0.720398485660553, emotion_loss=1.0724924802780151\n",
      "\n",
      "01_20_01:17:46 Seen so far: 215072 samples\n",
      "\n",
      "01_20_01:17:46 --- 1.9124195575714111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:48 Training loss at epoch 3 step 6730: 3.116858220100403\n",
      "\n",
      " This round's valence_loss=1.42989182472229, arousal_loss=1.3318169116973877, emotion_loss=1.0019595623016357\n",
      "\n",
      "01_20_01:17:48 Seen so far: 215392 samples\n",
      "\n",
      "01_20_01:17:48 --- 1.7387409210205078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:50 Training loss at epoch 3 step 6740: 2.6408214926719666\n",
      "\n",
      " This round's valence_loss=0.8957459330558777, arousal_loss=0.7187943458557129, emotion_loss=0.6894800662994385\n",
      "\n",
      "01_20_01:17:50 Seen so far: 215712 samples\n",
      "\n",
      "01_20_01:17:50 --- 1.8661842346191406 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:51 Training loss at epoch 3 step 6750: 2.9299489498138427\n",
      "\n",
      " This round's valence_loss=0.7864036560058594, arousal_loss=0.5540446639060974, emotion_loss=0.9525260329246521\n",
      "\n",
      "01_20_01:17:51 Seen so far: 216032 samples\n",
      "\n",
      "01_20_01:17:51 --- 1.7116177082061768 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:53 Training loss at epoch 3 step 6760: 2.9738110661506654\n",
      "\n",
      " This round's valence_loss=1.1664398908615112, arousal_loss=1.100569486618042, emotion_loss=0.9893537759780884\n",
      "\n",
      "01_20_01:17:53 Seen so far: 216352 samples\n",
      "\n",
      "01_20_01:17:53 --- 1.89793062210083 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:55 Training loss at epoch 3 step 6770: 2.765717339515686\n",
      "\n",
      " This round's valence_loss=1.295790433883667, arousal_loss=1.0878078937530518, emotion_loss=0.7060146331787109\n",
      "\n",
      "01_20_01:17:55 Seen so far: 216672 samples\n",
      "\n",
      "01_20_01:17:55 --- 1.762669324874878 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:57 Training loss at epoch 3 step 6780: 2.9282690048217774\n",
      "\n",
      " This round's valence_loss=1.1742137670516968, arousal_loss=1.060011863708496, emotion_loss=1.1536414623260498\n",
      "\n",
      "01_20_01:17:57 Seen so far: 216992 samples\n",
      "\n",
      "01_20_01:17:57 --- 1.8537826538085938 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:17:59 Training loss at epoch 3 step 6790: 2.9665533304214478\n",
      "\n",
      " This round's valence_loss=1.0513916015625, arousal_loss=0.9571473002433777, emotion_loss=1.0000784397125244\n",
      "\n",
      "01_20_01:17:59 Seen so far: 217312 samples\n",
      "\n",
      "01_20_01:17:59 --- 1.7858796119689941 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:00 Training loss at epoch 3 step 6800: 3.0865619659423826\n",
      "\n",
      " This round's valence_loss=1.0158162117004395, arousal_loss=0.8208065032958984, emotion_loss=0.8387555480003357\n",
      "\n",
      "01_20_01:18:00 Seen so far: 217632 samples\n",
      "\n",
      "01_20_01:18:00 --- 1.7567017078399658 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:02 Training loss at epoch 3 step 6810: 2.798959231376648\n",
      "\n",
      " This round's valence_loss=1.1989219188690186, arousal_loss=1.1255943775177002, emotion_loss=1.3329496383666992\n",
      "\n",
      "01_20_01:18:02 Seen so far: 217952 samples\n",
      "\n",
      "01_20_01:18:02 --- 1.6737403869628906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:04 Training loss at epoch 3 step 6820: 3.156342315673828\n",
      "\n",
      " This round's valence_loss=1.243654727935791, arousal_loss=1.0882370471954346, emotion_loss=0.9102096557617188\n",
      "\n",
      "01_20_01:18:04 Seen so far: 218272 samples\n",
      "\n",
      "01_20_01:18:04 --- 1.7000579833984375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:05 Training loss at epoch 3 step 6830: 2.9916926622390747\n",
      "\n",
      " This round's valence_loss=0.6758334636688232, arousal_loss=0.5775998830795288, emotion_loss=1.049752950668335\n",
      "\n",
      "01_20_01:18:05 Seen so far: 218592 samples\n",
      "\n",
      "01_20_01:18:05 --- 1.666989803314209 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:07 Training loss at epoch 3 step 6840: 2.9072765827178957\n",
      "\n",
      " This round's valence_loss=0.8251367807388306, arousal_loss=0.7020363211631775, emotion_loss=0.7407446503639221\n",
      "\n",
      "01_20_01:18:07 Seen so far: 218912 samples\n",
      "\n",
      "01_20_01:18:07 --- 1.8441760540008545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:09 Training loss at epoch 3 step 6850: 3.1667362213134767\n",
      "\n",
      " This round's valence_loss=0.6619149446487427, arousal_loss=0.689384937286377, emotion_loss=1.0140310525894165\n",
      "\n",
      "01_20_01:18:09 Seen so far: 219232 samples\n",
      "\n",
      "01_20_01:18:09 --- 1.917875051498413 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:11 Training loss at epoch 3 step 6860: 3.073923134803772\n",
      "\n",
      " This round's valence_loss=0.8171837329864502, arousal_loss=0.6792155504226685, emotion_loss=0.9280290603637695\n",
      "\n",
      "01_20_01:18:11 Seen so far: 219552 samples\n",
      "\n",
      "01_20_01:18:11 --- 1.8416073322296143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:13 Training loss at epoch 3 step 6870: 2.8044354796409605\n",
      "\n",
      " This round's valence_loss=0.7497836351394653, arousal_loss=0.5954217910766602, emotion_loss=0.9527556300163269\n",
      "\n",
      "01_20_01:18:13 Seen so far: 219872 samples\n",
      "\n",
      "01_20_01:18:13 --- 1.8060121536254883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:15 Training loss at epoch 3 step 6880: 2.8953986167907715\n",
      "\n",
      " This round's valence_loss=0.8837771415710449, arousal_loss=0.6936969757080078, emotion_loss=0.5869008302688599\n",
      "\n",
      "01_20_01:18:15 Seen so far: 220192 samples\n",
      "\n",
      "01_20_01:18:15 --- 1.8093831539154053 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:17 Training loss at epoch 3 step 6890: 3.086286926269531\n",
      "\n",
      " This round's valence_loss=1.408039927482605, arousal_loss=1.3085888624191284, emotion_loss=1.1209512948989868\n",
      "\n",
      "01_20_01:18:17 Seen so far: 220512 samples\n",
      "\n",
      "01_20_01:18:17 --- 1.8778793811798096 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:18 Training loss at epoch 3 step 6900: 3.0708322763442992\n",
      "\n",
      " This round's valence_loss=0.6568642854690552, arousal_loss=0.48393478989601135, emotion_loss=0.87959885597229\n",
      "\n",
      "01_20_01:18:18 Seen so far: 220832 samples\n",
      "\n",
      "01_20_01:18:18 --- 1.740950107574463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:20 Training loss at epoch 3 step 6910: 2.759561038017273\n",
      "\n",
      " This round's valence_loss=0.8852081298828125, arousal_loss=0.7295542359352112, emotion_loss=0.7629069089889526\n",
      "\n",
      "01_20_01:18:20 Seen so far: 221152 samples\n",
      "\n",
      "01_20_01:18:20 --- 1.886563777923584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:22 Training loss at epoch 3 step 6920: 2.959079384803772\n",
      "\n",
      " This round's valence_loss=1.3952271938323975, arousal_loss=1.2697234153747559, emotion_loss=0.7558395862579346\n",
      "\n",
      "01_20_01:18:22 Seen so far: 221472 samples\n",
      "\n",
      "01_20_01:18:22 --- 1.769958734512329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:24 Training loss at epoch 3 step 6930: 2.95991907119751\n",
      "\n",
      " This round's valence_loss=0.958310067653656, arousal_loss=0.8247155547142029, emotion_loss=0.7809395790100098\n",
      "\n",
      "01_20_01:18:24 Seen so far: 221792 samples\n",
      "\n",
      "01_20_01:18:24 --- 1.804427146911621 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:25 Training loss at epoch 3 step 6940: 3.0386563777923583\n",
      "\n",
      " This round's valence_loss=0.7006446123123169, arousal_loss=0.6547654867172241, emotion_loss=1.2376453876495361\n",
      "\n",
      "01_20_01:18:25 Seen so far: 222112 samples\n",
      "\n",
      "01_20_01:18:25 --- 1.6496565341949463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:27 Training loss at epoch 3 step 6950: 3.1843244314193724\n",
      "\n",
      " This round's valence_loss=0.9162274599075317, arousal_loss=0.6912986040115356, emotion_loss=0.8590316772460938\n",
      "\n",
      "01_20_01:18:27 Seen so far: 222432 samples\n",
      "\n",
      "01_20_01:18:27 --- 1.625084400177002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:29 Training loss at epoch 3 step 6960: 3.147520160675049\n",
      "\n",
      " This round's valence_loss=1.200739860534668, arousal_loss=1.111074686050415, emotion_loss=1.424468755722046\n",
      "\n",
      "01_20_01:18:29 Seen so far: 222752 samples\n",
      "\n",
      "01_20_01:18:29 --- 1.7613635063171387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:31 Training loss at epoch 3 step 6970: 3.018917953968048\n",
      "\n",
      " This round's valence_loss=0.9556249380111694, arousal_loss=0.8257211446762085, emotion_loss=1.1310133934020996\n",
      "\n",
      "01_20_01:18:31 Seen so far: 223072 samples\n",
      "\n",
      "01_20_01:18:31 --- 1.7765440940856934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:32 Training loss at epoch 3 step 6980: 3.0153207302093508\n",
      "\n",
      " This round's valence_loss=1.263291835784912, arousal_loss=1.0465242862701416, emotion_loss=0.7991863489151001\n",
      "\n",
      "01_20_01:18:32 Seen so far: 223392 samples\n",
      "\n",
      "01_20_01:18:32 --- 1.7603890895843506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:34 Training loss at epoch 3 step 6990: 3.039890456199646\n",
      "\n",
      " This round's valence_loss=1.0755976438522339, arousal_loss=0.9565091133117676, emotion_loss=1.1254329681396484\n",
      "\n",
      "01_20_01:18:34 Seen so far: 223712 samples\n",
      "\n",
      "01_20_01:18:34 --- 1.7283780574798584 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:36 Training loss at epoch 3 step 7000: 2.8999834775924684\n",
      "\n",
      " This round's valence_loss=0.7520562410354614, arousal_loss=0.5980110168457031, emotion_loss=0.7146581411361694\n",
      "\n",
      "01_20_01:18:36 Seen so far: 224032 samples\n",
      "\n",
      "01_20_01:18:36 --- 1.828622579574585 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:38 Training loss at epoch 3 step 7010: 2.9379751205444338\n",
      "\n",
      " This round's valence_loss=1.0371679067611694, arousal_loss=0.8024908304214478, emotion_loss=0.6932424306869507\n",
      "\n",
      "01_20_01:18:38 Seen so far: 224352 samples\n",
      "\n",
      "01_20_01:18:38 --- 1.8567876815795898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:40 Training loss at epoch 3 step 7020: 2.8909207582473755\n",
      "\n",
      " This round's valence_loss=1.0138249397277832, arousal_loss=0.8983283042907715, emotion_loss=0.8560941219329834\n",
      "\n",
      "01_20_01:18:40 Seen so far: 224672 samples\n",
      "\n",
      "01_20_01:18:40 --- 1.8630542755126953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:41 Training loss at epoch 3 step 7030: 2.78455011844635\n",
      "\n",
      " This round's valence_loss=1.2374486923217773, arousal_loss=1.0674843788146973, emotion_loss=0.909238338470459\n",
      "\n",
      "01_20_01:18:41 Seen so far: 224992 samples\n",
      "\n",
      "01_20_01:18:41 --- 1.8007776737213135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:43 Training loss at epoch 3 step 7040: 3.001522946357727\n",
      "\n",
      " This round's valence_loss=0.9568578600883484, arousal_loss=0.7010471224784851, emotion_loss=1.149346113204956\n",
      "\n",
      "01_20_01:18:43 Seen so far: 225312 samples\n",
      "\n",
      "01_20_01:18:43 --- 1.7754716873168945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:45 Training loss at epoch 3 step 7050: 2.8384727239608765\n",
      "\n",
      " This round's valence_loss=0.9316742420196533, arousal_loss=0.7559927701950073, emotion_loss=1.0542693138122559\n",
      "\n",
      "01_20_01:18:45 Seen so far: 225632 samples\n",
      "\n",
      "01_20_01:18:45 --- 1.7954885959625244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:47 Training loss at epoch 3 step 7060: 2.7026336789131165\n",
      "\n",
      " This round's valence_loss=1.4117071628570557, arousal_loss=1.302429437637329, emotion_loss=1.163835048675537\n",
      "\n",
      "01_20_01:18:47 Seen so far: 225952 samples\n",
      "\n",
      "01_20_01:18:47 --- 1.9204068183898926 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:49 Training loss at epoch 3 step 7070: 2.7837297439575197\n",
      "\n",
      " This round's valence_loss=1.2167034149169922, arousal_loss=1.084594964981079, emotion_loss=0.5860515832901001\n",
      "\n",
      "01_20_01:18:49 Seen so far: 226272 samples\n",
      "\n",
      "01_20_01:18:49 --- 1.6850550174713135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:50 Training loss at epoch 3 step 7080: 2.9430176496505736\n",
      "\n",
      " This round's valence_loss=0.921826958656311, arousal_loss=0.9600149393081665, emotion_loss=0.8931491374969482\n",
      "\n",
      "01_20_01:18:50 Seen so far: 226592 samples\n",
      "\n",
      "01_20_01:18:50 --- 1.680281400680542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:52 Training loss at epoch 3 step 7090: 3.0865493059158324\n",
      "\n",
      " This round's valence_loss=1.8045027256011963, arousal_loss=1.7476847171783447, emotion_loss=1.0357704162597656\n",
      "\n",
      "01_20_01:18:52 Seen so far: 226912 samples\n",
      "\n",
      "01_20_01:18:52 --- 1.797727346420288 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:54 Training loss at epoch 3 step 7100: 2.6690217018127442\n",
      "\n",
      " This round's valence_loss=1.0294619798660278, arousal_loss=0.8465646505355835, emotion_loss=1.055372953414917\n",
      "\n",
      "01_20_01:18:54 Seen so far: 227232 samples\n",
      "\n",
      "01_20_01:18:54 --- 1.6879520416259766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:56 Training loss at epoch 3 step 7110: 3.1977415561676024\n",
      "\n",
      " This round's valence_loss=1.043245792388916, arousal_loss=0.9328901767730713, emotion_loss=0.8341505527496338\n",
      "\n",
      "01_20_01:18:56 Seen so far: 227552 samples\n",
      "\n",
      "01_20_01:18:56 --- 1.8180384635925293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:57 Training loss at epoch 3 step 7120: 2.8707717418670655\n",
      "\n",
      " This round's valence_loss=0.7412863969802856, arousal_loss=0.5921453237533569, emotion_loss=1.0871742963790894\n",
      "\n",
      "01_20_01:18:57 Seen so far: 227872 samples\n",
      "\n",
      "01_20_01:18:57 --- 1.7944836616516113 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:18:59 Training loss at epoch 3 step 7130: 2.780081939697266\n",
      "\n",
      " This round's valence_loss=1.540284514427185, arousal_loss=1.4493263959884644, emotion_loss=0.8732311725616455\n",
      "\n",
      "01_20_01:18:59 Seen so far: 228192 samples\n",
      "\n",
      "01_20_01:18:59 --- 1.8871777057647705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:01 Training loss at epoch 3 step 7140: 2.8379708528518677\n",
      "\n",
      " This round's valence_loss=0.8068565130233765, arousal_loss=0.6094135046005249, emotion_loss=0.6840033531188965\n",
      "\n",
      "01_20_01:19:01 Seen so far: 228512 samples\n",
      "\n",
      "01_20_01:19:01 --- 1.9173057079315186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:03 Training loss at epoch 3 step 7150: 3.3666115045547484\n",
      "\n",
      " This round's valence_loss=1.177797555923462, arousal_loss=1.032073736190796, emotion_loss=0.7203648090362549\n",
      "\n",
      "01_20_01:19:03 Seen so far: 228832 samples\n",
      "\n",
      "01_20_01:19:03 --- 1.742429256439209 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:05 Training loss at epoch 3 step 7160: 3.0483699083328246\n",
      "\n",
      " This round's valence_loss=1.2764036655426025, arousal_loss=1.2044692039489746, emotion_loss=0.9285732507705688\n",
      "\n",
      "01_20_01:19:05 Seen so far: 229152 samples\n",
      "\n",
      "01_20_01:19:05 --- 1.6854870319366455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:06 Training loss at epoch 3 step 7170: 2.9219394445419313\n",
      "\n",
      " This round's valence_loss=0.7508203983306885, arousal_loss=0.6177865266799927, emotion_loss=1.0041446685791016\n",
      "\n",
      "01_20_01:19:06 Seen so far: 229472 samples\n",
      "\n",
      "01_20_01:19:06 --- 1.904801368713379 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:08 Training loss at epoch 3 step 7180: 3.5727140426635744\n",
      "\n",
      " This round's valence_loss=1.1974663734436035, arousal_loss=1.1688729524612427, emotion_loss=0.8604815602302551\n",
      "\n",
      "01_20_01:19:08 Seen so far: 229792 samples\n",
      "\n",
      "01_20_01:19:08 --- 1.7892229557037354 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:10 Training loss at epoch 3 step 7190: 3.215543007850647\n",
      "\n",
      " This round's valence_loss=1.1545283794403076, arousal_loss=0.8995183110237122, emotion_loss=1.0002708435058594\n",
      "\n",
      "01_20_01:19:10 Seen so far: 230112 samples\n",
      "\n",
      "01_20_01:19:10 --- 1.849013090133667 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:12 Training loss at epoch 3 step 7200: 3.0988873720169066\n",
      "\n",
      " This round's valence_loss=1.1968574523925781, arousal_loss=1.0752776861190796, emotion_loss=0.8699756860733032\n",
      "\n",
      "01_20_01:19:12 Seen so far: 230432 samples\n",
      "\n",
      "01_20_01:19:12 --- 1.6802723407745361 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:14 Training loss at epoch 3 step 7210: 2.9033781766891478\n",
      "\n",
      " This round's valence_loss=1.2602952718734741, arousal_loss=1.0566517114639282, emotion_loss=1.2803460359573364\n",
      "\n",
      "01_20_01:19:14 Seen so far: 230752 samples\n",
      "\n",
      "01_20_01:19:14 --- 1.7218194007873535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:15 Training loss at epoch 3 step 7220: 2.920010495185852\n",
      "\n",
      " This round's valence_loss=1.2572416067123413, arousal_loss=1.0445778369903564, emotion_loss=0.5881116986274719\n",
      "\n",
      "01_20_01:19:15 Seen so far: 231072 samples\n",
      "\n",
      "01_20_01:19:15 --- 1.8745968341827393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:17 Training loss at epoch 3 step 7230: 2.891157126426697\n",
      "\n",
      " This round's valence_loss=1.257340908050537, arousal_loss=1.2279863357543945, emotion_loss=1.0123573541641235\n",
      "\n",
      "01_20_01:19:17 Seen so far: 231392 samples\n",
      "\n",
      "01_20_01:19:17 --- 1.706331729888916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:19 Training loss at epoch 3 step 7240: 2.700968384742737\n",
      "\n",
      " This round's valence_loss=0.6734048128128052, arousal_loss=0.45037195086479187, emotion_loss=0.8461851477622986\n",
      "\n",
      "01_20_01:19:19 Seen so far: 231712 samples\n",
      "\n",
      "01_20_01:19:19 --- 1.8491251468658447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:21 Training loss at epoch 3 step 7250: 2.861916422843933\n",
      "\n",
      " This round's valence_loss=0.9232109785079956, arousal_loss=0.7326103448867798, emotion_loss=1.141434907913208\n",
      "\n",
      "01_20_01:19:21 Seen so far: 232032 samples\n",
      "\n",
      "01_20_01:19:21 --- 1.7856838703155518 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:22 Training loss at epoch 3 step 7260: 3.1392431020736695\n",
      "\n",
      " This round's valence_loss=0.7148473262786865, arousal_loss=0.6384248733520508, emotion_loss=0.8333939909934998\n",
      "\n",
      "01_20_01:19:22 Seen so far: 232352 samples\n",
      "\n",
      "01_20_01:19:22 --- 1.6842429637908936 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:24 Training loss at epoch 3 step 7270: 2.8419109344482423\n",
      "\n",
      " This round's valence_loss=0.7118986248970032, arousal_loss=0.6282211542129517, emotion_loss=1.3353941440582275\n",
      "\n",
      "01_20_01:19:24 Seen so far: 232672 samples\n",
      "\n",
      "01_20_01:19:24 --- 1.86838698387146 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:26 Training loss at epoch 3 step 7280: 3.046693229675293\n",
      "\n",
      " This round's valence_loss=0.7050670981407166, arousal_loss=0.6146782636642456, emotion_loss=1.1801453828811646\n",
      "\n",
      "01_20_01:19:26 Seen so far: 232992 samples\n",
      "\n",
      "01_20_01:19:26 --- 1.7077827453613281 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:28 Training loss at epoch 3 step 7290: 2.969060850143433\n",
      "\n",
      " This round's valence_loss=1.0814647674560547, arousal_loss=1.0249922275543213, emotion_loss=1.1183903217315674\n",
      "\n",
      "01_20_01:19:28 Seen so far: 233312 samples\n",
      "\n",
      "01_20_01:19:28 --- 1.854964017868042 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:30 Training loss at epoch 3 step 7300: 3.0012473344802855\n",
      "\n",
      " This round's valence_loss=1.0742689371109009, arousal_loss=0.9801188707351685, emotion_loss=1.014097809791565\n",
      "\n",
      "01_20_01:19:30 Seen so far: 233632 samples\n",
      "\n",
      "01_20_01:19:30 --- 1.8461041450500488 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:32 Training loss at epoch 3 step 7310: 3.486559009552002\n",
      "\n",
      " This round's valence_loss=1.4048576354980469, arousal_loss=1.2287280559539795, emotion_loss=0.8492083549499512\n",
      "\n",
      "01_20_01:19:32 Seen so far: 233952 samples\n",
      "\n",
      "01_20_01:19:32 --- 1.8413560390472412 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:33 Training loss at epoch 3 step 7320: 2.7080353021621706\n",
      "\n",
      " This round's valence_loss=0.9514967203140259, arousal_loss=0.8571920990943909, emotion_loss=1.0268356800079346\n",
      "\n",
      "01_20_01:19:33 Seen so far: 234272 samples\n",
      "\n",
      "01_20_01:19:33 --- 1.8358638286590576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:35 Training loss at epoch 3 step 7330: 2.93803790807724\n",
      "\n",
      " This round's valence_loss=1.2259132862091064, arousal_loss=1.0770576000213623, emotion_loss=0.7772772312164307\n",
      "\n",
      "01_20_01:19:35 Seen so far: 234592 samples\n",
      "\n",
      "01_20_01:19:35 --- 2.0047266483306885 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:37 Training loss at epoch 3 step 7340: 3.0155502557754517\n",
      "\n",
      " This round's valence_loss=1.296684980392456, arousal_loss=1.0501344203948975, emotion_loss=0.899681568145752\n",
      "\n",
      "01_20_01:19:37 Seen so far: 234912 samples\n",
      "\n",
      "01_20_01:19:37 --- 1.685410499572754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:39 Training loss at epoch 3 step 7350: 2.951505351066589\n",
      "\n",
      " This round's valence_loss=0.708842396736145, arousal_loss=0.6283010244369507, emotion_loss=0.970823347568512\n",
      "\n",
      "01_20_01:19:39 Seen so far: 235232 samples\n",
      "\n",
      "01_20_01:19:39 --- 1.8223528861999512 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:41 Training loss at epoch 3 step 7360: 2.916464114189148\n",
      "\n",
      " This round's valence_loss=1.1004542112350464, arousal_loss=0.9457927942276001, emotion_loss=0.7122933864593506\n",
      "\n",
      "01_20_01:19:41 Seen so far: 235552 samples\n",
      "\n",
      "01_20_01:19:41 --- 1.757215976715088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:43 Training loss at epoch 3 step 7370: 2.995880436897278\n",
      "\n",
      " This round's valence_loss=1.0195176601409912, arousal_loss=0.8713015913963318, emotion_loss=1.0496504306793213\n",
      "\n",
      "01_20_01:19:43 Seen so far: 235872 samples\n",
      "\n",
      "01_20_01:19:43 --- 1.8817155361175537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:44 Training loss at epoch 3 step 7380: 2.928308844566345\n",
      "\n",
      " This round's valence_loss=0.6774150133132935, arousal_loss=0.4824361205101013, emotion_loss=1.0648325681686401\n",
      "\n",
      "01_20_01:19:44 Seen so far: 236192 samples\n",
      "\n",
      "01_20_01:19:44 --- 1.7895612716674805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:46 Training loss at epoch 3 step 7390: 3.1127804040908815\n",
      "\n",
      " This round's valence_loss=1.1964092254638672, arousal_loss=1.132032871246338, emotion_loss=1.351641297340393\n",
      "\n",
      "01_20_01:19:46 Seen so far: 236512 samples\n",
      "\n",
      "01_20_01:19:46 --- 1.7574987411499023 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:48 Training loss at epoch 3 step 7400: 2.8728132486343383\n",
      "\n",
      " This round's valence_loss=0.7062100172042847, arousal_loss=0.6119483709335327, emotion_loss=1.0760051012039185\n",
      "\n",
      "01_20_01:19:48 Seen so far: 236832 samples\n",
      "\n",
      "01_20_01:19:48 --- 1.6261413097381592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:50 Training loss at epoch 3 step 7410: 2.9012482166290283\n",
      "\n",
      " This round's valence_loss=0.8914926052093506, arousal_loss=0.7259331941604614, emotion_loss=0.6577202677726746\n",
      "\n",
      "01_20_01:19:50 Seen so far: 237152 samples\n",
      "\n",
      "01_20_01:19:50 --- 1.9013240337371826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:51 Training loss at epoch 3 step 7420: 3.112435054779053\n",
      "\n",
      " This round's valence_loss=0.780370831489563, arousal_loss=0.7452532052993774, emotion_loss=0.8425090312957764\n",
      "\n",
      "01_20_01:19:51 Seen so far: 237472 samples\n",
      "\n",
      "01_20_01:19:51 --- 1.8323643207550049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:53 Training loss at epoch 3 step 7430: 2.9354828238487243\n",
      "\n",
      " This round's valence_loss=0.7706823945045471, arousal_loss=0.5703942775726318, emotion_loss=0.8560943603515625\n",
      "\n",
      "01_20_01:19:53 Seen so far: 237792 samples\n",
      "\n",
      "01_20_01:19:53 --- 1.7792282104492188 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:55 Training loss at epoch 3 step 7440: 3.302491021156311\n",
      "\n",
      " This round's valence_loss=1.4916681051254272, arousal_loss=1.4368736743927002, emotion_loss=0.7832180261611938\n",
      "\n",
      "01_20_01:19:55 Seen so far: 238112 samples\n",
      "\n",
      "01_20_01:19:55 --- 1.6519153118133545 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:57 Training loss at epoch 3 step 7450: 2.9167913436889648\n",
      "\n",
      " This round's valence_loss=0.8257749080657959, arousal_loss=0.7314435243606567, emotion_loss=0.9076435565948486\n",
      "\n",
      "01_20_01:19:57 Seen so far: 238432 samples\n",
      "\n",
      "01_20_01:19:57 --- 1.8976609706878662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:19:59 Training loss at epoch 3 step 7460: 2.873244786262512\n",
      "\n",
      " This round's valence_loss=0.7504243850708008, arousal_loss=0.6231483221054077, emotion_loss=1.0140951871871948\n",
      "\n",
      "01_20_01:19:59 Seen so far: 238752 samples\n",
      "\n",
      "01_20_01:19:59 --- 1.8191382884979248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:01 Training loss at epoch 3 step 7470: 3.1187647581100464\n",
      "\n",
      " This round's valence_loss=1.2187995910644531, arousal_loss=1.1396677494049072, emotion_loss=1.2923017740249634\n",
      "\n",
      "01_20_01:20:01 Seen so far: 239072 samples\n",
      "\n",
      "01_20_01:20:01 --- 2.036999464035034 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:02 Training loss at epoch 3 step 7480: 2.7795634508132934\n",
      "\n",
      " This round's valence_loss=1.3623697757720947, arousal_loss=1.3251988887786865, emotion_loss=1.265834927558899\n",
      "\n",
      "01_20_01:20:02 Seen so far: 239392 samples\n",
      "\n",
      "01_20_01:20:02 --- 1.6917917728424072 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:04 Training loss at epoch 3 step 7490: 3.290782928466797\n",
      "\n",
      " This round's valence_loss=1.2990708351135254, arousal_loss=1.179136872291565, emotion_loss=0.8228631019592285\n",
      "\n",
      "01_20_01:20:04 Seen so far: 239712 samples\n",
      "\n",
      "01_20_01:20:04 --- 1.7707326412200928 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:06 Training loss at epoch 3 step 7500: 3.0915446996688845\n",
      "\n",
      " This round's valence_loss=1.300445556640625, arousal_loss=1.2614073753356934, emotion_loss=0.9337891936302185\n",
      "\n",
      "01_20_01:20:06 Seen so far: 240032 samples\n",
      "\n",
      "01_20_01:20:06 --- 1.7882952690124512 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:08 Training loss at epoch 3 step 7510: 2.8454245567321776\n",
      "\n",
      " This round's valence_loss=1.1645891666412354, arousal_loss=0.9740419387817383, emotion_loss=0.9763269424438477\n",
      "\n",
      "01_20_01:20:08 Seen so far: 240352 samples\n",
      "\n",
      "01_20_01:20:08 --- 1.7973792552947998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:09 Training loss at epoch 3 step 7520: 3.044120764732361\n",
      "\n",
      " This round's valence_loss=1.155347228050232, arousal_loss=1.147623062133789, emotion_loss=1.070243000984192\n",
      "\n",
      "01_20_01:20:09 Seen so far: 240672 samples\n",
      "\n",
      "01_20_01:20:09 --- 1.6411750316619873 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:11 Training loss at epoch 3 step 7530: 2.82707417011261\n",
      "\n",
      " This round's valence_loss=0.9856398701667786, arousal_loss=0.8130334615707397, emotion_loss=0.7189551591873169\n",
      "\n",
      "01_20_01:20:11 Seen so far: 240992 samples\n",
      "\n",
      "01_20_01:20:11 --- 1.7637522220611572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:13 Training loss at epoch 3 step 7540: 3.013761115074158\n",
      "\n",
      " This round's valence_loss=1.5896875858306885, arousal_loss=1.492456078529358, emotion_loss=0.9572335481643677\n",
      "\n",
      "01_20_01:20:13 Seen so far: 241312 samples\n",
      "\n",
      "01_20_01:20:13 --- 1.6026904582977295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:14 Training loss at epoch 3 step 7550: 3.020853042602539\n",
      "\n",
      " This round's valence_loss=1.3069713115692139, arousal_loss=1.2257676124572754, emotion_loss=0.6752001047134399\n",
      "\n",
      "01_20_01:20:14 Seen so far: 241632 samples\n",
      "\n",
      "01_20_01:20:14 --- 1.7019248008728027 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:16 Training loss at epoch 3 step 7560: 2.939973568916321\n",
      "\n",
      " This round's valence_loss=1.291374921798706, arousal_loss=1.0565781593322754, emotion_loss=0.938995897769928\n",
      "\n",
      "01_20_01:20:16 Seen so far: 241952 samples\n",
      "\n",
      "01_20_01:20:16 --- 1.7405447959899902 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:18 Training loss at epoch 3 step 7570: 3.0963284969329834\n",
      "\n",
      " This round's valence_loss=1.3298664093017578, arousal_loss=1.191969871520996, emotion_loss=0.9569178819656372\n",
      "\n",
      "01_20_01:20:18 Seen so far: 242272 samples\n",
      "\n",
      "01_20_01:20:18 --- 1.5921714305877686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:19 Training loss at epoch 3 step 7580: 2.960458207130432\n",
      "\n",
      " This round's valence_loss=1.1248040199279785, arousal_loss=0.9370169639587402, emotion_loss=0.7884457111358643\n",
      "\n",
      "01_20_01:20:19 Seen so far: 242592 samples\n",
      "\n",
      "01_20_01:20:19 --- 1.7251489162445068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:21 Training loss at epoch 3 step 7590: 3.1337042093276977\n",
      "\n",
      " This round's valence_loss=1.0129311084747314, arousal_loss=0.8639395236968994, emotion_loss=0.8001983761787415\n",
      "\n",
      "01_20_01:20:21 Seen so far: 242912 samples\n",
      "\n",
      "01_20_01:20:21 --- 1.7058072090148926 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:23 Training loss at epoch 3 step 7600: 2.9128479242324827\n",
      "\n",
      " This round's valence_loss=1.4320547580718994, arousal_loss=1.2990808486938477, emotion_loss=0.9436339139938354\n",
      "\n",
      "01_20_01:20:23 Seen so far: 243232 samples\n",
      "\n",
      "01_20_01:20:23 --- 1.6909942626953125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:25 Training loss at epoch 3 step 7610: 2.892776370048523\n",
      "\n",
      " This round's valence_loss=1.1618335247039795, arousal_loss=0.976834774017334, emotion_loss=0.6336255669593811\n",
      "\n",
      "01_20_01:20:25 Seen so far: 243552 samples\n",
      "\n",
      "01_20_01:20:25 --- 1.860813856124878 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:27 Training loss at epoch 3 step 7620: 3.0160671710968017\n",
      "\n",
      " This round's valence_loss=1.433307409286499, arousal_loss=1.3337116241455078, emotion_loss=1.008958339691162\n",
      "\n",
      "01_20_01:20:27 Seen so far: 243872 samples\n",
      "\n",
      "01_20_01:20:27 --- 1.8193354606628418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:28 Training loss at epoch 3 step 7630: 3.0561070919036863\n",
      "\n",
      " This round's valence_loss=0.9693175554275513, arousal_loss=0.8660486936569214, emotion_loss=1.355576992034912\n",
      "\n",
      "01_20_01:20:28 Seen so far: 244192 samples\n",
      "\n",
      "01_20_01:20:28 --- 1.7286148071289062 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:30 Training loss at epoch 3 step 7640: 2.8964306116104126\n",
      "\n",
      " This round's valence_loss=1.1013227701187134, arousal_loss=0.9576493501663208, emotion_loss=0.7682861089706421\n",
      "\n",
      "01_20_01:20:30 Seen so far: 244512 samples\n",
      "\n",
      "01_20_01:20:30 --- 1.684467077255249 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:32 Training loss at epoch 3 step 7650: 3.415036988258362\n",
      "\n",
      " This round's valence_loss=1.3197287321090698, arousal_loss=1.2092504501342773, emotion_loss=1.128669261932373\n",
      "\n",
      "01_20_01:20:32 Seen so far: 244832 samples\n",
      "\n",
      "01_20_01:20:32 --- 1.7521154880523682 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:33 Training loss at epoch 3 step 7660: 2.706157910823822\n",
      "\n",
      " This round's valence_loss=0.9181474447250366, arousal_loss=0.8165900707244873, emotion_loss=1.1389877796173096\n",
      "\n",
      "01_20_01:20:33 Seen so far: 245152 samples\n",
      "\n",
      "01_20_01:20:33 --- 1.742967128753662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:35 Training loss at epoch 3 step 7670: 2.7777073264122008\n",
      "\n",
      " This round's valence_loss=1.1268930435180664, arousal_loss=1.0439367294311523, emotion_loss=0.8719096183776855\n",
      "\n",
      "01_20_01:20:35 Seen so far: 245472 samples\n",
      "\n",
      "01_20_01:20:35 --- 1.7396705150604248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:37 Training loss at epoch 3 step 7680: 2.9768481969833376\n",
      "\n",
      " This round's valence_loss=1.091538667678833, arousal_loss=0.9254461526870728, emotion_loss=0.7755267024040222\n",
      "\n",
      "01_20_01:20:37 Seen so far: 245792 samples\n",
      "\n",
      "01_20_01:20:37 --- 1.7807679176330566 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:39 Training loss at epoch 3 step 7690: 3.002617883682251\n",
      "\n",
      " This round's valence_loss=1.3478807210922241, arousal_loss=1.202804684638977, emotion_loss=1.0524296760559082\n",
      "\n",
      "01_20_01:20:39 Seen so far: 246112 samples\n",
      "\n",
      "01_20_01:20:39 --- 1.7363390922546387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:40 Training loss at epoch 3 step 7700: 3.347461628913879\n",
      "\n",
      " This round's valence_loss=0.9165599346160889, arousal_loss=0.6802049875259399, emotion_loss=0.6932730674743652\n",
      "\n",
      "01_20_01:20:40 Seen so far: 246432 samples\n",
      "\n",
      "01_20_01:20:40 --- 1.706092357635498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:42 Training loss at epoch 3 step 7710: 3.304789423942566\n",
      "\n",
      " This round's valence_loss=1.6238081455230713, arousal_loss=1.4571326971054077, emotion_loss=1.007242202758789\n",
      "\n",
      "01_20_01:20:42 Seen so far: 246752 samples\n",
      "\n",
      "01_20_01:20:42 --- 1.8186616897583008 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:44 Training loss at epoch 3 step 7720: 2.780199205875397\n",
      "\n",
      " This round's valence_loss=1.2562847137451172, arousal_loss=1.1125106811523438, emotion_loss=1.0263948440551758\n",
      "\n",
      "01_20_01:20:44 Seen so far: 247072 samples\n",
      "\n",
      "01_20_01:20:44 --- 1.7215399742126465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:46 Training loss at epoch 3 step 7730: 3.001265621185303\n",
      "\n",
      " This round's valence_loss=1.2846763134002686, arousal_loss=1.0868315696716309, emotion_loss=0.9599542617797852\n",
      "\n",
      "01_20_01:20:46 Seen so far: 247392 samples\n",
      "\n",
      "01_20_01:20:46 --- 1.6999461650848389 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:47 Training loss at epoch 3 step 7740: 2.7882799386978148\n",
      "\n",
      " This round's valence_loss=1.2115567922592163, arousal_loss=1.0637061595916748, emotion_loss=0.7484288215637207\n",
      "\n",
      "01_20_01:20:47 Seen so far: 247712 samples\n",
      "\n",
      "01_20_01:20:47 --- 1.7512240409851074 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:49 Training loss at epoch 3 step 7750: 3.0562716484069825\n",
      "\n",
      " This round's valence_loss=0.8711527585983276, arousal_loss=0.7372246980667114, emotion_loss=1.0061628818511963\n",
      "\n",
      "01_20_01:20:49 Seen so far: 248032 samples\n",
      "\n",
      "01_20_01:20:49 --- 1.8134219646453857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:51 Training loss at epoch 3 step 7760: 3.0758177757263185\n",
      "\n",
      " This round's valence_loss=0.806860089302063, arousal_loss=0.8161565065383911, emotion_loss=0.8472398519515991\n",
      "\n",
      "01_20_01:20:51 Seen so far: 248352 samples\n",
      "\n",
      "01_20_01:20:51 --- 1.6871933937072754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:53 Training loss at epoch 3 step 7770: 3.1169005155563356\n",
      "\n",
      " This round's valence_loss=0.8341027498245239, arousal_loss=0.727186918258667, emotion_loss=0.922849714756012\n",
      "\n",
      "01_20_01:20:53 Seen so far: 248672 samples\n",
      "\n",
      "01_20_01:20:53 --- 1.8685791492462158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:55 Training loss at epoch 3 step 7780: 2.9590113878250124\n",
      "\n",
      " This round's valence_loss=1.3541303873062134, arousal_loss=1.221069574356079, emotion_loss=0.8189808130264282\n",
      "\n",
      "01_20_01:20:55 Seen so far: 248992 samples\n",
      "\n",
      "01_20_01:20:55 --- 1.9368979930877686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:57 Training loss at epoch 3 step 7790: 2.9701040029525756\n",
      "\n",
      " This round's valence_loss=0.951858639717102, arousal_loss=0.821256160736084, emotion_loss=1.0387449264526367\n",
      "\n",
      "01_20_01:20:57 Seen so far: 249312 samples\n",
      "\n",
      "01_20_01:20:57 --- 1.8019609451293945 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:20:59 Training loss at epoch 3 step 7800: 3.2764829635620116\n",
      "\n",
      " This round's valence_loss=1.4707309007644653, arousal_loss=1.359365701675415, emotion_loss=1.0706706047058105\n",
      "\n",
      "01_20_01:20:59 Seen so far: 249632 samples\n",
      "\n",
      "01_20_01:20:59 --- 1.998718500137329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:00 Training loss at epoch 3 step 7810: 2.834922659397125\n",
      "\n",
      " This round's valence_loss=1.1146929264068604, arousal_loss=0.9821147918701172, emotion_loss=0.8898599147796631\n",
      "\n",
      "01_20_01:21:00 Seen so far: 249952 samples\n",
      "\n",
      "01_20_01:21:00 --- 1.6381855010986328 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:02 Training loss at epoch 3 step 7820: 2.937529134750366\n",
      "\n",
      " This round's valence_loss=0.9235565066337585, arousal_loss=0.8628890514373779, emotion_loss=1.0084525346755981\n",
      "\n",
      "01_20_01:21:02 Seen so far: 250272 samples\n",
      "\n",
      "01_20_01:21:02 --- 1.627192735671997 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:04 Training loss at epoch 3 step 7830: 2.791728711128235\n",
      "\n",
      " This round's valence_loss=0.5100951194763184, arousal_loss=0.4408077597618103, emotion_loss=1.133610725402832\n",
      "\n",
      "01_20_01:21:04 Seen so far: 250592 samples\n",
      "\n",
      "01_20_01:21:04 --- 1.760077953338623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:05 Training loss at epoch 3 step 7840: 3.0992191791534425\n",
      "\n",
      " This round's valence_loss=1.1518465280532837, arousal_loss=0.9846546053886414, emotion_loss=0.8989931344985962\n",
      "\n",
      "01_20_01:21:05 Seen so far: 250912 samples\n",
      "\n",
      "01_20_01:21:05 --- 1.7307310104370117 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:07 Training loss at epoch 3 step 7850: 3.0992446184158324\n",
      "\n",
      " This round's valence_loss=1.1191517114639282, arousal_loss=0.9380838871002197, emotion_loss=0.9321056604385376\n",
      "\n",
      "01_20_01:21:07 Seen so far: 251232 samples\n",
      "\n",
      "01_20_01:21:07 --- 1.851691722869873 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:09 Training loss at epoch 3 step 7860: 2.666848611831665\n",
      "\n",
      " This round's valence_loss=0.8852992653846741, arousal_loss=0.6709186434745789, emotion_loss=0.8432019352912903\n",
      "\n",
      "01_20_01:21:09 Seen so far: 251552 samples\n",
      "\n",
      "01_20_01:21:09 --- 1.8673131465911865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:11 Training loss at epoch 3 step 7870: 2.6211658000946043\n",
      "\n",
      " This round's valence_loss=0.8108630180358887, arousal_loss=0.7598692178726196, emotion_loss=0.9093549847602844\n",
      "\n",
      "01_20_01:21:11 Seen so far: 251872 samples\n",
      "\n",
      "01_20_01:21:11 --- 1.7898266315460205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:12 Training loss at epoch 3 step 7880: 2.942030692100525\n",
      "\n",
      " This round's valence_loss=1.1034353971481323, arousal_loss=1.0137981176376343, emotion_loss=0.8859630227088928\n",
      "\n",
      "01_20_01:21:12 Seen so far: 252192 samples\n",
      "\n",
      "01_20_01:21:12 --- 1.628483533859253 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:14 Training loss at epoch 3 step 7890: 2.97240571975708\n",
      "\n",
      " This round's valence_loss=1.46891188621521, arousal_loss=1.313690185546875, emotion_loss=0.6988346576690674\n",
      "\n",
      "01_20_01:21:14 Seen so far: 252512 samples\n",
      "\n",
      "01_20_01:21:14 --- 1.783416748046875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:16 Training loss at epoch 3 step 7900: 2.8998907923698427\n",
      "\n",
      " This round's valence_loss=0.9799818396568298, arousal_loss=0.840224027633667, emotion_loss=0.8820968866348267\n",
      "\n",
      "01_20_01:21:16 Seen so far: 252832 samples\n",
      "\n",
      "01_20_01:21:16 --- 1.7254879474639893 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:18 Training loss at epoch 3 step 7910: 3.0531514167785643\n",
      "\n",
      " This round's valence_loss=1.0758545398712158, arousal_loss=0.9540555477142334, emotion_loss=1.11769437789917\n",
      "\n",
      "01_20_01:21:18 Seen so far: 253152 samples\n",
      "\n",
      "01_20_01:21:18 --- 1.7285611629486084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:19 Training loss at epoch 3 step 7920: 3.0893087863922117\n",
      "\n",
      " This round's valence_loss=0.9468239545822144, arousal_loss=0.8614479303359985, emotion_loss=1.0615925788879395\n",
      "\n",
      "01_20_01:21:19 Seen so far: 253472 samples\n",
      "\n",
      "01_20_01:21:19 --- 1.7368497848510742 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:21 Training loss at epoch 3 step 7930: 3.000571441650391\n",
      "\n",
      " This round's valence_loss=1.1037583351135254, arousal_loss=0.9277288913726807, emotion_loss=0.9331136345863342\n",
      "\n",
      "01_20_01:21:21 Seen so far: 253792 samples\n",
      "\n",
      "01_20_01:21:21 --- 1.94028639793396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:23 Training loss at epoch 3 step 7940: 2.8969583034515383\n",
      "\n",
      " This round's valence_loss=0.8052330017089844, arousal_loss=0.7639654874801636, emotion_loss=1.1286118030548096\n",
      "\n",
      "01_20_01:21:23 Seen so far: 254112 samples\n",
      "\n",
      "01_20_01:21:23 --- 1.9681508541107178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:25 Training loss at epoch 3 step 7950: 2.8752421379089355\n",
      "\n",
      " This round's valence_loss=0.4171004891395569, arousal_loss=0.2566604018211365, emotion_loss=1.0146279335021973\n",
      "\n",
      "01_20_01:21:25 Seen so far: 254432 samples\n",
      "\n",
      "01_20_01:21:25 --- 1.7497873306274414 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:27 Training loss at epoch 3 step 7960: 2.8302443742752077\n",
      "\n",
      " This round's valence_loss=1.0923689603805542, arousal_loss=0.9734265208244324, emotion_loss=0.949449896812439\n",
      "\n",
      "01_20_01:21:27 Seen so far: 254752 samples\n",
      "\n",
      "01_20_01:21:27 --- 1.7305004596710205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:29 Training loss at epoch 3 step 7970: 2.8746256113052366\n",
      "\n",
      " This round's valence_loss=0.8944031000137329, arousal_loss=0.772312343120575, emotion_loss=0.7660836577415466\n",
      "\n",
      "01_20_01:21:29 Seen so far: 255072 samples\n",
      "\n",
      "01_20_01:21:29 --- 1.738264560699463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:30 Training loss at epoch 3 step 7980: 3.246357464790344\n",
      "\n",
      " This round's valence_loss=1.5360729694366455, arousal_loss=1.4464843273162842, emotion_loss=1.159909963607788\n",
      "\n",
      "01_20_01:21:30 Seen so far: 255392 samples\n",
      "\n",
      "01_20_01:21:30 --- 1.8297228813171387 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:32 Training loss at epoch 3 step 7990: 2.795077991485596\n",
      "\n",
      " This round's valence_loss=0.7309157848358154, arousal_loss=0.585237979888916, emotion_loss=1.104562520980835\n",
      "\n",
      "01_20_01:21:32 Seen so far: 255712 samples\n",
      "\n",
      "01_20_01:21:32 --- 1.785029411315918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:34 Training loss at epoch 3 step 8000: 2.920811116695404\n",
      "\n",
      " This round's valence_loss=0.8028558492660522, arousal_loss=0.7315492630004883, emotion_loss=1.0825583934783936\n",
      "\n",
      "01_20_01:21:34 Seen so far: 256032 samples\n",
      "\n",
      "01_20_01:21:34 --- 1.793821096420288 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:36 Training loss at epoch 3 step 8010: 2.889998459815979\n",
      "\n",
      " This round's valence_loss=0.89714515209198, arousal_loss=0.7518734931945801, emotion_loss=0.8448076248168945\n",
      "\n",
      "01_20_01:21:36 Seen so far: 256352 samples\n",
      "\n",
      "01_20_01:21:36 --- 1.803971767425537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:38 Training loss at epoch 3 step 8020: 3.03328275680542\n",
      "\n",
      " This round's valence_loss=1.139520287513733, arousal_loss=0.9701555967330933, emotion_loss=0.9514883756637573\n",
      "\n",
      "01_20_01:21:38 Seen so far: 256672 samples\n",
      "\n",
      "01_20_01:21:38 --- 1.8170287609100342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:39 Training loss at epoch 3 step 8030: 3.0406654119491576\n",
      "\n",
      " This round's valence_loss=1.319716215133667, arousal_loss=1.239654541015625, emotion_loss=1.1428141593933105\n",
      "\n",
      "01_20_01:21:39 Seen so far: 256992 samples\n",
      "\n",
      "01_20_01:21:39 --- 1.5986440181732178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:41 Training loss at epoch 3 step 8040: 2.6974812030792235\n",
      "\n",
      " This round's valence_loss=1.060942530632019, arousal_loss=0.9624598026275635, emotion_loss=1.200151801109314\n",
      "\n",
      "01_20_01:21:41 Seen so far: 257312 samples\n",
      "\n",
      "01_20_01:21:41 --- 1.7448062896728516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:43 Training loss at epoch 3 step 8050: 3.2274260997772215\n",
      "\n",
      " This round's valence_loss=1.3302242755889893, arousal_loss=1.2165250778198242, emotion_loss=0.9831405282020569\n",
      "\n",
      "01_20_01:21:43 Seen so far: 257632 samples\n",
      "\n",
      "01_20_01:21:43 --- 1.886610507965088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:45 Training loss at epoch 3 step 8060: 3.0091786861419676\n",
      "\n",
      " This round's valence_loss=1.0853681564331055, arousal_loss=0.9788593649864197, emotion_loss=0.6101946234703064\n",
      "\n",
      "01_20_01:21:45 Seen so far: 257952 samples\n",
      "\n",
      "01_20_01:21:45 --- 1.803736686706543 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:46 Training loss at epoch 3 step 8070: 2.763545274734497\n",
      "\n",
      " This round's valence_loss=1.0629466772079468, arousal_loss=0.9459556341171265, emotion_loss=1.0684049129486084\n",
      "\n",
      "01_20_01:21:46 Seen so far: 258272 samples\n",
      "\n",
      "01_20_01:21:46 --- 1.7057201862335205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:48 Training loss at epoch 3 step 8080: 2.9085166454315186\n",
      "\n",
      " This round's valence_loss=1.5927753448486328, arousal_loss=1.439213514328003, emotion_loss=0.8404098153114319\n",
      "\n",
      "01_20_01:21:48 Seen so far: 258592 samples\n",
      "\n",
      "01_20_01:21:48 --- 1.5723094940185547 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:50 Training loss at epoch 3 step 8090: 3.184832954406738\n",
      "\n",
      " This round's valence_loss=0.9551789164543152, arousal_loss=0.8364262580871582, emotion_loss=1.1509935855865479\n",
      "\n",
      "01_20_01:21:50 Seen so far: 258912 samples\n",
      "\n",
      "01_20_01:21:50 --- 1.8151326179504395 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:51 Training loss at epoch 3 step 8100: 2.797425639629364\n",
      "\n",
      " This round's valence_loss=1.347468376159668, arousal_loss=1.1998822689056396, emotion_loss=0.922308087348938\n",
      "\n",
      "01_20_01:21:51 Seen so far: 259232 samples\n",
      "\n",
      "01_20_01:21:51 --- 1.7467131614685059 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:53 Training loss at epoch 3 step 8110: 2.9171285748481752\n",
      "\n",
      " This round's valence_loss=0.9935973882675171, arousal_loss=0.8794955015182495, emotion_loss=1.097805380821228\n",
      "\n",
      "01_20_01:21:53 Seen so far: 259552 samples\n",
      "\n",
      "01_20_01:21:53 --- 1.822417974472046 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:55 Training loss at epoch 3 step 8120: 2.964863348007202\n",
      "\n",
      " This round's valence_loss=1.2787306308746338, arousal_loss=1.1892458200454712, emotion_loss=0.7694130539894104\n",
      "\n",
      "01_20_01:21:55 Seen so far: 259872 samples\n",
      "\n",
      "01_20_01:21:55 --- 1.7478587627410889 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:57 Training loss at epoch 3 step 8130: 2.97825825214386\n",
      "\n",
      " This round's valence_loss=0.642135500907898, arousal_loss=0.4175703525543213, emotion_loss=0.8449986577033997\n",
      "\n",
      "01_20_01:21:57 Seen so far: 260192 samples\n",
      "\n",
      "01_20_01:21:57 --- 1.8457906246185303 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:21:59 Training loss at epoch 3 step 8140: 2.997847843170166\n",
      "\n",
      " This round's valence_loss=0.7035629749298096, arousal_loss=0.4043509364128113, emotion_loss=0.566935122013092\n",
      "\n",
      "01_20_01:21:59 Seen so far: 260512 samples\n",
      "\n",
      "01_20_01:21:59 --- 1.6864430904388428 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:00 Training loss at epoch 3 step 8150: 2.8440540075302123\n",
      "\n",
      " This round's valence_loss=1.4882290363311768, arousal_loss=1.3129007816314697, emotion_loss=0.8749953508377075\n",
      "\n",
      "01_20_01:22:00 Seen so far: 260832 samples\n",
      "\n",
      "01_20_01:22:00 --- 1.8820691108703613 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:02 Training loss at epoch 3 step 8160: 3.1025065660476683\n",
      "\n",
      " This round's valence_loss=1.2067525386810303, arousal_loss=1.1030677556991577, emotion_loss=1.010967493057251\n",
      "\n",
      "01_20_01:22:02 Seen so far: 261152 samples\n",
      "\n",
      "01_20_01:22:02 --- 1.7948319911956787 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:04 Training loss at epoch 3 step 8170: 2.9698160171508787\n",
      "\n",
      " This round's valence_loss=1.2529256343841553, arousal_loss=1.2185930013656616, emotion_loss=1.0645198822021484\n",
      "\n",
      "01_20_01:22:04 Seen so far: 261472 samples\n",
      "\n",
      "01_20_01:22:04 --- 1.815000295639038 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:06 Training loss at epoch 3 step 8180: 2.982219362258911\n",
      "\n",
      " This round's valence_loss=1.250781536102295, arousal_loss=1.1017712354660034, emotion_loss=1.0085995197296143\n",
      "\n",
      "01_20_01:22:06 Seen so far: 261792 samples\n",
      "\n",
      "01_20_01:22:06 --- 1.7515816688537598 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:08 Training loss at epoch 3 step 8190: 3.148358237743378\n",
      "\n",
      " This round's valence_loss=1.2239885330200195, arousal_loss=1.067274570465088, emotion_loss=0.9488294124603271\n",
      "\n",
      "01_20_01:22:08 Seen so far: 262112 samples\n",
      "\n",
      "01_20_01:22:08 --- 1.8302428722381592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:10 Training loss at epoch 3 step 8200: 2.9265474557876585\n",
      "\n",
      " This round's valence_loss=1.0930352210998535, arousal_loss=0.9920421838760376, emotion_loss=1.2963666915893555\n",
      "\n",
      "01_20_01:22:10 Seen so far: 262432 samples\n",
      "\n",
      "01_20_01:22:10 --- 1.992419719696045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:12 Training loss at epoch 3 step 8210: 3.1361075401306153\n",
      "\n",
      " This round's valence_loss=1.2033876180648804, arousal_loss=0.9766350984573364, emotion_loss=0.5817434787750244\n",
      "\n",
      "01_20_01:22:12 Seen so far: 262752 samples\n",
      "\n",
      "01_20_01:22:12 --- 1.9314000606536865 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:13 Training loss at epoch 3 step 8220: 2.551882338523865\n",
      "\n",
      " This round's valence_loss=1.298403263092041, arousal_loss=1.0805853605270386, emotion_loss=0.9406691789627075\n",
      "\n",
      "01_20_01:22:13 Seen so far: 263072 samples\n",
      "\n",
      "01_20_01:22:13 --- 1.774780511856079 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:15 Training loss at epoch 3 step 8230: 2.6679836750030517\n",
      "\n",
      " This round's valence_loss=1.1181950569152832, arousal_loss=0.981413722038269, emotion_loss=0.9327822923660278\n",
      "\n",
      "01_20_01:22:15 Seen so far: 263392 samples\n",
      "\n",
      "01_20_01:22:15 --- 1.8196425437927246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:17 Training loss at epoch 3 step 8240: 2.9832917213439942\n",
      "\n",
      " This round's valence_loss=0.7722699642181396, arousal_loss=0.6062576770782471, emotion_loss=0.8240562081336975\n",
      "\n",
      "01_20_01:22:17 Seen so far: 263712 samples\n",
      "\n",
      "01_20_01:22:17 --- 1.6932506561279297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:19 Training loss at epoch 3 step 8250: 2.9063357591629027\n",
      "\n",
      " This round's valence_loss=1.0306564569473267, arousal_loss=0.8099292516708374, emotion_loss=0.5938029289245605\n",
      "\n",
      "01_20_01:22:19 Seen so far: 264032 samples\n",
      "\n",
      "01_20_01:22:19 --- 1.82429838180542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:20 Training loss at epoch 3 step 8260: 3.260779285430908\n",
      "\n",
      " This round's valence_loss=1.1098790168762207, arousal_loss=0.9493973255157471, emotion_loss=1.0294198989868164\n",
      "\n",
      "01_20_01:22:20 Seen so far: 264352 samples\n",
      "\n",
      "01_20_01:22:20 --- 1.7482223510742188 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:22 Training loss at epoch 3 step 8270: 2.86879940032959\n",
      "\n",
      " This round's valence_loss=1.3157472610473633, arousal_loss=1.0835984945297241, emotion_loss=0.7820295095443726\n",
      "\n",
      "01_20_01:22:22 Seen so far: 264672 samples\n",
      "\n",
      "01_20_01:22:22 --- 1.9141747951507568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:24 Training loss at epoch 3 step 8280: 3.143049621582031\n",
      "\n",
      " This round's valence_loss=0.7223281860351562, arousal_loss=0.5858423709869385, emotion_loss=0.9251372814178467\n",
      "\n",
      "01_20_01:22:24 Seen so far: 264992 samples\n",
      "\n",
      "01_20_01:22:24 --- 1.9179110527038574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:26 Training loss at epoch 3 step 8290: 2.8089901208877563\n",
      "\n",
      " This round's valence_loss=1.0088913440704346, arousal_loss=0.8537013530731201, emotion_loss=0.9910053014755249\n",
      "\n",
      "01_20_01:22:26 Seen so far: 265312 samples\n",
      "\n",
      "01_20_01:22:26 --- 1.6747512817382812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:28 Training loss at epoch 3 step 8300: 2.793719971179962\n",
      "\n",
      " This round's valence_loss=1.4331567287445068, arousal_loss=1.3362982273101807, emotion_loss=1.1183204650878906\n",
      "\n",
      "01_20_01:22:28 Seen so far: 265632 samples\n",
      "\n",
      "01_20_01:22:28 --- 1.838064432144165 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:29 Training loss at epoch 3 step 8310: 3.042201566696167\n",
      "\n",
      " This round's valence_loss=0.9474447965621948, arousal_loss=0.7341198921203613, emotion_loss=1.082066297531128\n",
      "\n",
      "01_20_01:22:29 Seen so far: 265952 samples\n",
      "\n",
      "01_20_01:22:29 --- 1.7806873321533203 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:31 Training loss at epoch 3 step 8320: 2.926272082328796\n",
      "\n",
      " This round's valence_loss=0.8176774978637695, arousal_loss=0.7303242683410645, emotion_loss=1.1598752737045288\n",
      "\n",
      "01_20_01:22:31 Seen so far: 266272 samples\n",
      "\n",
      "01_20_01:22:31 --- 1.6708354949951172 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:33 Training loss at epoch 3 step 8330: 2.8561864376068113\n",
      "\n",
      " This round's valence_loss=1.432773232460022, arousal_loss=1.3269429206848145, emotion_loss=0.9484825134277344\n",
      "\n",
      "01_20_01:22:33 Seen so far: 266592 samples\n",
      "\n",
      "01_20_01:22:33 --- 1.8914620876312256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:35 Training loss at epoch 3 step 8340: 2.993621277809143\n",
      "\n",
      " This round's valence_loss=0.8373074531555176, arousal_loss=0.7081660628318787, emotion_loss=0.9364947080612183\n",
      "\n",
      "01_20_01:22:35 Seen so far: 266912 samples\n",
      "\n",
      "01_20_01:22:35 --- 1.7475345134735107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:36 Training loss at epoch 3 step 8350: 2.811291980743408\n",
      "\n",
      " This round's valence_loss=0.5447055101394653, arousal_loss=0.37759286165237427, emotion_loss=0.8629622459411621\n",
      "\n",
      "01_20_01:22:36 Seen so far: 267232 samples\n",
      "\n",
      "01_20_01:22:36 --- 1.6734490394592285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:38 Training loss at epoch 3 step 8360: 2.6890316009521484\n",
      "\n",
      " This round's valence_loss=0.5404964685440063, arousal_loss=0.31805986166000366, emotion_loss=0.8244978785514832\n",
      "\n",
      "01_20_01:22:38 Seen so far: 267552 samples\n",
      "\n",
      "01_20_01:22:38 --- 1.7698845863342285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:40 Training loss at epoch 3 step 8370: 3.1937052726745607\n",
      "\n",
      " This round's valence_loss=0.7951618432998657, arousal_loss=0.5884410738945007, emotion_loss=0.8667160272598267\n",
      "\n",
      "01_20_01:22:40 Seen so far: 267872 samples\n",
      "\n",
      "01_20_01:22:40 --- 1.836745023727417 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:42 Training loss at epoch 3 step 8380: 3.29942991733551\n",
      "\n",
      " This round's valence_loss=1.2269879579544067, arousal_loss=1.0919053554534912, emotion_loss=0.8809623122215271\n",
      "\n",
      "01_20_01:22:42 Seen so far: 268192 samples\n",
      "\n",
      "01_20_01:22:42 --- 1.5265498161315918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:43 Training loss at epoch 3 step 8390: 2.994749903678894\n",
      "\n",
      " This round's valence_loss=1.1266257762908936, arousal_loss=0.988695502281189, emotion_loss=0.7948763370513916\n",
      "\n",
      "01_20_01:22:43 Seen so far: 268512 samples\n",
      "\n",
      "01_20_01:22:43 --- 1.711951494216919 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:45 Training loss at epoch 3 step 8400: 3.179775428771973\n",
      "\n",
      " This round's valence_loss=1.041118860244751, arousal_loss=0.8129489421844482, emotion_loss=0.7873705625534058\n",
      "\n",
      "01_20_01:22:45 Seen so far: 268832 samples\n",
      "\n",
      "01_20_01:22:45 --- 1.7078673839569092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:47 Training loss at epoch 3 step 8410: 2.7239147424697876\n",
      "\n",
      " This round's valence_loss=0.7224509119987488, arousal_loss=0.493667870759964, emotion_loss=0.7938125133514404\n",
      "\n",
      "01_20_01:22:47 Seen so far: 269152 samples\n",
      "\n",
      "01_20_01:22:47 --- 1.5939357280731201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:48 Training loss at epoch 3 step 8420: 3.2530513763427735\n",
      "\n",
      " This round's valence_loss=1.4617071151733398, arousal_loss=1.3152539730072021, emotion_loss=0.9685279726982117\n",
      "\n",
      "01_20_01:22:48 Seen so far: 269472 samples\n",
      "\n",
      "01_20_01:22:48 --- 1.5872437953948975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:50 Training loss at epoch 3 step 8430: 3.0641451597213747\n",
      "\n",
      " This round's valence_loss=1.3132975101470947, arousal_loss=1.044647455215454, emotion_loss=0.9374313354492188\n",
      "\n",
      "01_20_01:22:50 Seen so far: 269792 samples\n",
      "\n",
      "01_20_01:22:50 --- 1.6505134105682373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:52 Training loss at epoch 3 step 8440: 3.073027420043945\n",
      "\n",
      " This round's valence_loss=1.1317682266235352, arousal_loss=0.9621914625167847, emotion_loss=0.722075343132019\n",
      "\n",
      "01_20_01:22:52 Seen so far: 270112 samples\n",
      "\n",
      "01_20_01:22:52 --- 1.8699657917022705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:53 Training loss at epoch 3 step 8450: 3.066195011138916\n",
      "\n",
      " This round's valence_loss=0.6946687698364258, arousal_loss=0.5622851848602295, emotion_loss=1.1497856378555298\n",
      "\n",
      "01_20_01:22:53 Seen so far: 270432 samples\n",
      "\n",
      "01_20_01:22:53 --- 1.686959981918335 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:55 Training loss at epoch 3 step 8460: 2.903353714942932\n",
      "\n",
      " This round's valence_loss=0.8187927007675171, arousal_loss=0.7288744449615479, emotion_loss=1.4160561561584473\n",
      "\n",
      "01_20_01:22:55 Seen so far: 270752 samples\n",
      "\n",
      "01_20_01:22:55 --- 1.7993662357330322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:57 Training loss at epoch 3 step 8470: 3.130255603790283\n",
      "\n",
      " This round's valence_loss=0.8766018748283386, arousal_loss=0.7089509963989258, emotion_loss=0.9256118535995483\n",
      "\n",
      "01_20_01:22:57 Seen so far: 271072 samples\n",
      "\n",
      "01_20_01:22:57 --- 1.7071521282196045 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:22:59 Training loss at epoch 3 step 8480: 2.9531743049621584\n",
      "\n",
      " This round's valence_loss=1.0798144340515137, arousal_loss=1.0024359226226807, emotion_loss=0.9694157242774963\n",
      "\n",
      "01_20_01:22:59 Seen so far: 271392 samples\n",
      "\n",
      "01_20_01:22:59 --- 1.7503182888031006 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:00 Training loss at epoch 3 step 8490: 2.572770690917969\n",
      "\n",
      " This round's valence_loss=0.8080307245254517, arousal_loss=0.7317053079605103, emotion_loss=1.1215908527374268\n",
      "\n",
      "01_20_01:23:00 Seen so far: 271712 samples\n",
      "\n",
      "01_20_01:23:00 --- 1.6937494277954102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:02 Training loss at epoch 3 step 8500: 3.0650275468826296\n",
      "\n",
      " This round's valence_loss=1.3247101306915283, arousal_loss=1.1854628324508667, emotion_loss=0.8311365842819214\n",
      "\n",
      "01_20_01:23:02 Seen so far: 272032 samples\n",
      "\n",
      "01_20_01:23:02 --- 1.9287710189819336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:04 Training loss at epoch 3 step 8510: 2.671750068664551\n",
      "\n",
      " This round's valence_loss=0.5902724266052246, arousal_loss=0.5111837387084961, emotion_loss=1.0001716613769531\n",
      "\n",
      "01_20_01:23:04 Seen so far: 272352 samples\n",
      "\n",
      "01_20_01:23:04 --- 1.7210745811462402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:06 Training loss at epoch 3 step 8520: 3.0506919860839843\n",
      "\n",
      " This round's valence_loss=0.8661385774612427, arousal_loss=0.6936193108558655, emotion_loss=0.9685064554214478\n",
      "\n",
      "01_20_01:23:06 Seen so far: 272672 samples\n",
      "\n",
      "01_20_01:23:06 --- 1.7006738185882568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:07 Training loss at epoch 3 step 8530: 2.8458993315696715\n",
      "\n",
      " This round's valence_loss=1.3120067119598389, arousal_loss=1.193597435951233, emotion_loss=0.8599775433540344\n",
      "\n",
      "01_20_01:23:07 Seen so far: 272992 samples\n",
      "\n",
      "01_20_01:23:07 --- 1.7217166423797607 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:09 Training loss at epoch 3 step 8540: 2.967536997795105\n",
      "\n",
      " This round's valence_loss=0.9534251689910889, arousal_loss=0.8339856863021851, emotion_loss=0.9262359738349915\n",
      "\n",
      "01_20_01:23:09 Seen so far: 273312 samples\n",
      "\n",
      "01_20_01:23:09 --- 1.8393259048461914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:11 Training loss at epoch 3 step 8550: 2.905820894241333\n",
      "\n",
      " This round's valence_loss=1.3458200693130493, arousal_loss=1.2008991241455078, emotion_loss=0.8518626689910889\n",
      "\n",
      "01_20_01:23:11 Seen so far: 273632 samples\n",
      "\n",
      "01_20_01:23:11 --- 1.7524032592773438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:13 Training loss at epoch 3 step 8560: 3.120195913314819\n",
      "\n",
      " This round's valence_loss=1.2973945140838623, arousal_loss=1.1814870834350586, emotion_loss=0.4641863703727722\n",
      "\n",
      "01_20_01:23:13 Seen so far: 273952 samples\n",
      "\n",
      "01_20_01:23:13 --- 1.7503077983856201 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:15 Training loss at epoch 3 step 8570: 2.7419150829315186\n",
      "\n",
      " This round's valence_loss=0.8969415426254272, arousal_loss=0.7333678007125854, emotion_loss=0.6384224891662598\n",
      "\n",
      "01_20_01:23:15 Seen so far: 274272 samples\n",
      "\n",
      "01_20_01:23:15 --- 1.7838289737701416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:16 Training loss at epoch 3 step 8580: 3.038578987121582\n",
      "\n",
      " This round's valence_loss=0.862151563167572, arousal_loss=0.7450975179672241, emotion_loss=1.355696439743042\n",
      "\n",
      "01_20_01:23:16 Seen so far: 274592 samples\n",
      "\n",
      "01_20_01:23:16 --- 1.6743295192718506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:18 Training loss at epoch 3 step 8590: 2.6152918934822083\n",
      "\n",
      " This round's valence_loss=1.4226421117782593, arousal_loss=1.327641487121582, emotion_loss=0.7539817094802856\n",
      "\n",
      "01_20_01:23:18 Seen so far: 274912 samples\n",
      "\n",
      "01_20_01:23:18 --- 1.6234986782073975 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:20 Training loss at epoch 3 step 8600: 2.971624255180359\n",
      "\n",
      " This round's valence_loss=0.8994699716567993, arousal_loss=0.7484009861946106, emotion_loss=0.9304261207580566\n",
      "\n",
      "01_20_01:23:20 Seen so far: 275232 samples\n",
      "\n",
      "01_20_01:23:20 --- 1.8207426071166992 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:21 Training loss at epoch 3 step 8610: 2.9941171050071715\n",
      "\n",
      " This round's valence_loss=0.8957829475402832, arousal_loss=0.6890525817871094, emotion_loss=0.5920178890228271\n",
      "\n",
      "01_20_01:23:21 Seen so far: 275552 samples\n",
      "\n",
      "01_20_01:23:21 --- 1.728651523590088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:23 Training loss at epoch 3 step 8620: 3.1086487889289858\n",
      "\n",
      " This round's valence_loss=0.9372107982635498, arousal_loss=0.8920648097991943, emotion_loss=0.8138995170593262\n",
      "\n",
      "01_20_01:23:23 Seen so far: 275872 samples\n",
      "\n",
      "01_20_01:23:23 --- 1.8935644626617432 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:25 Training loss at epoch 3 step 8630: 3.008274269104004\n",
      "\n",
      " This round's valence_loss=1.581159234046936, arousal_loss=1.5251588821411133, emotion_loss=1.0702357292175293\n",
      "\n",
      "01_20_01:23:25 Seen so far: 276192 samples\n",
      "\n",
      "01_20_01:23:25 --- 1.6596169471740723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:27 Training loss at epoch 3 step 8640: 2.904510426521301\n",
      "\n",
      " This round's valence_loss=0.9616515636444092, arousal_loss=0.8748652935028076, emotion_loss=0.9088606238365173\n",
      "\n",
      "01_20_01:23:27 Seen so far: 276512 samples\n",
      "\n",
      "01_20_01:23:27 --- 1.8956506252288818 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:29 Training loss at epoch 3 step 8650: 2.682859253883362\n",
      "\n",
      " This round's valence_loss=0.6157615780830383, arousal_loss=0.4771254062652588, emotion_loss=0.8157286643981934\n",
      "\n",
      "01_20_01:23:29 Seen so far: 276832 samples\n",
      "\n",
      "01_20_01:23:29 --- 1.9973130226135254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:31 Training loss at epoch 3 step 8660: 2.9864042520523073\n",
      "\n",
      " This round's valence_loss=1.122862458229065, arousal_loss=0.9473967552185059, emotion_loss=1.294037938117981\n",
      "\n",
      "01_20_01:23:31 Seen so far: 277152 samples\n",
      "\n",
      "01_20_01:23:31 --- 1.7992515563964844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:33 Training loss at epoch 3 step 8670: 2.8069887161254883\n",
      "\n",
      " This round's valence_loss=0.7445172667503357, arousal_loss=0.6206380724906921, emotion_loss=0.9554765224456787\n",
      "\n",
      "01_20_01:23:33 Seen so far: 277472 samples\n",
      "\n",
      "01_20_01:23:33 --- 1.8361856937408447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:35 Training loss at epoch 3 step 8680: 2.822661828994751\n",
      "\n",
      " This round's valence_loss=1.0701950788497925, arousal_loss=1.0083478689193726, emotion_loss=0.9911754131317139\n",
      "\n",
      "01_20_01:23:35 Seen so far: 277792 samples\n",
      "\n",
      "01_20_01:23:35 --- 2.0720160007476807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:36 Training loss at epoch 3 step 8690: 2.724032473564148\n",
      "\n",
      " This round's valence_loss=0.9167212247848511, arousal_loss=0.7335503101348877, emotion_loss=0.8593943119049072\n",
      "\n",
      "01_20_01:23:36 Seen so far: 278112 samples\n",
      "\n",
      "01_20_01:23:36 --- 1.6870887279510498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:38 Training loss at epoch 3 step 8700: 3.140133595466614\n",
      "\n",
      " This round's valence_loss=1.3078136444091797, arousal_loss=1.2068499326705933, emotion_loss=1.1874372959136963\n",
      "\n",
      "01_20_01:23:38 Seen so far: 278432 samples\n",
      "\n",
      "01_20_01:23:38 --- 1.7212371826171875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:40 Training loss at epoch 3 step 8710: 3.1082701683044434\n",
      "\n",
      " This round's valence_loss=1.097091794013977, arousal_loss=1.0439836978912354, emotion_loss=0.8376061320304871\n",
      "\n",
      "01_20_01:23:40 Seen so far: 278752 samples\n",
      "\n",
      "01_20_01:23:40 --- 1.7041881084442139 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:42 Training loss at epoch 3 step 8720: 2.8845279097557066\n",
      "\n",
      " This round's valence_loss=1.7409814596176147, arousal_loss=1.5397909879684448, emotion_loss=1.3805551528930664\n",
      "\n",
      "01_20_01:23:42 Seen so far: 279072 samples\n",
      "\n",
      "01_20_01:23:42 --- 1.8582861423492432 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:43 Training loss at epoch 3 step 8730: 2.8396138191223144\n",
      "\n",
      " This round's valence_loss=0.9559799432754517, arousal_loss=0.715635359287262, emotion_loss=0.662738025188446\n",
      "\n",
      "01_20_01:23:43 Seen so far: 279392 samples\n",
      "\n",
      "01_20_01:23:43 --- 1.8102786540985107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:45 Training loss at epoch 3 step 8740: 3.0689517498016357\n",
      "\n",
      " This round's valence_loss=1.070176124572754, arousal_loss=1.002441644668579, emotion_loss=0.9406746625900269\n",
      "\n",
      "01_20_01:23:45 Seen so far: 279712 samples\n",
      "\n",
      "01_20_01:23:45 --- 1.7193946838378906 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:47 Training loss at epoch 3 step 8750: 3.02425103187561\n",
      "\n",
      " This round's valence_loss=0.9520534873008728, arousal_loss=0.8418768644332886, emotion_loss=1.0195167064666748\n",
      "\n",
      "01_20_01:23:47 Seen so far: 280032 samples\n",
      "\n",
      "01_20_01:23:47 --- 1.9370975494384766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:49 Training loss at epoch 3 step 8760: 2.849899423122406\n",
      "\n",
      " This round's valence_loss=1.1408140659332275, arousal_loss=1.1004705429077148, emotion_loss=0.8971675634384155\n",
      "\n",
      "01_20_01:23:49 Seen so far: 280352 samples\n",
      "\n",
      "01_20_01:23:49 --- 1.7369797229766846 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:50 Training loss at epoch 3 step 8770: 3.1305582761764525\n",
      "\n",
      " This round's valence_loss=0.8150310516357422, arousal_loss=0.8208296298980713, emotion_loss=0.9112942814826965\n",
      "\n",
      "01_20_01:23:50 Seen so far: 280672 samples\n",
      "\n",
      "01_20_01:23:50 --- 1.7049500942230225 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:52 Training loss at epoch 3 step 8780: 2.7658582448959352\n",
      "\n",
      " This round's valence_loss=0.846077561378479, arousal_loss=0.7046449184417725, emotion_loss=1.221808910369873\n",
      "\n",
      "01_20_01:23:52 Seen so far: 280992 samples\n",
      "\n",
      "01_20_01:23:52 --- 1.6121783256530762 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:54 Training loss at epoch 3 step 8790: 2.9874711990356446\n",
      "\n",
      " This round's valence_loss=1.3255935907363892, arousal_loss=1.2284932136535645, emotion_loss=0.9359193444252014\n",
      "\n",
      "01_20_01:23:54 Seen so far: 281312 samples\n",
      "\n",
      "01_20_01:23:54 --- 1.620521068572998 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:55 Training loss at epoch 3 step 8800: 3.0712136030197144\n",
      "\n",
      " This round's valence_loss=1.0871713161468506, arousal_loss=1.0162851810455322, emotion_loss=0.7204179763793945\n",
      "\n",
      "01_20_01:23:55 Seen so far: 281632 samples\n",
      "\n",
      "01_20_01:23:55 --- 1.6773040294647217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:57 Training loss at epoch 3 step 8810: 2.8153056383132933\n",
      "\n",
      " This round's valence_loss=1.3359242677688599, arousal_loss=1.2054182291030884, emotion_loss=0.6769127249717712\n",
      "\n",
      "01_20_01:23:57 Seen so far: 281952 samples\n",
      "\n",
      "01_20_01:23:57 --- 1.6167736053466797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:23:59 Training loss at epoch 3 step 8820: 2.976720762252808\n",
      "\n",
      " This round's valence_loss=0.9520324468612671, arousal_loss=0.8074977397918701, emotion_loss=0.8940799236297607\n",
      "\n",
      "01_20_01:23:59 Seen so far: 282272 samples\n",
      "\n",
      "01_20_01:23:59 --- 1.686467170715332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:01 Training loss at epoch 3 step 8830: 2.9835888862609865\n",
      "\n",
      " This round's valence_loss=0.8775503039360046, arousal_loss=0.7534563541412354, emotion_loss=1.3591954708099365\n",
      "\n",
      "01_20_01:24:01 Seen so far: 282592 samples\n",
      "\n",
      "01_20_01:24:01 --- 1.9051275253295898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:02 Training loss at epoch 3 step 8840: 2.887475109100342\n",
      "\n",
      " This round's valence_loss=0.8953883051872253, arousal_loss=0.6903681755065918, emotion_loss=0.840185284614563\n",
      "\n",
      "01_20_01:24:02 Seen so far: 282912 samples\n",
      "\n",
      "01_20_01:24:02 --- 1.8685815334320068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:04 Training loss at epoch 3 step 8850: 3.064677584171295\n",
      "\n",
      " This round's valence_loss=1.669283390045166, arousal_loss=1.5870258808135986, emotion_loss=0.5319014191627502\n",
      "\n",
      "01_20_01:24:04 Seen so far: 283232 samples\n",
      "\n",
      "01_20_01:24:04 --- 1.9012870788574219 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:06 Training loss at epoch 3 step 8860: 3.047222948074341\n",
      "\n",
      " This round's valence_loss=0.9934896230697632, arousal_loss=0.8727107048034668, emotion_loss=0.8569781184196472\n",
      "\n",
      "01_20_01:24:06 Seen so far: 283552 samples\n",
      "\n",
      "01_20_01:24:06 --- 1.7366220951080322 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:08 Training loss at epoch 3 step 8870: 3.0416460990905763\n",
      "\n",
      " This round's valence_loss=1.1441006660461426, arousal_loss=0.9829584956169128, emotion_loss=0.8613227605819702\n",
      "\n",
      "01_20_01:24:08 Seen so far: 283872 samples\n",
      "\n",
      "01_20_01:24:08 --- 1.828120231628418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:10 Training loss at epoch 3 step 8880: 2.6910741329193115\n",
      "\n",
      " This round's valence_loss=0.7967276573181152, arousal_loss=0.7223944067955017, emotion_loss=0.7738472819328308\n",
      "\n",
      "01_20_01:24:10 Seen so far: 284192 samples\n",
      "\n",
      "01_20_01:24:10 --- 1.9118616580963135 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:12 Training loss at epoch 3 step 8890: 3.008993649482727\n",
      "\n",
      " This round's valence_loss=1.3413505554199219, arousal_loss=1.1871006488800049, emotion_loss=0.84883713722229\n",
      "\n",
      "01_20_01:24:12 Seen so far: 284512 samples\n",
      "\n",
      "01_20_01:24:12 --- 1.868473768234253 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:13 Training loss at epoch 3 step 8900: 2.8756677389144896\n",
      "\n",
      " This round's valence_loss=1.0782358646392822, arousal_loss=0.9854567050933838, emotion_loss=0.7132975459098816\n",
      "\n",
      "01_20_01:24:13 Seen so far: 284832 samples\n",
      "\n",
      "01_20_01:24:13 --- 1.7513542175292969 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:15 Training loss at epoch 3 step 8910: 2.9433308601379395\n",
      "\n",
      " This round's valence_loss=0.9243451356887817, arousal_loss=0.8152997493743896, emotion_loss=1.2111419439315796\n",
      "\n",
      "01_20_01:24:15 Seen so far: 285152 samples\n",
      "\n",
      "01_20_01:24:15 --- 1.676941156387329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:17 Training loss at epoch 3 step 8920: 3.104750943183899\n",
      "\n",
      " This round's valence_loss=1.1064198017120361, arousal_loss=0.8298493027687073, emotion_loss=0.6473671793937683\n",
      "\n",
      "01_20_01:24:17 Seen so far: 285472 samples\n",
      "\n",
      "01_20_01:24:17 --- 1.7987756729125977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:19 Training loss at epoch 3 step 8930: 2.991645574569702\n",
      "\n",
      " This round's valence_loss=1.0003435611724854, arousal_loss=0.8190421462059021, emotion_loss=1.0345594882965088\n",
      "\n",
      "01_20_01:24:19 Seen so far: 285792 samples\n",
      "\n",
      "01_20_01:24:19 --- 1.696979284286499 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:20 Training loss at epoch 3 step 8940: 2.9870365858078003\n",
      "\n",
      " This round's valence_loss=0.7706105709075928, arousal_loss=0.5923001170158386, emotion_loss=1.1527884006500244\n",
      "\n",
      "01_20_01:24:20 Seen so far: 286112 samples\n",
      "\n",
      "01_20_01:24:20 --- 1.6331617832183838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:22 Training loss at epoch 3 step 8950: 3.1647253036499023\n",
      "\n",
      " This round's valence_loss=1.2960171699523926, arousal_loss=1.261393427848816, emotion_loss=1.2742912769317627\n",
      "\n",
      "01_20_01:24:22 Seen so far: 286432 samples\n",
      "\n",
      "01_20_01:24:22 --- 1.6403017044067383 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:24 Training loss at epoch 3 step 8960: 2.829448938369751\n",
      "\n",
      " This round's valence_loss=1.1424779891967773, arousal_loss=1.0305860042572021, emotion_loss=0.9048724174499512\n",
      "\n",
      "01_20_01:24:24 Seen so far: 286752 samples\n",
      "\n",
      "01_20_01:24:24 --- 1.7454991340637207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:25 Training loss at epoch 3 step 8970: 2.9821183919906615\n",
      "\n",
      " This round's valence_loss=0.6107548475265503, arousal_loss=0.4591418504714966, emotion_loss=0.8609445095062256\n",
      "\n",
      "01_20_01:24:25 Seen so far: 287072 samples\n",
      "\n",
      "01_20_01:24:25 --- 1.7898917198181152 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:27 Training loss at epoch 3 step 8980: 3.102009320259094\n",
      "\n",
      " This round's valence_loss=1.1875526905059814, arousal_loss=1.0552504062652588, emotion_loss=0.9767799377441406\n",
      "\n",
      "01_20_01:24:27 Seen so far: 287392 samples\n",
      "\n",
      "01_20_01:24:27 --- 1.5989134311676025 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:29 Training loss at epoch 3 step 8990: 3.29503173828125\n",
      "\n",
      " This round's valence_loss=1.464308500289917, arousal_loss=1.3256006240844727, emotion_loss=0.9831440448760986\n",
      "\n",
      "01_20_01:24:29 Seen so far: 287712 samples\n",
      "\n",
      "01_20_01:24:29 --- 1.768486499786377 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:31 Training loss at epoch 3 step 9000: 3.2030664682388306\n",
      "\n",
      " This round's valence_loss=0.9653123021125793, arousal_loss=0.8503928184509277, emotion_loss=0.9044340252876282\n",
      "\n",
      "01_20_01:24:31 Seen so far: 288032 samples\n",
      "\n",
      "01_20_01:24:31 --- 1.7514774799346924 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:32 Training loss at epoch 3 step 9010: 3.038128399848938\n",
      "\n",
      " This round's valence_loss=1.056382179260254, arousal_loss=0.8246210813522339, emotion_loss=0.8203109502792358\n",
      "\n",
      "01_20_01:24:32 Seen so far: 288352 samples\n",
      "\n",
      "01_20_01:24:32 --- 1.7426419258117676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:34 Training loss at epoch 3 step 9020: 2.9811078548431396\n",
      "\n",
      " This round's valence_loss=1.4297709465026855, arousal_loss=1.3317196369171143, emotion_loss=1.0505905151367188\n",
      "\n",
      "01_20_01:24:34 Seen so far: 288672 samples\n",
      "\n",
      "01_20_01:24:34 --- 1.7828319072723389 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:36 Training loss at epoch 3 step 9030: 2.7119657039642333\n",
      "\n",
      " This round's valence_loss=1.0126231908798218, arousal_loss=0.8044066429138184, emotion_loss=0.7745698690414429\n",
      "\n",
      "01_20_01:24:36 Seen so far: 288992 samples\n",
      "\n",
      "01_20_01:24:36 --- 1.6294491291046143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:37 Training loss at epoch 3 step 9040: 2.885630524158478\n",
      "\n",
      " This round's valence_loss=1.306424617767334, arousal_loss=1.2056500911712646, emotion_loss=1.178560495376587\n",
      "\n",
      "01_20_01:24:37 Seen so far: 289312 samples\n",
      "\n",
      "01_20_01:24:37 --- 1.6769447326660156 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:39 Training loss at epoch 3 step 9050: 2.866169309616089\n",
      "\n",
      " This round's valence_loss=1.090376615524292, arousal_loss=1.0107934474945068, emotion_loss=0.7451247572898865\n",
      "\n",
      "01_20_01:24:39 Seen so far: 289632 samples\n",
      "\n",
      "01_20_01:24:39 --- 1.8836424350738525 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:41 Training loss at epoch 3 step 9060: 3.055237317085266\n",
      "\n",
      " This round's valence_loss=0.9617416262626648, arousal_loss=0.8461908102035522, emotion_loss=1.6523892879486084\n",
      "\n",
      "01_20_01:24:41 Seen so far: 289952 samples\n",
      "\n",
      "01_20_01:24:41 --- 2.041609287261963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:43 Training loss at epoch 3 step 9070: 2.803819751739502\n",
      "\n",
      " This round's valence_loss=0.738193154335022, arousal_loss=0.5955222249031067, emotion_loss=1.054784893989563\n",
      "\n",
      "01_20_01:24:43 Seen so far: 290272 samples\n",
      "\n",
      "01_20_01:24:43 --- 1.7984163761138916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:45 Training loss at epoch 3 step 9080: 3.0835204839706423\n",
      "\n",
      " This round's valence_loss=0.9607542753219604, arousal_loss=0.8484318256378174, emotion_loss=1.176967740058899\n",
      "\n",
      "01_20_01:24:45 Seen so far: 290592 samples\n",
      "\n",
      "01_20_01:24:45 --- 1.8767666816711426 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:47 Training loss at epoch 3 step 9090: 3.0528043270111085\n",
      "\n",
      " This round's valence_loss=1.0951428413391113, arousal_loss=0.9384716749191284, emotion_loss=0.6965476274490356\n",
      "\n",
      "01_20_01:24:47 Seen so far: 290912 samples\n",
      "\n",
      "01_20_01:24:47 --- 1.7304472923278809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:49 Training loss at epoch 3 step 9100: 3.1067517757415772\n",
      "\n",
      " This round's valence_loss=1.2656452655792236, arousal_loss=1.062175989151001, emotion_loss=1.1216944456100464\n",
      "\n",
      "01_20_01:24:49 Seen so far: 291232 samples\n",
      "\n",
      "01_20_01:24:49 --- 1.8543028831481934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:51 Training loss at epoch 3 step 9110: 2.8777720808982847\n",
      "\n",
      " This round's valence_loss=1.1374763250350952, arousal_loss=0.9718109965324402, emotion_loss=0.8894358277320862\n",
      "\n",
      "01_20_01:24:51 Seen so far: 291552 samples\n",
      "\n",
      "01_20_01:24:51 --- 1.9424419403076172 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:52 Training loss at epoch 3 step 9120: 3.0396323919296266\n",
      "\n",
      " This round's valence_loss=0.9701366424560547, arousal_loss=0.8501571416854858, emotion_loss=0.6591857671737671\n",
      "\n",
      "01_20_01:24:52 Seen so far: 291872 samples\n",
      "\n",
      "01_20_01:24:52 --- 1.6998586654663086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:54 Training loss at epoch 3 step 9130: 3.02953155040741\n",
      "\n",
      " This round's valence_loss=1.0067522525787354, arousal_loss=0.8558893203735352, emotion_loss=0.5432345867156982\n",
      "\n",
      "01_20_01:24:54 Seen so far: 292192 samples\n",
      "\n",
      "01_20_01:24:54 --- 1.8950791358947754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:56 Training loss at epoch 3 step 9140: 2.9856486082077027\n",
      "\n",
      " This round's valence_loss=0.7950229644775391, arousal_loss=0.7227253913879395, emotion_loss=0.8972877860069275\n",
      "\n",
      "01_20_01:24:56 Seen so far: 292512 samples\n",
      "\n",
      "01_20_01:24:56 --- 1.884462833404541 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:24:58 Training loss at epoch 3 step 9150: 3.1804646253585815\n",
      "\n",
      " This round's valence_loss=0.8055319786071777, arousal_loss=0.6060583591461182, emotion_loss=1.171306848526001\n",
      "\n",
      "01_20_01:24:58 Seen so far: 292832 samples\n",
      "\n",
      "01_20_01:24:58 --- 1.7608821392059326 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:00 Training loss at epoch 3 step 9160: 3.2008278608322143\n",
      "\n",
      " This round's valence_loss=1.4280871152877808, arousal_loss=1.3532044887542725, emotion_loss=1.2427825927734375\n",
      "\n",
      "01_20_01:25:00 Seen so far: 293152 samples\n",
      "\n",
      "01_20_01:25:00 --- 1.8227624893188477 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:01 Training loss at epoch 3 step 9170: 3.4808390855789186\n",
      "\n",
      " This round's valence_loss=1.1798095703125, arousal_loss=1.1220604181289673, emotion_loss=0.8743127584457397\n",
      "\n",
      "01_20_01:25:01 Seen so far: 293472 samples\n",
      "\n",
      "01_20_01:25:01 --- 1.762129545211792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:03 Training loss at epoch 3 step 9180: 2.782644581794739\n",
      "\n",
      " This round's valence_loss=0.9334576725959778, arousal_loss=0.8429014086723328, emotion_loss=0.7076510787010193\n",
      "\n",
      "01_20_01:25:03 Seen so far: 293792 samples\n",
      "\n",
      "01_20_01:25:03 --- 1.741534948348999 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:05 Training loss at epoch 3 step 9190: 2.8468186378479006\n",
      "\n",
      " This round's valence_loss=0.9296934604644775, arousal_loss=0.6774351596832275, emotion_loss=0.8559991121292114\n",
      "\n",
      "01_20_01:25:05 Seen so far: 294112 samples\n",
      "\n",
      "01_20_01:25:05 --- 1.6368024349212646 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:06 Training loss at epoch 3 step 9200: 3.1788093566894533\n",
      "\n",
      " This round's valence_loss=0.9213632941246033, arousal_loss=0.8274457454681396, emotion_loss=0.9609189033508301\n",
      "\n",
      "01_20_01:25:06 Seen so far: 294432 samples\n",
      "\n",
      "01_20_01:25:06 --- 1.7354748249053955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:08 Training loss at epoch 3 step 9210: 2.759085953235626\n",
      "\n",
      " This round's valence_loss=1.5640194416046143, arousal_loss=1.436372995376587, emotion_loss=0.7710304856300354\n",
      "\n",
      "01_20_01:25:08 Seen so far: 294752 samples\n",
      "\n",
      "01_20_01:25:08 --- 1.7200186252593994 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:10 Training loss at epoch 3 step 9220: 2.941976451873779\n",
      "\n",
      " This round's valence_loss=1.117996096611023, arousal_loss=0.9888878464698792, emotion_loss=0.9689958095550537\n",
      "\n",
      "01_20_01:25:10 Seen so far: 295072 samples\n",
      "\n",
      "01_20_01:25:10 --- 1.7218773365020752 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:12 Training loss at epoch 3 step 9230: 2.8372385025024416\n",
      "\n",
      " This round's valence_loss=0.885265052318573, arousal_loss=0.7721281051635742, emotion_loss=1.004425287246704\n",
      "\n",
      "01_20_01:25:12 Seen so far: 295392 samples\n",
      "\n",
      "01_20_01:25:12 --- 1.8604331016540527 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:13 Training loss at epoch 3 step 9240: 2.669249141216278\n",
      "\n",
      " This round's valence_loss=1.0675427913665771, arousal_loss=0.9665805101394653, emotion_loss=0.5790387392044067\n",
      "\n",
      "01_20_01:25:13 Seen so far: 295712 samples\n",
      "\n",
      "01_20_01:25:13 --- 1.6439757347106934 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:15 Training loss at epoch 3 step 9250: 3.0239172697067263\n",
      "\n",
      " This round's valence_loss=1.4784266948699951, arousal_loss=1.2841869592666626, emotion_loss=0.6243001222610474\n",
      "\n",
      "01_20_01:25:15 Seen so far: 296032 samples\n",
      "\n",
      "01_20_01:25:15 --- 1.878913402557373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:17 Training loss at epoch 3 step 9260: 2.5155824422836304\n",
      "\n",
      " This round's valence_loss=1.090987205505371, arousal_loss=0.9786494970321655, emotion_loss=0.6842772960662842\n",
      "\n",
      "01_20_01:25:17 Seen so far: 296352 samples\n",
      "\n",
      "01_20_01:25:17 --- 1.7785403728485107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:19 Training loss at epoch 3 step 9270: 3.084138822555542\n",
      "\n",
      " This round's valence_loss=0.9446162581443787, arousal_loss=0.8295037150382996, emotion_loss=0.8752803206443787\n",
      "\n",
      "01_20_01:25:19 Seen so far: 296672 samples\n",
      "\n",
      "01_20_01:25:19 --- 1.6789131164550781 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:20 Training loss at epoch 3 step 9280: 3.1392415523529054\n",
      "\n",
      " This round's valence_loss=1.1221182346343994, arousal_loss=0.934184193611145, emotion_loss=0.6469086408615112\n",
      "\n",
      "01_20_01:25:20 Seen so far: 296992 samples\n",
      "\n",
      "01_20_01:25:20 --- 1.7522079944610596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:22 Training loss at epoch 3 step 9290: 2.7761356830596924\n",
      "\n",
      " This round's valence_loss=1.2065937519073486, arousal_loss=1.1120280027389526, emotion_loss=0.8416723012924194\n",
      "\n",
      "01_20_01:25:22 Seen so far: 297312 samples\n",
      "\n",
      "01_20_01:25:22 --- 1.8601298332214355 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:24 Training loss at epoch 3 step 9300: 3.090559387207031\n",
      "\n",
      " This round's valence_loss=1.0411087274551392, arousal_loss=0.9772834777832031, emotion_loss=0.9745234251022339\n",
      "\n",
      "01_20_01:25:24 Seen so far: 297632 samples\n",
      "\n",
      "01_20_01:25:24 --- 1.756652593612671 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:26 Training loss at epoch 3 step 9310: 3.0648675203323363\n",
      "\n",
      " This round's valence_loss=0.9887949228286743, arousal_loss=0.823951005935669, emotion_loss=0.8947969675064087\n",
      "\n",
      "01_20_01:25:26 Seen so far: 297952 samples\n",
      "\n",
      "01_20_01:25:26 --- 1.75126051902771 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:28 Training loss at epoch 3 step 9320: 2.8320753931999207\n",
      "\n",
      " This round's valence_loss=1.133340835571289, arousal_loss=0.9766873717308044, emotion_loss=0.9671784043312073\n",
      "\n",
      "01_20_01:25:28 Seen so far: 298272 samples\n",
      "\n",
      "01_20_01:25:28 --- 1.7410516738891602 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:29 Training loss at epoch 3 step 9330: 3.0192473888397218\n",
      "\n",
      " This round's valence_loss=1.2261162996292114, arousal_loss=1.0674867630004883, emotion_loss=0.6412562131881714\n",
      "\n",
      "01_20_01:25:29 Seen so far: 298592 samples\n",
      "\n",
      "01_20_01:25:29 --- 1.5770959854125977 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:31 Training loss at epoch 3 step 9340: 3.240974760055542\n",
      "\n",
      " This round's valence_loss=1.409651756286621, arousal_loss=1.3572039604187012, emotion_loss=1.0496323108673096\n",
      "\n",
      "01_20_01:25:31 Seen so far: 298912 samples\n",
      "\n",
      "01_20_01:25:31 --- 1.827629804611206 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:33 Training loss at epoch 3 step 9350: 3.0252123355865477\n",
      "\n",
      " This round's valence_loss=1.202101707458496, arousal_loss=1.0942808389663696, emotion_loss=0.81855309009552\n",
      "\n",
      "01_20_01:25:33 Seen so far: 299232 samples\n",
      "\n",
      "01_20_01:25:33 --- 1.7896029949188232 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:35 Training loss at epoch 3 step 9360: 3.0186460256576537\n",
      "\n",
      " This round's valence_loss=1.562330722808838, arousal_loss=1.4259834289550781, emotion_loss=0.8689247369766235\n",
      "\n",
      "01_20_01:25:35 Seen so far: 299552 samples\n",
      "\n",
      "01_20_01:25:35 --- 1.7758021354675293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:36 Training loss at epoch 3 step 9370: 2.706447720527649\n",
      "\n",
      " This round's valence_loss=1.1017844676971436, arousal_loss=0.962584376335144, emotion_loss=0.6200901865959167\n",
      "\n",
      "01_20_01:25:36 Seen so far: 299872 samples\n",
      "\n",
      "01_20_01:25:36 --- 1.7233860492706299 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:38 Training loss at epoch 3 step 9380: 2.6833447933197023\n",
      "\n",
      " This round's valence_loss=1.0841368436813354, arousal_loss=0.9984143972396851, emotion_loss=0.9972995519638062\n",
      "\n",
      "01_20_01:25:38 Seen so far: 300192 samples\n",
      "\n",
      "01_20_01:25:38 --- 2.01969051361084 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:40 Training loss at epoch 3 step 9390: 2.9432262420654296\n",
      "\n",
      " This round's valence_loss=0.5545274019241333, arousal_loss=0.338641881942749, emotion_loss=0.8831040859222412\n",
      "\n",
      "01_20_01:25:40 Seen so far: 300512 samples\n",
      "\n",
      "01_20_01:25:40 --- 1.6403076648712158 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:42 Training loss at epoch 3 step 9400: 2.862521505355835\n",
      "\n",
      " This round's valence_loss=0.8039489388465881, arousal_loss=0.5868657827377319, emotion_loss=0.7844492197036743\n",
      "\n",
      "01_20_01:25:42 Seen so far: 300832 samples\n",
      "\n",
      "01_20_01:25:42 --- 1.7695550918579102 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:43 Training loss at epoch 3 step 9410: 3.050172138214111\n",
      "\n",
      " This round's valence_loss=1.160032033920288, arousal_loss=1.1047931909561157, emotion_loss=1.010972023010254\n",
      "\n",
      "01_20_01:25:43 Seen so far: 301152 samples\n",
      "\n",
      "01_20_01:25:43 --- 1.7073211669921875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:45 Training loss at epoch 3 step 9420: 2.766357445716858\n",
      "\n",
      " This round's valence_loss=0.8999003171920776, arousal_loss=0.7100527286529541, emotion_loss=1.1760554313659668\n",
      "\n",
      "01_20_01:25:45 Seen so far: 301472 samples\n",
      "\n",
      "01_20_01:25:45 --- 1.8257887363433838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:47 Training loss at epoch 3 step 9430: 2.4928571939468385\n",
      "\n",
      " This round's valence_loss=0.8290518522262573, arousal_loss=0.7198536396026611, emotion_loss=1.0938396453857422\n",
      "\n",
      "01_20_01:25:47 Seen so far: 301792 samples\n",
      "\n",
      "01_20_01:25:47 --- 1.6306846141815186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:49 Training loss at epoch 3 step 9440: 3.3431417465209963\n",
      "\n",
      " This round's valence_loss=1.5808440446853638, arousal_loss=1.437873363494873, emotion_loss=1.1746020317077637\n",
      "\n",
      "01_20_01:25:49 Seen so far: 302112 samples\n",
      "\n",
      "01_20_01:25:49 --- 1.7048561573028564 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:50 Training loss at epoch 3 step 9450: 2.618079054355621\n",
      "\n",
      " This round's valence_loss=1.0090105533599854, arousal_loss=0.8664803504943848, emotion_loss=0.7841398119926453\n",
      "\n",
      "01_20_01:25:50 Seen so far: 302432 samples\n",
      "\n",
      "01_20_01:25:50 --- 1.669687032699585 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:52 Training loss at epoch 3 step 9460: 3.0502305030822754\n",
      "\n",
      " This round's valence_loss=0.9151368141174316, arousal_loss=0.6937360763549805, emotion_loss=0.9245024919509888\n",
      "\n",
      "01_20_01:25:52 Seen so far: 302752 samples\n",
      "\n",
      "01_20_01:25:52 --- 1.6763956546783447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:54 Training loss at epoch 3 step 9470: 2.855514705181122\n",
      "\n",
      " This round's valence_loss=1.5836677551269531, arousal_loss=1.4361083507537842, emotion_loss=0.7934228181838989\n",
      "\n",
      "01_20_01:25:54 Seen so far: 303072 samples\n",
      "\n",
      "01_20_01:25:54 --- 1.716137170791626 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:55 Training loss at epoch 3 step 9480: 2.8308727502822877\n",
      "\n",
      " This round's valence_loss=0.8264999389648438, arousal_loss=0.7387921810150146, emotion_loss=0.8701804876327515\n",
      "\n",
      "01_20_01:25:55 Seen so far: 303392 samples\n",
      "\n",
      "01_20_01:25:55 --- 1.7224147319793701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:57 Training loss at epoch 3 step 9490: 3.057817983627319\n",
      "\n",
      " This round's valence_loss=0.8280808925628662, arousal_loss=0.6999992728233337, emotion_loss=0.8140631914138794\n",
      "\n",
      "01_20_01:25:57 Seen so far: 303712 samples\n",
      "\n",
      "01_20_01:25:57 --- 1.8425371646881104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:25:59 Training loss at epoch 3 step 9500: 2.9694403409957886\n",
      "\n",
      " This round's valence_loss=1.4622611999511719, arousal_loss=1.3730483055114746, emotion_loss=0.899693489074707\n",
      "\n",
      "01_20_01:25:59 Seen so far: 304032 samples\n",
      "\n",
      "01_20_01:25:59 --- 1.7798511981964111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:01 Training loss at epoch 3 step 9510: 3.1153330564498902\n",
      "\n",
      " This round's valence_loss=1.1501237154006958, arousal_loss=1.0892488956451416, emotion_loss=0.8420976996421814\n",
      "\n",
      "01_20_01:26:01 Seen so far: 304352 samples\n",
      "\n",
      "01_20_01:26:01 --- 1.6371550559997559 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:02 Training loss at epoch 3 step 9520: 2.955791735649109\n",
      "\n",
      " This round's valence_loss=1.2619764804840088, arousal_loss=1.0520977973937988, emotion_loss=0.6296699047088623\n",
      "\n",
      "01_20_01:26:02 Seen so far: 304672 samples\n",
      "\n",
      "01_20_01:26:02 --- 1.7230358123779297 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:04 Training loss at epoch 3 step 9530: 3.198012351989746\n",
      "\n",
      " This round's valence_loss=1.1173174381256104, arousal_loss=0.9483197927474976, emotion_loss=1.008683204650879\n",
      "\n",
      "01_20_01:26:04 Seen so far: 304992 samples\n",
      "\n",
      "01_20_01:26:04 --- 1.5409085750579834 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:06 Training loss at epoch 3 step 9540: 3.0594135761260985\n",
      "\n",
      " This round's valence_loss=1.0776581764221191, arousal_loss=0.9517067074775696, emotion_loss=1.171568512916565\n",
      "\n",
      "01_20_01:26:06 Seen so far: 305312 samples\n",
      "\n",
      "01_20_01:26:06 --- 1.8084359169006348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:07 Training loss at epoch 3 step 9550: 2.69904944896698\n",
      "\n",
      " This round's valence_loss=1.218719720840454, arousal_loss=1.100287675857544, emotion_loss=1.1171218156814575\n",
      "\n",
      "01_20_01:26:07 Seen so far: 305632 samples\n",
      "\n",
      "01_20_01:26:07 --- 1.732579231262207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:09 Training loss at epoch 3 step 9560: 2.95508930683136\n",
      "\n",
      " This round's valence_loss=0.44804444909095764, arousal_loss=0.3337128460407257, emotion_loss=1.0105122327804565\n",
      "\n",
      "01_20_01:26:09 Seen so far: 305952 samples\n",
      "\n",
      "01_20_01:26:09 --- 1.7019972801208496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:11 Training loss at epoch 3 step 9570: 3.303446364402771\n",
      "\n",
      " This round's valence_loss=1.1455703973770142, arousal_loss=0.9407922029495239, emotion_loss=1.3114345073699951\n",
      "\n",
      "01_20_01:26:11 Seen so far: 306272 samples\n",
      "\n",
      "01_20_01:26:11 --- 1.859205722808838 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:13 Training loss at epoch 3 step 9580: 2.823284459114075\n",
      "\n",
      " This round's valence_loss=0.7386380434036255, arousal_loss=0.5513829588890076, emotion_loss=0.9204738140106201\n",
      "\n",
      "01_20_01:26:13 Seen so far: 306592 samples\n",
      "\n",
      "01_20_01:26:13 --- 1.8434810638427734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:15 Training loss at epoch 3 step 9590: 2.797029972076416\n",
      "\n",
      " This round's valence_loss=0.7708278894424438, arousal_loss=0.5705001354217529, emotion_loss=0.8775687217712402\n",
      "\n",
      "01_20_01:26:15 Seen so far: 306912 samples\n",
      "\n",
      "01_20_01:26:15 --- 2.088665246963501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:17 Training loss at epoch 3 step 9600: 2.8642396688461305\n",
      "\n",
      " This round's valence_loss=1.5509088039398193, arousal_loss=1.4512174129486084, emotion_loss=0.8351889848709106\n",
      "\n",
      "01_20_01:26:17 Seen so far: 307232 samples\n",
      "\n",
      "01_20_01:26:17 --- 1.6532745361328125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:18 Training loss at epoch 3 step 9610: 2.9216711282730103\n",
      "\n",
      " This round's valence_loss=1.2304208278656006, arousal_loss=1.1014232635498047, emotion_loss=0.8655887246131897\n",
      "\n",
      "01_20_01:26:18 Seen so far: 307552 samples\n",
      "\n",
      "01_20_01:26:18 --- 1.8562862873077393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:20 Training loss at epoch 3 step 9620: 3.0975794076919554\n",
      "\n",
      " This round's valence_loss=1.2122246026992798, arousal_loss=1.1616020202636719, emotion_loss=0.950563907623291\n",
      "\n",
      "01_20_01:26:20 Seen so far: 307872 samples\n",
      "\n",
      "01_20_01:26:20 --- 1.8345420360565186 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:22 Training loss at epoch 3 step 9630: 2.9117428779602053\n",
      "\n",
      " This round's valence_loss=1.6157382726669312, arousal_loss=1.436964511871338, emotion_loss=0.4562835097312927\n",
      "\n",
      "01_20_01:26:22 Seen so far: 308192 samples\n",
      "\n",
      "01_20_01:26:22 --- 2.076894998550415 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:24 Training loss at epoch 3 step 9640: 2.5778820395469664\n",
      "\n",
      " This round's valence_loss=0.7251689434051514, arousal_loss=0.6042811870574951, emotion_loss=1.0294427871704102\n",
      "\n",
      "01_20_01:26:24 Seen so far: 308512 samples\n",
      "\n",
      "01_20_01:26:24 --- 1.7073779106140137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:26 Training loss at epoch 3 step 9650: 3.244803619384766\n",
      "\n",
      " This round's valence_loss=1.1944644451141357, arousal_loss=1.0744290351867676, emotion_loss=1.104832649230957\n",
      "\n",
      "01_20_01:26:26 Seen so far: 308832 samples\n",
      "\n",
      "01_20_01:26:26 --- 1.8156201839447021 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:28 Training loss at epoch 3 step 9660: 2.8072928905487062\n",
      "\n",
      " This round's valence_loss=0.9602516889572144, arousal_loss=0.7174274921417236, emotion_loss=0.6492624282836914\n",
      "\n",
      "01_20_01:26:28 Seen so far: 309152 samples\n",
      "\n",
      "01_20_01:26:28 --- 1.7122914791107178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:29 Training loss at epoch 3 step 9670: 2.434470796585083\n",
      "\n",
      " This round's valence_loss=0.7380746603012085, arousal_loss=0.6307094693183899, emotion_loss=1.011626124382019\n",
      "\n",
      "01_20_01:26:29 Seen so far: 309472 samples\n",
      "\n",
      "01_20_01:26:29 --- 1.749704360961914 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:31 Training loss at epoch 3 step 9680: 2.867357921600342\n",
      "\n",
      " This round's valence_loss=0.9516969919204712, arousal_loss=0.8046078085899353, emotion_loss=1.047935128211975\n",
      "\n",
      "01_20_01:26:31 Seen so far: 309792 samples\n",
      "\n",
      "01_20_01:26:31 --- 1.7534048557281494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:33 Training loss at epoch 3 step 9690: 3.357912611961365\n",
      "\n",
      " This round's valence_loss=0.7310367822647095, arousal_loss=0.5503569841384888, emotion_loss=0.9412006735801697\n",
      "\n",
      "01_20_01:26:33 Seen so far: 310112 samples\n",
      "\n",
      "01_20_01:26:33 --- 1.831096887588501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:35 Training loss at epoch 3 step 9700: 3.009805679321289\n",
      "\n",
      " This round's valence_loss=0.8087913393974304, arousal_loss=0.6022382378578186, emotion_loss=0.8175848722457886\n",
      "\n",
      "01_20_01:26:35 Seen so far: 310432 samples\n",
      "\n",
      "01_20_01:26:35 --- 1.602344274520874 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:36 Training loss at epoch 3 step 9710: 2.5711831569671633\n",
      "\n",
      " This round's valence_loss=1.1578927040100098, arousal_loss=0.9049252271652222, emotion_loss=0.7304905652999878\n",
      "\n",
      "01_20_01:26:36 Seen so far: 310752 samples\n",
      "\n",
      "01_20_01:26:36 --- 1.7931349277496338 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:38 Training loss at epoch 3 step 9720: 2.959547591209412\n",
      "\n",
      " This round's valence_loss=0.9809859395027161, arousal_loss=0.8748023509979248, emotion_loss=1.2172167301177979\n",
      "\n",
      "01_20_01:26:38 Seen so far: 311072 samples\n",
      "\n",
      "01_20_01:26:38 --- 1.7004988193511963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:40 Training loss at epoch 3 step 9730: 2.8074923753738403\n",
      "\n",
      " This round's valence_loss=0.9251857995986938, arousal_loss=0.7899794578552246, emotion_loss=0.8376697897911072\n",
      "\n",
      "01_20_01:26:40 Seen so far: 311392 samples\n",
      "\n",
      "01_20_01:26:40 --- 1.8040847778320312 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:42 Training loss at epoch 3 step 9740: 3.0014989376068115\n",
      "\n",
      " This round's valence_loss=0.8113584518432617, arousal_loss=0.7177850008010864, emotion_loss=1.1530358791351318\n",
      "\n",
      "01_20_01:26:42 Seen so far: 311712 samples\n",
      "\n",
      "01_20_01:26:42 --- 1.7259211540222168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:43 Training loss at epoch 3 step 9750: 3.0753097772598266\n",
      "\n",
      " This round's valence_loss=1.1937737464904785, arousal_loss=0.9545893669128418, emotion_loss=0.430940181016922\n",
      "\n",
      "01_20_01:26:43 Seen so far: 312032 samples\n",
      "\n",
      "01_20_01:26:43 --- 1.8685927391052246 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:45 Training loss at epoch 3 step 9760: 3.0126760244369506\n",
      "\n",
      " This round's valence_loss=1.3568165302276611, arousal_loss=1.2549030780792236, emotion_loss=0.9249019622802734\n",
      "\n",
      "01_20_01:26:45 Seen so far: 312352 samples\n",
      "\n",
      "01_20_01:26:45 --- 1.816671371459961 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:47 Training loss at epoch 3 step 9770: 2.6339821219444275\n",
      "\n",
      " This round's valence_loss=0.6444586515426636, arousal_loss=0.4545478820800781, emotion_loss=0.8594675064086914\n",
      "\n",
      "01_20_01:26:47 Seen so far: 312672 samples\n",
      "\n",
      "01_20_01:26:47 --- 1.7791202068328857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:49 Training loss at epoch 3 step 9780: 2.751648283004761\n",
      "\n",
      " This round's valence_loss=0.4971882104873657, arousal_loss=0.3645707070827484, emotion_loss=0.6871147155761719\n",
      "\n",
      "01_20_01:26:49 Seen so far: 312992 samples\n",
      "\n",
      "01_20_01:26:49 --- 1.8243420124053955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:51 Training loss at epoch 3 step 9790: 2.8342560648918154\n",
      "\n",
      " This round's valence_loss=1.0085757970809937, arousal_loss=0.8352935314178467, emotion_loss=0.9323394894599915\n",
      "\n",
      "01_20_01:26:51 Seen so far: 313312 samples\n",
      "\n",
      "01_20_01:26:51 --- 1.8921253681182861 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:53 Training loss at epoch 3 step 9800: 3.1404239654541017\n",
      "\n",
      " This round's valence_loss=1.1215863227844238, arousal_loss=0.9664026498794556, emotion_loss=0.9450452923774719\n",
      "\n",
      "01_20_01:26:53 Seen so far: 313632 samples\n",
      "\n",
      "01_20_01:26:53 --- 1.7819139957427979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:54 Training loss at epoch 3 step 9810: 2.851261389255524\n",
      "\n",
      " This round's valence_loss=1.7012766599655151, arousal_loss=1.571202278137207, emotion_loss=0.9586796760559082\n",
      "\n",
      "01_20_01:26:54 Seen so far: 313952 samples\n",
      "\n",
      "01_20_01:26:54 --- 1.8014447689056396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:56 Training loss at epoch 3 step 9820: 2.839698052406311\n",
      "\n",
      " This round's valence_loss=0.8985142111778259, arousal_loss=0.796582043170929, emotion_loss=0.8570817708969116\n",
      "\n",
      "01_20_01:26:56 Seen so far: 314272 samples\n",
      "\n",
      "01_20_01:26:56 --- 1.7941489219665527 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:26:58 Training loss at epoch 3 step 9830: 2.6947041392326354\n",
      "\n",
      " This round's valence_loss=1.201422929763794, arousal_loss=1.1091341972351074, emotion_loss=0.8069085478782654\n",
      "\n",
      "01_20_01:26:58 Seen so far: 314592 samples\n",
      "\n",
      "01_20_01:26:58 --- 1.8049256801605225 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:00 Training loss at epoch 3 step 9840: 3.009601867198944\n",
      "\n",
      " This round's valence_loss=1.8593107461929321, arousal_loss=1.817947268486023, emotion_loss=1.2727378606796265\n",
      "\n",
      "01_20_01:27:00 Seen so far: 314912 samples\n",
      "\n",
      "01_20_01:27:00 --- 1.6723744869232178 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:01 Training loss at epoch 3 step 9850: 2.8962481737136843\n",
      "\n",
      " This round's valence_loss=0.7091008424758911, arousal_loss=0.598605751991272, emotion_loss=0.8608776330947876\n",
      "\n",
      "01_20_01:27:01 Seen so far: 315232 samples\n",
      "\n",
      "01_20_01:27:01 --- 1.7260265350341797 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:03 Training loss at epoch 3 step 9860: 2.929411768913269\n",
      "\n",
      " This round's valence_loss=0.8774311542510986, arousal_loss=0.7225797772407532, emotion_loss=0.9718582034111023\n",
      "\n",
      "01_20_01:27:03 Seen so far: 315552 samples\n",
      "\n",
      "01_20_01:27:03 --- 1.8432412147521973 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:05 Training loss at epoch 3 step 9870: 2.9495423793792725\n",
      "\n",
      " This round's valence_loss=0.9544201493263245, arousal_loss=0.6773872971534729, emotion_loss=0.7662190198898315\n",
      "\n",
      "01_20_01:27:05 Seen so far: 315872 samples\n",
      "\n",
      "01_20_01:27:05 --- 1.794454574584961 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:06 Training loss at epoch 3 step 9880: 2.901319718360901\n",
      "\n",
      " This round's valence_loss=0.6626308560371399, arousal_loss=0.6393932104110718, emotion_loss=1.1219656467437744\n",
      "\n",
      "01_20_01:27:06 Seen so far: 316192 samples\n",
      "\n",
      "01_20_01:27:06 --- 1.530698537826538 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:08 Training loss at epoch 3 step 9890: 3.097757411003113\n",
      "\n",
      " This round's valence_loss=0.9338278770446777, arousal_loss=0.8624157905578613, emotion_loss=0.743675172328949\n",
      "\n",
      "01_20_01:27:08 Seen so far: 316512 samples\n",
      "\n",
      "01_20_01:27:08 --- 1.7683889865875244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:10 Training loss at epoch 3 step 9900: 2.776089239120483\n",
      "\n",
      " This round's valence_loss=0.8602901697158813, arousal_loss=0.7775551676750183, emotion_loss=0.7167509198188782\n",
      "\n",
      "01_20_01:27:10 Seen so far: 316832 samples\n",
      "\n",
      "01_20_01:27:10 --- 1.9173579216003418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:12 Training loss at epoch 3 step 9910: 3.0715168714523315\n",
      "\n",
      " This round's valence_loss=1.5803325176239014, arousal_loss=1.4765970706939697, emotion_loss=0.8838227987289429\n",
      "\n",
      "01_20_01:27:12 Seen so far: 317152 samples\n",
      "\n",
      "01_20_01:27:12 --- 1.7602028846740723 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:14 Training loss at epoch 3 step 9920: 3.0956445217132567\n",
      "\n",
      " This round's valence_loss=1.6160321235656738, arousal_loss=1.441007375717163, emotion_loss=0.8077421188354492\n",
      "\n",
      "01_20_01:27:14 Seen so far: 317472 samples\n",
      "\n",
      "01_20_01:27:14 --- 1.6316213607788086 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:15 Training loss at epoch 3 step 9930: 3.094675612449646\n",
      "\n",
      " This round's valence_loss=1.2558705806732178, arousal_loss=1.0870033502578735, emotion_loss=0.7014822363853455\n",
      "\n",
      "01_20_01:27:15 Seen so far: 317792 samples\n",
      "\n",
      "01_20_01:27:15 --- 1.718712329864502 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:17 Training loss at epoch 3 step 9940: 3.086238145828247\n",
      "\n",
      " This round's valence_loss=1.2864952087402344, arousal_loss=1.2125508785247803, emotion_loss=0.6474326252937317\n",
      "\n",
      "01_20_01:27:17 Seen so far: 318112 samples\n",
      "\n",
      "01_20_01:27:17 --- 1.765876293182373 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:19 Training loss at epoch 3 step 9950: 2.885816586017609\n",
      "\n",
      " This round's valence_loss=1.337838888168335, arousal_loss=1.199912190437317, emotion_loss=0.8318259716033936\n",
      "\n",
      "01_20_01:27:19 Seen so far: 318432 samples\n",
      "\n",
      "01_20_01:27:19 --- 1.823437213897705 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:21 Training loss at epoch 3 step 9960: 3.2321024894714356\n",
      "\n",
      " This round's valence_loss=1.323789119720459, arousal_loss=1.1678671836853027, emotion_loss=1.043321132659912\n",
      "\n",
      "01_20_01:27:21 Seen so far: 318752 samples\n",
      "\n",
      "01_20_01:27:21 --- 1.984882116317749 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:23 Training loss at epoch 3 step 9970: 2.717551517486572\n",
      "\n",
      " This round's valence_loss=0.9962896108627319, arousal_loss=0.8374276161193848, emotion_loss=0.796517014503479\n",
      "\n",
      "01_20_01:27:23 Seen so far: 319072 samples\n",
      "\n",
      "01_20_01:27:23 --- 1.6904077529907227 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:24 Training loss at epoch 3 step 9980: 2.967994236946106\n",
      "\n",
      " This round's valence_loss=1.2359967231750488, arousal_loss=1.090221643447876, emotion_loss=1.1414955854415894\n",
      "\n",
      "01_20_01:27:24 Seen so far: 319392 samples\n",
      "\n",
      "01_20_01:27:24 --- 1.8223345279693604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:26 Training loss at epoch 3 step 9990: 2.8800193428993226\n",
      "\n",
      " This round's valence_loss=1.1680312156677246, arousal_loss=1.112746238708496, emotion_loss=1.0283931493759155\n",
      "\n",
      "01_20_01:27:26 Seen so far: 319712 samples\n",
      "\n",
      "01_20_01:27:26 --- 1.7370867729187012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:28 Training loss at epoch 3 step 10000: 2.9817618846893312\n",
      "\n",
      " This round's valence_loss=1.1021263599395752, arousal_loss=0.9891842007637024, emotion_loss=1.0746150016784668\n",
      "\n",
      "01_20_01:27:28 Seen so far: 320032 samples\n",
      "\n",
      "01_20_01:27:28 --- 1.845562219619751 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:30 Training loss at epoch 3 step 10010: 2.943702507019043\n",
      "\n",
      " This round's valence_loss=1.812272310256958, arousal_loss=1.662636399269104, emotion_loss=0.9894018173217773\n",
      "\n",
      "01_20_01:27:30 Seen so far: 320352 samples\n",
      "\n",
      "01_20_01:27:30 --- 1.786055326461792 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:32 Training loss at epoch 3 step 10020: 3.146028685569763\n",
      "\n",
      " This round's valence_loss=0.8513047695159912, arousal_loss=0.7560440301895142, emotion_loss=0.9996465444564819\n",
      "\n",
      "01_20_01:27:32 Seen so far: 320672 samples\n",
      "\n",
      "01_20_01:27:32 --- 1.7698016166687012 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:33 Training loss at epoch 3 step 10030: 3.0040547847747803\n",
      "\n",
      " This round's valence_loss=1.4522342681884766, arousal_loss=1.3324286937713623, emotion_loss=0.950334370136261\n",
      "\n",
      "01_20_01:27:33 Seen so far: 320992 samples\n",
      "\n",
      "01_20_01:27:33 --- 1.9696967601776123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:35 Training loss at epoch 3 step 10040: 2.806248927116394\n",
      "\n",
      " This round's valence_loss=0.7028321623802185, arousal_loss=0.6017329692840576, emotion_loss=0.7652254104614258\n",
      "\n",
      "01_20_01:27:35 Seen so far: 321312 samples\n",
      "\n",
      "01_20_01:27:35 --- 1.784022569656372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:37 Training loss at epoch 3 step 10050: 2.9816528439521788\n",
      "\n",
      " This round's valence_loss=0.530988335609436, arousal_loss=0.35159289836883545, emotion_loss=1.310865879058838\n",
      "\n",
      "01_20_01:27:37 Seen so far: 321632 samples\n",
      "\n",
      "01_20_01:27:37 --- 1.7099320888519287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:39 Training loss at epoch 3 step 10060: 3.181321930885315\n",
      "\n",
      " This round's valence_loss=1.1310644149780273, arousal_loss=0.9681140184402466, emotion_loss=1.0842255353927612\n",
      "\n",
      "01_20_01:27:39 Seen so far: 321952 samples\n",
      "\n",
      "01_20_01:27:39 --- 1.7343103885650635 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:41 Training loss at epoch 3 step 10070: 2.99578697681427\n",
      "\n",
      " This round's valence_loss=1.1048082113265991, arousal_loss=0.959320604801178, emotion_loss=0.841881513595581\n",
      "\n",
      "01_20_01:27:41 Seen so far: 322272 samples\n",
      "\n",
      "01_20_01:27:41 --- 1.8481194972991943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:42 Training loss at epoch 3 step 10080: 3.0351741552352904\n",
      "\n",
      " This round's valence_loss=1.3077163696289062, arousal_loss=1.1717767715454102, emotion_loss=0.6088283061981201\n",
      "\n",
      "01_20_01:27:42 Seen so far: 322592 samples\n",
      "\n",
      "01_20_01:27:42 --- 1.8059015274047852 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:44 Training loss at epoch 3 step 10090: 2.892221653461456\n",
      "\n",
      " This round's valence_loss=1.3245257139205933, arousal_loss=1.0825040340423584, emotion_loss=1.1196095943450928\n",
      "\n",
      "01_20_01:27:44 Seen so far: 322912 samples\n",
      "\n",
      "01_20_01:27:44 --- 1.7207763195037842 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:46 Training loss at epoch 3 step 10100: 2.8440382719039916\n",
      "\n",
      " This round's valence_loss=1.0193376541137695, arousal_loss=0.8662370443344116, emotion_loss=0.9347046613693237\n",
      "\n",
      "01_20_01:27:46 Seen so far: 323232 samples\n",
      "\n",
      "01_20_01:27:46 --- 1.7891709804534912 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:48 Training loss at epoch 3 step 10110: 2.710309588909149\n",
      "\n",
      " This round's valence_loss=0.7242754101753235, arousal_loss=0.6265510320663452, emotion_loss=0.8258299827575684\n",
      "\n",
      "01_20_01:27:48 Seen so far: 323552 samples\n",
      "\n",
      "01_20_01:27:48 --- 1.9418461322784424 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:50 Training loss at epoch 3 step 10120: 3.1307509183883666\n",
      "\n",
      " This round's valence_loss=1.2017138004302979, arousal_loss=0.9196413159370422, emotion_loss=0.8184243440628052\n",
      "\n",
      "01_20_01:27:50 Seen so far: 323872 samples\n",
      "\n",
      "01_20_01:27:50 --- 1.8485934734344482 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:51 Training loss at epoch 3 step 10130: 2.8154780149459837\n",
      "\n",
      " This round's valence_loss=0.951064944267273, arousal_loss=0.8498642444610596, emotion_loss=0.7389673590660095\n",
      "\n",
      "01_20_01:27:51 Seen so far: 324192 samples\n",
      "\n",
      "01_20_01:27:51 --- 1.7367489337921143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:53 Training loss at epoch 3 step 10140: 2.9970930099487303\n",
      "\n",
      " This round's valence_loss=1.8193740844726562, arousal_loss=1.660042643547058, emotion_loss=0.705146849155426\n",
      "\n",
      "01_20_01:27:53 Seen so far: 324512 samples\n",
      "\n",
      "01_20_01:27:53 --- 1.8793666362762451 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:55 Training loss at epoch 3 step 10150: 3.0587229251861574\n",
      "\n",
      " This round's valence_loss=1.0054558515548706, arousal_loss=0.8416234254837036, emotion_loss=0.7620863914489746\n",
      "\n",
      "01_20_01:27:55 Seen so far: 324832 samples\n",
      "\n",
      "01_20_01:27:55 --- 1.882314682006836 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:57 Training loss at epoch 3 step 10160: 2.793532109260559\n",
      "\n",
      " This round's valence_loss=0.9404889941215515, arousal_loss=0.8621615171432495, emotion_loss=1.1836426258087158\n",
      "\n",
      "01_20_01:27:57 Seen so far: 325152 samples\n",
      "\n",
      "01_20_01:27:57 --- 1.8270208835601807 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:27:59 Training loss at epoch 3 step 10170: 3.088794982433319\n",
      "\n",
      " This round's valence_loss=1.3265738487243652, arousal_loss=1.1861063241958618, emotion_loss=0.687137246131897\n",
      "\n",
      "01_20_01:27:59 Seen so far: 325472 samples\n",
      "\n",
      "01_20_01:27:59 --- 1.8414320945739746 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:01 Training loss at epoch 3 step 10180: 2.7150038719177245\n",
      "\n",
      " This round's valence_loss=1.0341081619262695, arousal_loss=0.9513165950775146, emotion_loss=1.2506049871444702\n",
      "\n",
      "01_20_01:28:01 Seen so far: 325792 samples\n",
      "\n",
      "01_20_01:28:01 --- 1.8021509647369385 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:02 Training loss at epoch 3 step 10190: 2.8223724603652953\n",
      "\n",
      " This round's valence_loss=1.0759849548339844, arousal_loss=0.9469993114471436, emotion_loss=0.9107085466384888\n",
      "\n",
      "01_20_01:28:02 Seen so far: 326112 samples\n",
      "\n",
      "01_20_01:28:02 --- 1.6851518154144287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:04 Training loss at epoch 3 step 10200: 3.1843352556228637\n",
      "\n",
      " This round's valence_loss=1.1470787525177002, arousal_loss=0.9499474167823792, emotion_loss=0.9426466226577759\n",
      "\n",
      "01_20_01:28:04 Seen so far: 326432 samples\n",
      "\n",
      "01_20_01:28:04 --- 1.8903613090515137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:06 Training loss at epoch 3 step 10210: 3.160774087905884\n",
      "\n",
      " This round's valence_loss=0.9608950614929199, arousal_loss=0.8705207705497742, emotion_loss=0.9825937747955322\n",
      "\n",
      "01_20_01:28:06 Seen so far: 326752 samples\n",
      "\n",
      "01_20_01:28:06 --- 2.013115882873535 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:08 Training loss at epoch 3 step 10220: 2.729457104206085\n",
      "\n",
      " This round's valence_loss=0.8316691517829895, arousal_loss=0.6985241174697876, emotion_loss=0.9407642483711243\n",
      "\n",
      "01_20_01:28:08 Seen so far: 327072 samples\n",
      "\n",
      "01_20_01:28:08 --- 1.8503005504608154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:10 Training loss at epoch 3 step 10230: 2.7900988936424254\n",
      "\n",
      " This round's valence_loss=1.0005638599395752, arousal_loss=0.8573207259178162, emotion_loss=1.1864347457885742\n",
      "\n",
      "01_20_01:28:10 Seen so far: 327392 samples\n",
      "\n",
      "01_20_01:28:10 --- 1.6355879306793213 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:11 Training loss at epoch 3 step 10240: 3.2201942682266234\n",
      "\n",
      " This round's valence_loss=1.3542479276657104, arousal_loss=1.180340051651001, emotion_loss=0.7629395723342896\n",
      "\n",
      "01_20_01:28:11 Seen so far: 327712 samples\n",
      "\n",
      "01_20_01:28:11 --- 1.6521968841552734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:13 Training loss at epoch 3 step 10250: 2.756434774398804\n",
      "\n",
      " This round's valence_loss=1.0862836837768555, arousal_loss=1.0014419555664062, emotion_loss=0.9018805027008057\n",
      "\n",
      "01_20_01:28:13 Seen so far: 328032 samples\n",
      "\n",
      "01_20_01:28:13 --- 1.7881534099578857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:15 Training loss at epoch 3 step 10260: 3.2948381185531614\n",
      "\n",
      " This round's valence_loss=1.1558200120925903, arousal_loss=1.0948283672332764, emotion_loss=0.8414943814277649\n",
      "\n",
      "01_20_01:28:15 Seen so far: 328352 samples\n",
      "\n",
      "01_20_01:28:15 --- 1.7180371284484863 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:16 Training loss at epoch 3 step 10270: 2.8276528120040894\n",
      "\n",
      " This round's valence_loss=0.9750373959541321, arousal_loss=0.6823438405990601, emotion_loss=0.5507474541664124\n",
      "\n",
      "01_20_01:28:16 Seen so far: 328672 samples\n",
      "\n",
      "01_20_01:28:16 --- 1.6211962699890137 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:18 Training loss at epoch 3 step 10280: 2.7714166402816773\n",
      "\n",
      " This round's valence_loss=1.0595608949661255, arousal_loss=0.9444363713264465, emotion_loss=0.9857852458953857\n",
      "\n",
      "01_20_01:28:18 Seen so far: 328992 samples\n",
      "\n",
      "01_20_01:28:18 --- 1.6223924160003662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:20 Training loss at epoch 3 step 10290: 2.746204447746277\n",
      "\n",
      " This round's valence_loss=0.8418257832527161, arousal_loss=0.724310040473938, emotion_loss=0.6740841865539551\n",
      "\n",
      "01_20_01:28:20 Seen so far: 329312 samples\n",
      "\n",
      "01_20_01:28:20 --- 1.796679973602295 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:22 Training loss at epoch 3 step 10300: 2.9237024664878843\n",
      "\n",
      " This round's valence_loss=1.4504722356796265, arousal_loss=1.350406527519226, emotion_loss=1.177692174911499\n",
      "\n",
      "01_20_01:28:22 Seen so far: 329632 samples\n",
      "\n",
      "01_20_01:28:22 --- 1.6807246208190918 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:23 Training loss at epoch 3 step 10310: 3.0221911430358888\n",
      "\n",
      " This round's valence_loss=1.1009160280227661, arousal_loss=0.9540895223617554, emotion_loss=1.020558476448059\n",
      "\n",
      "01_20_01:28:23 Seen so far: 329952 samples\n",
      "\n",
      "01_20_01:28:23 --- 1.6135389804840088 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:25 Training loss at epoch 3 step 10320: 2.873989462852478\n",
      "\n",
      " This round's valence_loss=0.6716649532318115, arousal_loss=0.4583849310874939, emotion_loss=0.9329322576522827\n",
      "\n",
      "01_20_01:28:25 Seen so far: 330272 samples\n",
      "\n",
      "01_20_01:28:25 --- 1.719027042388916 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:27 Training loss at epoch 3 step 10330: 2.730024015903473\n",
      "\n",
      " This round's valence_loss=0.8452883958816528, arousal_loss=0.7217996120452881, emotion_loss=0.8801587820053101\n",
      "\n",
      "01_20_01:28:27 Seen so far: 330592 samples\n",
      "\n",
      "01_20_01:28:27 --- 1.8665015697479248 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:28 Training loss at epoch 3 step 10340: 2.9205440044403077\n",
      "\n",
      " This round's valence_loss=1.1005408763885498, arousal_loss=0.9216271638870239, emotion_loss=0.8617691397666931\n",
      "\n",
      "01_20_01:28:28 Seen so far: 330912 samples\n",
      "\n",
      "01_20_01:28:28 --- 1.6935791969299316 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:30 Training loss at epoch 3 step 10350: 3.0555904626846315\n",
      "\n",
      " This round's valence_loss=1.2990590333938599, arousal_loss=1.1830137968063354, emotion_loss=1.0860986709594727\n",
      "\n",
      "01_20_01:28:30 Seen so far: 331232 samples\n",
      "\n",
      "01_20_01:28:30 --- 1.8209125995635986 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:32 Training loss at epoch 3 step 10360: 2.7259857773780825\n",
      "\n",
      " This round's valence_loss=0.6658414006233215, arousal_loss=0.522568941116333, emotion_loss=1.055816888809204\n",
      "\n",
      "01_20_01:28:32 Seen so far: 331552 samples\n",
      "\n",
      "01_20_01:28:32 --- 1.628100872039795 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:34 Training loss at epoch 3 step 10370: 2.2523219108581545\n",
      "\n",
      " This round's valence_loss=0.5196207761764526, arousal_loss=0.3720209002494812, emotion_loss=1.170140266418457\n",
      "\n",
      "01_20_01:28:34 Seen so far: 331872 samples\n",
      "\n",
      "01_20_01:28:34 --- 1.7762606143951416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:35 Training loss at epoch 3 step 10380: 2.757315754890442\n",
      "\n",
      " This round's valence_loss=1.2006934881210327, arousal_loss=1.090952754020691, emotion_loss=0.567903995513916\n",
      "\n",
      "01_20_01:28:35 Seen so far: 332192 samples\n",
      "\n",
      "01_20_01:28:35 --- 1.6429977416992188 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:37 Training loss at epoch 3 step 10390: 2.885990118980408\n",
      "\n",
      " This round's valence_loss=1.0246806144714355, arousal_loss=0.8128019571304321, emotion_loss=1.0266379117965698\n",
      "\n",
      "01_20_01:28:37 Seen so far: 332512 samples\n",
      "\n",
      "01_20_01:28:37 --- 1.9884545803070068 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:39 Training loss at epoch 3 step 10400: 2.85724458694458\n",
      "\n",
      " This round's valence_loss=1.6302330493927002, arousal_loss=1.5833189487457275, emotion_loss=1.019881248474121\n",
      "\n",
      "01_20_01:28:39 Seen so far: 332832 samples\n",
      "\n",
      "01_20_01:28:39 --- 1.7152411937713623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:41 Training loss at epoch 3 step 10410: 2.7270570516586305\n",
      "\n",
      " This round's valence_loss=1.5401887893676758, arousal_loss=1.4159326553344727, emotion_loss=0.6531034708023071\n",
      "\n",
      "01_20_01:28:41 Seen so far: 333152 samples\n",
      "\n",
      "01_20_01:28:41 --- 1.752101182937622 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:42 Training loss at epoch 3 step 10420: 2.9432769775390626\n",
      "\n",
      " This round's valence_loss=0.8700719475746155, arousal_loss=0.7638977766036987, emotion_loss=0.9564698338508606\n",
      "\n",
      "01_20_01:28:42 Seen so far: 333472 samples\n",
      "\n",
      "01_20_01:28:42 --- 1.6387810707092285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:44 Training loss at epoch 3 step 10430: 3.0914566993713377\n",
      "\n",
      " This round's valence_loss=1.4240961074829102, arousal_loss=1.3467820882797241, emotion_loss=0.9970695376396179\n",
      "\n",
      "01_20_01:28:44 Seen so far: 333792 samples\n",
      "\n",
      "01_20_01:28:44 --- 2.023366689682007 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:46 Training loss at epoch 3 step 10440: 3.0217155694961546\n",
      "\n",
      " This round's valence_loss=1.6774351596832275, arousal_loss=1.4686188697814941, emotion_loss=1.033864974975586\n",
      "\n",
      "01_20_01:28:46 Seen so far: 334112 samples\n",
      "\n",
      "01_20_01:28:46 --- 1.6945405006408691 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:48 Training loss at epoch 3 step 10450: 3.0492746114730833\n",
      "\n",
      " This round's valence_loss=0.9015816450119019, arousal_loss=0.7094101309776306, emotion_loss=0.9360318183898926\n",
      "\n",
      "01_20_01:28:48 Seen so far: 334432 samples\n",
      "\n",
      "01_20_01:28:48 --- 1.6696393489837646 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:50 Training loss at epoch 3 step 10460: 3.089052677154541\n",
      "\n",
      " This round's valence_loss=0.7852360606193542, arousal_loss=0.5718114972114563, emotion_loss=0.7972614169120789\n",
      "\n",
      "01_20_01:28:50 Seen so far: 334752 samples\n",
      "\n",
      "01_20_01:28:50 --- 1.940519094467163 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:52 Training loss at epoch 3 step 10470: 2.967600393295288\n",
      "\n",
      " This round's valence_loss=1.4492712020874023, arousal_loss=1.341876745223999, emotion_loss=0.9789363145828247\n",
      "\n",
      "01_20_01:28:52 Seen so far: 335072 samples\n",
      "\n",
      "01_20_01:28:52 --- 1.757643699645996 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:53 Training loss at epoch 3 step 10480: 3.085490870475769\n",
      "\n",
      " This round's valence_loss=1.3611901998519897, arousal_loss=1.185713291168213, emotion_loss=0.8544033765792847\n",
      "\n",
      "01_20_01:28:53 Seen so far: 335392 samples\n",
      "\n",
      "01_20_01:28:53 --- 1.7564949989318848 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:55 Training loss at epoch 3 step 10490: 2.9222904443740845\n",
      "\n",
      " This round's valence_loss=0.7046473622322083, arousal_loss=0.600560188293457, emotion_loss=0.9746631383895874\n",
      "\n",
      "01_20_01:28:55 Seen so far: 335712 samples\n",
      "\n",
      "01_20_01:28:55 --- 1.904965877532959 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:57 Training loss at epoch 3 step 10500: 2.762997579574585\n",
      "\n",
      " This round's valence_loss=0.7540478706359863, arousal_loss=0.6455159187316895, emotion_loss=1.3951835632324219\n",
      "\n",
      "01_20_01:28:57 Seen so far: 336032 samples\n",
      "\n",
      "01_20_01:28:57 --- 1.7563557624816895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:28:59 Training loss at epoch 3 step 10510: 3.4104556798934937\n",
      "\n",
      " This round's valence_loss=0.8172996044158936, arousal_loss=0.6822368502616882, emotion_loss=1.0144535303115845\n",
      "\n",
      "01_20_01:28:59 Seen so far: 336352 samples\n",
      "\n",
      "01_20_01:28:59 --- 1.8440372943878174 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:00 Training loss at epoch 3 step 10520: 2.857737958431244\n",
      "\n",
      " This round's valence_loss=1.2328883409500122, arousal_loss=1.075208067893982, emotion_loss=1.018674373626709\n",
      "\n",
      "01_20_01:29:00 Seen so far: 336672 samples\n",
      "\n",
      "01_20_01:29:00 --- 1.6223056316375732 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:02 Training loss at epoch 3 step 10530: 3.2838260889053346\n",
      "\n",
      " This round's valence_loss=1.0760366916656494, arousal_loss=1.0082347393035889, emotion_loss=0.8424323201179504\n",
      "\n",
      "01_20_01:29:02 Seen so far: 336992 samples\n",
      "\n",
      "01_20_01:29:02 --- 1.9258615970611572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:04 Training loss at epoch 3 step 10540: 2.7510326862335206\n",
      "\n",
      " This round's valence_loss=1.1144530773162842, arousal_loss=0.9518873691558838, emotion_loss=1.1300104856491089\n",
      "\n",
      "01_20_01:29:04 Seen so far: 337312 samples\n",
      "\n",
      "01_20_01:29:04 --- 1.628173828125 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:06 Training loss at epoch 3 step 10550: 3.0758599281311034\n",
      "\n",
      " This round's valence_loss=0.873038113117218, arousal_loss=0.7314073443412781, emotion_loss=0.6567049026489258\n",
      "\n",
      "01_20_01:29:06 Seen so far: 337632 samples\n",
      "\n",
      "01_20_01:29:06 --- 1.831343412399292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:07 Training loss at epoch 3 step 10560: 3.390290451049805\n",
      "\n",
      " This round's valence_loss=0.9680230617523193, arousal_loss=0.8502609133720398, emotion_loss=1.0183640718460083\n",
      "\n",
      "01_20_01:29:07 Seen so far: 337952 samples\n",
      "\n",
      "01_20_01:29:07 --- 1.6587340831756592 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:09 Training loss at epoch 3 step 10570: 2.803749752044678\n",
      "\n",
      " This round's valence_loss=0.8504490852355957, arousal_loss=0.6232789754867554, emotion_loss=1.3718459606170654\n",
      "\n",
      "01_20_01:29:09 Seen so far: 338272 samples\n",
      "\n",
      "01_20_01:29:09 --- 1.6340947151184082 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:11 Training loss at epoch 3 step 10580: 3.1314952850341795\n",
      "\n",
      " This round's valence_loss=1.1185901165008545, arousal_loss=0.9898862838745117, emotion_loss=0.614911675453186\n",
      "\n",
      "01_20_01:29:11 Seen so far: 338592 samples\n",
      "\n",
      "01_20_01:29:11 --- 1.6523778438568115 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:13 Training loss at epoch 3 step 10590: 2.8801400899887084\n",
      "\n",
      " This round's valence_loss=1.4641872644424438, arousal_loss=1.369110107421875, emotion_loss=1.1549063920974731\n",
      "\n",
      "01_20_01:29:13 Seen so far: 338912 samples\n",
      "\n",
      "01_20_01:29:13 --- 1.7902746200561523 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:14 Training loss at epoch 3 step 10600: 2.6711668491363527\n",
      "\n",
      " This round's valence_loss=0.8589540719985962, arousal_loss=0.6807800531387329, emotion_loss=0.7783347964286804\n",
      "\n",
      "01_20_01:29:14 Seen so far: 339232 samples\n",
      "\n",
      "01_20_01:29:14 --- 1.6986026763916016 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:16 Training loss at epoch 3 step 10610: 2.794610285758972\n",
      "\n",
      " This round's valence_loss=0.9945900440216064, arousal_loss=0.7890689373016357, emotion_loss=0.9405770301818848\n",
      "\n",
      "01_20_01:29:16 Seen so far: 339552 samples\n",
      "\n",
      "01_20_01:29:16 --- 1.6553165912628174 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:18 Training loss at epoch 3 step 10620: 2.767200565338135\n",
      "\n",
      " This round's valence_loss=0.9945093393325806, arousal_loss=0.8505730628967285, emotion_loss=0.49179914593696594\n",
      "\n",
      "01_20_01:29:18 Seen so far: 339872 samples\n",
      "\n",
      "01_20_01:29:18 --- 1.6866323947906494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:19 Training loss at epoch 3 step 10630: 3.1313738107681273\n",
      "\n",
      " This round's valence_loss=1.0015519857406616, arousal_loss=0.9092687368392944, emotion_loss=1.1491096019744873\n",
      "\n",
      "01_20_01:29:19 Seen so far: 340192 samples\n",
      "\n",
      "01_20_01:29:19 --- 1.7875545024871826 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:21 Training loss at epoch 3 step 10640: 3.168970012664795\n",
      "\n",
      " This round's valence_loss=1.7790218591690063, arousal_loss=1.674074649810791, emotion_loss=0.7694627046585083\n",
      "\n",
      "01_20_01:29:21 Seen so far: 340512 samples\n",
      "\n",
      "01_20_01:29:21 --- 1.901949405670166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:23 Training loss at epoch 3 step 10650: 2.8387619495391845\n",
      "\n",
      " This round's valence_loss=0.8003628849983215, arousal_loss=0.738419771194458, emotion_loss=0.8140876293182373\n",
      "\n",
      "01_20_01:29:23 Seen so far: 340832 samples\n",
      "\n",
      "01_20_01:29:23 --- 1.7139606475830078 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:25 Training loss at epoch 3 step 10660: 2.871404242515564\n",
      "\n",
      " This round's valence_loss=0.5365562438964844, arousal_loss=0.3666040301322937, emotion_loss=0.9807324409484863\n",
      "\n",
      "01_20_01:29:25 Seen so far: 341152 samples\n",
      "\n",
      "01_20_01:29:25 --- 2.062756061553955 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:27 Training loss at epoch 3 step 10670: 2.795975589752197\n",
      "\n",
      " This round's valence_loss=1.2666202783584595, arousal_loss=1.1041650772094727, emotion_loss=0.6402546763420105\n",
      "\n",
      "01_20_01:29:27 Seen so far: 341472 samples\n",
      "\n",
      "01_20_01:29:27 --- 1.6382536888122559 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:28 Training loss at epoch 3 step 10680: 3.2694996118545534\n",
      "\n",
      " This round's valence_loss=0.8545664548873901, arousal_loss=0.6242938041687012, emotion_loss=0.8330901265144348\n",
      "\n",
      "01_20_01:29:28 Seen so far: 341792 samples\n",
      "\n",
      "01_20_01:29:28 --- 1.7384896278381348 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:30 Training loss at epoch 3 step 10690: 3.105234670639038\n",
      "\n",
      " This round's valence_loss=0.9651832580566406, arousal_loss=0.7399336099624634, emotion_loss=0.6382668018341064\n",
      "\n",
      "01_20_01:29:30 Seen so far: 342112 samples\n",
      "\n",
      "01_20_01:29:30 --- 1.8492553234100342 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:32 Training loss at epoch 3 step 10700: 2.9738669395446777\n",
      "\n",
      " This round's valence_loss=1.0638420581817627, arousal_loss=0.9769503474235535, emotion_loss=0.9574635028839111\n",
      "\n",
      "01_20_01:29:32 Seen so far: 342432 samples\n",
      "\n",
      "01_20_01:29:32 --- 1.7211177349090576 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:34 Training loss at epoch 3 step 10710: 3.038746547698975\n",
      "\n",
      " This round's valence_loss=0.8710612654685974, arousal_loss=0.690895676612854, emotion_loss=0.9872927069664001\n",
      "\n",
      "01_20_01:29:34 Seen so far: 342752 samples\n",
      "\n",
      "01_20_01:29:34 --- 1.665276288986206 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:35 Training loss at epoch 3 step 10720: 2.8530734539031983\n",
      "\n",
      " This round's valence_loss=1.0054471492767334, arousal_loss=0.7971839308738708, emotion_loss=0.899207353591919\n",
      "\n",
      "01_20_01:29:35 Seen so far: 343072 samples\n",
      "\n",
      "01_20_01:29:35 --- 1.8248848915100098 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:37 Training loss at epoch 3 step 10730: 2.872425174713135\n",
      "\n",
      " This round's valence_loss=1.2454856634140015, arousal_loss=1.067053198814392, emotion_loss=0.9868237972259521\n",
      "\n",
      "01_20_01:29:37 Seen so far: 343392 samples\n",
      "\n",
      "01_20_01:29:37 --- 1.8076951503753662 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:39 Training loss at epoch 3 step 10740: 2.8131253004074095\n",
      "\n",
      " This round's valence_loss=1.0649782419204712, arousal_loss=0.9794633984565735, emotion_loss=0.6628277897834778\n",
      "\n",
      "01_20_01:29:39 Seen so far: 343712 samples\n",
      "\n",
      "01_20_01:29:39 --- 1.518387794494629 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:40 Training loss at epoch 3 step 10750: 3.2534843921661376\n",
      "\n",
      " This round's valence_loss=1.0034414529800415, arousal_loss=0.8543592691421509, emotion_loss=0.6427371501922607\n",
      "\n",
      "01_20_01:29:40 Seen so far: 344032 samples\n",
      "\n",
      "01_20_01:29:40 --- 1.6565616130828857 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:42 Training loss at epoch 3 step 10760: 2.991681623458862\n",
      "\n",
      " This round's valence_loss=0.9960795640945435, arousal_loss=0.8500293493270874, emotion_loss=0.9288612604141235\n",
      "\n",
      "01_20_01:29:42 Seen so far: 344352 samples\n",
      "\n",
      "01_20_01:29:42 --- 1.7445173263549805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:44 Training loss at epoch 3 step 10770: 3.0256869435310363\n",
      "\n",
      " This round's valence_loss=1.2380530834197998, arousal_loss=1.0973457098007202, emotion_loss=0.8398594260215759\n",
      "\n",
      "01_20_01:29:44 Seen so far: 344672 samples\n",
      "\n",
      "01_20_01:29:44 --- 1.874943733215332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:46 Training loss at epoch 3 step 10780: 2.7329047679901124\n",
      "\n",
      " This round's valence_loss=0.7028176784515381, arousal_loss=0.5106625556945801, emotion_loss=0.5244963765144348\n",
      "\n",
      "01_20_01:29:46 Seen so far: 344992 samples\n",
      "\n",
      "01_20_01:29:46 --- 1.707312822341919 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:48 Training loss at epoch 3 step 10790: 3.1165820837020872\n",
      "\n",
      " This round's valence_loss=0.9320181608200073, arousal_loss=0.85658860206604, emotion_loss=1.0508803129196167\n",
      "\n",
      "01_20_01:29:48 Seen so far: 345312 samples\n",
      "\n",
      "01_20_01:29:48 --- 1.7426469326019287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:49 Training loss at epoch 3 step 10800: 2.919000840187073\n",
      "\n",
      " This round's valence_loss=1.003605842590332, arousal_loss=0.827608048915863, emotion_loss=0.8178777694702148\n",
      "\n",
      "01_20_01:29:49 Seen so far: 345632 samples\n",
      "\n",
      "01_20_01:29:49 --- 1.8605141639709473 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:51 Training loss at epoch 3 step 10810: 3.1166080713272093\n",
      "\n",
      " This round's valence_loss=0.9451953172683716, arousal_loss=0.7975289821624756, emotion_loss=0.882836639881134\n",
      "\n",
      "01_20_01:29:51 Seen so far: 345952 samples\n",
      "\n",
      "01_20_01:29:51 --- 1.7293438911437988 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:53 Training loss at epoch 3 step 10820: 2.9134675741195677\n",
      "\n",
      " This round's valence_loss=1.1437199115753174, arousal_loss=0.9259782433509827, emotion_loss=0.556458592414856\n",
      "\n",
      "01_20_01:29:53 Seen so far: 346272 samples\n",
      "\n",
      "01_20_01:29:53 --- 1.719956636428833 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:55 Training loss at epoch 3 step 10830: 3.357073259353638\n",
      "\n",
      " This round's valence_loss=1.5812993049621582, arousal_loss=1.4461772441864014, emotion_loss=1.0636942386627197\n",
      "\n",
      "01_20_01:29:55 Seen so far: 346592 samples\n",
      "\n",
      "01_20_01:29:55 --- 1.8864226341247559 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:57 Training loss at epoch 3 step 10840: 3.173146963119507\n",
      "\n",
      " This round's valence_loss=1.492152214050293, arousal_loss=1.2928967475891113, emotion_loss=0.8038297891616821\n",
      "\n",
      "01_20_01:29:57 Seen so far: 346912 samples\n",
      "\n",
      "01_20_01:29:57 --- 1.8008694648742676 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:29:58 Training loss at epoch 3 step 10850: 3.1041032791137697\n",
      "\n",
      " This round's valence_loss=1.0198379755020142, arousal_loss=0.7934284210205078, emotion_loss=0.5829676985740662\n",
      "\n",
      "01_20_01:29:58 Seen so far: 347232 samples\n",
      "\n",
      "01_20_01:29:58 --- 1.6545236110687256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:00 Training loss at epoch 3 step 10860: 2.71948219537735\n",
      "\n",
      " This round's valence_loss=0.4815309941768646, arousal_loss=0.40069735050201416, emotion_loss=1.0810083150863647\n",
      "\n",
      "01_20_01:30:00 Seen so far: 347552 samples\n",
      "\n",
      "01_20_01:30:00 --- 1.9615230560302734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:02 Training loss at epoch 3 step 10870: 2.8060887932777403\n",
      "\n",
      " This round's valence_loss=0.8138002157211304, arousal_loss=0.6740021705627441, emotion_loss=0.832894504070282\n",
      "\n",
      "01_20_01:30:02 Seen so far: 347872 samples\n",
      "\n",
      "01_20_01:30:02 --- 1.7963132858276367 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:04 Training loss at epoch 3 step 10880: 2.8068211555480955\n",
      "\n",
      " This round's valence_loss=1.3270514011383057, arousal_loss=1.2550239562988281, emotion_loss=0.7560902833938599\n",
      "\n",
      "01_20_01:30:04 Seen so far: 348192 samples\n",
      "\n",
      "01_20_01:30:04 --- 1.5633392333984375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:05 Training loss at epoch 3 step 10890: 2.852950930595398\n",
      "\n",
      " This round's valence_loss=0.8655552864074707, arousal_loss=0.6830295324325562, emotion_loss=0.824766218662262\n",
      "\n",
      "01_20_01:30:05 Seen so far: 348512 samples\n",
      "\n",
      "01_20_01:30:05 --- 1.702800989151001 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:07 Training loss at epoch 3 step 10900: 2.71057368516922\n",
      "\n",
      " This round's valence_loss=0.5926178097724915, arousal_loss=0.3708777129650116, emotion_loss=0.7187155485153198\n",
      "\n",
      "01_20_01:30:07 Seen so far: 348832 samples\n",
      "\n",
      "01_20_01:30:07 --- 1.7981953620910645 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:09 Training loss at epoch 3 step 10910: 2.9904084146022796\n",
      "\n",
      " This round's valence_loss=1.2154937982559204, arousal_loss=1.080077886581421, emotion_loss=1.0580317974090576\n",
      "\n",
      "01_20_01:30:09 Seen so far: 349152 samples\n",
      "\n",
      "01_20_01:30:09 --- 1.917097568511963 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:11 Training loss at epoch 3 step 10920: 3.1048945426940917\n",
      "\n",
      " This round's valence_loss=1.4279356002807617, arousal_loss=1.4035253524780273, emotion_loss=0.6763895750045776\n",
      "\n",
      "01_20_01:30:11 Seen so far: 349472 samples\n",
      "\n",
      "01_20_01:30:11 --- 1.7000296115875244 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:12 Training loss at epoch 3 step 10930: 3.1278974771499635\n",
      "\n",
      " This round's valence_loss=1.0546391010284424, arousal_loss=0.8275748491287231, emotion_loss=0.6024860739707947\n",
      "\n",
      "01_20_01:30:12 Seen so far: 349792 samples\n",
      "\n",
      "01_20_01:30:12 --- 1.7542455196380615 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:14 Training loss at epoch 3 step 10940: 2.8773090124130247\n",
      "\n",
      " This round's valence_loss=0.6480280160903931, arousal_loss=0.5289521813392639, emotion_loss=1.1659586429595947\n",
      "\n",
      "01_20_01:30:14 Seen so far: 350112 samples\n",
      "\n",
      "01_20_01:30:14 --- 2.0394272804260254 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:16 Training loss at epoch 3 step 10950: 2.698009157180786\n",
      "\n",
      " This round's valence_loss=1.2999603748321533, arousal_loss=1.2460830211639404, emotion_loss=1.1816978454589844\n",
      "\n",
      "01_20_01:30:16 Seen so far: 350432 samples\n",
      "\n",
      "01_20_01:30:16 --- 1.7507109642028809 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:18 Training loss at epoch 3 step 10960: 2.992572379112244\n",
      "\n",
      " This round's valence_loss=0.6944184899330139, arousal_loss=0.6048375368118286, emotion_loss=0.9676733016967773\n",
      "\n",
      "01_20_01:30:18 Seen so far: 350752 samples\n",
      "\n",
      "01_20_01:30:18 --- 1.7733373641967773 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:20 Training loss at epoch 3 step 10970: 2.6439552307128906\n",
      "\n",
      " This round's valence_loss=0.9563312530517578, arousal_loss=0.8003115653991699, emotion_loss=1.0695719718933105\n",
      "\n",
      "01_20_01:30:20 Seen so far: 351072 samples\n",
      "\n",
      "01_20_01:30:20 --- 1.5760424137115479 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:21 Training loss at epoch 3 step 10980: 3.0916312456130983\n",
      "\n",
      " This round's valence_loss=1.0693172216415405, arousal_loss=0.9755470752716064, emotion_loss=1.1215994358062744\n",
      "\n",
      "01_20_01:30:21 Seen so far: 351392 samples\n",
      "\n",
      "01_20_01:30:21 --- 1.7942826747894287 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:23 Training loss at epoch 3 step 10990: 2.950020909309387\n",
      "\n",
      " This round's valence_loss=0.8093613386154175, arousal_loss=0.5553700923919678, emotion_loss=0.8319289684295654\n",
      "\n",
      "01_20_01:30:23 Seen so far: 351712 samples\n",
      "\n",
      "01_20_01:30:23 --- 1.637178659439087 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:25 Training loss at epoch 3 step 11000: 2.6578258275985718\n",
      "\n",
      " This round's valence_loss=0.9775689244270325, arousal_loss=0.9149265289306641, emotion_loss=0.8253207206726074\n",
      "\n",
      "01_20_01:30:25 Seen so far: 352032 samples\n",
      "\n",
      "01_20_01:30:25 --- 1.8346965312957764 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:27 Training loss at epoch 3 step 11010: 2.797328495979309\n",
      "\n",
      " This round's valence_loss=1.057438611984253, arousal_loss=0.9510852694511414, emotion_loss=0.7945483922958374\n",
      "\n",
      "01_20_01:30:27 Seen so far: 352352 samples\n",
      "\n",
      "01_20_01:30:27 --- 1.8876779079437256 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:28 Training loss at epoch 3 step 11020: 2.6066674470901487\n",
      "\n",
      " This round's valence_loss=0.8675134181976318, arousal_loss=0.8613784313201904, emotion_loss=0.9452834129333496\n",
      "\n",
      "01_20_01:30:28 Seen so far: 352672 samples\n",
      "\n",
      "01_20_01:30:28 --- 1.8059039115905762 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:30 Training loss at epoch 3 step 11030: 2.7754669904708864\n",
      "\n",
      " This round's valence_loss=1.2907423973083496, arousal_loss=1.2013823986053467, emotion_loss=0.8067270517349243\n",
      "\n",
      "01_20_01:30:30 Seen so far: 352992 samples\n",
      "\n",
      "01_20_01:30:30 --- 1.678894281387329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:32 Training loss at epoch 3 step 11040: 2.8622148990631104\n",
      "\n",
      " This round's valence_loss=1.4804620742797852, arousal_loss=1.3044317960739136, emotion_loss=0.8664035797119141\n",
      "\n",
      "01_20_01:30:32 Seen so far: 353312 samples\n",
      "\n",
      "01_20_01:30:32 --- 1.6720030307769775 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:34 Training loss at epoch 3 step 11050: 2.9231148242950438\n",
      "\n",
      " This round's valence_loss=0.8303574919700623, arousal_loss=0.7894605994224548, emotion_loss=1.0958331823349\n",
      "\n",
      "01_20_01:30:34 Seen so far: 353632 samples\n",
      "\n",
      "01_20_01:30:34 --- 1.6715378761291504 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:35 Training loss at epoch 3 step 11060: 2.7317286491394044\n",
      "\n",
      " This round's valence_loss=1.3604897260665894, arousal_loss=1.2143492698669434, emotion_loss=0.7793914079666138\n",
      "\n",
      "01_20_01:30:35 Seen so far: 353952 samples\n",
      "\n",
      "01_20_01:30:35 --- 1.7578814029693604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:37 Training loss at epoch 3 step 11070: 2.801870918273926\n",
      "\n",
      " This round's valence_loss=1.2348525524139404, arousal_loss=1.1079691648483276, emotion_loss=0.962538480758667\n",
      "\n",
      "01_20_01:30:37 Seen so far: 354272 samples\n",
      "\n",
      "01_20_01:30:37 --- 1.7238678932189941 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:39 Training loss at epoch 3 step 11080: 2.9357551097869874\n",
      "\n",
      " This round's valence_loss=1.1554639339447021, arousal_loss=1.1428241729736328, emotion_loss=1.0780880451202393\n",
      "\n",
      "01_20_01:30:39 Seen so far: 354592 samples\n",
      "\n",
      "01_20_01:30:39 --- 2.0075767040252686 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:41 Training loss at epoch 3 step 11090: 2.747827577590942\n",
      "\n",
      " This round's valence_loss=0.5865978598594666, arousal_loss=0.45869922637939453, emotion_loss=1.0923705101013184\n",
      "\n",
      "01_20_01:30:41 Seen so far: 354912 samples\n",
      "\n",
      "01_20_01:30:41 --- 1.565474271774292 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:43 Training loss at epoch 3 step 11100: 2.7128671407699585\n",
      "\n",
      " This round's valence_loss=1.3388320207595825, arousal_loss=1.1425334215164185, emotion_loss=0.6578468680381775\n",
      "\n",
      "01_20_01:30:43 Seen so far: 355232 samples\n",
      "\n",
      "01_20_01:30:43 --- 2.004108190536499 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:44 Training loss at epoch 3 step 11110: 2.7394079685211183\n",
      "\n",
      " This round's valence_loss=1.0361976623535156, arousal_loss=0.8489023447036743, emotion_loss=1.323298454284668\n",
      "\n",
      "01_20_01:30:44 Seen so far: 355552 samples\n",
      "\n",
      "01_20_01:30:44 --- 1.6874096393585205 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:46 Training loss at epoch 3 step 11120: 2.8191974997520446\n",
      "\n",
      " This round's valence_loss=0.5585426688194275, arousal_loss=0.5053060054779053, emotion_loss=0.8227051496505737\n",
      "\n",
      "01_20_01:30:46 Seen so far: 355872 samples\n",
      "\n",
      "01_20_01:30:46 --- 1.720646619796753 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:48 Training loss at epoch 3 step 11130: 3.0643052101135253\n",
      "\n",
      " This round's valence_loss=0.9996404647827148, arousal_loss=0.8489264845848083, emotion_loss=1.219933032989502\n",
      "\n",
      "01_20_01:30:48 Seen so far: 356192 samples\n",
      "\n",
      "01_20_01:30:48 --- 1.9421892166137695 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:50 Training loss at epoch 3 step 11140: 3.064676070213318\n",
      "\n",
      " This round's valence_loss=0.7969387769699097, arousal_loss=0.6691591739654541, emotion_loss=0.5958055257797241\n",
      "\n",
      "01_20_01:30:50 Seen so far: 356512 samples\n",
      "\n",
      "01_20_01:30:50 --- 1.685429334640503 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:51 Training loss at epoch 3 step 11150: 2.5801106691360474\n",
      "\n",
      " This round's valence_loss=0.9271759986877441, arousal_loss=0.6791282892227173, emotion_loss=0.6708383560180664\n",
      "\n",
      "01_20_01:30:51 Seen so far: 356832 samples\n",
      "\n",
      "01_20_01:30:51 --- 1.7837684154510498 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:53 Training loss at epoch 3 step 11160: 2.9252938508987425\n",
      "\n",
      " This round's valence_loss=1.1154417991638184, arousal_loss=0.9401163458824158, emotion_loss=0.8750632405281067\n",
      "\n",
      "01_20_01:30:53 Seen so far: 357152 samples\n",
      "\n",
      "01_20_01:30:53 --- 1.7043631076812744 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:55 Training loss at epoch 3 step 11170: 3.094233238697052\n",
      "\n",
      " This round's valence_loss=1.0121443271636963, arousal_loss=0.855826735496521, emotion_loss=1.0427327156066895\n",
      "\n",
      "01_20_01:30:55 Seen so far: 357472 samples\n",
      "\n",
      "01_20_01:30:55 --- 1.8780336380004883 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:57 Training loss at epoch 3 step 11180: 3.011873245239258\n",
      "\n",
      " This round's valence_loss=1.2460923194885254, arousal_loss=1.1050870418548584, emotion_loss=1.203805685043335\n",
      "\n",
      "01_20_01:30:57 Seen so far: 357792 samples\n",
      "\n",
      "01_20_01:30:57 --- 1.6089725494384766 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:30:59 Training loss at epoch 3 step 11190: 3.023708724975586\n",
      "\n",
      " This round's valence_loss=1.1904515027999878, arousal_loss=0.9537171721458435, emotion_loss=1.0092566013336182\n",
      "\n",
      "01_20_01:30:59 Seen so far: 358112 samples\n",
      "\n",
      "01_20_01:30:59 --- 1.944979190826416 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:00 Training loss at epoch 3 step 11200: 2.8858001232147217\n",
      "\n",
      " This round's valence_loss=1.1215198040008545, arousal_loss=0.9463787078857422, emotion_loss=1.2005870342254639\n",
      "\n",
      "01_20_01:31:00 Seen so far: 358432 samples\n",
      "\n",
      "01_20_01:31:00 --- 1.7427654266357422 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:02 Training loss at epoch 3 step 11210: 2.7294891357421873\n",
      "\n",
      " This round's valence_loss=1.332220196723938, arousal_loss=1.2174646854400635, emotion_loss=1.0278571844100952\n",
      "\n",
      "01_20_01:31:02 Seen so far: 358752 samples\n",
      "\n",
      "01_20_01:31:02 --- 1.9152419567108154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:04 Training loss at epoch 3 step 11220: 3.1622486114501953\n",
      "\n",
      " This round's valence_loss=0.9556717872619629, arousal_loss=0.7043343782424927, emotion_loss=0.952170729637146\n",
      "\n",
      "01_20_01:31:04 Seen so far: 359072 samples\n",
      "\n",
      "01_20_01:31:04 --- 1.6642723083496094 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:06 Training loss at epoch 3 step 11230: 3.115580105781555\n",
      "\n",
      " This round's valence_loss=1.3659095764160156, arousal_loss=1.2673351764678955, emotion_loss=0.9665570855140686\n",
      "\n",
      "01_20_01:31:06 Seen so far: 359392 samples\n",
      "\n",
      "01_20_01:31:06 --- 1.6876466274261475 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:07 Training loss at epoch 3 step 11240: 3.095800757408142\n",
      "\n",
      " This round's valence_loss=0.9441922307014465, arousal_loss=0.923676609992981, emotion_loss=0.8027205467224121\n",
      "\n",
      "01_20_01:31:07 Seen so far: 359712 samples\n",
      "\n",
      "01_20_01:31:07 --- 1.7913451194763184 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:09 Training loss at epoch 3 step 11250: 2.815784454345703\n",
      "\n",
      " This round's valence_loss=0.8045399188995361, arousal_loss=0.756431519985199, emotion_loss=0.9622825980186462\n",
      "\n",
      "01_20_01:31:09 Seen so far: 360032 samples\n",
      "\n",
      "01_20_01:31:09 --- 1.666994571685791 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:11 Training loss at epoch 3 step 11260: 3.26447389125824\n",
      "\n",
      " This round's valence_loss=1.4555549621582031, arousal_loss=1.3282139301300049, emotion_loss=0.9720854759216309\n",
      "\n",
      "01_20_01:31:11 Seen so far: 360352 samples\n",
      "\n",
      "01_20_01:31:11 --- 1.7343881130218506 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:12 Training loss at epoch 3 step 11270: 2.7950279712677\n",
      "\n",
      " This round's valence_loss=0.683547854423523, arousal_loss=0.6883805990219116, emotion_loss=1.0037527084350586\n",
      "\n",
      "01_20_01:31:12 Seen so far: 360672 samples\n",
      "\n",
      "01_20_01:31:12 --- 1.735703706741333 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:14 Training loss at epoch 3 step 11280: 2.6779866814613342\n",
      "\n",
      " This round's valence_loss=1.546460747718811, arousal_loss=1.442591667175293, emotion_loss=0.9865977764129639\n",
      "\n",
      "01_20_01:31:14 Seen so far: 360992 samples\n",
      "\n",
      "01_20_01:31:14 --- 1.6749773025512695 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:16 Training loss at epoch 3 step 11290: 2.8530576467514037\n",
      "\n",
      " This round's valence_loss=0.8274353742599487, arousal_loss=0.7049557566642761, emotion_loss=1.0993133783340454\n",
      "\n",
      "01_20_01:31:16 Seen so far: 361312 samples\n",
      "\n",
      "01_20_01:31:16 --- 1.7368793487548828 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:18 Training loss at epoch 3 step 11300: 2.746363806724548\n",
      "\n",
      " This round's valence_loss=0.6136665940284729, arousal_loss=0.504839301109314, emotion_loss=1.0317555665969849\n",
      "\n",
      "01_20_01:31:18 Seen so far: 361632 samples\n",
      "\n",
      "01_20_01:31:18 --- 1.8402178287506104 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:20 Training loss at epoch 3 step 11310: 2.9007788419723513\n",
      "\n",
      " This round's valence_loss=0.8130170106887817, arousal_loss=0.7597478032112122, emotion_loss=0.6863741874694824\n",
      "\n",
      "01_20_01:31:20 Seen so far: 361952 samples\n",
      "\n",
      "01_20_01:31:20 --- 1.9150722026824951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:21 Training loss at epoch 3 step 11320: 3.2212476253509523\n",
      "\n",
      " This round's valence_loss=1.2301409244537354, arousal_loss=1.0398544073104858, emotion_loss=0.611164927482605\n",
      "\n",
      "01_20_01:31:21 Seen so far: 362272 samples\n",
      "\n",
      "01_20_01:31:21 --- 1.6743206977844238 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:23 Training loss at epoch 3 step 11330: 2.9376893997192384\n",
      "\n",
      " This round's valence_loss=0.9265048503875732, arousal_loss=0.7381287813186646, emotion_loss=0.9060732126235962\n",
      "\n",
      "01_20_01:31:23 Seen so far: 362592 samples\n",
      "\n",
      "01_20_01:31:23 --- 1.7059381008148193 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:25 Training loss at epoch 3 step 11340: 2.4890599489212035\n",
      "\n",
      " This round's valence_loss=0.7011013627052307, arousal_loss=0.558288037776947, emotion_loss=1.030782699584961\n",
      "\n",
      "01_20_01:31:25 Seen so far: 362912 samples\n",
      "\n",
      "01_20_01:31:25 --- 1.757375955581665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:27 Training loss at epoch 3 step 11350: 2.824093198776245\n",
      "\n",
      " This round's valence_loss=1.3551793098449707, arousal_loss=1.0485594272613525, emotion_loss=1.006089210510254\n",
      "\n",
      "01_20_01:31:27 Seen so far: 363232 samples\n",
      "\n",
      "01_20_01:31:27 --- 1.786421775817871 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:28 Training loss at epoch 3 step 11360: 2.42560476064682\n",
      "\n",
      " This round's valence_loss=0.8345999717712402, arousal_loss=0.5349562764167786, emotion_loss=0.7264296412467957\n",
      "\n",
      "01_20_01:31:28 Seen so far: 363552 samples\n",
      "\n",
      "01_20_01:31:28 --- 1.6677074432373047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:30 Training loss at epoch 3 step 11370: 3.257833385467529\n",
      "\n",
      " This round's valence_loss=1.693404197692871, arousal_loss=1.6063807010650635, emotion_loss=1.2045793533325195\n",
      "\n",
      "01_20_01:31:30 Seen so far: 363872 samples\n",
      "\n",
      "01_20_01:31:30 --- 1.715311050415039 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:32 Training loss at epoch 3 step 11380: 3.023821401596069\n",
      "\n",
      " This round's valence_loss=1.14247727394104, arousal_loss=0.9566484689712524, emotion_loss=0.6252295970916748\n",
      "\n",
      "01_20_01:31:32 Seen so far: 364192 samples\n",
      "\n",
      "01_20_01:31:32 --- 1.8030364513397217 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:33 Training loss at epoch 3 step 11390: 2.8809303760528566\n",
      "\n",
      " This round's valence_loss=1.112684726715088, arousal_loss=0.9855659604072571, emotion_loss=0.8888694643974304\n",
      "\n",
      "01_20_01:31:33 Seen so far: 364512 samples\n",
      "\n",
      "01_20_01:31:33 --- 1.698516607284546 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:35 Training loss at epoch 3 step 11400: 2.8494237661361694\n",
      "\n",
      " This round's valence_loss=1.1214962005615234, arousal_loss=0.9422388076782227, emotion_loss=0.9757004976272583\n",
      "\n",
      "01_20_01:31:35 Seen so far: 364832 samples\n",
      "\n",
      "01_20_01:31:35 --- 2.040654182434082 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:37 Training loss at epoch 3 step 11410: 2.972585666179657\n",
      "\n",
      " This round's valence_loss=0.3388742208480835, arousal_loss=0.1586306095123291, emotion_loss=1.0388469696044922\n",
      "\n",
      "01_20_01:31:37 Seen so far: 365152 samples\n",
      "\n",
      "01_20_01:31:37 --- 1.8413991928100586 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:39 Training loss at epoch 3 step 11420: 3.2257536172866823\n",
      "\n",
      " This round's valence_loss=1.3437178134918213, arousal_loss=1.179905891418457, emotion_loss=0.934535562992096\n",
      "\n",
      "01_20_01:31:39 Seen so far: 365472 samples\n",
      "\n",
      "01_20_01:31:39 --- 1.654724359512329 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:41 Training loss at epoch 3 step 11430: 3.0505277156829833\n",
      "\n",
      " This round's valence_loss=1.1431810855865479, arousal_loss=0.9256840944290161, emotion_loss=1.0980546474456787\n",
      "\n",
      "01_20_01:31:41 Seen so far: 365792 samples\n",
      "\n",
      "01_20_01:31:41 --- 1.9044876098632812 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:43 Training loss at epoch 3 step 11440: 2.816035568714142\n",
      "\n",
      " This round's valence_loss=1.0826029777526855, arousal_loss=0.9307519793510437, emotion_loss=0.9986635446548462\n",
      "\n",
      "01_20_01:31:43 Seen so far: 366112 samples\n",
      "\n",
      "01_20_01:31:43 --- 1.783717393875122 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:44 Training loss at epoch 3 step 11450: 2.7450405955314636\n",
      "\n",
      " This round's valence_loss=1.2906620502471924, arousal_loss=1.1803793907165527, emotion_loss=0.7789095640182495\n",
      "\n",
      "01_20_01:31:44 Seen so far: 366432 samples\n",
      "\n",
      "01_20_01:31:44 --- 1.8084406852722168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:46 Training loss at epoch 3 step 11460: 3.0790056228637694\n",
      "\n",
      " This round's valence_loss=1.2671260833740234, arousal_loss=1.2011466026306152, emotion_loss=0.4735960364341736\n",
      "\n",
      "01_20_01:31:46 Seen so far: 366752 samples\n",
      "\n",
      "01_20_01:31:46 --- 1.8240375518798828 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:48 Training loss at epoch 3 step 11470: 2.896381068229675\n",
      "\n",
      " This round's valence_loss=1.1724448204040527, arousal_loss=1.117243766784668, emotion_loss=0.8247617483139038\n",
      "\n",
      "01_20_01:31:48 Seen so far: 367072 samples\n",
      "\n",
      "01_20_01:31:48 --- 1.7402172088623047 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:50 Training loss at epoch 3 step 11480: 2.948155069351196\n",
      "\n",
      " This round's valence_loss=1.2026519775390625, arousal_loss=1.105882167816162, emotion_loss=0.8214255571365356\n",
      "\n",
      "01_20_01:31:50 Seen so far: 367392 samples\n",
      "\n",
      "01_20_01:31:50 --- 1.806539535522461 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:52 Training loss at epoch 3 step 11490: 3.448100447654724\n",
      "\n",
      " This round's valence_loss=1.188326358795166, arousal_loss=1.111568808555603, emotion_loss=0.9949707388877869\n",
      "\n",
      "01_20_01:31:52 Seen so far: 367712 samples\n",
      "\n",
      "01_20_01:31:52 --- 1.7568891048431396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:53 Training loss at epoch 3 step 11500: 2.807856869697571\n",
      "\n",
      " This round's valence_loss=0.8581173419952393, arousal_loss=0.725793719291687, emotion_loss=0.8977747559547424\n",
      "\n",
      "01_20_01:31:53 Seen so far: 368032 samples\n",
      "\n",
      "01_20_01:31:53 --- 1.8545074462890625 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:55 Training loss at epoch 3 step 11510: 3.162328362464905\n",
      "\n",
      " This round's valence_loss=1.6078081130981445, arousal_loss=1.4395891427993774, emotion_loss=1.2130004167556763\n",
      "\n",
      "01_20_01:31:55 Seen so far: 368352 samples\n",
      "\n",
      "01_20_01:31:55 --- 1.733090877532959 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:57 Training loss at epoch 3 step 11520: 3.1838337659835814\n",
      "\n",
      " This round's valence_loss=1.1388823986053467, arousal_loss=0.9313490390777588, emotion_loss=0.8022065758705139\n",
      "\n",
      "01_20_01:31:57 Seen so far: 368672 samples\n",
      "\n",
      "01_20_01:31:57 --- 1.8889589309692383 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:31:59 Training loss at epoch 3 step 11530: 2.7637498140335084\n",
      "\n",
      " This round's valence_loss=1.3017586469650269, arousal_loss=1.2021411657333374, emotion_loss=0.9121770262718201\n",
      "\n",
      "01_20_01:31:59 Seen so far: 368992 samples\n",
      "\n",
      "01_20_01:31:59 --- 2.056591033935547 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:01 Training loss at epoch 3 step 11540: 2.7707547903060914\n",
      "\n",
      " This round's valence_loss=1.2722580432891846, arousal_loss=1.1081502437591553, emotion_loss=0.9949334859848022\n",
      "\n",
      "01_20_01:32:01 Seen so far: 369312 samples\n",
      "\n",
      "01_20_01:32:01 --- 1.8919501304626465 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:03 Training loss at epoch 3 step 11550: 2.793516993522644\n",
      "\n",
      " This round's valence_loss=0.7322028875350952, arousal_loss=0.6714528799057007, emotion_loss=0.9762681126594543\n",
      "\n",
      "01_20_01:32:03 Seen so far: 369632 samples\n",
      "\n",
      "01_20_01:32:03 --- 1.7543437480926514 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:05 Training loss at epoch 3 step 11560: 3.0675166130065916\n",
      "\n",
      " This round's valence_loss=0.9781773686408997, arousal_loss=0.8340147137641907, emotion_loss=0.7363958954811096\n",
      "\n",
      "01_20_01:32:05 Seen so far: 369952 samples\n",
      "\n",
      "01_20_01:32:05 --- 1.7256901264190674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:06 Training loss at epoch 3 step 11570: 3.0399886846542357\n",
      "\n",
      " This round's valence_loss=1.0058739185333252, arousal_loss=0.8753455877304077, emotion_loss=1.0461190938949585\n",
      "\n",
      "01_20_01:32:06 Seen so far: 370272 samples\n",
      "\n",
      "01_20_01:32:06 --- 1.950169563293457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:08 Training loss at epoch 3 step 11580: 2.890113019943237\n",
      "\n",
      " This round's valence_loss=1.4991912841796875, arousal_loss=1.324462652206421, emotion_loss=0.8892332315444946\n",
      "\n",
      "01_20_01:32:08 Seen so far: 370592 samples\n",
      "\n",
      "01_20_01:32:08 --- 1.6923327445983887 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:10 Training loss at epoch 3 step 11590: 2.906978392601013\n",
      "\n",
      " This round's valence_loss=0.7468309998512268, arousal_loss=0.625048041343689, emotion_loss=0.7009550333023071\n",
      "\n",
      "01_20_01:32:10 Seen so far: 370912 samples\n",
      "\n",
      "01_20_01:32:10 --- 1.73508882522583 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:12 Training loss at epoch 3 step 11600: 2.880715584754944\n",
      "\n",
      " This round's valence_loss=1.2006064653396606, arousal_loss=1.1013857126235962, emotion_loss=1.1805623769760132\n",
      "\n",
      "01_20_01:32:12 Seen so far: 371232 samples\n",
      "\n",
      "01_20_01:32:12 --- 1.9819605350494385 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:14 Training loss at epoch 3 step 11610: 2.6813472032547\n",
      "\n",
      " This round's valence_loss=0.9449163675308228, arousal_loss=0.8005135655403137, emotion_loss=0.6544060707092285\n",
      "\n",
      "01_20_01:32:14 Seen so far: 371552 samples\n",
      "\n",
      "01_20_01:32:14 --- 1.7177433967590332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:16 Training loss at epoch 3 step 11620: 3.044110870361328\n",
      "\n",
      " This round's valence_loss=1.2746765613555908, arousal_loss=1.2051280736923218, emotion_loss=0.8588989973068237\n",
      "\n",
      "01_20_01:32:16 Seen so far: 371872 samples\n",
      "\n",
      "01_20_01:32:16 --- 1.9163448810577393 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:17 Training loss at epoch 3 step 11630: 3.217450499534607\n",
      "\n",
      " This round's valence_loss=1.4266853332519531, arousal_loss=1.3301044702529907, emotion_loss=0.9308812618255615\n",
      "\n",
      "01_20_01:32:17 Seen so far: 372192 samples\n",
      "\n",
      "01_20_01:32:17 --- 1.660672903060913 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:19 Training loss at epoch 3 step 11640: 2.8493000745773314\n",
      "\n",
      " This round's valence_loss=1.0892490148544312, arousal_loss=0.9771943688392639, emotion_loss=0.8249945044517517\n",
      "\n",
      "01_20_01:32:19 Seen so far: 372512 samples\n",
      "\n",
      "01_20_01:32:19 --- 1.7941482067108154 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:21 Training loss at epoch 3 step 11650: 3.037510800361633\n",
      "\n",
      " This round's valence_loss=0.912866473197937, arousal_loss=0.8981657028198242, emotion_loss=1.096894383430481\n",
      "\n",
      "01_20_01:32:21 Seen so far: 372832 samples\n",
      "\n",
      "01_20_01:32:21 --- 1.7151594161987305 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:22 Training loss at epoch 3 step 11660: 3.210196650028229\n",
      "\n",
      " This round's valence_loss=1.818895697593689, arousal_loss=1.6540558338165283, emotion_loss=0.7822510004043579\n",
      "\n",
      "01_20_01:32:22 Seen so far: 373152 samples\n",
      "\n",
      "01_20_01:32:22 --- 1.7315402030944824 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:24 Training loss at epoch 3 step 11670: 3.1249724864959716\n",
      "\n",
      " This round's valence_loss=1.035236120223999, arousal_loss=0.8657447099685669, emotion_loss=0.5718258023262024\n",
      "\n",
      "01_20_01:32:24 Seen so far: 373472 samples\n",
      "\n",
      "01_20_01:32:24 --- 1.675691843032837 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:26 Training loss at epoch 3 step 11680: 2.9477484941482546\n",
      "\n",
      " This round's valence_loss=1.3652093410491943, arousal_loss=1.203598976135254, emotion_loss=0.9972330331802368\n",
      "\n",
      "01_20_01:32:26 Seen so far: 373792 samples\n",
      "\n",
      "01_20_01:32:26 --- 1.8673532009124756 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:28 Training loss at epoch 3 step 11690: 3.2294495820999147\n",
      "\n",
      " This round's valence_loss=1.0151294469833374, arousal_loss=0.8305994868278503, emotion_loss=0.8239301443099976\n",
      "\n",
      "01_20_01:32:28 Seen so far: 374112 samples\n",
      "\n",
      "01_20_01:32:28 --- 1.8082363605499268 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:29 Training loss at epoch 3 step 11700: 2.8201733112335203\n",
      "\n",
      " This round's valence_loss=0.8000304698944092, arousal_loss=0.6998136043548584, emotion_loss=1.2975897789001465\n",
      "\n",
      "01_20_01:32:29 Seen so far: 374432 samples\n",
      "\n",
      "01_20_01:32:29 --- 1.6821959018707275 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:31 Training loss at epoch 3 step 11710: 3.2044644355773926\n",
      "\n",
      " This round's valence_loss=1.2106761932373047, arousal_loss=1.1246249675750732, emotion_loss=1.0794222354888916\n",
      "\n",
      "01_20_01:32:31 Seen so far: 374752 samples\n",
      "\n",
      "01_20_01:32:31 --- 1.691981554031372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:33 Training loss at epoch 3 step 11720: 3.003233027458191\n",
      "\n",
      " This round's valence_loss=0.7970572710037231, arousal_loss=0.804146409034729, emotion_loss=1.1346931457519531\n",
      "\n",
      "01_20_01:32:33 Seen so far: 375072 samples\n",
      "\n",
      "01_20_01:32:33 --- 1.8716742992401123 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:35 Training loss at epoch 3 step 11730: 2.4272406578063963\n",
      "\n",
      " This round's valence_loss=0.6255711317062378, arousal_loss=0.45653823018074036, emotion_loss=1.0422284603118896\n",
      "\n",
      "01_20_01:32:35 Seen so far: 375392 samples\n",
      "\n",
      "01_20_01:32:35 --- 1.9375255107879639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:37 Training loss at epoch 3 step 11740: 2.9520532369613646\n",
      "\n",
      " This round's valence_loss=1.2310662269592285, arousal_loss=1.0959789752960205, emotion_loss=1.183337926864624\n",
      "\n",
      "01_20_01:32:37 Seen so far: 375712 samples\n",
      "\n",
      "01_20_01:32:37 --- 1.7880549430847168 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:39 Training loss at epoch 3 step 11750: 2.9880247354507445\n",
      "\n",
      " This round's valence_loss=1.0381028652191162, arousal_loss=0.8365864753723145, emotion_loss=0.6715714931488037\n",
      "\n",
      "01_20_01:32:39 Seen so far: 376032 samples\n",
      "\n",
      "01_20_01:32:39 --- 1.9418694972991943 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:41 Training loss at epoch 3 step 11760: 2.6447686433792112\n",
      "\n",
      " This round's valence_loss=1.1473511457443237, arousal_loss=0.9465128779411316, emotion_loss=0.338889479637146\n",
      "\n",
      "01_20_01:32:41 Seen so far: 376352 samples\n",
      "\n",
      "01_20_01:32:41 --- 1.9399263858795166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:42 Training loss at epoch 3 step 11770: 2.9203875064849854\n",
      "\n",
      " This round's valence_loss=1.0225021839141846, arousal_loss=0.776877760887146, emotion_loss=0.7844074964523315\n",
      "\n",
      "01_20_01:32:42 Seen so far: 376672 samples\n",
      "\n",
      "01_20_01:32:42 --- 1.76869797706604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:44 Training loss at epoch 3 step 11780: 2.527668297290802\n",
      "\n",
      " This round's valence_loss=1.1122963428497314, arousal_loss=0.9512429237365723, emotion_loss=0.798152506351471\n",
      "\n",
      "01_20_01:32:44 Seen so far: 376992 samples\n",
      "\n",
      "01_20_01:32:44 --- 1.891505241394043 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:46 Training loss at epoch 3 step 11790: 3.0091472864151\n",
      "\n",
      " This round's valence_loss=1.4442846775054932, arousal_loss=1.309619665145874, emotion_loss=1.1042370796203613\n",
      "\n",
      "01_20_01:32:46 Seen so far: 377312 samples\n",
      "\n",
      "01_20_01:32:46 --- 1.849961757659912 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:48 Training loss at epoch 3 step 11800: 2.797516345977783\n",
      "\n",
      " This round's valence_loss=0.9512032270431519, arousal_loss=0.828544020652771, emotion_loss=0.9188011884689331\n",
      "\n",
      "01_20_01:32:48 Seen so far: 377632 samples\n",
      "\n",
      "01_20_01:32:48 --- 1.740891933441162 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:50 Training loss at epoch 3 step 11810: 2.7299631953239443\n",
      "\n",
      " This round's valence_loss=0.7551736831665039, arousal_loss=0.5491578578948975, emotion_loss=0.5673571825027466\n",
      "\n",
      "01_20_01:32:50 Seen so far: 377952 samples\n",
      "\n",
      "01_20_01:32:50 --- 1.8788039684295654 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:51 Training loss at epoch 3 step 11820: 3.0061431646347048\n",
      "\n",
      " This round's valence_loss=1.452136754989624, arousal_loss=1.3292205333709717, emotion_loss=0.9282364845275879\n",
      "\n",
      "01_20_01:32:51 Seen so far: 378272 samples\n",
      "\n",
      "01_20_01:32:51 --- 1.6478142738342285 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:53 Training loss at epoch 3 step 11830: 2.8363691568374634\n",
      "\n",
      " This round's valence_loss=1.4245765209197998, arousal_loss=1.3039813041687012, emotion_loss=1.170154333114624\n",
      "\n",
      "01_20_01:32:53 Seen so far: 378592 samples\n",
      "\n",
      "01_20_01:32:53 --- 1.748774528503418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:55 Training loss at epoch 3 step 11840: 3.212720251083374\n",
      "\n",
      " This round's valence_loss=0.7990838289260864, arousal_loss=0.7047597169876099, emotion_loss=0.6536459922790527\n",
      "\n",
      "01_20_01:32:55 Seen so far: 378912 samples\n",
      "\n",
      "01_20_01:32:55 --- 1.816899299621582 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:57 Training loss at epoch 3 step 11850: 3.2882012605667112\n",
      "\n",
      " This round's valence_loss=1.2046270370483398, arousal_loss=0.9567395448684692, emotion_loss=0.8331706523895264\n",
      "\n",
      "01_20_01:32:57 Seen so far: 379232 samples\n",
      "\n",
      "01_20_01:32:57 --- 1.6340348720550537 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:32:58 Training loss at epoch 3 step 11860: 3.033778738975525\n",
      "\n",
      " This round's valence_loss=1.4243278503417969, arousal_loss=1.3091516494750977, emotion_loss=0.8263047933578491\n",
      "\n",
      "01_20_01:32:58 Seen so far: 379552 samples\n",
      "\n",
      "01_20_01:32:58 --- 1.889571189880371 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:00 Training loss at epoch 3 step 11870: 2.7401798248291014\n",
      "\n",
      " This round's valence_loss=0.6511809229850769, arousal_loss=0.6241160035133362, emotion_loss=0.9705907702445984\n",
      "\n",
      "01_20_01:33:00 Seen so far: 379872 samples\n",
      "\n",
      "01_20_01:33:00 --- 1.6976850032806396 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:02 Training loss at epoch 3 step 11880: 2.8648496747016905\n",
      "\n",
      " This round's valence_loss=1.0648075342178345, arousal_loss=0.9958236217498779, emotion_loss=1.1006193161010742\n",
      "\n",
      "01_20_01:33:02 Seen so far: 380192 samples\n",
      "\n",
      "01_20_01:33:02 --- 1.7691402435302734 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:04 Training loss at epoch 3 step 11890: 3.0568795919418337\n",
      "\n",
      " This round's valence_loss=1.1057846546173096, arousal_loss=1.0215095281600952, emotion_loss=0.8414875268936157\n",
      "\n",
      "01_20_01:33:04 Seen so far: 380512 samples\n",
      "\n",
      "01_20_01:33:04 --- 1.6860413551330566 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:05 Training loss at epoch 3 step 11900: 2.735551965236664\n",
      "\n",
      " This round's valence_loss=0.7435808181762695, arousal_loss=0.563724160194397, emotion_loss=0.647195041179657\n",
      "\n",
      "01_20_01:33:05 Seen so far: 380832 samples\n",
      "\n",
      "01_20_01:33:05 --- 1.6981055736541748 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:07 Training loss at epoch 3 step 11910: 2.9833911418914796\n",
      "\n",
      " This round's valence_loss=1.5059560537338257, arousal_loss=1.2842166423797607, emotion_loss=0.6666306853294373\n",
      "\n",
      "01_20_01:33:07 Seen so far: 381152 samples\n",
      "\n",
      "01_20_01:33:07 --- 1.9509608745574951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:09 Training loss at epoch 3 step 11920: 2.8208669662475585\n",
      "\n",
      " This round's valence_loss=1.0625038146972656, arousal_loss=0.9860831499099731, emotion_loss=0.6716784238815308\n",
      "\n",
      "01_20_01:33:09 Seen so far: 381472 samples\n",
      "\n",
      "01_20_01:33:09 --- 1.9791076183319092 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:11 Training loss at epoch 3 step 11930: 2.9937594413757322\n",
      "\n",
      " This round's valence_loss=0.955584704875946, arousal_loss=0.8574466109275818, emotion_loss=0.7007824778556824\n",
      "\n",
      "01_20_01:33:11 Seen so far: 381792 samples\n",
      "\n",
      "01_20_01:33:11 --- 1.6708159446716309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:13 Training loss at epoch 3 step 11940: 2.7965244174003603\n",
      "\n",
      " This round's valence_loss=1.5933985710144043, arousal_loss=1.4628374576568604, emotion_loss=0.9256885051727295\n",
      "\n",
      "01_20_01:33:13 Seen so far: 382112 samples\n",
      "\n",
      "01_20_01:33:13 --- 1.7881131172180176 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:14 Training loss at epoch 3 step 11950: 3.1835304260253907\n",
      "\n",
      " This round's valence_loss=1.2632519006729126, arousal_loss=1.1689891815185547, emotion_loss=0.9684985876083374\n",
      "\n",
      "01_20_01:33:14 Seen so far: 382432 samples\n",
      "\n",
      "01_20_01:33:14 --- 1.7752010822296143 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:17 Training loss at epoch 3 step 11960: 2.9235934734344484\n",
      "\n",
      " This round's valence_loss=1.283125877380371, arousal_loss=1.0761948823928833, emotion_loss=0.6959837675094604\n",
      "\n",
      "01_20_01:33:17 Seen so far: 382752 samples\n",
      "\n",
      "01_20_01:33:17 --- 2.1562607288360596 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:18 Training loss at epoch 3 step 11970: 2.9666627287864684\n",
      "\n",
      " This round's valence_loss=0.5995616912841797, arousal_loss=0.5054816603660583, emotion_loss=0.8634145855903625\n",
      "\n",
      "01_20_01:33:18 Seen so far: 383072 samples\n",
      "\n",
      "01_20_01:33:18 --- 1.8050484657287598 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:20 Training loss at epoch 3 step 11980: 2.766952300071716\n",
      "\n",
      " This round's valence_loss=1.095754861831665, arousal_loss=0.9619119167327881, emotion_loss=1.0611381530761719\n",
      "\n",
      "01_20_01:33:20 Seen so far: 383392 samples\n",
      "\n",
      "01_20_01:33:20 --- 1.8725204467773438 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:22 Training loss at epoch 3 step 11990: 3.034997797012329\n",
      "\n",
      " This round's valence_loss=1.0481853485107422, arousal_loss=0.9405885338783264, emotion_loss=0.7193704843521118\n",
      "\n",
      "01_20_01:33:22 Seen so far: 383712 samples\n",
      "\n",
      "01_20_01:33:22 --- 1.6631107330322266 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:24 Training loss at epoch 3 step 12000: 2.662077283859253\n",
      "\n",
      " This round's valence_loss=1.0486770868301392, arousal_loss=0.8011130094528198, emotion_loss=0.747764527797699\n",
      "\n",
      "01_20_01:33:24 Seen so far: 384032 samples\n",
      "\n",
      "01_20_01:33:24 --- 1.763869285583496 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:26 Training loss at epoch 3 step 12010: 3.0250208377838135\n",
      "\n",
      " This round's valence_loss=1.152750015258789, arousal_loss=1.0971299409866333, emotion_loss=0.9446201920509338\n",
      "\n",
      "01_20_01:33:26 Seen so far: 384352 samples\n",
      "\n",
      "01_20_01:33:26 --- 1.7521412372589111 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:27 Training loss at epoch 3 step 12020: 3.0047150611877442\n",
      "\n",
      " This round's valence_loss=0.899287760257721, arousal_loss=0.7021563053131104, emotion_loss=0.8470994234085083\n",
      "\n",
      "01_20_01:33:27 Seen so far: 384672 samples\n",
      "\n",
      "01_20_01:33:27 --- 1.7417559623718262 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:29 Training loss at epoch 3 step 12030: 2.9112728357315065\n",
      "\n",
      " This round's valence_loss=1.1226451396942139, arousal_loss=0.9412280917167664, emotion_loss=0.5912574529647827\n",
      "\n",
      "01_20_01:33:29 Seen so far: 384992 samples\n",
      "\n",
      "01_20_01:33:29 --- 1.9476890563964844 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:31 Training loss at epoch 3 step 12040: 2.4913589119911195\n",
      "\n",
      " This round's valence_loss=1.3241016864776611, arousal_loss=1.2712509632110596, emotion_loss=1.133355736732483\n",
      "\n",
      "01_20_01:33:31 Seen so far: 385312 samples\n",
      "\n",
      "01_20_01:33:31 --- 1.8473589420318604 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:33 Training loss at epoch 3 step 12050: 2.7227270126342775\n",
      "\n",
      " This round's valence_loss=0.9214745759963989, arousal_loss=0.7069333791732788, emotion_loss=0.7806931138038635\n",
      "\n",
      "01_20_01:33:33 Seen so far: 385632 samples\n",
      "\n",
      "01_20_01:33:33 --- 1.765423059463501 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:35 Training loss at epoch 3 step 12060: 3.237655591964722\n",
      "\n",
      " This round's valence_loss=1.3338398933410645, arousal_loss=1.2022666931152344, emotion_loss=1.0579824447631836\n",
      "\n",
      "01_20_01:33:35 Seen so far: 385952 samples\n",
      "\n",
      "01_20_01:33:35 --- 1.710768461227417 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:36 Training loss at epoch 3 step 12070: 2.8751794338226317\n",
      "\n",
      " This round's valence_loss=1.0867559909820557, arousal_loss=0.9340940713882446, emotion_loss=0.8516453504562378\n",
      "\n",
      "01_20_01:33:36 Seen so far: 386272 samples\n",
      "\n",
      "01_20_01:33:36 --- 1.8287205696105957 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:38 Training loss at epoch 3 step 12080: 3.155742883682251\n",
      "\n",
      " This round's valence_loss=0.8988394141197205, arousal_loss=0.5631074905395508, emotion_loss=1.3818188905715942\n",
      "\n",
      "01_20_01:33:38 Seen so far: 386592 samples\n",
      "\n",
      "01_20_01:33:38 --- 1.7301077842712402 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:40 Training loss at epoch 3 step 12090: 3.107803964614868\n",
      "\n",
      " This round's valence_loss=1.4391493797302246, arousal_loss=1.3395037651062012, emotion_loss=1.1346076726913452\n",
      "\n",
      "01_20_01:33:40 Seen so far: 386912 samples\n",
      "\n",
      "01_20_01:33:40 --- 1.6184971332550049 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:41 Training loss at epoch 3 step 12100: 2.8955537557601927\n",
      "\n",
      " This round's valence_loss=0.7740360498428345, arousal_loss=0.577306866645813, emotion_loss=0.8498414158821106\n",
      "\n",
      "01_20_01:33:41 Seen so far: 387232 samples\n",
      "\n",
      "01_20_01:33:41 --- 1.738985538482666 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:43 Training loss at epoch 3 step 12110: 2.928168797492981\n",
      "\n",
      " This round's valence_loss=1.2746765613555908, arousal_loss=1.0482878684997559, emotion_loss=0.913615345954895\n",
      "\n",
      "01_20_01:33:43 Seen so far: 387552 samples\n",
      "\n",
      "01_20_01:33:43 --- 1.6397745609283447 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:45 Training loss at epoch 3 step 12120: 2.940643882751465\n",
      "\n",
      " This round's valence_loss=1.533402681350708, arousal_loss=1.479196310043335, emotion_loss=0.8784332871437073\n",
      "\n",
      "01_20_01:33:45 Seen so far: 387872 samples\n",
      "\n",
      "01_20_01:33:45 --- 1.7420811653137207 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:47 Training loss at epoch 3 step 12130: 2.870123839378357\n",
      "\n",
      " This round's valence_loss=1.121585726737976, arousal_loss=0.9657142162322998, emotion_loss=1.085455298423767\n",
      "\n",
      "01_20_01:33:47 Seen so far: 388192 samples\n",
      "\n",
      "01_20_01:33:47 --- 1.7969427108764648 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:48 Training loss at epoch 3 step 12140: 2.8090653657913207\n",
      "\n",
      " This round's valence_loss=1.0759443044662476, arousal_loss=0.9640160202980042, emotion_loss=1.2132976055145264\n",
      "\n",
      "01_20_01:33:48 Seen so far: 388512 samples\n",
      "\n",
      "01_20_01:33:48 --- 1.7807438373565674 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:50 Training loss at epoch 3 step 12150: 2.7671449899673464\n",
      "\n",
      " This round's valence_loss=1.5163339376449585, arousal_loss=1.3245437145233154, emotion_loss=0.6328083276748657\n",
      "\n",
      "01_20_01:33:50 Seen so far: 388832 samples\n",
      "\n",
      "01_20_01:33:50 --- 1.9005730152130127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:52 Training loss at epoch 3 step 12160: 3.2643820524215696\n",
      "\n",
      " This round's valence_loss=1.7864453792572021, arousal_loss=1.548179030418396, emotion_loss=0.7347148656845093\n",
      "\n",
      "01_20_01:33:52 Seen so far: 389152 samples\n",
      "\n",
      "01_20_01:33:52 --- 1.8466370105743408 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:54 Training loss at epoch 3 step 12170: 2.85779983997345\n",
      "\n",
      " This round's valence_loss=0.7657749652862549, arousal_loss=0.5819672346115112, emotion_loss=0.8310970664024353\n",
      "\n",
      "01_20_01:33:54 Seen so far: 389472 samples\n",
      "\n",
      "01_20_01:33:54 --- 1.7348887920379639 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:56 Training loss at epoch 3 step 12180: 2.7371121406555177\n",
      "\n",
      " This round's valence_loss=0.9753713607788086, arousal_loss=0.8110411167144775, emotion_loss=0.4077034890651703\n",
      "\n",
      "01_20_01:33:56 Seen so far: 389792 samples\n",
      "\n",
      "01_20_01:33:56 --- 1.628641128540039 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:58 Training loss at epoch 3 step 12190: 2.9895962953567503\n",
      "\n",
      " This round's valence_loss=0.8689931035041809, arousal_loss=0.6893060803413391, emotion_loss=0.7057003974914551\n",
      "\n",
      "01_20_01:33:58 Seen so far: 390112 samples\n",
      "\n",
      "01_20_01:33:58 --- 2.112360954284668 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:33:59 Training loss at epoch 3 step 12200: 2.971877646446228\n",
      "\n",
      " This round's valence_loss=1.1234838962554932, arousal_loss=0.9413367509841919, emotion_loss=0.9563072919845581\n",
      "\n",
      "01_20_01:33:59 Seen so far: 390432 samples\n",
      "\n",
      "01_20_01:33:59 --- 1.737274169921875 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:01 Training loss at epoch 3 step 12210: 2.6240063190460203\n",
      "\n",
      " This round's valence_loss=0.7166074514389038, arousal_loss=0.5946694612503052, emotion_loss=1.0242215394973755\n",
      "\n",
      "01_20_01:34:01 Seen so far: 390752 samples\n",
      "\n",
      "01_20_01:34:01 --- 1.8379631042480469 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:03 Training loss at epoch 3 step 12220: 3.2989394903182983\n",
      "\n",
      " This round's valence_loss=1.0647985935211182, arousal_loss=0.8626210689544678, emotion_loss=0.6615577936172485\n",
      "\n",
      "01_20_01:34:03 Seen so far: 391072 samples\n",
      "\n",
      "01_20_01:34:03 --- 1.535491943359375 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:04 Training loss at epoch 3 step 12230: 2.939589190483093\n",
      "\n",
      " This round's valence_loss=0.9471095204353333, arousal_loss=0.7979880571365356, emotion_loss=0.7538235187530518\n",
      "\n",
      "01_20_01:34:04 Seen so far: 391392 samples\n",
      "\n",
      "01_20_01:34:04 --- 1.7445247173309326 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:06 Training loss at epoch 3 step 12240: 2.871745753288269\n",
      "\n",
      " This round's valence_loss=1.2671291828155518, arousal_loss=1.0985219478607178, emotion_loss=0.8901126384735107\n",
      "\n",
      "01_20_01:34:06 Seen so far: 391712 samples\n",
      "\n",
      "01_20_01:34:06 --- 1.7592952251434326 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:08 Training loss at epoch 3 step 12250: 3.0939717292785645\n",
      "\n",
      " This round's valence_loss=1.5039831399917603, arousal_loss=1.268634557723999, emotion_loss=0.8721168041229248\n",
      "\n",
      "01_20_01:34:08 Seen so far: 392032 samples\n",
      "\n",
      "01_20_01:34:08 --- 1.6007676124572754 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:10 Training loss at epoch 3 step 12260: 3.389268922805786\n",
      "\n",
      " This round's valence_loss=1.4981132745742798, arousal_loss=1.3226525783538818, emotion_loss=0.9330596327781677\n",
      "\n",
      "01_20_01:34:10 Seen so far: 392352 samples\n",
      "\n",
      "01_20_01:34:10 --- 1.9364118576049805 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:12 Training loss at epoch 3 step 12270: 2.6548445224761963\n",
      "\n",
      " This round's valence_loss=0.8571339845657349, arousal_loss=0.7218387126922607, emotion_loss=0.8596101403236389\n",
      "\n",
      "01_20_01:34:12 Seen so far: 392672 samples\n",
      "\n",
      "01_20_01:34:12 --- 2.165238380432129 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:14 Training loss at epoch 3 step 12280: 2.88430438041687\n",
      "\n",
      " This round's valence_loss=0.8895734548568726, arousal_loss=0.6914982795715332, emotion_loss=0.9045902490615845\n",
      "\n",
      "01_20_01:34:14 Seen so far: 392992 samples\n",
      "\n",
      "01_20_01:34:14 --- 1.8073489665985107 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:15 Training loss at epoch 3 step 12290: 3.1872106552124024\n",
      "\n",
      " This round's valence_loss=1.068521499633789, arousal_loss=0.9449875354766846, emotion_loss=0.5920854806900024\n",
      "\n",
      "01_20_01:34:15 Seen so far: 393312 samples\n",
      "\n",
      "01_20_01:34:15 --- 1.6911523342132568 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:17 Training loss at epoch 3 step 12300: 2.696640944480896\n",
      "\n",
      " This round's valence_loss=1.207314133644104, arousal_loss=1.0685782432556152, emotion_loss=0.9773097634315491\n",
      "\n",
      "01_20_01:34:17 Seen so far: 393632 samples\n",
      "\n",
      "01_20_01:34:17 --- 1.8135097026824951 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:19 Training loss at epoch 3 step 12310: 2.846052610874176\n",
      "\n",
      " This round's valence_loss=1.0053224563598633, arousal_loss=0.8328408002853394, emotion_loss=0.6851747035980225\n",
      "\n",
      "01_20_01:34:19 Seen so far: 393952 samples\n",
      "\n",
      "01_20_01:34:19 --- 1.6987173557281494 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:21 Training loss at epoch 3 step 12320: 2.7038453817367554\n",
      "\n",
      " This round's valence_loss=0.9072065949440002, arousal_loss=0.7154924869537354, emotion_loss=1.0205155611038208\n",
      "\n",
      "01_20_01:34:21 Seen so far: 394272 samples\n",
      "\n",
      "01_20_01:34:21 --- 1.7036519050598145 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:22 Training loss at epoch 3 step 12330: 3.0838414549827577\n",
      "\n",
      " This round's valence_loss=1.5377933979034424, arousal_loss=1.31089186668396, emotion_loss=1.1803064346313477\n",
      "\n",
      "01_20_01:34:22 Seen so far: 394592 samples\n",
      "\n",
      "01_20_01:34:22 --- 1.8046748638153076 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:24 Training loss at epoch 3 step 12340: 3.12255117893219\n",
      "\n",
      " This round's valence_loss=0.9687765836715698, arousal_loss=0.8331153392791748, emotion_loss=1.0342907905578613\n",
      "\n",
      "01_20_01:34:24 Seen so far: 394912 samples\n",
      "\n",
      "01_20_01:34:24 --- 1.7458302974700928 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:26 Training loss at epoch 3 step 12350: 3.2733432769775392\n",
      "\n",
      " This round's valence_loss=1.73868989944458, arousal_loss=1.7324763536453247, emotion_loss=1.1146221160888672\n",
      "\n",
      "01_20_01:34:26 Seen so far: 395232 samples\n",
      "\n",
      "01_20_01:34:26 --- 1.7584540843963623 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:28 Training loss at epoch 3 step 12360: 2.95730721950531\n",
      "\n",
      " This round's valence_loss=0.6684005260467529, arousal_loss=0.461922824382782, emotion_loss=0.8621487617492676\n",
      "\n",
      "01_20_01:34:28 Seen so far: 395552 samples\n",
      "\n",
      "01_20_01:34:28 --- 1.863046407699585 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:30 Training loss at epoch 3 step 12370: 2.8394928574562073\n",
      "\n",
      " This round's valence_loss=0.4834028482437134, arousal_loss=0.37781822681427, emotion_loss=0.5880261063575745\n",
      "\n",
      "01_20_01:34:30 Seen so far: 395872 samples\n",
      "\n",
      "01_20_01:34:30 --- 1.9639732837677002 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:32 Training loss at epoch 3 step 12380: 2.9521562576293947\n",
      "\n",
      " This round's valence_loss=0.7255170941352844, arousal_loss=0.6070961356163025, emotion_loss=0.9060485363006592\n",
      "\n",
      "01_20_01:34:32 Seen so far: 396192 samples\n",
      "\n",
      "01_20_01:34:32 --- 1.8341717720031738 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:33 Training loss at epoch 3 step 12390: 2.9145355939865114\n",
      "\n",
      " This round's valence_loss=1.1390187740325928, arousal_loss=0.9690345525741577, emotion_loss=1.0629911422729492\n",
      "\n",
      "01_20_01:34:33 Seen so far: 396512 samples\n",
      "\n",
      "01_20_01:34:33 --- 1.7513236999511719 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:35 Training loss at epoch 3 step 12400: 2.78731564283371\n",
      "\n",
      " This round's valence_loss=1.23213791847229, arousal_loss=1.0494599342346191, emotion_loss=0.7330889701843262\n",
      "\n",
      "01_20_01:34:35 Seen so far: 396832 samples\n",
      "\n",
      "01_20_01:34:35 --- 1.8402743339538574 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:37 Training loss at epoch 3 step 12410: 2.9540903091430666\n",
      "\n",
      " This round's valence_loss=1.0909481048583984, arousal_loss=0.9637270569801331, emotion_loss=1.0818579196929932\n",
      "\n",
      "01_20_01:34:37 Seen so far: 397152 samples\n",
      "\n",
      "01_20_01:34:37 --- 1.8453395366668701 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:39 Training loss at epoch 3 step 12420: 2.8204604387283325\n",
      "\n",
      " This round's valence_loss=0.6621809601783752, arousal_loss=0.48947566747665405, emotion_loss=0.8827448487281799\n",
      "\n",
      "01_20_01:34:39 Seen so far: 397472 samples\n",
      "\n",
      "01_20_01:34:39 --- 1.5592212677001953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:40 Training loss at epoch 3 step 12430: 2.822931718826294\n",
      "\n",
      " This round's valence_loss=1.1231378316879272, arousal_loss=0.9391456246376038, emotion_loss=0.9857444763183594\n",
      "\n",
      "01_20_01:34:40 Seen so far: 397792 samples\n",
      "\n",
      "01_20_01:34:40 --- 1.746877908706665 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:42 Training loss at epoch 3 step 12440: 2.5580615997314453\n",
      "\n",
      " This round's valence_loss=1.432161569595337, arousal_loss=1.3512271642684937, emotion_loss=0.8763141632080078\n",
      "\n",
      "01_20_01:34:42 Seen so far: 398112 samples\n",
      "\n",
      "01_20_01:34:42 --- 1.844597339630127 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:44 Training loss at epoch 3 step 12450: 3.072974169254303\n",
      "\n",
      " This round's valence_loss=1.3586820363998413, arousal_loss=1.2411400079727173, emotion_loss=1.0455209016799927\n",
      "\n",
      "01_20_01:34:44 Seen so far: 398432 samples\n",
      "\n",
      "01_20_01:34:44 --- 1.7781975269317627 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:46 Training loss at epoch 3 step 12460: 2.9257601499557495\n",
      "\n",
      " This round's valence_loss=0.7994893789291382, arousal_loss=0.7298901081085205, emotion_loss=0.7357865571975708\n",
      "\n",
      "01_20_01:34:46 Seen so far: 398752 samples\n",
      "\n",
      "01_20_01:34:46 --- 1.9415812492370605 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:48 Training loss at epoch 3 step 12470: 2.946020948886871\n",
      "\n",
      " This round's valence_loss=1.1502478122711182, arousal_loss=0.9318298697471619, emotion_loss=0.818956732749939\n",
      "\n",
      "01_20_01:34:48 Seen so far: 399072 samples\n",
      "\n",
      "01_20_01:34:48 --- 1.7130045890808105 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:49 Training loss at epoch 3 step 12480: 3.139412760734558\n",
      "\n",
      " This round's valence_loss=0.7412561178207397, arousal_loss=0.5886902809143066, emotion_loss=1.1102476119995117\n",
      "\n",
      "01_20_01:34:49 Seen so far: 399392 samples\n",
      "\n",
      "01_20_01:34:49 --- 1.774846076965332 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:51 Training loss at epoch 3 step 12490: 3.4149518251419066\n",
      "\n",
      " This round's valence_loss=1.4964911937713623, arousal_loss=1.279887080192566, emotion_loss=0.6763437986373901\n",
      "\n",
      "01_20_01:34:51 Seen so far: 399712 samples\n",
      "\n",
      "01_20_01:34:51 --- 1.734508991241455 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:53 Training loss at epoch 3 step 12500: 3.1285455226898193\n",
      "\n",
      " This round's valence_loss=1.2336392402648926, arousal_loss=1.1122848987579346, emotion_loss=0.950919508934021\n",
      "\n",
      "01_20_01:34:53 Seen so far: 400032 samples\n",
      "\n",
      "01_20_01:34:53 --- 1.7120532989501953 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:55 Training loss at epoch 3 step 12510: 2.9081467390060425\n",
      "\n",
      " This round's valence_loss=1.5172057151794434, arousal_loss=1.332892656326294, emotion_loss=1.089496374130249\n",
      "\n",
      "01_20_01:34:55 Seen so far: 400352 samples\n",
      "\n",
      "01_20_01:34:55 --- 1.6879198551177979 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:56 Training loss at epoch 3 step 12520: 2.569976246356964\n",
      "\n",
      " This round's valence_loss=0.8571240901947021, arousal_loss=0.6862450242042542, emotion_loss=0.7777541875839233\n",
      "\n",
      "01_20_01:34:56 Seen so far: 400672 samples\n",
      "\n",
      "01_20_01:34:56 --- 1.8375325202941895 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:34:58 Training loss at epoch 3 step 12530: 3.068182611465454\n",
      "\n",
      " This round's valence_loss=0.8974952101707458, arousal_loss=0.8321139216423035, emotion_loss=1.0254156589508057\n",
      "\n",
      "01_20_01:34:58 Seen so far: 400992 samples\n",
      "\n",
      "01_20_01:34:58 --- 1.664168119430542 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:00 Training loss at epoch 3 step 12540: 2.9694552183151246\n",
      "\n",
      " This round's valence_loss=1.1002063751220703, arousal_loss=0.9241111278533936, emotion_loss=0.7479391098022461\n",
      "\n",
      "01_20_01:35:00 Seen so far: 401312 samples\n",
      "\n",
      "01_20_01:35:00 --- 1.7921898365020752 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:02 Training loss at epoch 3 step 12550: 2.846929407119751\n",
      "\n",
      " This round's valence_loss=1.4414637088775635, arousal_loss=1.4012908935546875, emotion_loss=0.8940637707710266\n",
      "\n",
      "01_20_01:35:02 Seen so far: 401632 samples\n",
      "\n",
      "01_20_01:35:02 --- 1.782970666885376 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:03 Training loss at epoch 3 step 12560: 2.7968578815460203\n",
      "\n",
      " This round's valence_loss=1.5528273582458496, arousal_loss=1.4449121952056885, emotion_loss=0.9000189900398254\n",
      "\n",
      "01_20_01:35:03 Seen so far: 401952 samples\n",
      "\n",
      "01_20_01:35:03 --- 1.7964587211608887 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:05 Training loss at epoch 3 step 12570: 2.93462393283844\n",
      "\n",
      " This round's valence_loss=1.0991854667663574, arousal_loss=0.9987396001815796, emotion_loss=1.268672227859497\n",
      "\n",
      "01_20_01:35:05 Seen so far: 402272 samples\n",
      "\n",
      "01_20_01:35:05 --- 1.805872917175293 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:07 Training loss at epoch 3 step 12580: 2.833682656288147\n",
      "\n",
      " This round's valence_loss=0.7289060354232788, arousal_loss=0.6254415512084961, emotion_loss=0.9813922643661499\n",
      "\n",
      "01_20_01:35:07 Seen so far: 402592 samples\n",
      "\n",
      "01_20_01:35:07 --- 1.857396125793457 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:09 Training loss at epoch 3 step 12590: 3.1012917041778563\n",
      "\n",
      " This round's valence_loss=0.837769627571106, arousal_loss=0.743121862411499, emotion_loss=0.990673303604126\n",
      "\n",
      "01_20_01:35:09 Seen so far: 402912 samples\n",
      "\n",
      "01_20_01:35:09 --- 1.609370231628418 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:10 Training loss at epoch 3 step 12600: 3.055638647079468\n",
      "\n",
      " This round's valence_loss=0.679735541343689, arousal_loss=0.4347628355026245, emotion_loss=0.7830019593238831\n",
      "\n",
      "01_20_01:35:10 Seen so far: 403232 samples\n",
      "\n",
      "01_20_01:35:10 --- 1.6493561267852783 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:12 Training loss at epoch 3 step 12610: 3.026409721374512\n",
      "\n",
      " This round's valence_loss=1.1744129657745361, arousal_loss=1.080757975578308, emotion_loss=0.7528881430625916\n",
      "\n",
      "01_20_01:35:12 Seen so far: 403552 samples\n",
      "\n",
      "01_20_01:35:12 --- 1.728299617767334 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:14 Training loss at epoch 3 step 12620: 2.8145252466201782\n",
      "\n",
      " This round's valence_loss=1.2309634685516357, arousal_loss=1.0786455869674683, emotion_loss=1.0783638954162598\n",
      "\n",
      "01_20_01:35:14 Seen so far: 403872 samples\n",
      "\n",
      "01_20_01:35:14 --- 1.7184641361236572 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:16 Training loss at epoch 3 step 12630: 2.8163480281829836\n",
      "\n",
      " This round's valence_loss=1.3388817310333252, arousal_loss=1.181950330734253, emotion_loss=0.9132678508758545\n",
      "\n",
      "01_20_01:35:16 Seen so far: 404192 samples\n",
      "\n",
      "01_20_01:35:16 --- 1.7936773300170898 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:17 Training loss at epoch 3 step 12640: 2.8537065744400025\n",
      "\n",
      " This round's valence_loss=1.0722476243972778, arousal_loss=0.9593716859817505, emotion_loss=0.7165365219116211\n",
      "\n",
      "01_20_01:35:17 Seen so far: 404512 samples\n",
      "\n",
      "01_20_01:35:17 --- 1.758876085281372 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:19 Training loss at epoch 3 step 12650: 3.076626014709473\n",
      "\n",
      " This round's valence_loss=1.4053288698196411, arousal_loss=1.3357203006744385, emotion_loss=0.6831358671188354\n",
      "\n",
      "01_20_01:35:19 Seen so far: 404832 samples\n",
      "\n",
      "01_20_01:35:19 --- 1.757906436920166 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:21 Training loss at epoch 3 step 12660: 2.9203394651412964\n",
      "\n",
      " This round's valence_loss=1.4903864860534668, arousal_loss=1.3517696857452393, emotion_loss=0.6823330521583557\n",
      "\n",
      "01_20_01:35:21 Seen so far: 405152 samples\n",
      "\n",
      "01_20_01:35:21 --- 1.9439029693603516 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:23 Training loss at epoch 3 step 12670: 2.951290321350098\n",
      "\n",
      " This round's valence_loss=1.3290596008300781, arousal_loss=1.2020851373672485, emotion_loss=0.6348968148231506\n",
      "\n",
      "01_20_01:35:23 Seen so far: 405472 samples\n",
      "\n",
      "01_20_01:35:23 --- 1.7697653770446777 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:25 Training loss at epoch 3 step 12680: 2.9416823625564574\n",
      "\n",
      " This round's valence_loss=1.1930172443389893, arousal_loss=1.1178789138793945, emotion_loss=0.9128004908561707\n",
      "\n",
      "01_20_01:35:25 Seen so far: 405792 samples\n",
      "\n",
      "01_20_01:35:25 --- 1.894887924194336 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:27 Training loss at epoch 3 step 12690: 3.0843910694122316\n",
      "\n",
      " This round's valence_loss=1.0450483560562134, arousal_loss=1.0220770835876465, emotion_loss=0.8914927244186401\n",
      "\n",
      "01_20_01:35:27 Seen so far: 406112 samples\n",
      "\n",
      "01_20_01:35:27 --- 1.8792707920074463 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_01:35:29 Training loss at epoch 3 step 12700: 2.8280771732330323\n",
      "\n",
      " This round's valence_loss=1.2250559329986572, arousal_loss=1.074905514717102, emotion_loss=1.118948221206665\n",
      "\n",
      "01_20_01:35:29 Seen so far: 406432 samples\n",
      "\n",
      "01_20_01:35:29 --- 1.9203276634216309 seconds for iter 10 step, each step have 32, so the model train with 320 \n",
      "01_20_10:55:09 --- 0.0012357234954833984 seconds for evaluate 0 image ---\n",
      "\n",
      "\n",
      "\n",
      "01_20_10:56:01 --- 0.0013861656188964844 seconds for evaluate 0 image ---\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     d \u001b[38;5;241m=\u001b[39m log[idx]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     out_log[d[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      9\u001b[0m out_log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m log[\u001b[38;5;241m8\u001b[39m]\n\u001b[1;32m     11\u001b[0m out_log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m log[\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for log in logs:\n",
    "    log = log.split()\n",
    "    out_log = {}\n",
    "    for idx in [11,12,13]:\n",
    "        d = log[idx].split(\"=\")\n",
    "        out_log[d[0]] = float(d[1].replace(',',''))\n",
    "\n",
    "    out_log['total'] = log[8]\n",
    "\n",
    "    out_log['epoch'] = log[5]\n",
    "    out_log['step'] = log[7]\n",
    "    out_log['second'] = log[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:16:59.502950Z",
     "start_time": "2022-01-20T03:16:59.499924Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:17:08.733532Z",
     "start_time": "2022-01-20T03:17:08.729288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_20_10:55:09',\n",
       " '---',\n",
       " '0.0012357234954833984',\n",
       " 'seconds',\n",
       " 'for',\n",
       " 'evaluate',\n",
       " '0',\n",
       " 'image',\n",
       " '---',\n",
       " '01_20_10:56:01',\n",
       " '---',\n",
       " '0.0013861656188964844',\n",
       " 'seconds',\n",
       " 'for',\n",
       " 'evaluate',\n",
       " '0',\n",
       " 'image',\n",
       " '---']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:18:18.012292Z",
     "start_time": "2022-01-20T03:18:17.969380Z"
    }
   },
   "outputs": [],
   "source": [
    "log_df = []\n",
    "\n",
    "for log in logs:\n",
    "    log = log.split()\n",
    "    out_log = {}\n",
    "    \n",
    "    try:\n",
    "        for idx in [11,12,13]:\n",
    "            d = log[idx].split(\"=\")\n",
    "            out_log[d[0]] = float(d[1].replace(',',''))\n",
    "\n",
    "        out_log['total'] = log[8]\n",
    "\n",
    "        out_log['epoch'] = int(log[5])\n",
    "        out_log['step'] = int(log[7].replace(','))\n",
    "        out_log['second'] = log[22]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    log_df.append(out_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:18:18.175844Z",
     "start_time": "2022-01-20T03:18:18.163160Z"
    }
   },
   "outputs": [],
   "source": [
    "log_df = pd.DataFrame(log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:18:21.904575Z",
     "start_time": "2022-01-20T03:18:21.900305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5085, step=1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:17:51.841392Z",
     "start_time": "2022-01-20T03:17:50.847462Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:18:58.659666Z",
     "start_time": "2022-01-20T03:18:58.513638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7facff94c490>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_df.index, log_df.valence_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:19:07.751565Z",
     "start_time": "2022-01-20T03:19:07.607265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7facff922370>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_df.index, log_df.arousal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:19:13.437708Z",
     "start_time": "2022-01-20T03:19:13.289317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7facff8f6ca0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_df.index, log_df.emotion_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:19:34.383051Z",
     "start_time": "2022-01-20T03:19:34.378717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.950765540414467"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.arousal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:19:40.293758Z",
     "start_time": "2022-01-20T03:19:40.289654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0877243726390446"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.valence_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:18:35.792455Z",
     "start_time": "2022-01-20T03:18:35.788407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['valence_loss', 'arousal_loss', 'emotion_loss', 'total', 'epoch'], dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:14:18.254486Z",
     "start_time": "2022-01-20T03:14:18.251273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:10:51.174428Z",
     "start_time": "2022-01-20T03:10:51.171265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valence_loss', '2.7215681076049805,']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log[11].split(\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:10:20.290916Z",
     "start_time": "2022-01-20T03:10:20.286727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7215681076049805'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:09:57.600831Z",
     "start_time": "2022-01-20T03:09:57.589954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 01_19_22:57:23\n",
      "1 Training\n",
      "2 loss\n",
      "3 at\n",
      "4 epoch\n",
      "5 0\n",
      "6 step\n",
      "7 0:\n",
      "8 8.087566375732422\n",
      "9 This\n",
      "10 round's\n",
      "11 valence_loss=2.7215681076049805,\n",
      "12 arousal_loss=2.8208649158477783,\n",
      "13 emotion_loss=2.545133113861084\n",
      "14 01_19_22:57:23\n",
      "15 Seen\n",
      "16 so\n",
      "17 far:\n",
      "18 32\n",
      "19 samples\n",
      "20 01_19_22:57:23\n",
      "21 ---\n",
      "22 2.6277694702148438\n",
      "23 seconds\n",
      "24 for\n",
      "25 iter\n",
      "26 1\n",
      "27 step,\n",
      "28 each\n",
      "29 step\n",
      "30 have\n",
      "31 32,\n",
      "32 so\n",
      "33 the\n",
      "34 model\n",
      "35 train\n",
      "36 with\n",
      "37 32\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(log):\n",
    "    print(i, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:09:42.056024Z",
     "start_time": "2022-01-20T03:09:42.052889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.087566375732422'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T02:58:26.982286Z",
     "start_time": "2022-01-20T02:58:26.980296Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:00:24.388175Z",
     "start_time": "2022-01-20T03:00:24.385190Z"
    }
   },
   "outputs": [],
   "source": [
    "t = \"\\\"arousal_loss=\\\":\\\"111111\\\"\"\n",
    "m = re.match(\"^[-+][0-9]+\\.[0-9]+[eE][-+]?[0-9]+$\", logs[0])\n",
    "if m:\n",
    "    print(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "tf27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
