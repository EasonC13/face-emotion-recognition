{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T12:50:25.876212Z",
     "start_time": "2022-01-18T12:50:25.870149Z"
    }
   },
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:48.301068Z",
     "start_time": "2022-01-20T14:14:48.289038Z"
    }
   },
   "outputs": [],
   "source": [
    "description = 'mobilenet_from_face_pretrain_sep_feat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:50.013892Z",
     "start_time": "2022-01-20T14:14:48.303386Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#from scipy.misc import imread, imresize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:50.022001Z",
     "start_time": "2022-01-20T14:14:50.015251Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:54.827240Z",
     "start_time": "2022-01-20T14:14:50.023822Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/Manually_Annotated_file_lists/training_face_mesh_crop.csv')\n",
    "train_df.subDirectory_filePath = '../../data/Manually_Annotated_Images_FaceMesh_Cropped/' + train_df.subDirectory_filePath\n",
    "\n",
    "#train_df_2 = pd.read_csv('../../data/Automatically_annotated_file_list/automatically_annotated_face_mesh_crop.csv')\n",
    "#train_df_2.subDirectory_filePath = '../../data/Automatically_Annotated_Images_FaceMesh_Cropped/' + train_df_2.subDirectory_filePath\n",
    "#train_df = train_df.append(train_df_2)\n",
    "#del train_df_2\n",
    "\n",
    "train_df = train_df[train_df['have_facemesh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:54.833038Z",
     "start_time": "2022-01-20T14:14:54.828633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_file_name='01_20_22:14:54.log'\n"
     ]
    }
   ],
   "source": [
    "from eason_utils import DataFrameBatchIterator\n",
    "from eason_utils import lprint, now_time_string, log_file_name, change_log_file_name\n",
    "\n",
    "change_log_file_name(f'''{log_file_name.replace('.log', '')}_{description}.log''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T13:57:18.682279Z",
     "start_time": "2022-01-19T13:57:18.670590Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:57.438901Z",
     "start_time": "2022-01-20T14:14:54.834634Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(allow_growth = True))\n",
    "sess = tf.compat.v1.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:58.306687Z",
     "start_time": "2022-01-20T14:14:57.440573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "mobilenet_pretrained = tf.keras.models.load_model('../models/pretrained_faces/age_gender_tf2_224_deep-03-0.13-0.97.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:58.310705Z",
     "start_time": "2022-01-20T14:14:58.308083Z"
    }
   },
   "outputs": [],
   "source": [
    "mobilenet_output = mobilenet_pretrained.get_layer(\"global_pooling\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:58.314510Z",
     "start_time": "2022-01-20T14:14:58.312237Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_layers = [256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:58.383150Z",
     "start_time": "2022-01-20T14:14:58.317670Z"
    }
   },
   "outputs": [],
   "source": [
    "valaence_feat = mobilenet_output\n",
    "for size in hidden_layers:\n",
    "    valence_feat = tf.keras.layers.Dense(size, activation = 'relu', name = f'feat_valence')(valaence_feat)\n",
    "outputs_valence = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'outputs_valence')(valence_feat)\n",
    "\n",
    "arousal_feat = mobilenet_output\n",
    "for size in hidden_layers:\n",
    "    arousal_feat = tf.keras.layers.Dense(size, activation = 'relu', name = f'feat_arousal')(arousal_feat)\n",
    "outputs_arousal = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'outputs_arousal')(arousal_feat)\n",
    "\n",
    "emotion_feat = mobilenet_output\n",
    "for size in hidden_layers:\n",
    "    emotion_feat = tf.keras.layers.Dense(size, activation = 'relu', name = f'feat_emotion')(emotion_feat)\n",
    "emotions_count = len(np.unique(train_df.expression))\n",
    "outputs_emotion = tf.keras.layers.Dense(emotions_count, activation = 'softmax', name = 'outputs_emotion')(emotion_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:58.395217Z",
     "start_time": "2022-01-20T14:14:58.384642Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=mobilenet_pretrained.input,\n",
    "                       outputs=(outputs_valence, outputs_arousal, outputs_emotion) , name=\"mobilenet_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:58.446897Z",
     "start_time": "2022-01-20T14:14:58.398248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_train\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 225, 225, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 112, 112, 32  864         ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 32  128         ['conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (ReLU)              (None, 112, 112, 32  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1 (DepthwiseConv2D)    (None, 112, 112, 32  288         ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1_bn (BatchNormalizati  (None, 112, 112, 32  128        ['conv_dw_1[0][0]']              \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_1_relu (ReLU)          (None, 112, 112, 32  0           ['conv_dw_1_bn[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1 (Conv2D)             (None, 112, 112, 64  2048        ['conv_dw_1_relu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1_bn (BatchNormalizati  (None, 112, 112, 64  256        ['conv_pw_1[0][0]']              \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv_pw_1_relu (ReLU)          (None, 112, 112, 64  0           ['conv_pw_1_bn[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_pad_2 (ZeroPadding2D)     (None, 113, 113, 64  0           ['conv_pw_1_relu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_dw_2 (DepthwiseConv2D)    (None, 56, 56, 64)   576         ['conv_pad_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_2_bn (BatchNormalizati  (None, 56, 56, 64)  256         ['conv_dw_2[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_2_relu (ReLU)          (None, 56, 56, 64)   0           ['conv_dw_2_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_2 (Conv2D)             (None, 56, 56, 128)  8192        ['conv_dw_2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_2_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_pw_2[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_2_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_pw_2_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_3 (DepthwiseConv2D)    (None, 56, 56, 128)  1152        ['conv_pw_2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_3_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_dw_3[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_3_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_dw_3_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_3 (Conv2D)             (None, 56, 56, 128)  16384       ['conv_dw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_3_bn (BatchNormalizati  (None, 56, 56, 128)  512        ['conv_pw_3[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_3_relu (ReLU)          (None, 56, 56, 128)  0           ['conv_pw_3_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pad_4 (ZeroPadding2D)     (None, 57, 57, 128)  0           ['conv_pw_3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_4 (DepthwiseConv2D)    (None, 28, 28, 128)  1152        ['conv_pad_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_4_bn (BatchNormalizati  (None, 28, 28, 128)  512        ['conv_dw_4[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_4_relu (ReLU)          (None, 28, 28, 128)  0           ['conv_dw_4_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_4 (Conv2D)             (None, 28, 28, 256)  32768       ['conv_dw_4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_4_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_pw_4[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_4_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_pw_4_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_5 (DepthwiseConv2D)    (None, 28, 28, 256)  2304        ['conv_pw_4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_5_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_dw_5[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_5_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_dw_5_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_5 (Conv2D)             (None, 28, 28, 256)  65536       ['conv_dw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_5_bn (BatchNormalizati  (None, 28, 28, 256)  1024       ['conv_pw_5[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_5_relu (ReLU)          (None, 28, 28, 256)  0           ['conv_pw_5_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pad_6 (ZeroPadding2D)     (None, 29, 29, 256)  0           ['conv_pw_5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_6 (DepthwiseConv2D)    (None, 14, 14, 256)  2304        ['conv_pad_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv_dw_6_bn (BatchNormalizati  (None, 14, 14, 256)  1024       ['conv_dw_6[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_6_relu (ReLU)          (None, 14, 14, 256)  0           ['conv_dw_6_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_6 (Conv2D)             (None, 14, 14, 512)  131072      ['conv_dw_6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_6_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_6[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_6_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_6_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_7 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_7_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_7[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_7_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_7_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_7 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_7_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_7_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_7[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_7_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_7_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_8 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_7_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_8_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_8[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_8_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_8_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_8 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_8_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_8_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_8[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_8_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_8_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_9 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        ['conv_pw_8_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_9_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_dw_9[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_dw_9_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_dw_9_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_pw_9 (Conv2D)             (None, 14, 14, 512)  262144      ['conv_dw_9_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_pw_9_bn (BatchNormalizati  (None, 14, 14, 512)  2048       ['conv_pw_9[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv_pw_9_relu (ReLU)          (None, 14, 14, 512)  0           ['conv_pw_9_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv_dw_10 (DepthwiseConv2D)   (None, 14, 14, 512)  4608        ['conv_pw_9_relu[0][0]']         \n",
      "                                                                                                  \n",
      " conv_dw_10_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_dw_10[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_10_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_dw_10_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_10 (Conv2D)            (None, 14, 14, 512)  262144      ['conv_dw_10_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_10_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_pw_10[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_10_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_pw_10_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_dw_11 (DepthwiseConv2D)   (None, 14, 14, 512)  4608        ['conv_pw_10_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_11_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_dw_11[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_11_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_dw_11_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_11 (Conv2D)            (None, 14, 14, 512)  262144      ['conv_dw_11_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_11_bn (BatchNormalizat  (None, 14, 14, 512)  2048       ['conv_pw_11[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_11_relu (ReLU)         (None, 14, 14, 512)  0           ['conv_pw_11_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pad_12 (ZeroPadding2D)    (None, 15, 15, 512)  0           ['conv_pw_11_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_12 (DepthwiseConv2D)   (None, 7, 7, 512)    4608        ['conv_pad_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv_dw_12_bn (BatchNormalizat  (None, 7, 7, 512)   2048        ['conv_dw_12[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_12_relu (ReLU)         (None, 7, 7, 512)    0           ['conv_dw_12_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_12 (Conv2D)            (None, 7, 7, 1024)   524288      ['conv_dw_12_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_12_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_pw_12[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_12_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_pw_12_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_dw_13 (DepthwiseConv2D)   (None, 7, 7, 1024)   9216        ['conv_pw_12_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_dw_13_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_dw_13[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_dw_13_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_dw_13_bn[0][0]']          \n",
      "                                                                                                  \n",
      " conv_pw_13 (Conv2D)            (None, 7, 7, 1024)   1048576     ['conv_dw_13_relu[0][0]']        \n",
      "                                                                                                  \n",
      " conv_pw_13_bn (BatchNormalizat  (None, 7, 7, 1024)  4096        ['conv_pw_13[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_pw_13_relu (ReLU)         (None, 7, 7, 1024)   0           ['conv_pw_13_bn[0][0]']          \n",
      "                                                                                                  \n",
      " global_pooling (GlobalAverageP  (None, 1024)        0           ['conv_pw_13_relu[0][0]']        \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " feat_valence (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " feat_arousal (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " feat_emotion (Dense)           (None, 256)          262400      ['global_pooling[0][0]']         \n",
      "                                                                                                  \n",
      " outputs_valence (Dense)        (None, 1)            257         ['feat_valence[0][0]']           \n",
      "                                                                                                  \n",
      " outputs_arousal (Dense)        (None, 1)            257         ['feat_arousal[0][0]']           \n",
      "                                                                                                  \n",
      " outputs_emotion (Dense)        (None, 11)           2827        ['feat_emotion[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,019,405\n",
      "Trainable params: 3,997,517\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:58.451953Z",
     "start_time": "2022-01-20T14:14:58.448108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# Instantiate a loss function.\n",
    "MSE_loss = tf.keras.losses.MeanSquaredError()\n",
    "SCC_loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T14:14:58.457228Z",
     "start_time": "2022-01-20T14:14:58.453561Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 16\n",
    "\n",
    "logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-20T14:14:42.184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 2, \"valence_loss\": 2.756927490234375, \"arousal_loss\": 2.5483057498931885, \"emotion_loss\": 2.3268074989318848, \"time_take\": 3.7601218223571777}\n",
      "{\"emotion_correct\": 6, \"valence_loss\": 1.0605723857879639, \"arousal_loss\": 0.910541296005249, \"emotion_loss\": 2.2088069915771484, \"time_take\": 4.083930730819702}\n",
      "{\"emotion_correct\": 11, \"valence_loss\": 1.5213910341262817, \"arousal_loss\": 1.3364959955215454, \"emotion_loss\": 1.9057841300964355, \"time_take\": 4.290806293487549}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.1198079586029053, \"arousal_loss\": 0.955219030380249, \"emotion_loss\": 1.7774360179901123, \"time_take\": 4.601081848144531}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.8867492079734802, \"arousal_loss\": 0.6715497374534607, \"emotion_loss\": 1.52064847946167, \"time_take\": 4.919289588928223}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8881931304931641, \"arousal_loss\": 0.7615321278572083, \"emotion_loss\": 1.6821653842926025, \"time_take\": 5.282388687133789}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.2054634094238281, \"arousal_loss\": 1.0755057334899902, \"emotion_loss\": 2.049058437347412, \"time_take\": 5.618699550628662}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.4209071397781372, \"arousal_loss\": 1.2020866870880127, \"emotion_loss\": 1.5125198364257812, \"time_take\": 6.036032676696777}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0039793252944946, \"arousal_loss\": 0.7141493558883667, \"emotion_loss\": 1.522505521774292, \"time_take\": 6.344008445739746}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.273566722869873, \"arousal_loss\": 1.2294790744781494, \"emotion_loss\": 1.769836187362671, \"time_take\": 6.514890909194946}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.7429713010787964, \"arousal_loss\": 0.5690313577651978, \"emotion_loss\": 1.2024399042129517, \"time_take\": 6.881788492202759}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.7793030738830566, \"arousal_loss\": 0.6221244931221008, \"emotion_loss\": 1.879082441329956, \"time_take\": 7.088010549545288}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 0.7028868198394775, \"arousal_loss\": 0.5372268557548523, \"emotion_loss\": 1.7896361351013184, \"time_take\": 7.304283857345581}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.3466744422912598, \"arousal_loss\": 1.2193522453308105, \"emotion_loss\": 1.5328710079193115, \"time_take\": 7.5977699756622314}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.2045714855194092, \"arousal_loss\": 1.1161389350891113, \"emotion_loss\": 1.659947395324707, \"time_take\": 7.81230902671814}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.1354235410690308, \"arousal_loss\": 0.9775733351707458, \"emotion_loss\": 1.725039005279541, \"time_take\": 8.0282723903656}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.4491615295410156, \"arousal_loss\": 1.3316529989242554, \"emotion_loss\": 1.3933066129684448, \"time_take\": 8.297675609588623}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 0.9364736676216125, \"arousal_loss\": 0.8615490198135376, \"emotion_loss\": 1.8955284357070923, \"time_take\": 8.516414642333984}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.1829473972320557, \"arousal_loss\": 1.110336422920227, \"emotion_loss\": 1.6582715511322021, \"time_take\": 8.707824230194092}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.5316264629364014, \"arousal_loss\": 1.3058565855026245, \"emotion_loss\": 1.1570954322814941, \"time_take\": 8.950223445892334}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.1345034837722778, \"arousal_loss\": 0.9791577458381653, \"emotion_loss\": 1.5816723108291626, \"time_take\": 9.456322193145752}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.454878807067871, \"arousal_loss\": 1.346673846244812, \"emotion_loss\": 1.3077399730682373, \"time_take\": 9.706271171569824}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.1038471460342407, \"arousal_loss\": 0.9634373188018799, \"emotion_loss\": 1.541198492050171, \"time_take\": 9.97914457321167}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.9510038495063782, \"arousal_loss\": 0.8470083475112915, \"emotion_loss\": 1.3663222789764404, \"time_take\": 10.32978081703186}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.6365123987197876, \"arousal_loss\": 0.4696187674999237, \"emotion_loss\": 1.3333358764648438, \"time_take\": 10.551856994628906}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.2370977401733398, \"arousal_loss\": 1.0822511911392212, \"emotion_loss\": 1.576941728591919, \"time_take\": 10.830079793930054}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.209892749786377, \"arousal_loss\": 1.0737626552581787, \"emotion_loss\": 1.0926034450531006, \"time_take\": 11.036228656768799}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.4847297668457031, \"arousal_loss\": 1.3589892387390137, \"emotion_loss\": 1.629197597503662, \"time_take\": 11.337021112442017}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.2101356983184814, \"arousal_loss\": 1.0943059921264648, \"emotion_loss\": 1.8059179782867432, \"time_take\": 11.619779586791992}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0162949562072754, \"arousal_loss\": 0.8321540355682373, \"emotion_loss\": 1.4859607219696045, \"time_take\": 11.870667457580566}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.1074073314666748, \"arousal_loss\": 0.958770215511322, \"emotion_loss\": 1.6420488357543945, \"time_take\": 12.198087930679321}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.7555103898048401, \"arousal_loss\": 0.6198359727859497, \"emotion_loss\": 1.6660956144332886, \"time_take\": 12.364880323410034}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1550557613372803, \"arousal_loss\": 1.1127214431762695, \"emotion_loss\": 1.7401151657104492, \"time_take\": 12.603011846542358}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 1.1522674560546875, \"arousal_loss\": 1.064698338508606, \"emotion_loss\": 1.7836229801177979, \"time_take\": 12.846498489379883}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.012495517730713, \"arousal_loss\": 1.0003893375396729, \"emotion_loss\": 1.7649043798446655, \"time_take\": 13.048787593841553}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.3598744869232178, \"arousal_loss\": 1.1691274642944336, \"emotion_loss\": 1.6898775100708008, \"time_take\": 13.547676801681519}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9951032400131226, \"arousal_loss\": 0.8335247039794922, \"emotion_loss\": 1.5247795581817627, \"time_take\": 13.919014930725098}\n",
      "{\"emotion_correct\": 11, \"valence_loss\": 1.6050673723220825, \"arousal_loss\": 1.4648535251617432, \"emotion_loss\": 1.9529163837432861, \"time_take\": 14.195461750030518}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.9595134258270264, \"arousal_loss\": 0.8473793268203735, \"emotion_loss\": 1.909814715385437, \"time_take\": 14.593470573425293}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.1192965507507324, \"arousal_loss\": 0.946791410446167, \"emotion_loss\": 1.4150004386901855, \"time_take\": 14.908288478851318}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 0.9624812602996826, \"arousal_loss\": 0.8513326048851013, \"emotion_loss\": 1.728392481803894, \"time_take\": 15.172615766525269}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9378671646118164, \"arousal_loss\": 0.8432114124298096, \"emotion_loss\": 1.6188080310821533, \"time_take\": 15.48508620262146}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8487078547477722, \"arousal_loss\": 0.7128903269767761, \"emotion_loss\": 1.5499361753463745, \"time_take\": 15.661173105239868}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.1687588691711426, \"arousal_loss\": 0.931247889995575, \"emotion_loss\": 1.193664312362671, \"time_take\": 15.919362306594849}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.7205601334571838, \"arousal_loss\": 0.573279619216919, \"emotion_loss\": 1.055545449256897, \"time_take\": 16.16488790512085}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.24784255027771, \"arousal_loss\": 1.038064956665039, \"emotion_loss\": 1.249007225036621, \"time_take\": 16.498258590698242}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 0.5987902283668518, \"arousal_loss\": 0.507246196269989, \"emotion_loss\": 1.8122189044952393, \"time_take\": 16.74977397918701}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.9850540161132812, \"arousal_loss\": 0.7937287092208862, \"emotion_loss\": 1.3745566606521606, \"time_take\": 17.112016916275024}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.137699842453003, \"arousal_loss\": 0.9757383465766907, \"emotion_loss\": 2.041599988937378, \"time_take\": 17.311158418655396}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.1021971702575684, \"arousal_loss\": 0.9672492146492004, \"emotion_loss\": 1.2196260690689087, \"time_take\": 17.54916214942932}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.3388855457305908, \"arousal_loss\": 1.218135952949524, \"emotion_loss\": 1.6464425325393677, \"time_take\": 17.834933519363403}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 15, \"valence_loss\": 1.1764615774154663, \"arousal_loss\": 1.1205761432647705, \"emotion_loss\": 1.5504088401794434, \"time_take\": 18.099183320999146}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8973537683486938, \"arousal_loss\": 0.7201874852180481, \"emotion_loss\": 1.3589215278625488, \"time_take\": 18.41706418991089}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.0065486431121826, \"arousal_loss\": 0.8076820373535156, \"emotion_loss\": 1.6351312398910522, \"time_take\": 18.6439425945282}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0528804063796997, \"arousal_loss\": 0.9171227812767029, \"emotion_loss\": 1.2168645858764648, \"time_take\": 18.918928861618042}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 0.8614283204078674, \"arousal_loss\": 0.7409688234329224, \"emotion_loss\": 1.7003986835479736, \"time_take\": 19.237633228302002}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.300057053565979, \"arousal_loss\": 1.0828254222869873, \"emotion_loss\": 1.4850261211395264, \"time_take\": 19.518555402755737}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1642060279846191, \"arousal_loss\": 1.1154389381408691, \"emotion_loss\": 1.2560033798217773, \"time_take\": 19.791831254959106}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.423285722732544, \"arousal_loss\": 1.379197597503662, \"emotion_loss\": 1.5079045295715332, \"time_take\": 20.07930278778076}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.9423438310623169, \"arousal_loss\": 0.8820867538452148, \"emotion_loss\": 1.4858341217041016, \"time_take\": 20.36122751235962}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 0.9460973143577576, \"arousal_loss\": 0.8683119416236877, \"emotion_loss\": 1.4746400117874146, \"time_take\": 20.695541858673096}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.9680572748184204, \"arousal_loss\": 0.8370123505592346, \"emotion_loss\": 1.4357120990753174, \"time_take\": 21.03602647781372}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9457513689994812, \"arousal_loss\": 0.7083679437637329, \"emotion_loss\": 1.1667503118515015, \"time_take\": 21.37604260444641}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9901341199874878, \"arousal_loss\": 0.8825488090515137, \"emotion_loss\": 1.3028345108032227, \"time_take\": 21.606019020080566}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.8946009874343872, \"arousal_loss\": 0.7792593240737915, \"emotion_loss\": 1.710645079612732, \"time_take\": 21.841187000274658}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.0044772624969482, \"arousal_loss\": 0.884716272354126, \"emotion_loss\": 1.4730002880096436, \"time_take\": 22.08022928237915}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.782181978225708, \"arousal_loss\": 0.5704573392868042, \"emotion_loss\": 1.1055643558502197, \"time_take\": 22.352824687957764}\n",
      "{\"emotion_correct\": 26, \"valence_loss\": 0.8637305498123169, \"arousal_loss\": 0.7216272354125977, \"emotion_loss\": 1.1205761432647705, \"time_take\": 22.621391773223877}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.2154780626296997, \"arousal_loss\": 1.0915429592132568, \"emotion_loss\": 1.29408860206604, \"time_take\": 22.891793966293335}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.3840954303741455, \"arousal_loss\": 1.3256837129592896, \"emotion_loss\": 1.6216654777526855, \"time_take\": 23.136329889297485}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.591119110584259, \"arousal_loss\": 0.34676772356033325, \"emotion_loss\": 1.0935161113739014, \"time_take\": 23.3651442527771}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.5514895915985107, \"arousal_loss\": 1.45306396484375, \"emotion_loss\": 1.7182519435882568, \"time_take\": 23.61286759376526}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.3507158756256104, \"arousal_loss\": 1.1895928382873535, \"emotion_loss\": 1.3162580728530884, \"time_take\": 23.875827074050903}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0055619478225708, \"arousal_loss\": 0.8334445953369141, \"emotion_loss\": 1.5373531579971313, \"time_take\": 24.155375003814697}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.5042324662208557, \"arousal_loss\": 0.31806042790412903, \"emotion_loss\": 0.8948276042938232, \"time_take\": 24.55937433242798}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9642466306686401, \"arousal_loss\": 0.8096671104431152, \"emotion_loss\": 1.1139614582061768, \"time_take\": 24.79568839073181}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.4711995124816895, \"arousal_loss\": 1.343827724456787, \"emotion_loss\": 1.5112335681915283, \"time_take\": 25.09374237060547}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.6798577308654785, \"arousal_loss\": 0.5056074857711792, \"emotion_loss\": 1.8355433940887451, \"time_take\": 25.265592098236084}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.7496414184570312, \"arousal_loss\": 0.6305177211761475, \"emotion_loss\": 1.4253902435302734, \"time_take\": 25.593810319900513}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.6693775653839111, \"arousal_loss\": 1.6019513607025146, \"emotion_loss\": 1.461888313293457, \"time_take\": 25.864806413650513}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.8005969524383545, \"arousal_loss\": 1.7186505794525146, \"emotion_loss\": 1.4126274585723877, \"time_take\": 26.066474676132202}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8797392845153809, \"arousal_loss\": 0.7560071349143982, \"emotion_loss\": 1.4436993598937988, \"time_take\": 26.3039288520813}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.6967449188232422, \"arousal_loss\": 0.591507613658905, \"emotion_loss\": 1.2739709615707397, \"time_take\": 26.583642721176147}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8761646151542664, \"arousal_loss\": 0.7346940040588379, \"emotion_loss\": 1.3003438711166382, \"time_take\": 26.849090099334717}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.633519172668457, \"arousal_loss\": 1.441941499710083, \"emotion_loss\": 1.331801414489746, \"time_take\": 27.119231462478638}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.8577731847763062, \"arousal_loss\": 0.7092846632003784, \"emotion_loss\": 1.2233504056930542, \"time_take\": 27.432564735412598}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8632568717002869, \"arousal_loss\": 0.7593001127243042, \"emotion_loss\": 1.3361122608184814, \"time_take\": 27.704222440719604}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.0228136777877808, \"arousal_loss\": 0.9954652190208435, \"emotion_loss\": 1.7297978401184082, \"time_take\": 27.883430242538452}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 1.0905365943908691, \"arousal_loss\": 0.9420325756072998, \"emotion_loss\": 1.6228806972503662, \"time_take\": 28.17001509666443}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.7601091861724854, \"arousal_loss\": 0.5883805155754089, \"emotion_loss\": 1.488338589668274, \"time_take\": 28.40881085395813}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.319905161857605, \"arousal_loss\": 1.1761000156402588, \"emotion_loss\": 1.1144094467163086, \"time_take\": 28.63293433189392}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0833373069763184, \"arousal_loss\": 1.021071195602417, \"emotion_loss\": 1.530937671661377, \"time_take\": 28.896535396575928}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.700154721736908, \"arousal_loss\": 0.6514228582382202, \"emotion_loss\": 1.7418162822723389, \"time_take\": 29.212637901306152}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.9660350680351257, \"arousal_loss\": 0.8780941963195801, \"emotion_loss\": 1.5207109451293945, \"time_take\": 29.40310025215149}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.3187942504882812, \"arousal_loss\": 1.2143656015396118, \"emotion_loss\": 1.4469552040100098, \"time_take\": 29.69785499572754}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.5380868911743164, \"arousal_loss\": 1.321546196937561, \"emotion_loss\": 1.2990717887878418, \"time_take\": 29.921342134475708}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.9480619430541992, \"arousal_loss\": 0.8753381967544556, \"emotion_loss\": 1.4078242778778076, \"time_take\": 30.18164086341858}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8439549207687378, \"arousal_loss\": 0.7668226361274719, \"emotion_loss\": 1.3820303678512573, \"time_take\": 30.523051738739014}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1321849822998047, \"arousal_loss\": 0.9331625699996948, \"emotion_loss\": 1.5397076606750488, \"time_take\": 30.833829641342163}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.2369136810302734, \"arousal_loss\": 1.06889009475708, \"emotion_loss\": 1.3176624774932861, \"time_take\": 31.08889150619507}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 20, \"valence_loss\": 0.5947421789169312, \"arousal_loss\": 0.4883272647857666, \"emotion_loss\": 1.3004716634750366, \"time_take\": 31.289317846298218}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1196165084838867, \"arousal_loss\": 0.9686561226844788, \"emotion_loss\": 1.488154649734497, \"time_take\": 31.53326153755188}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.186267614364624, \"arousal_loss\": 1.0787780284881592, \"emotion_loss\": 1.5496225357055664, \"time_take\": 31.80396342277527}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.1028962135314941, \"arousal_loss\": 0.9521522521972656, \"emotion_loss\": 1.1434223651885986, \"time_take\": 32.02362012863159}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.8519669771194458, \"arousal_loss\": 0.7446374893188477, \"emotion_loss\": 1.6431982517242432, \"time_take\": 32.384533405303955}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.010996699333191, \"arousal_loss\": 0.9469037652015686, \"emotion_loss\": 1.718285083770752, \"time_take\": 32.646446228027344}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8811126947402954, \"arousal_loss\": 0.707674503326416, \"emotion_loss\": 1.3864145278930664, \"time_take\": 32.93781757354736}\n",
      "{\"emotion_correct\": 12, \"valence_loss\": 1.2529211044311523, \"arousal_loss\": 1.262563943862915, \"emotion_loss\": 1.8371503353118896, \"time_take\": 33.34355401992798}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.1335078477859497, \"arousal_loss\": 0.9850073456764221, \"emotion_loss\": 1.3952494859695435, \"time_take\": 33.523476362228394}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.12925124168396, \"arousal_loss\": 0.9462242126464844, \"emotion_loss\": 1.2870752811431885, \"time_take\": 33.78088688850403}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.245405673980713, \"arousal_loss\": 1.0914978981018066, \"emotion_loss\": 1.2264223098754883, \"time_take\": 34.11339783668518}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.1117593050003052, \"arousal_loss\": 0.9832345247268677, \"emotion_loss\": 1.5854874849319458, \"time_take\": 34.37679696083069}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.9536130428314209, \"arousal_loss\": 0.8720361590385437, \"emotion_loss\": 1.3000164031982422, \"time_take\": 34.66732454299927}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.03555166721344, \"arousal_loss\": 0.8225974440574646, \"emotion_loss\": 1.3548210859298706, \"time_take\": 34.95389246940613}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.4100420475006104, \"arousal_loss\": 1.336426854133606, \"emotion_loss\": 1.3659894466400146, \"time_take\": 35.18333578109741}\n",
      "{\"emotion_correct\": 11, \"valence_loss\": 0.5755568742752075, \"arousal_loss\": 0.5111654996871948, \"emotion_loss\": 1.997216820716858, \"time_take\": 35.424591302871704}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.0981098413467407, \"arousal_loss\": 0.9544480443000793, \"emotion_loss\": 1.4621682167053223, \"time_take\": 35.79366874694824}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.12486732006073, \"arousal_loss\": 1.1166725158691406, \"emotion_loss\": 1.4183462858200073, \"time_take\": 36.198174715042114}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.223372459411621, \"arousal_loss\": 1.0635035037994385, \"emotion_loss\": 1.425898551940918, \"time_take\": 36.50631785392761}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9933856725692749, \"arousal_loss\": 0.8733408451080322, \"emotion_loss\": 1.262437105178833, \"time_take\": 36.83580708503723}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0684856176376343, \"arousal_loss\": 0.9768699407577515, \"emotion_loss\": 1.6253429651260376, \"time_take\": 37.05239963531494}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9943585991859436, \"arousal_loss\": 0.8258054256439209, \"emotion_loss\": 1.2590299844741821, \"time_take\": 37.27662372589111}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0979636907577515, \"arousal_loss\": 0.9159302115440369, \"emotion_loss\": 1.2750442028045654, \"time_take\": 37.50812339782715}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.133557677268982, \"arousal_loss\": 0.9880378246307373, \"emotion_loss\": 1.2684792280197144, \"time_take\": 37.798768281936646}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8970040082931519, \"arousal_loss\": 0.8742645978927612, \"emotion_loss\": 1.2318527698516846, \"time_take\": 38.10425281524658}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.1627166271209717, \"arousal_loss\": 0.9828574657440186, \"emotion_loss\": 1.2251062393188477, \"time_take\": 38.32235598564148}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.133000135421753, \"arousal_loss\": 0.963253378868103, \"emotion_loss\": 1.6078519821166992, \"time_take\": 38.500073194503784}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9589362740516663, \"arousal_loss\": 0.8083812594413757, \"emotion_loss\": 1.4606688022613525, \"time_take\": 38.8082172870636}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.092942237854004, \"arousal_loss\": 0.9694518446922302, \"emotion_loss\": 1.845900535583496, \"time_take\": 38.96591591835022}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.280572772026062, \"arousal_loss\": 1.1169166564941406, \"emotion_loss\": 1.1964499950408936, \"time_take\": 39.26214027404785}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.5926010012626648, \"arousal_loss\": 0.34391921758651733, \"emotion_loss\": 1.5413075685501099, \"time_take\": 39.54045557975769}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.3741035461425781, \"arousal_loss\": 1.2461845874786377, \"emotion_loss\": 1.550248384475708, \"time_take\": 39.826685667037964}\n",
      "{\"emotion_correct\": 25, \"valence_loss\": 0.8328292965888977, \"arousal_loss\": 0.7097936868667603, \"emotion_loss\": 1.012345314025879, \"time_take\": 40.24921441078186}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.329341173171997, \"arousal_loss\": 1.1455739736557007, \"emotion_loss\": 1.176776647567749, \"time_take\": 40.53932476043701}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.093185305595398, \"arousal_loss\": 0.9897845387458801, \"emotion_loss\": 1.6546646356582642, \"time_take\": 40.81345224380493}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1007599830627441, \"arousal_loss\": 0.9833415746688843, \"emotion_loss\": 1.5599840879440308, \"time_take\": 41.12684226036072}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.1771491765975952, \"arousal_loss\": 1.001781940460205, \"emotion_loss\": 1.4769986867904663, \"time_take\": 41.40849757194519}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2279996871948242, \"arousal_loss\": 1.1176425218582153, \"emotion_loss\": 1.2856061458587646, \"time_take\": 41.7424852848053}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2248814105987549, \"arousal_loss\": 1.1143989562988281, \"emotion_loss\": 1.2707083225250244, \"time_take\": 41.99105501174927}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 0.6659277677536011, \"arousal_loss\": 0.5783815383911133, \"emotion_loss\": 1.420933723449707, \"time_take\": 42.27558898925781}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.3394105434417725, \"arousal_loss\": 1.2300574779510498, \"emotion_loss\": 1.259927749633789, \"time_take\": 42.555492639541626}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.2507672309875488, \"arousal_loss\": 1.2270078659057617, \"emotion_loss\": 1.8665345907211304, \"time_take\": 42.90078115463257}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.167534351348877, \"arousal_loss\": 0.9235134124755859, \"emotion_loss\": 1.1993753910064697, \"time_take\": 43.16102862358093}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 0.9209021329879761, \"arousal_loss\": 0.855796217918396, \"emotion_loss\": 1.3046735525131226, \"time_take\": 43.51203274726868}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.0286691188812256, \"arousal_loss\": 0.8172237873077393, \"emotion_loss\": 1.3788139820098877, \"time_take\": 43.78259325027466}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.712598443031311, \"arousal_loss\": 0.6018326878547668, \"emotion_loss\": 1.476036548614502, \"time_take\": 44.09858727455139}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.2023329734802246, \"arousal_loss\": 1.098831057548523, \"emotion_loss\": 1.4316548109054565, \"time_take\": 44.37110495567322}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.7637962102890015, \"arousal_loss\": 0.6426661014556885, \"emotion_loss\": 1.195271611213684, \"time_take\": 44.62073826789856}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.959892213344574, \"arousal_loss\": 0.8090410828590393, \"emotion_loss\": 1.422135829925537, \"time_take\": 44.95454502105713}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.323951244354248, \"arousal_loss\": 1.2030086517333984, \"emotion_loss\": 1.5145018100738525, \"time_take\": 45.16425943374634}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8365343809127808, \"arousal_loss\": 0.714349627494812, \"emotion_loss\": 1.2708836793899536, \"time_take\": 45.475191593170166}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0708295106887817, \"arousal_loss\": 0.9807083010673523, \"emotion_loss\": 1.6538755893707275, \"time_take\": 45.72609996795654}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.3494195938110352, \"arousal_loss\": 1.2201205492019653, \"emotion_loss\": 1.232127070426941, \"time_take\": 46.01568841934204}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 0.7703313827514648, \"arousal_loss\": 0.5751356482505798, \"emotion_loss\": 1.086447834968567, \"time_take\": 46.39025616645813}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2944364547729492, \"arousal_loss\": 1.0416874885559082, \"emotion_loss\": 1.0563983917236328, \"time_take\": 46.699623107910156}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9688553810119629, \"arousal_loss\": 0.8234134912490845, \"emotion_loss\": 1.2940974235534668, \"time_take\": 46.95645022392273}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8472476005554199, \"arousal_loss\": 0.6366068124771118, \"emotion_loss\": 1.2390143871307373, \"time_take\": 47.227752685546875}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.1789679527282715, \"arousal_loss\": 1.1019468307495117, \"emotion_loss\": 1.5133498907089233, \"time_take\": 47.445942401885986}\n",
      "{\"emotion_correct\": 21, \"valence_loss\": 1.1959443092346191, \"arousal_loss\": 0.9341928958892822, \"emotion_loss\": 1.0350978374481201, \"time_take\": 47.78540873527527}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.087275505065918, \"arousal_loss\": 0.9833213686943054, \"emotion_loss\": 0.9370043277740479, \"time_take\": 48.162147998809814}\n",
      "{\"emotion_correct\": 16, \"valence_loss\": 1.0153357982635498, \"arousal_loss\": 0.9035592079162598, \"emotion_loss\": 1.502946376800537, \"time_take\": 48.54976487159729}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.2426631450653076, \"arousal_loss\": 1.0765104293823242, \"emotion_loss\": 1.8276547193527222, \"time_take\": 48.854987382888794}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.2517285346984863, \"arousal_loss\": 1.0736738443374634, \"emotion_loss\": 1.132962703704834, \"time_take\": 49.12417435646057}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.029262661933899, \"arousal_loss\": 0.8384974002838135, \"emotion_loss\": 1.295888900756836, \"time_take\": 49.509477376937866}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8654059171676636, \"arousal_loss\": 0.6734840869903564, \"emotion_loss\": 1.3751909732818604, \"time_take\": 49.846071004867554}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.47565892338752747, \"arousal_loss\": 0.4029337167739868, \"emotion_loss\": 1.602517008781433, \"time_take\": 50.11319828033447}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.7403426170349121, \"arousal_loss\": 0.5885432362556458, \"emotion_loss\": 1.604292869567871, \"time_take\": 50.397382497787476}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.5395326614379883, \"arousal_loss\": 1.4318363666534424, \"emotion_loss\": 1.4433870315551758, \"time_take\": 50.6372504234314}\n",
      "{\"emotion_correct\": 11, \"valence_loss\": 1.5789225101470947, \"arousal_loss\": 1.418755292892456, \"emotion_loss\": 1.6043874025344849, \"time_take\": 50.873693227767944}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.9769730567932129, \"arousal_loss\": 0.8475466966629028, \"emotion_loss\": 1.4129639863967896, \"time_take\": 51.240819215774536}\n",
      "{\"emotion_correct\": 23, \"valence_loss\": 1.3627541065216064, \"arousal_loss\": 1.2098220586776733, \"emotion_loss\": 1.1826263666152954, \"time_take\": 51.56544637680054}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 0.826040506362915, \"arousal_loss\": 0.7282664179801941, \"emotion_loss\": 1.3925113677978516, \"time_take\": 51.81389832496643}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.3126038312911987, \"arousal_loss\": 1.2326229810714722, \"emotion_loss\": 1.4996118545532227, \"time_take\": 52.0632643699646}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0389478206634521, \"arousal_loss\": 0.8073948621749878, \"emotion_loss\": 1.2548446655273438, \"time_take\": 52.35883951187134}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.2777090072631836, \"arousal_loss\": 1.254730463027954, \"emotion_loss\": 1.9200433492660522, \"time_take\": 52.53275942802429}\n",
      "{\"emotion_correct\": 22, \"valence_loss\": 1.0068738460540771, \"arousal_loss\": 0.8551908731460571, \"emotion_loss\": 1.062516689300537, \"time_take\": 52.8288311958313}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.9851821660995483, \"arousal_loss\": 0.8674934506416321, \"emotion_loss\": 1.682377815246582, \"time_take\": 53.132219314575195}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.8140948414802551, \"arousal_loss\": 0.7373363971710205, \"emotion_loss\": 1.7149410247802734, \"time_take\": 53.43406939506531}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.3019652366638184, \"arousal_loss\": 1.2221271991729736, \"emotion_loss\": 1.6267783641815186, \"time_take\": 53.70218873023987}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 1.0979235172271729, \"arousal_loss\": 0.9599958658218384, \"emotion_loss\": 1.6020549535751343, \"time_take\": 54.02081060409546}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.0767853260040283, \"arousal_loss\": 0.961685299873352, \"emotion_loss\": 1.5529794692993164, \"time_take\": 54.43412113189697}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.014473795890808, \"arousal_loss\": 0.8390627503395081, \"emotion_loss\": 1.35271155834198, \"time_take\": 54.74812173843384}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.7294571399688721, \"arousal_loss\": 0.567327618598938, \"emotion_loss\": 1.5109803676605225, \"time_take\": 55.04014563560486}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.6575181484222412, \"arousal_loss\": 1.415639042854309, \"emotion_loss\": 1.1757488250732422, \"time_take\": 55.3001606464386}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.2414900064468384, \"arousal_loss\": 1.0822639465332031, \"emotion_loss\": 1.3383772373199463, \"time_take\": 55.62577795982361}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.3331996202468872, \"arousal_loss\": 1.2335536479949951, \"emotion_loss\": 1.0791897773742676, \"time_take\": 55.976731300354004}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 0.8075896501541138, \"arousal_loss\": 0.7344348430633545, \"emotion_loss\": 1.6473016738891602, \"time_take\": 56.219374895095825}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 0.8497214317321777, \"arousal_loss\": 0.7475252151489258, \"emotion_loss\": 1.2665977478027344, \"time_take\": 56.60699152946472}\n",
      "{\"emotion_correct\": 13, \"valence_loss\": 1.0471229553222656, \"arousal_loss\": 0.9610865116119385, \"emotion_loss\": 1.5365667343139648, \"time_take\": 57.16328763961792}\n",
      "{\"emotion_correct\": 24, \"valence_loss\": 1.3586732149124146, \"arousal_loss\": 1.2044358253479004, \"emotion_loss\": 0.9660952091217041, \"time_take\": 57.40417456626892}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 1.1655994653701782, \"arousal_loss\": 0.9569475650787354, \"emotion_loss\": 1.0689411163330078, \"time_take\": 57.69322943687439}\n",
      "{\"emotion_correct\": 14, \"valence_loss\": 1.1037315130233765, \"arousal_loss\": 1.0501737594604492, \"emotion_loss\": 1.5491565465927124, \"time_take\": 57.98772215843201}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9879086017608643, \"arousal_loss\": 0.8360152840614319, \"emotion_loss\": 1.5962183475494385, \"time_take\": 58.262192487716675}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 1.0106784105300903, \"arousal_loss\": 0.8377943634986877, \"emotion_loss\": 1.303513526916504, \"time_take\": 58.563559770584106}\n",
      "{\"emotion_correct\": 19, \"valence_loss\": 1.5598840713500977, \"arousal_loss\": 1.4692370891571045, \"emotion_loss\": 1.2213716506958008, \"time_take\": 58.85555148124695}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8557931184768677, \"arousal_loss\": 0.7591169476509094, \"emotion_loss\": 1.401041030883789, \"time_take\": 59.1234564781189}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.9486606121063232, \"arousal_loss\": 0.8344464302062988, \"emotion_loss\": 1.3660902976989746, \"time_take\": 59.526052713394165}\n",
      "{\"emotion_correct\": 18, \"valence_loss\": 0.8725606203079224, \"arousal_loss\": 0.7600860595703125, \"emotion_loss\": 1.3862384557724, \"time_take\": 59.796865940093994}\n",
      "{\"emotion_correct\": 15, \"valence_loss\": 0.8767881393432617, \"arousal_loss\": 0.6806399822235107, \"emotion_loss\": 1.3482139110565186, \"time_take\": 60.03749084472656}\n",
      "{\"emotion_correct\": 20, \"valence_loss\": 0.8437769412994385, \"arousal_loss\": 0.716273307800293, \"emotion_loss\": 1.2688870429992676, \"time_take\": 60.27673029899597}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 0.9669620990753174, \"arousal_loss\": 0.8483456373214722, \"emotion_loss\": 1.5236058235168457, \"time_take\": 60.51427888870239}\n",
      "{\"emotion_correct\": 17, \"valence_loss\": 1.8184516429901123, \"arousal_loss\": 1.660376787185669, \"emotion_loss\": 1.1427600383758545, \"time_take\": 60.890738010406494}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"emotion_correct\": 19, \"valence_loss\": 1.0173518657684326, \"arousal_loss\": 0.823983907699585, \"emotion_loss\": 1.3129957914352417, \"time_take\": 61.149840354919434}\n"
     ]
    }
   ],
   "source": [
    "from telegram_notifier import send_message\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_step = 0\n",
    "    total_emotion_correct = 0\n",
    "    total_valence_loss = 0\n",
    "    total_arousal_loss = 0\n",
    "    total_emotion_loss = 0\n",
    "    total_process = 0\n",
    "    for step, row in enumerate(DataFrameBatchIterator(train_df, batch_size=batch_size)):\n",
    "\n",
    "        imgs = row.subDirectory_filePath.apply(lambda x: cv2.resize(\n",
    "            cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2RGB), (224, 224)))\n",
    "        img_array = np.array(list(imgs))\n",
    "\n",
    "        y_valence = np.array(row.valence)\n",
    "        y_arousal = np.array(row.arousal)\n",
    "        y_emotion = np.array(row.expression)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(img_array, training=True)\n",
    "\n",
    "            pred_valence = logits[0]\n",
    "            pred_arousal = logits[1]\n",
    "            pred_emotion = logits[2]\n",
    "\n",
    "            valence_loss = MSE_loss(y_valence, pred_valence)\n",
    "            arousal_loss = MSE_loss(y_arousal, pred_arousal)\n",
    "            emotion_loss = SCC_loss(y_emotion, pred_emotion)\n",
    "\n",
    "            loss = valence_loss + arousal_loss + emotion_loss\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_weights)\n",
    "\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        total_loss += float(loss)\n",
    "        total_step += 1\n",
    "        \n",
    "        total_process += len(row)\n",
    "\n",
    "        valence_loss = float(valence_loss)\n",
    "        arousal_loss = float(arousal_loss)\n",
    "        emotion_loss = float(emotion_loss)\n",
    "        \n",
    "        total_valence_loss += valence_loss\n",
    "        total_arousal_loss += arousal_loss\n",
    "        total_emotion_loss += emotion_loss\n",
    "        \n",
    "        emotion_correct = int(sum(pred_emotion.numpy().argmax(axis = 1) == y_emotion))\n",
    "        total_emotion_correct += emotion_correct\n",
    "        \n",
    "        log = {\n",
    "            'emotion_correct': emotion_correct,\n",
    "            'valence_loss': valence_loss,\n",
    "            'arousal_loss': arousal_loss,\n",
    "            'emotion_loss': emotion_loss,\n",
    "            'time_take': time.time() - start_time\n",
    "        }\n",
    "        log = json.dumps(log)\n",
    "        lprint(log)\n",
    "    save_model_path = f\"models/{now_time_string}_{description}_epoch{epoch}_batch_{batch_size}\"\n",
    "    model.save(save_model_path)\n",
    "    lprint(f\"Save {save_model_path}\")\n",
    "    send_message(f\"Save {save_model_path}\\nepoch {epoch} is finish\")\n",
    "    log = {\n",
    "        'model_path': save_model_path,\n",
    "        'total_emotion_correct': total_emotion_correct,\n",
    "        'total_loss': total_loss,\n",
    "        'total_valence_loss': total_valence_loss,\n",
    "        'total_arousal_loss': total_arousal_loss,\n",
    "        'total_emotion_loss': total_emotion_loss,\n",
    "        'total_process': total_process,\n",
    "        'time_take': time.time() - start_time\n",
    "    }\n",
    "    log = json.dumps(log)\n",
    "    lprint(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "tf27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
