{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T12:50:25.876212Z",
     "start_time": "2022-01-18T12:50:25.870149Z"
    }
   },
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:20.697377Z",
     "start_time": "2022-01-21T10:38:16.073499Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#from scipy.misc import imread, imresize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:20.722815Z",
     "start_time": "2022-01-21T10:38:20.699803Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:20.736446Z",
     "start_time": "2022-01-21T10:38:20.726554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_file_name='01_21_18:38:20.log'\n"
     ]
    }
   ],
   "source": [
    "from eason_utils import DataFrameBatchIterator\n",
    "from eason_utils import lprint, now_time_string, log_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:36.577267Z",
     "start_time": "2022-01-21T10:38:26.538156Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(allow_growth = True))\n",
    "sess = tf.compat.v1.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:36.789825Z",
     "start_time": "2022-01-21T10:38:36.579397Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('../../data/Manually_Annotated_file_lists/validation_face_mesh_crop.csv')\n",
    "eval_df.subDirectory_filePath = '../../data/Manually_Annotated_Images_FaceMesh_Cropped/' + eval_df.subDirectory_filePath\n",
    "\n",
    "\n",
    "eval_df = eval_df[eval_df['have_facemesh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T03:39:48.888640Z",
     "start_time": "2022-01-20T03:39:44.861299Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:36.805898Z",
     "start_time": "2022-01-21T10:38:36.800189Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "MSE_loss = tf.keras.losses.MeanSquaredError()\n",
    "SCC_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "eval_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:36.823764Z",
     "start_time": "2022-01-21T10:38:36.812660Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_files = os.listdir(\"./models\")\n",
    "model_files.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:36.841238Z",
     "start_time": "2022-01-21T10:38:36.825951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:36.849256Z",
     "start_time": "2022-01-21T10:38:36.842765Z"
    }
   },
   "outputs": [],
   "source": [
    "model_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:36.861443Z",
     "start_time": "2022-01-21T10:38:36.851091Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_result_df = pd.read_csv('./eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:38:36.878526Z",
     "start_time": "2022-01-21T10:38:36.863238Z"
    }
   },
   "outputs": [],
   "source": [
    "model_files = list(filter(lambda x: x not in list(eval_result_df.model), model_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-21T05:46:11.683Z"
    }
   },
   "outputs": [],
   "source": [
    "model_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:40:06.122745Z",
     "start_time": "2022-01-21T10:39:57.770747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/681.5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (265838384.py, line 67)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [16]\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./models/mobilenet_from_pretrain_no_train/')\n",
    "\n",
    "total_process = 0\n",
    "start_time = time.time()\n",
    "\n",
    "total_loss = 0\n",
    "total_step = 0\n",
    "total_valence_loss = 0\n",
    "total_arousal_loss = 0\n",
    "total_emotion_loss = 0\n",
    "total_emotion_correct = 0\n",
    "for step, row in tqdm.tqdm(enumerate(DataFrameBatchIterator(eval_df, batch_size=batch_size)), total = len(eval_df) / batch_size):\n",
    "    if len(row) == 0:\n",
    "        continue\n",
    "    imgs = row.subDirectory_filePath.apply(lambda x: cv2.resize(\n",
    "        cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2RGB), (224, 224)))\n",
    "\n",
    "    img_array = np.array(list(imgs))\n",
    "\n",
    "\n",
    "    y_valence = np.array(row.valence)\n",
    "    y_arousal = np.array(row.arousal)\n",
    "    y_emotion = np.array(row.expression)\n",
    "\n",
    "\n",
    "    logits = model(img_array, training=True)\n",
    "\n",
    "    if model.output_shape != (None, 11):\n",
    "        pred_valence = logits[0]\n",
    "        pred_arousal = logits[1]\n",
    "        pred_emotion = logits[2]\n",
    "        break\n",
    "        valence_loss = MSE_loss(y_valence, pred_valence)\n",
    "        arousal_loss = MSE_loss(y_arousal, pred_arousal)\n",
    "    else:\n",
    "        valence_loss = 0\n",
    "        arousal_loss = 0\n",
    "        pred_emotion = logits\n",
    "\n",
    "\n",
    "    emotion_loss = SCC_loss(y_emotion, pred_emotion)\n",
    "\n",
    "    loss = valence_loss + arousal_loss + emotion_loss\n",
    "\n",
    "    total_loss += float(loss)\n",
    "    total_step += 1\n",
    "    total_process += len(img_array)\n",
    "\n",
    "    total_valence_loss += float(valence_loss)\n",
    "    total_arousal_loss += float(arousal_loss)\n",
    "    total_emotion_loss += float(emotion_loss)\n",
    "\n",
    "    emotion_correct = pred_emotion.numpy().argmax(axis = 1) == y_emotion\n",
    "    total_emotion_correct += sum(emotion_correct)\n",
    "\n",
    "#lprint(f\"--- {time.time() - start_time} seconds for evaluate {total_process} image ---\\n\")\n",
    "eval_logs.append({\n",
    "    'model': model_file,\n",
    "    'total_emotion_correct': total_emotion_correct,\n",
    "    'total_loss': total_loss,\n",
    "    'total_valence_loss': total_valence_loss,\n",
    "    'total_arousal_loss': total_arousal_loss,\n",
    "    'total_emotion_loss': total_emotion_loss,\n",
    "    'total_process': total_process,\n",
    "    'time_take': time.time() - start_time\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T10:39:35.022925Z",
     "start_time": "2022-01-21T10:39:34.974839Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_valence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpred_valence\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_valence' is not defined"
     ]
    }
   ],
   "source": [
    "pred_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-21T05:46:11.686Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(eval_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-20T11:22:57.968975Z",
     "start_time": "2022-01-20T11:22:57.962653Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "tf27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
